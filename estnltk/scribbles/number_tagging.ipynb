{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tagging tokens on text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To use a grammar for information extraction, we first need to split the text into some kind of tokens that serve as terminal symbols in our grammar. These tokens do not need to overlap with words - they can be whole words, but also parts of words or consist of multiple words. \n",
    "\n",
    "To tag the tokens on text, we can use RegexTagger. Its full tutorial can be found from [here](https://github.com/estnltk/estnltk/blob/devel_1.6/tutorials/raw_text_taggers/regex_tagger.ipynb), but let's look at an example here as well. \n",
    "\n",
    "Let's use the following sentences as an example corpus:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "lines = ['PSA 03042012 - 0,83ng/ml perearsti poolt .',\n",
    " 'PSA 2010. 3ng/ml, PSA 2012. 1,53ng/ml . - Bx va',\n",
    " 'PSA 20105,99 ja 26.01.2012 uuesti .',\n",
    " 'PSA 2011 oli 0 , 4 nG7ml .',\n",
    " 'PSA 201222,25ng/ml',\n",
    " 'PSA 2 aastajooksuldünaamikata , eriuuring',\n",
    " ':psa 16,81! ! ! ! ! ,',\n",
    " 'Happe-aluse tasakaal 6.0 ( 5.0 .. 8.0 )',\n",
    " 'loli 25 mgx1 ja Monoprili 10 mg Kolesterool 2011a',\n",
    " 'Kolesterool 1k aastas .',\n",
    " 'Kõrgenenud kolesterool 2a ( mõõdetud ). Ei pea dieetist kinni',\n",
    " 'Kontr Verekol 08.12a Per-le juurde .',\n",
    " 's vas munajuha kasvaja op , günekol 3a tagssi .',\n",
    " '08.11.2010 PSA 13.12.2011 7,2ng/ml PSADT on väike .',\n",
    " 'Rütmihäire tsüklipikkus 330 msek',\n",
    " 'Loote pikkus : \\xa0 3 mm - vastab\\xa0 5 nädalat 6 päeva.',\n",
    " 'Põhjendus: PALAT 10 # ALAT maksanäitaja',\n",
    " 'ärme vähk 2007 aastast cT3N0M0PSA 59ng/ml .',\n",
    " 'PSA 8,5( püsib aastaid selles väärtus',\n",
    " 'S , P-PSA 4.130( <4.100 µg/L )',\n",
    " 'PSA 5,2.',\n",
    " 'Kolesterool oli 7,9 mmol/l 0',\n",
    " 'kolesterool 6.4.',\n",
    " 'Kolesterool 5,2 mmol/l - esialgu dieet .',\n",
    " 'SK 3900 g , SP 51 cm .',\n",
    " 'Lapse kaal 5,4 kg/82 mg/0,82 ml i/m .',\n",
    " 'Kehakaal 80,2 kg , KMI 25,9',\n",
    " 'S , P-NT-proBNP 668 ( <125 pg/mL ) S , P-Albumiin 43 ( 35 .. 52 g/L ) S , P-ALAT 25 ( <33 U/L )',\n",
    " 'PSA 6,5 ng/ml, eesnäärme maht67cm3',\n",
    " 'rjeldus : Siinusbradükardia Fr 587min']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assuming that we want to extract the measurements from the texts, we have to decide what kind of tokens we would need to define for that. As there are different measurements in the sentences (PSA, cholesterol, etc), we will need to find the **measurement object**. Of course we need the measurement itself which is expressed as a **number**. However, not every number following a measurement object is actually a measurement. If we look at the examples above, we can define the following ways to deal with these problems:\n",
    "\n",
    "1) A **number** following a **measurement object** that does not express this measurement: we can also extract **units** and check whether the unit and measurement object are in agreement (e.g \"Kõrgenenud kolesterool 2a\" - cholesterol is not 2 because 'a' is not a unit that can measure cholesterol but signifies time. \n",
    "\n",
    "2) **Dates** right after the measurement objects in texts: we should also tag **dates** in addition to **numbers**. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, we should define the appropriate regular expressions for all the symbols mentioned. We can do this in a csv file where we can also describe different attributes that we want to add to the tagged tokens. Let's have a look at an example file written for the sentences above:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, as we can see from the examples, tagging dates and numbers is not a trivial task: sometimes there is a space inside the number before and/or after the decimal separator, in other cases, there is no space between a date and a number expressing a measurement. To deal with the latter cases, we will add another symbol type **datenum** because these are the only cases where we want to allow a digit to be directly before a **number** (as it is part of the date). \n",
    "\n",
    "Let's look at the regexes defined for the examples file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas import read_csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabulary = read_csv(\"regexes_fixed.csv\", na_filter=False, index_col=False, encoding = 'utf8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_regex_pattern_</th>\n",
       "      <th>_group_</th>\n",
       "      <th>_priority_</th>\n",
       "      <th>normalized</th>\n",
       "      <th>regex_type</th>\n",
       "      <th>value</th>\n",
       "      <th>grammar_symbol</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>((K|k)olesteroo?l|KOLESTEROOL|(K|k)olester|Cho...</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td></td>\n",
       "      <td>measurement_object</td>\n",
       "      <td>kolesterool</td>\n",
       "      <td>MO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(((S|s)iinus)?r.tm(iline|ilised)?|[Ff]rekv?(en...</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td></td>\n",
       "      <td>measurement_object</td>\n",
       "      <td>pulss</td>\n",
       "      <td>MO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>((([Ss]ünni)|([Kk]eha))?(p|P)ikkus|PIKKUS|pikk...</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td></td>\n",
       "      <td>measurement_object</td>\n",
       "      <td>pikkus</td>\n",
       "      <td>MO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(psa|Psa|S-PSA|[Pp]rostataspetsiifiline\\s*anti...</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td></td>\n",
       "      <td>measurement_object</td>\n",
       "      <td>psa</td>\n",
       "      <td>MO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>((((K|k)eha)|((S|s)ünni))?(K|k)aal(uga)?|kAAL|...</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td></td>\n",
       "      <td>measurement_object</td>\n",
       "      <td>kaal</td>\n",
       "      <td>MO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ALAT</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td></td>\n",
       "      <td>measurement_object</td>\n",
       "      <td>alat</td>\n",
       "      <td>MO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>(ng/mL|ng/L|mk(ro)?g/[Ll]|ng/\\s*ml|ng7ml|mg/ml...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td>psa_unit</td>\n",
       "      <td>lambda m: re.search('(ng/mL|ng/L|mk(ro)?g/[Ll]...</td>\n",
       "      <td>UNIT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>(a[. ]|k[. ]|aasta|kuu|nädal|[Xx]|kord|min|mse...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td>time_unit</td>\n",
       "      <td>x</td>\n",
       "      <td>UNIT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>((mmoo?l?i?|mm|MMOL|mol)(\\s*[-/]\\s*(L|l))?|MMO...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td>chol_unit</td>\n",
       "      <td>x</td>\n",
       "      <td>UNIT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>(((l|x|X|lööki))\\s*/?\\s*(1\\s*)?min(utis)?)|/mi...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td>pulss_unit</td>\n",
       "      <td>x</td>\n",
       "      <td>UNIT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>U/L</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td>alat_unit</td>\n",
       "      <td>x</td>\n",
       "      <td>UNIT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>(cm|Cm|sm|SM|CM|m)</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td>pikkus_unit</td>\n",
       "      <td>x</td>\n",
       "      <td>UNIT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>(gramm|kg|mg|kG|gr|g|KG|G)</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td>kaal_unit</td>\n",
       "      <td>x</td>\n",
       "      <td>UNIT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>(^|[^0-9,.])([0-9]+(\\s?[,.]\\s?[0-9]+)?)</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td>anynumber</td>\n",
       "      <td>lambda m: re.sub('\\s?[.,]\\s?' ,'.' , m.group(2))</td>\n",
       "      <td>NUMBER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>(^|[^0-9,.])([0-9]+)</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td></td>\n",
       "      <td>int</td>\n",
       "      <td>some_int</td>\n",
       "      <td>NUMBER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>\\s[,.][0-9]+</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td>commanumber</td>\n",
       "      <td>why</td>\n",
       "      <td>NUMBER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>(^|[^0-9,.])([0-9]+\\s?[,.]\\s)</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td>numbercomma</td>\n",
       "      <td>why</td>\n",
       "      <td>NUMBER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>((19[0-9]{2})|(20[0-9]{2}))[.]?([0-9]+(\\s?[,.]...</td>\n",
       "      <td>4</td>\n",
       "      <td>-2</td>\n",
       "      <td></td>\n",
       "      <td>datenum</td>\n",
       "      <td>date_and_num</td>\n",
       "      <td>DATENUM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>PALAT</td>\n",
       "      <td>0</td>\n",
       "      <td>-2</td>\n",
       "      <td></td>\n",
       "      <td>rubbish</td>\n",
       "      <td>whatever</td>\n",
       "      <td>RUBBISH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>(([Tt]asa|[Ee]ri|[Oo]sa)kaal[-.: ]*)</td>\n",
       "      <td>0</td>\n",
       "      <td>-2</td>\n",
       "      <td></td>\n",
       "      <td>rubbish</td>\n",
       "      <td>kaal_trash</td>\n",
       "      <td>RUBBISH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>(mg|mkg|tsentiil|prts|(pro)?tsentiil|pt|mm)($|...</td>\n",
       "      <td>0</td>\n",
       "      <td>-2</td>\n",
       "      <td></td>\n",
       "      <td>rubbish</td>\n",
       "      <td>not_pikkus_unit</td>\n",
       "      <td>UNIT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>k(el)?l\\s(?P&lt;hour&gt;[0-2][0-9])[.:](?P&lt;minute&gt;[0...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td></td>\n",
       "      <td>date1</td>\n",
       "      <td>time</td>\n",
       "      <td>DATE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>(?P&lt;DAY&gt;(0?[1-9]|[12][0-9]|3[01]))\\.?\\s*(?P&lt;MO...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td></td>\n",
       "      <td>date2</td>\n",
       "      <td>date_time</td>\n",
       "      <td>DATE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>(?P&lt;DAY&gt;(0?[1-9]|[12][0-9]|3[01]))\\.?\\s*(?P&lt;MO...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td></td>\n",
       "      <td>date3</td>\n",
       "      <td>date_time</td>\n",
       "      <td>DATE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>(?P&lt;DAY&gt;(0[1-9]|[12][0-9]|3[01]))\\.?\\s*(?P&lt;MON...</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td></td>\n",
       "      <td>date4</td>\n",
       "      <td>date</td>\n",
       "      <td>DATE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>(?P&lt;DAY&gt;(0?[1-9]|[12][0-9]|3[01]))\\.\\s?(?P&lt;MON...</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td></td>\n",
       "      <td>date5</td>\n",
       "      <td>partial_date</td>\n",
       "      <td>DATE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>(?P&lt;MONTH&gt;(0?[1-9]|1[0-2]))\\.\\s?(?P&lt;LONGYEAR&gt;(...</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td></td>\n",
       "      <td>date6</td>\n",
       "      <td>partial_date</td>\n",
       "      <td>DATE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>(?P&lt;DAY&gt;(0?[1-9]|[12][0-9]|3[01]))\\.\\s?(?P&lt;MON...</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td></td>\n",
       "      <td>date7</td>\n",
       "      <td>partial_date</td>\n",
       "      <td>DATE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>(?P&lt;LONGYEAR&gt;((19[0-9]{2})|(20[0-9]{2})))\\s*a</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>date8</td>\n",
       "      <td>partial_date</td>\n",
       "      <td>DATE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>(?P&lt;LONGYEAR&gt;((19[0-9]{2})|(20[0-9]{2})))</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>date9</td>\n",
       "      <td>partial_date</td>\n",
       "      <td>DATE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>[-=.&gt;&lt; ]*</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td>space</td>\n",
       "      <td>space</td>\n",
       "      <td>SPACE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>\\.?\\s*-?\\s*</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td>space</td>\n",
       "      <td>space</td>\n",
       "      <td>SPACE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>[-=.&gt;&lt; ]*(on|oli)\\s*</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td>space</td>\n",
       "      <td>space</td>\n",
       "      <td>SPACE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>\\s*-?:?\\s*\\&lt;?</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td>space</td>\n",
       "      <td>space</td>\n",
       "      <td>SPACE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>\\s*</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td>space</td>\n",
       "      <td>space</td>\n",
       "      <td>SPACE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      _regex_pattern_  _group_  _priority_  \\\n",
       "0   ((K|k)olesteroo?l|KOLESTEROOL|(K|k)olester|Cho...        0          -1   \n",
       "1   (((S|s)iinus)?r.tm(iline|ilised)?|[Ff]rekv?(en...        0          -1   \n",
       "2   ((([Ss]ünni)|([Kk]eha))?(p|P)ikkus|PIKKUS|pikk...        0          -1   \n",
       "3   (psa|Psa|S-PSA|[Pp]rostataspetsiifiline\\s*anti...        0          -1   \n",
       "4   ((((K|k)eha)|((S|s)ünni))?(K|k)aal(uga)?|kAAL|...        0          -1   \n",
       "5                                                ALAT        0          -1   \n",
       "6   (ng/mL|ng/L|mk(ro)?g/[Ll]|ng/\\s*ml|ng7ml|mg/ml...        0           1   \n",
       "7   (a[. ]|k[. ]|aasta|kuu|nädal|[Xx]|kord|min|mse...        0           1   \n",
       "8   ((mmoo?l?i?|mm|MMOL|mol)(\\s*[-/]\\s*(L|l))?|MMO...        0           1   \n",
       "9   (((l|x|X|lööki))\\s*/?\\s*(1\\s*)?min(utis)?)|/mi...        0           1   \n",
       "10                                                U/L        0           1   \n",
       "11                                 (cm|Cm|sm|SM|CM|m)        0           1   \n",
       "12                         (gramm|kg|mg|kG|gr|g|KG|G)        0           1   \n",
       "13            (^|[^0-9,.])([0-9]+(\\s?[,.]\\s?[0-9]+)?)        2           1   \n",
       "14                               (^|[^0-9,.])([0-9]+)        2           2   \n",
       "15                                       \\s[,.][0-9]+        0           1   \n",
       "16                      (^|[^0-9,.])([0-9]+\\s?[,.]\\s)        2           1   \n",
       "17  ((19[0-9]{2})|(20[0-9]{2}))[.]?([0-9]+(\\s?[,.]...        4          -2   \n",
       "18                                              PALAT        0          -2   \n",
       "19               (([Tt]asa|[Ee]ri|[Oo]sa)kaal[-.: ]*)        0          -2   \n",
       "20  (mg|mkg|tsentiil|prts|(pro)?tsentiil|pt|mm)($|...        0          -2   \n",
       "21  k(el)?l\\s(?P<hour>[0-2][0-9])[.:](?P<minute>[0...        0           2   \n",
       "22  (?P<DAY>(0?[1-9]|[12][0-9]|3[01]))\\.?\\s*(?P<MO...        0           2   \n",
       "23  (?P<DAY>(0?[1-9]|[12][0-9]|3[01]))\\.?\\s*(?P<MO...        0           2   \n",
       "24  (?P<DAY>(0[1-9]|[12][0-9]|3[01]))\\.?\\s*(?P<MON...        0          -1   \n",
       "25  (?P<DAY>(0?[1-9]|[12][0-9]|3[01]))\\.\\s?(?P<MON...        0           3   \n",
       "26  (?P<MONTH>(0?[1-9]|1[0-2]))\\.\\s?(?P<LONGYEAR>(...        0           3   \n",
       "27  (?P<DAY>(0?[1-9]|[12][0-9]|3[01]))\\.\\s?(?P<MON...        0           3   \n",
       "28      (?P<LONGYEAR>((19[0-9]{2})|(20[0-9]{2})))\\s*a        0           0   \n",
       "29          (?P<LONGYEAR>((19[0-9]{2})|(20[0-9]{2})))        0           0   \n",
       "30                                          [-=.>< ]*        0           1   \n",
       "31                                        \\.?\\s*-?\\s*        0           1   \n",
       "32                               [-=.>< ]*(on|oli)\\s*        0           1   \n",
       "33                                      \\s*-?:?\\s*\\<?        0           1   \n",
       "34                                                \\s*        0           1   \n",
       "\n",
       "   normalized          regex_type  \\\n",
       "0              measurement_object   \n",
       "1              measurement_object   \n",
       "2              measurement_object   \n",
       "3              measurement_object   \n",
       "4              measurement_object   \n",
       "5              measurement_object   \n",
       "6                        psa_unit   \n",
       "7                       time_unit   \n",
       "8                       chol_unit   \n",
       "9                      pulss_unit   \n",
       "10                      alat_unit   \n",
       "11                    pikkus_unit   \n",
       "12                      kaal_unit   \n",
       "13                      anynumber   \n",
       "14                            int   \n",
       "15                    commanumber   \n",
       "16                    numbercomma   \n",
       "17                        datenum   \n",
       "18                        rubbish   \n",
       "19                        rubbish   \n",
       "20                        rubbish   \n",
       "21                          date1   \n",
       "22                          date2   \n",
       "23                          date3   \n",
       "24                          date4   \n",
       "25                          date5   \n",
       "26                          date6   \n",
       "27                          date7   \n",
       "28                          date8   \n",
       "29                          date9   \n",
       "30                          space   \n",
       "31                          space   \n",
       "32                          space   \n",
       "33                          space   \n",
       "34                          space   \n",
       "\n",
       "                                                value grammar_symbol  \n",
       "0                                         kolesterool             MO  \n",
       "1                                               pulss             MO  \n",
       "2                                              pikkus             MO  \n",
       "3                                                 psa             MO  \n",
       "4                                                kaal             MO  \n",
       "5                                                alat             MO  \n",
       "6   lambda m: re.search('(ng/mL|ng/L|mk(ro)?g/[Ll]...           UNIT  \n",
       "7                                                   x           UNIT  \n",
       "8                                                   x           UNIT  \n",
       "9                                                   x           UNIT  \n",
       "10                                                  x           UNIT  \n",
       "11                                                  x           UNIT  \n",
       "12                                                  x           UNIT  \n",
       "13   lambda m: re.sub('\\s?[.,]\\s?' ,'.' , m.group(2))         NUMBER  \n",
       "14                                           some_int         NUMBER  \n",
       "15                                                why         NUMBER  \n",
       "16                                                why         NUMBER  \n",
       "17                                       date_and_num        DATENUM  \n",
       "18                                           whatever        RUBBISH  \n",
       "19                                         kaal_trash        RUBBISH  \n",
       "20                                    not_pikkus_unit           UNIT  \n",
       "21                                               time           DATE  \n",
       "22                                          date_time           DATE  \n",
       "23                                          date_time           DATE  \n",
       "24                                               date           DATE  \n",
       "25                                       partial_date           DATE  \n",
       "26                                       partial_date           DATE  \n",
       "27                                       partial_date           DATE  \n",
       "28                                       partial_date           DATE  \n",
       "29                                       partial_date           DATE  \n",
       "30                                              space          SPACE  \n",
       "31                                              space          SPACE  \n",
       "32                                              space          SPACE  \n",
       "33                                              space          SPACE  \n",
       "34                                              space          SPACE  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocabulary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Of course, as can be seen from the table *vocabulary*, we can have multiple regular expressions to define one token type or symbol in our grammar, e.g. there are 6 different measurement objects currently that all have different values added to them as an attribute, but also 5 regular expressions for dates which all have *partial_date* as their value. \n",
    "\n",
    "In addition to the *value* attribute that will help us understand which symbols make up a measurement together in the grammar (e.g. psa and psa_unit are compatible), there are also the columns _priority_ and _group_. _priority_ allows us to define which regular expression should be matched on the text if several regexes would match the same character(s). _group_ defines the the regex match group that should be extracted."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we should define the RegexTagger(s) to tag the example sentences with the symbols. To keep things easy, let's make only one RegexTagger that tags all the symbols and adds them the attributes from the _vocabulary_ file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from estnltk.taggers import RegexTagger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "regex_tagger = RegexTagger(vocabulary=vocabulary[:30],\n",
    "                                    attributes=['regex_type', 'value', 'grammar_symbol'],\n",
    "                                    conflict_resolving_strategy='ALL',\n",
    "                                    overlapped=True,\n",
    "                                    layer_name='type')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h4>Tagger</h4>\n",
       "Tags regular expression matches on the text.\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>name</th>\n",
       "      <th>layer</th>\n",
       "      <th>attributes</th>\n",
       "      <th>depends_on</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>RegexTagger</td>\n",
       "      <td>type</td>\n",
       "      <td>[regex_type, value, grammar_symbol]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<h4>Configuration</h4>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>conflict_resolving_strategy</th>\n",
       "      <td>ALL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>overlapped</th>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "RegexTagger(conflict_resolving_strategy=ALL, overlapped=True)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regex_tagger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'_group_': 0,\n",
       "  '_priority_': -1,\n",
       "  '_regex_pattern_': regex.Regex('((K|k)olesteroo?l|KOLESTEROOL|(K|k)olester|Chol|(K|k)olest?|kol|chol|CHol|CHL|KOL|Kol|cHOL|CHOL|ÜK|ük|Ük)', flags=regex.V0),\n",
       "  '_validator_': <function estnltk.taggers.raw_text_tagging.regex_tagger.RegexTagger._read_expression_vocabulary.<locals>.<lambda>>,\n",
       "  'grammar_symbol': 'MO',\n",
       "  'regex_type': 'measurement_object',\n",
       "  'value': 'kolesterool'},\n",
       " {'_group_': 0,\n",
       "  '_priority_': -1,\n",
       "  '_regex_pattern_': regex.Regex('(((S|s)iinus)?r.tm(iline|ilised)?|[Ff]rekv?(ents)?|fr\\\\.?|Fr|BPM|bpm|SR|SLS|FR|HR|(P|p)ulss(i)?|Ps)(\\\\s*[xX]\\\\s*)?', flags=regex.V0),\n",
       "  '_validator_': <function estnltk.taggers.raw_text_tagging.regex_tagger.RegexTagger._read_expression_vocabulary.<locals>.<lambda>>,\n",
       "  'grammar_symbol': 'MO',\n",
       "  'regex_type': 'measurement_object',\n",
       "  'value': 'pulss'},\n",
       " {'_group_': 0,\n",
       "  '_priority_': -1,\n",
       "  '_regex_pattern_': regex.Regex('((([Ss]ünni)|([Kk]eha))?(p|P)ikkus|PIKKUS|pikkusega|[^A-Z]SP|sp|pikk|kasv|Kasv)', flags=regex.V0),\n",
       "  '_validator_': <function estnltk.taggers.raw_text_tagging.regex_tagger.RegexTagger._read_expression_vocabulary.<locals>.<lambda>>,\n",
       "  'grammar_symbol': 'MO',\n",
       "  'regex_type': 'measurement_object',\n",
       "  'value': 'pikkus'},\n",
       " {'_group_': 0,\n",
       "  '_priority_': -1,\n",
       "  '_regex_pattern_': regex.Regex('(psa|Psa|S-PSA|[Pp]rostataspetsiifiline\\\\s*antigeen(\\\\s*seerumis)?|PSA|(S\\\\s*,\\\\s*P-)?(\\\\s*PSA))', flags=regex.V0),\n",
       "  '_validator_': <function estnltk.taggers.raw_text_tagging.regex_tagger.RegexTagger._read_expression_vocabulary.<locals>.<lambda>>,\n",
       "  'grammar_symbol': 'MO',\n",
       "  'regex_type': 'measurement_object',\n",
       "  'value': 'psa'},\n",
       " {'_group_': 0,\n",
       "  '_priority_': -1,\n",
       "  '_regex_pattern_': regex.Regex('((((K|k)eha)|((S|s)ünni))?(K|k)aal(uga)?|kAAL|SK|Sk|[^a-z]sk|KAAL|SM|[Ss]/k|(K|k)aalu(ga|nud|b|s))', flags=regex.V0),\n",
       "  '_validator_': <function estnltk.taggers.raw_text_tagging.regex_tagger.RegexTagger._read_expression_vocabulary.<locals>.<lambda>>,\n",
       "  'grammar_symbol': 'MO',\n",
       "  'regex_type': 'measurement_object',\n",
       "  'value': 'kaal'},\n",
       " {'_group_': 0,\n",
       "  '_priority_': -1,\n",
       "  '_regex_pattern_': regex.Regex('ALAT', flags=regex.V0),\n",
       "  '_validator_': <function estnltk.taggers.raw_text_tagging.regex_tagger.RegexTagger._read_expression_vocabulary.<locals>.<lambda>>,\n",
       "  'grammar_symbol': 'MO',\n",
       "  'regex_type': 'measurement_object',\n",
       "  'value': 'alat'},\n",
       " {'_group_': 0,\n",
       "  '_priority_': 1,\n",
       "  '_regex_pattern_': regex.Regex('(ng/mL|ng/L|mk(ro)?g/[Ll]|ng/\\\\s*ml|ng7ml|mg/ml|ng\\\\\\\\ml|ng/l|ug/L|ngIml|µg/L|mcg/L|ng/mg)', flags=regex.V0),\n",
       "  '_validator_': <function estnltk.taggers.raw_text_tagging.regex_tagger.RegexTagger._read_expression_vocabulary.<locals>.<lambda>>,\n",
       "  'grammar_symbol': 'UNIT',\n",
       "  'regex_type': 'psa_unit',\n",
       "  'value': <function estnltk.taggers.raw_text_tagging.regex_tagger.<lambda>>},\n",
       " {'_group_': 0,\n",
       "  '_priority_': 1,\n",
       "  '_regex_pattern_': regex.Regex('(a[. ]|k[. ]|aasta|kuu|nädal|[Xx]|kord|min|msek|ms|)', flags=regex.V0),\n",
       "  '_validator_': <function estnltk.taggers.raw_text_tagging.regex_tagger.RegexTagger._read_expression_vocabulary.<locals>.<lambda>>,\n",
       "  'grammar_symbol': 'UNIT',\n",
       "  'regex_type': 'time_unit',\n",
       "  'value': 'x'},\n",
       " {'_group_': 0,\n",
       "  '_priority_': 1,\n",
       "  '_regex_pattern_': regex.Regex('((mmoo?l?i?|mm|MMOL|mol)(\\\\s*[-/]\\\\s*(L|l))?|MMOL/L)', flags=regex.V0),\n",
       "  '_validator_': <function estnltk.taggers.raw_text_tagging.regex_tagger.RegexTagger._read_expression_vocabulary.<locals>.<lambda>>,\n",
       "  'grammar_symbol': 'UNIT',\n",
       "  'regex_type': 'chol_unit',\n",
       "  'value': 'x'},\n",
       " {'_group_': 0,\n",
       "  '_priority_': 1,\n",
       "  '_regex_pattern_': regex.Regex(\"(((l|x|X|lööki))\\\\s*/?\\\\s*(1\\\\s*)?min(utis)?)|/min|x[\\\\'´`]|bpm|BPM\", flags=regex.V0),\n",
       "  '_validator_': <function estnltk.taggers.raw_text_tagging.regex_tagger.RegexTagger._read_expression_vocabulary.<locals>.<lambda>>,\n",
       "  'grammar_symbol': 'UNIT',\n",
       "  'regex_type': 'pulss_unit',\n",
       "  'value': 'x'},\n",
       " {'_group_': 0,\n",
       "  '_priority_': 1,\n",
       "  '_regex_pattern_': regex.Regex('U/L', flags=regex.V0),\n",
       "  '_validator_': <function estnltk.taggers.raw_text_tagging.regex_tagger.RegexTagger._read_expression_vocabulary.<locals>.<lambda>>,\n",
       "  'grammar_symbol': 'UNIT',\n",
       "  'regex_type': 'alat_unit',\n",
       "  'value': 'x'},\n",
       " {'_group_': 0,\n",
       "  '_priority_': 1,\n",
       "  '_regex_pattern_': regex.Regex('(cm|Cm|sm|SM|CM|m)', flags=regex.V0),\n",
       "  '_validator_': <function estnltk.taggers.raw_text_tagging.regex_tagger.RegexTagger._read_expression_vocabulary.<locals>.<lambda>>,\n",
       "  'grammar_symbol': 'UNIT',\n",
       "  'regex_type': 'pikkus_unit',\n",
       "  'value': 'x'},\n",
       " {'_group_': 0,\n",
       "  '_priority_': 1,\n",
       "  '_regex_pattern_': regex.Regex('(gramm|kg|mg|kG|gr|g|KG|G)', flags=regex.V0),\n",
       "  '_validator_': <function estnltk.taggers.raw_text_tagging.regex_tagger.RegexTagger._read_expression_vocabulary.<locals>.<lambda>>,\n",
       "  'grammar_symbol': 'UNIT',\n",
       "  'regex_type': 'kaal_unit',\n",
       "  'value': 'x'},\n",
       " {'_group_': 2,\n",
       "  '_priority_': 1,\n",
       "  '_regex_pattern_': regex.Regex('(^|[^0-9,.])([0-9]+(\\\\s?[,.]\\\\s?[0-9]+)?)', flags=regex.V0),\n",
       "  '_validator_': <function estnltk.taggers.raw_text_tagging.regex_tagger.RegexTagger._read_expression_vocabulary.<locals>.<lambda>>,\n",
       "  'grammar_symbol': 'NUMBER',\n",
       "  'regex_type': 'anynumber',\n",
       "  'value': <function estnltk.taggers.raw_text_tagging.regex_tagger.<lambda>>},\n",
       " {'_group_': 2,\n",
       "  '_priority_': 2,\n",
       "  '_regex_pattern_': regex.Regex('(^|[^0-9,.])([0-9]+)', flags=regex.V0),\n",
       "  '_validator_': <function estnltk.taggers.raw_text_tagging.regex_tagger.RegexTagger._read_expression_vocabulary.<locals>.<lambda>>,\n",
       "  'grammar_symbol': 'NUMBER',\n",
       "  'regex_type': 'int',\n",
       "  'value': 'some_int'},\n",
       " {'_group_': 0,\n",
       "  '_priority_': 1,\n",
       "  '_regex_pattern_': regex.Regex('\\\\s[,.][0-9]+', flags=regex.V0),\n",
       "  '_validator_': <function estnltk.taggers.raw_text_tagging.regex_tagger.RegexTagger._read_expression_vocabulary.<locals>.<lambda>>,\n",
       "  'grammar_symbol': 'NUMBER',\n",
       "  'regex_type': 'commanumber',\n",
       "  'value': 'why'},\n",
       " {'_group_': 2,\n",
       "  '_priority_': 1,\n",
       "  '_regex_pattern_': regex.Regex('(^|[^0-9,.])([0-9]+\\\\s?[,.]\\\\s)', flags=regex.V0),\n",
       "  '_validator_': <function estnltk.taggers.raw_text_tagging.regex_tagger.RegexTagger._read_expression_vocabulary.<locals>.<lambda>>,\n",
       "  'grammar_symbol': 'NUMBER',\n",
       "  'regex_type': 'numbercomma',\n",
       "  'value': 'why'},\n",
       " {'_group_': 4,\n",
       "  '_priority_': -2,\n",
       "  '_regex_pattern_': regex.Regex('((19[0-9]{2})|(20[0-9]{2}))[.]?([0-9]+(\\\\s?[,.]\\\\s?[0-9]+)?)', flags=regex.V0),\n",
       "  '_validator_': <function estnltk.taggers.raw_text_tagging.regex_tagger.RegexTagger._read_expression_vocabulary.<locals>.<lambda>>,\n",
       "  'grammar_symbol': 'DATENUM',\n",
       "  'regex_type': 'datenum',\n",
       "  'value': 'date_and_num'},\n",
       " {'_group_': 0,\n",
       "  '_priority_': -2,\n",
       "  '_regex_pattern_': regex.Regex('PALAT', flags=regex.V0),\n",
       "  '_validator_': <function estnltk.taggers.raw_text_tagging.regex_tagger.RegexTagger._read_expression_vocabulary.<locals>.<lambda>>,\n",
       "  'grammar_symbol': 'RUBBISH',\n",
       "  'regex_type': 'rubbish',\n",
       "  'value': 'whatever'},\n",
       " {'_group_': 0,\n",
       "  '_priority_': -2,\n",
       "  '_regex_pattern_': regex.Regex('(([Tt]asa|[Ee]ri|[Oo]sa)kaal[-.: ]*)', flags=regex.V0),\n",
       "  '_validator_': <function estnltk.taggers.raw_text_tagging.regex_tagger.RegexTagger._read_expression_vocabulary.<locals>.<lambda>>,\n",
       "  'grammar_symbol': 'RUBBISH',\n",
       "  'regex_type': 'rubbish',\n",
       "  'value': 'kaal_trash'},\n",
       " {'_group_': 0,\n",
       "  '_priority_': -2,\n",
       "  '_regex_pattern_': regex.Regex('(mg|mkg|tsentiil|prts|(pro)?tsentiil|pt|mm)($|[^a-zA-Z]])', flags=regex.V0),\n",
       "  '_validator_': <function estnltk.taggers.raw_text_tagging.regex_tagger.RegexTagger._read_expression_vocabulary.<locals>.<lambda>>,\n",
       "  'grammar_symbol': 'UNIT',\n",
       "  'regex_type': 'rubbish',\n",
       "  'value': 'not_pikkus_unit'},\n",
       " {'_group_': 0,\n",
       "  '_priority_': 2,\n",
       "  '_regex_pattern_': regex.Regex('k(el)?l\\\\s(?P<hour>[0-2][0-9])[.:](?P<minute>[0-5][0-9])(:(?P<second>[0-5][0-9]))?', flags=regex.V0),\n",
       "  '_validator_': <function estnltk.taggers.raw_text_tagging.regex_tagger.RegexTagger._read_expression_vocabulary.<locals>.<lambda>>,\n",
       "  'grammar_symbol': 'DATE',\n",
       "  'regex_type': 'date1',\n",
       "  'value': 'time'},\n",
       " {'_group_': 0,\n",
       "  '_priority_': 2,\n",
       "  '_regex_pattern_': regex.Regex('(?P<DAY>(0?[1-9]|[12][0-9]|3[01]))\\\\.?\\\\s*(?P<MONTH>(0?[1-9]|1[0-2]))\\\\.?\\\\s*(?P<YEAR>((19[0-9]{2})|(20[0-9]{2})|([0-9]{2})))\\\\s*(?P<hour>[0-2][0-9])[.:](?P<minute>[0-5][0-9])(:(?P<second>[0-5][0-9]))?', flags=regex.V0),\n",
       "  '_validator_': <function estnltk.taggers.raw_text_tagging.regex_tagger.RegexTagger._read_expression_vocabulary.<locals>.<lambda>>,\n",
       "  'grammar_symbol': 'DATE',\n",
       "  'regex_type': 'date2',\n",
       "  'value': 'date_time'},\n",
       " {'_group_': 0,\n",
       "  '_priority_': 2,\n",
       "  '_regex_pattern_': regex.Regex('(?P<DAY>(0?[1-9]|[12][0-9]|3[01]))\\\\.?\\\\s*(?P<MONTH>(0?[1-9]|1[0-2]))\\\\.?\\\\s*(?P<YEAR>((19[0-9]{2})|(20[0-9]{2})|([0-9]{2})))[.a ]+\\\\s*k(el)?l\\\\.*\\\\s*(?P<hour>[0-2][0-9])[.:](?P<minute>[0-5][0-9])(:(?P<second>[0-5][0-9]))?', flags=regex.V0),\n",
       "  '_validator_': <function estnltk.taggers.raw_text_tagging.regex_tagger.RegexTagger._read_expression_vocabulary.<locals>.<lambda>>,\n",
       "  'grammar_symbol': 'DATE',\n",
       "  'regex_type': 'date3',\n",
       "  'value': 'date_time'},\n",
       " {'_group_': 0,\n",
       "  '_priority_': -1,\n",
       "  '_regex_pattern_': regex.Regex('(?P<DAY>(0[1-9]|[12][0-9]|3[01]))\\\\.?\\\\s*(?P<MONTH>(0[1-9]|1[0-2]))\\\\.?\\\\s*(?P<YEAR>((19[0-9]{2})|(20[0-9]{2})|([0-9]{2})))', flags=regex.V0),\n",
       "  '_validator_': <function estnltk.taggers.raw_text_tagging.regex_tagger.RegexTagger._read_expression_vocabulary.<locals>.<lambda>>,\n",
       "  'grammar_symbol': 'DATE',\n",
       "  'regex_type': 'date4',\n",
       "  'value': 'date'},\n",
       " {'_group_': 0,\n",
       "  '_priority_': 3,\n",
       "  '_regex_pattern_': regex.Regex('(?P<DAY>(0?[1-9]|[12][0-9]|3[01]))\\\\.\\\\s?(?P<MONTH>(0?[1-9]|1[0-2]))', flags=regex.V0),\n",
       "  '_validator_': <function estnltk.taggers.raw_text_tagging.regex_tagger.RegexTagger._read_expression_vocabulary.<locals>.<lambda>>,\n",
       "  'grammar_symbol': 'DATE',\n",
       "  'regex_type': 'date5',\n",
       "  'value': 'partial_date'},\n",
       " {'_group_': 0,\n",
       "  '_priority_': 3,\n",
       "  '_regex_pattern_': regex.Regex('(?P<MONTH>(0?[1-9]|1[0-2]))\\\\.\\\\s?(?P<LONGYEAR>((19[0-9]{2})|(20[0-9]{2})))', flags=regex.V0),\n",
       "  '_validator_': <function estnltk.taggers.raw_text_tagging.regex_tagger.RegexTagger._read_expression_vocabulary.<locals>.<lambda>>,\n",
       "  'grammar_symbol': 'DATE',\n",
       "  'regex_type': 'date6',\n",
       "  'value': 'partial_date'},\n",
       " {'_group_': 0,\n",
       "  '_priority_': 3,\n",
       "  '_regex_pattern_': regex.Regex('(?P<DAY>(0?[1-9]|[12][0-9]|3[01]))\\\\.\\\\s?(?P<MONTH>(0?[1-9]|1[0-2]))\\\\s*k(el)?l\\\\s(?P<hour>[0-2][0-9])[.:](?P<minute>[0-5][0-9])(:(?P<second>[0-5][0-9]))?', flags=regex.V0),\n",
       "  '_validator_': <function estnltk.taggers.raw_text_tagging.regex_tagger.RegexTagger._read_expression_vocabulary.<locals>.<lambda>>,\n",
       "  'grammar_symbol': 'DATE',\n",
       "  'regex_type': 'date7',\n",
       "  'value': 'partial_date'},\n",
       " {'_group_': 0,\n",
       "  '_priority_': 0,\n",
       "  '_regex_pattern_': regex.Regex('(?P<LONGYEAR>((19[0-9]{2})|(20[0-9]{2})))\\\\s*a', flags=regex.V0),\n",
       "  '_validator_': <function estnltk.taggers.raw_text_tagging.regex_tagger.RegexTagger._read_expression_vocabulary.<locals>.<lambda>>,\n",
       "  'grammar_symbol': 'DATE',\n",
       "  'regex_type': 'date8',\n",
       "  'value': 'partial_date'},\n",
       " {'_group_': 0,\n",
       "  '_priority_': 0,\n",
       "  '_regex_pattern_': regex.Regex('(?P<LONGYEAR>((19[0-9]{2})|(20[0-9]{2})))', flags=regex.V0),\n",
       "  '_validator_': <function estnltk.taggers.raw_text_tagging.regex_tagger.RegexTagger._read_expression_vocabulary.<locals>.<lambda>>,\n",
       "  'grammar_symbol': 'DATE',\n",
       "  'regex_type': 'date9',\n",
       "  'value': 'partial_date'}]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regex_tagger._vocabulary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we have 'ALL' as the conflict_resolving_strategy, all the possible matches of different regular expressions are given out, even the conflicting/overlapping ones. overlapped = True ensures that we do get overlapping matches from the same RegexTagger regular expression as well."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In addition to the defined symbols, we want to check if there's **any other text** between the tagged symbols - if a **measurement object** is at the beginning of a sentence and a **number** comes 20 tokens later at the end of the sentence, it might not be the measurement, although no other defined symbols appeared between them. For this, we need to define another tagger - GapsTagger:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we do not want every space and other random character to be considered as \"text between symbols\", we exclude those with a trim function that removes the characters that are accepted between symbols. These are mostly punctuation markers, but here also the verbs *on*, *oli* are included:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trim(text):\n",
    "    \n",
    "    t_1 = re.sub('^[-=.>< ]*', '', text)\n",
    "    t_1 = re.sub('^\\.?\\s*-?\\s*', '', t_1)\n",
    "    t_1 = re.sub('^[-=.>< ]*(on|oli)\\s*', '', t_1)\n",
    "    t_1 = re.sub('^\\s*-?:?\\s*\\<?', '', t_1)\n",
    "    t_1 = re.sub('^\\s*', '', t_1)\n",
    "    t_1 = re.sub('[-=.>< ]*$', '', t_1)\n",
    "    t_1 = re.sub('\\.?\\s*-?\\s*$', '', t_1)\n",
    "    t_1 = re.sub('[-=.>< ]*(on|oli)\\s*$', '', t_1)\n",
    "    t_1 = re.sub('\\s*-?:?\\s*\\<?$', '', t_1)\n",
    "    t_1 = re.sub('\\s*$', '', t_1)\n",
    "    \n",
    "    return t_1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also add a decorator that gives the gaps a grammar_symbol attribute, here it is named **RANDOM_TEXT**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decorator(text:str):\n",
    "    return {'gap_length':len(text), 'grammar_symbol': 'RANDOM_TEXT'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from estnltk.taggers.gaps_tagging.gap_tagger import GapTagger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "gap_tagger = GapTagger(layer_name='gaps',\n",
    "                       input_layers=['type'],\n",
    "                       trim=trim, \n",
    "                       decorator=decorator,\n",
    "                       attributes=['gap_length', 'grammar_symbol'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "If we want the symbols tagged with different taggers to be in the same layer, we can create and use a MergeTagger. Here, it takes the layers **type** created with regex_tagger and **gaps** created with gaps_tagger and merges them into **grammar_tags** layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from estnltk.taggers import MergeTagger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "merge_tagger = MergeTagger(layer_name='grammar_tags',\n",
    "                           input_layers=['type', 'gaps'],\n",
    "                           attributes=('grammar_symbol', 'value'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we need to run all the taggers in correct order on our examples. As GapsTagger uses layers from RegexTagger as its input, it needs to be the second, MergeTagger needs all the previous layers, so it needs to be the last:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from estnltk import Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "tagged_lines = []\n",
    "for line in lines:\n",
    "    text = Text(line)\n",
    "    regex_tagger.tag(text)\n",
    "\n",
    "    gap_tagger.tag(text)\n",
    "    merge_tagger.tag(text)\n",
    "    tagged_lines.append(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now we can see the layers tagged on the texts:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>PSA 2010. 3ng/ml, PSA 2012. 1,53ng/ml . - Bx va</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>layer name</th>\n",
       "      <th>attributes</th>\n",
       "      <th>parent</th>\n",
       "      <th>enveloping</th>\n",
       "      <th>ambiguous</th>\n",
       "      <th>span count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>gaps</td>\n",
       "      <td>gap_length, grammar_symbol</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>grammar_tags</td>\n",
       "      <td>grammar_symbol, value</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>type</td>\n",
       "      <td>regex_type, value, grammar_symbol</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "Text(text=\"PSA 2010. 3ng/ml, PSA 2012. 1,53ng/ml . - Bx va\")"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tagged_lines[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h4>SpanList</h4>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>layer name</th>\n",
       "      <th>attributes</th>\n",
       "      <th>parent</th>\n",
       "      <th>enveloping</th>\n",
       "      <th>ambiguous</th>\n",
       "      <th>span count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>type</td>\n",
       "      <td>regex_type, value, grammar_symbol</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>text</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "      <th>regex_type</th>\n",
       "      <th>value</th>\n",
       "      <th>grammar_symbol</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>PSA</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>measurement_object</td>\n",
       "      <td>psa</td>\n",
       "      <td>MO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2010</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>date9</td>\n",
       "      <td>partial_date</td>\n",
       "      <td>DATE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>11</td>\n",
       "      <td>anynumber</td>\n",
       "      <td>3</td>\n",
       "      <td>NUMBER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>ng/ml</td>\n",
       "      <td>11</td>\n",
       "      <td>16</td>\n",
       "      <td>psa_unit</td>\n",
       "      <td>ng/ml</td>\n",
       "      <td>UNIT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>g</td>\n",
       "      <td>12</td>\n",
       "      <td>13</td>\n",
       "      <td>kaal_unit</td>\n",
       "      <td>x</td>\n",
       "      <td>UNIT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>m</td>\n",
       "      <td>14</td>\n",
       "      <td>15</td>\n",
       "      <td>pikkus_unit</td>\n",
       "      <td>x</td>\n",
       "      <td>UNIT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>PSA</td>\n",
       "      <td>17</td>\n",
       "      <td>21</td>\n",
       "      <td>measurement_object</td>\n",
       "      <td>psa</td>\n",
       "      <td>MO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>PSA</td>\n",
       "      <td>18</td>\n",
       "      <td>21</td>\n",
       "      <td>measurement_object</td>\n",
       "      <td>psa</td>\n",
       "      <td>MO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2012</td>\n",
       "      <td>22</td>\n",
       "      <td>26</td>\n",
       "      <td>date9</td>\n",
       "      <td>partial_date</td>\n",
       "      <td>DATE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1,53</td>\n",
       "      <td>28</td>\n",
       "      <td>32</td>\n",
       "      <td>anynumber</td>\n",
       "      <td>1.53</td>\n",
       "      <td>NUMBER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>ng/ml</td>\n",
       "      <td>32</td>\n",
       "      <td>37</td>\n",
       "      <td>psa_unit</td>\n",
       "      <td>ng/ml</td>\n",
       "      <td>UNIT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>g</td>\n",
       "      <td>33</td>\n",
       "      <td>34</td>\n",
       "      <td>kaal_unit</td>\n",
       "      <td>x</td>\n",
       "      <td>UNIT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>m</td>\n",
       "      <td>35</td>\n",
       "      <td>36</td>\n",
       "      <td>pikkus_unit</td>\n",
       "      <td>x</td>\n",
       "      <td>UNIT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>x</td>\n",
       "      <td>43</td>\n",
       "      <td>44</td>\n",
       "      <td>time_unit</td>\n",
       "      <td>x</td>\n",
       "      <td>UNIT</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "SL[Span(PSA, {'grammar_symbol': 'MO', 'regex_type': 'measurement_object', 'value': 'psa'}),\n",
       "Span(2010, {'grammar_symbol': 'DATE', 'regex_type': 'date9', 'value': 'partial_date'}),\n",
       "Span(3, {'grammar_symbol': 'NUMBER', 'regex_type': 'anynumber', 'value': '3'}),\n",
       "Span(ng/ml, {'grammar_symbol': 'UNIT', 'regex_type': 'psa_unit', 'value': 'ng/ml'}),\n",
       "Span(g, {'grammar_symbol': 'UNIT', 'regex_type': 'kaal_unit', 'value': 'x'}),\n",
       "Span(m, {'grammar_symbol': 'UNIT', 'regex_type': 'pikkus_unit', 'value': 'x'}),\n",
       "Span( PSA, {'grammar_symbol': 'MO', 'regex_type': 'measurement_object', 'value': 'psa'}),\n",
       "Span(PSA, {'grammar_symbol': 'MO', 'regex_type': 'measurement_object', 'value': 'psa'}),\n",
       "Span(2012, {'grammar_symbol': 'DATE', 'regex_type': 'date9', 'value': 'partial_date'}),\n",
       "Span(1,53, {'grammar_symbol': 'NUMBER', 'regex_type': 'anynumber', 'value': '1.53'}),\n",
       "Span(ng/ml, {'grammar_symbol': 'UNIT', 'regex_type': 'psa_unit', 'value': 'ng/ml'}),\n",
       "Span(g, {'grammar_symbol': 'UNIT', 'regex_type': 'kaal_unit', 'value': 'x'}),\n",
       "Span(m, {'grammar_symbol': 'UNIT', 'regex_type': 'pikkus_unit', 'value': 'x'}),\n",
       "Span(x, {'grammar_symbol': 'UNIT', 'regex_type': 'time_unit', 'value': 'x'})]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tagged_lines[1].type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h4>SpanList</h4>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>layer name</th>\n",
       "      <th>attributes</th>\n",
       "      <th>parent</th>\n",
       "      <th>enveloping</th>\n",
       "      <th>ambiguous</th>\n",
       "      <th>span count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>gaps</td>\n",
       "      <td>gap_length, grammar_symbol</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>text</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "      <th>gap_length</th>\n",
       "      <th>grammar_symbol</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>,</td>\n",
       "      <td>16</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>RANDOM_TEXT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>B</td>\n",
       "      <td>42</td>\n",
       "      <td>43</td>\n",
       "      <td>1</td>\n",
       "      <td>RANDOM_TEXT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>va</td>\n",
       "      <td>45</td>\n",
       "      <td>47</td>\n",
       "      <td>2</td>\n",
       "      <td>RANDOM_TEXT</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "SL[Span(,, {'gap_length': 1, 'grammar_symbol': 'RANDOM_TEXT'}),\n",
       "Span(B, {'gap_length': 1, 'grammar_symbol': 'RANDOM_TEXT'}),\n",
       "Span(va, {'gap_length': 2, 'grammar_symbol': 'RANDOM_TEXT'})]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tagged_lines[1].gaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h4>SpanList</h4>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>layer name</th>\n",
       "      <th>attributes</th>\n",
       "      <th>parent</th>\n",
       "      <th>enveloping</th>\n",
       "      <th>ambiguous</th>\n",
       "      <th>span count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>grammar_tags</td>\n",
       "      <td>grammar_symbol, value</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>text</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "      <th>grammar_symbol</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>PSA</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>MO</td>\n",
       "      <td>psa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2010</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>DATE</td>\n",
       "      <td>partial_date</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>11</td>\n",
       "      <td>NUMBER</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>ng/ml</td>\n",
       "      <td>11</td>\n",
       "      <td>16</td>\n",
       "      <td>UNIT</td>\n",
       "      <td>ng/ml</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>g</td>\n",
       "      <td>12</td>\n",
       "      <td>13</td>\n",
       "      <td>UNIT</td>\n",
       "      <td>x</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>m</td>\n",
       "      <td>14</td>\n",
       "      <td>15</td>\n",
       "      <td>UNIT</td>\n",
       "      <td>x</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>,</td>\n",
       "      <td>16</td>\n",
       "      <td>17</td>\n",
       "      <td>RANDOM_TEXT</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>PSA</td>\n",
       "      <td>17</td>\n",
       "      <td>21</td>\n",
       "      <td>MO</td>\n",
       "      <td>psa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>PSA</td>\n",
       "      <td>18</td>\n",
       "      <td>21</td>\n",
       "      <td>MO</td>\n",
       "      <td>psa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2012</td>\n",
       "      <td>22</td>\n",
       "      <td>26</td>\n",
       "      <td>DATE</td>\n",
       "      <td>partial_date</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1,53</td>\n",
       "      <td>28</td>\n",
       "      <td>32</td>\n",
       "      <td>NUMBER</td>\n",
       "      <td>1.53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>ng/ml</td>\n",
       "      <td>32</td>\n",
       "      <td>37</td>\n",
       "      <td>UNIT</td>\n",
       "      <td>ng/ml</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>g</td>\n",
       "      <td>33</td>\n",
       "      <td>34</td>\n",
       "      <td>UNIT</td>\n",
       "      <td>x</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>m</td>\n",
       "      <td>35</td>\n",
       "      <td>36</td>\n",
       "      <td>UNIT</td>\n",
       "      <td>x</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>B</td>\n",
       "      <td>42</td>\n",
       "      <td>43</td>\n",
       "      <td>RANDOM_TEXT</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>x</td>\n",
       "      <td>43</td>\n",
       "      <td>44</td>\n",
       "      <td>UNIT</td>\n",
       "      <td>x</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>va</td>\n",
       "      <td>45</td>\n",
       "      <td>47</td>\n",
       "      <td>RANDOM_TEXT</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "SL[Span(PSA, {'grammar_symbol': 'MO', 'value': 'psa'}),\n",
       "Span(2010, {'grammar_symbol': 'DATE', 'value': 'partial_date'}),\n",
       "Span(3, {'grammar_symbol': 'NUMBER', 'value': '3'}),\n",
       "Span(ng/ml, {'grammar_symbol': 'UNIT', 'value': 'ng/ml'}),\n",
       "Span(g, {'grammar_symbol': 'UNIT', 'value': 'x'}),\n",
       "Span(m, {'grammar_symbol': 'UNIT', 'value': 'x'}),\n",
       "Span(,, {'grammar_symbol': 'RANDOM_TEXT', 'value': None}),\n",
       "Span( PSA, {'grammar_symbol': 'MO', 'value': 'psa'}),\n",
       "Span(PSA, {'grammar_symbol': 'MO', 'value': 'psa'}),\n",
       "Span(2012, {'grammar_symbol': 'DATE', 'value': 'partial_date'}),\n",
       "Span(1,53, {'grammar_symbol': 'NUMBER', 'value': '1.53'}),\n",
       "Span(ng/ml, {'grammar_symbol': 'UNIT', 'value': 'ng/ml'}),\n",
       "Span(g, {'grammar_symbol': 'UNIT', 'value': 'x'}),\n",
       "Span(m, {'grammar_symbol': 'UNIT', 'value': 'x'}),\n",
       "Span(B, {'grammar_symbol': 'RANDOM_TEXT', 'value': None}),\n",
       "Span(x, {'grammar_symbol': 'UNIT', 'value': 'x'}),\n",
       "Span(va, {'grammar_symbol': 'RANDOM_TEXT', 'value': None})]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tagged_lines[1].grammar_tags"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### TESTING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import unittest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_function(line):\n",
    "    line = Text(line)\n",
    "    regex_tagger.tag(line)\n",
    "    numbers = []\n",
    "    for n, r in zip(line.type.text, line.type.grammar_symbol):\n",
    "        if r == 'NUMBER' or r == 'DATE' or r == 'DATENUM':\n",
    "            numbers.append(n)\n",
    "    return numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['12 , ', '12 , 53', '53']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_function('PSA 12 , 53')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def more_complex_test_function(line):\n",
    "    line = Text(line)\n",
    "    regex_tagger.tag(line)\n",
    "    #numbers = []\n",
    "    #for n, r in zip(line.type.text, line.type.grammar_symbol):\n",
    "    #    if r == 'NUMBER' or r == 'DATE' or r == 'DATENUM':\n",
    "    #        numbers.append(n)\n",
    "    return line.type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyTest(unittest.TestCase):\n",
    "    def test(self):\n",
    "        self.assertEqual(test_function('PSA 2012. 1,53'), ['2012', '1,53'])\n",
    "    def test2(self):\n",
    "        self.assertEqual(test_function('PSA 12. 53'), ['12. ', '12. 53', '53'])\n",
    "    def test3(self):\n",
    "        self.assertEqual(test_function('PSA 12, 53'), ['12, ', '12, 53', '53'])\n",
    "    def test4(self):\n",
    "        self.assertEqual(test_function('PSA 12 , 53'), ['12 , ', '12 , 53', '53'])\n",
    "    def test5(self):\n",
    "        self.assertEqual(test_function('PSA 2012.1,53'), ['2012', '1,53'])\n",
    "    def test6(self):\n",
    "        self.assertEqual(test_function('PSA 20121,53'), ['2012', '1,53'])\n",
    "    def test7(self):\n",
    "        self.assertEqual(test_function('PSA ,315'), [' ,315'])    \n",
    "    def test8(self):\n",
    "        self.assertEqual(test_function('PSA 030420121,53'), ['03042012', '1,53'])  \n",
    "        \n",
    "    def test9(self):\n",
    "        t = more_complex_test_function('PSA 2012. 1,53')\n",
    "        self.assertEqual(t[0].regex_type, 'measurement_object')\n",
    "        self.assertEqual(t[0].start, 0)\n",
    "        self.assertEqual(t[0].end, 3)\n",
    "        self.assertEqual(t[1].regex_type, 'date9')\n",
    "        self.assertEqual(t[1].start, 4)\n",
    "        self.assertEqual(t[1].end, 8)\n",
    "        self.assertEqual(t[2].regex_type, 'anynumber')\n",
    "        self.assertEqual(t[2].start, 10)\n",
    "        self.assertEqual(t[2].end, 14) \n",
    "    \n",
    "    def test10(self):\n",
    "        t = more_complex_test_function('PSA 12. 53')\n",
    "        self.assertEqual(t[0].regex_type, 'measurement_object')\n",
    "        self.assertEqual(t[0].start, 0)\n",
    "        self.assertEqual(t[0].end, 3)\n",
    "        self.assertEqual(t[1].regex_type, 'numbercomma')\n",
    "        self.assertEqual(t[1].start, 4)\n",
    "        self.assertEqual(t[1].end, 8)\n",
    "        self.assertEqual(t[2].regex_type, 'anynumber')\n",
    "        self.assertEqual(t[2].start, 4)\n",
    "        self.assertEqual(t[2].end, 10)\n",
    "        self.assertEqual(t[3].regex_type, 'anynumber')\n",
    "        self.assertEqual(t[3].start, 8)\n",
    "        self.assertEqual(t[3].end, 10) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "..........\n",
      "----------------------------------------------------------------------\n",
      "Ran 10 tests in 0.022s\n",
      "\n",
      "OK\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    unittest.main(argv=['first-arg-is-ignored'], exit=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyTest(unittest.TestCase):\n",
    "    def test(self):\n",
    "        t = more_complex_test_function('PSA 2012. 1,53')\n",
    "        self.assertEqual(t[0].grammar_symbol, 'MO')\n",
    "        self.assertEqual(t[0].start, 0)\n",
    "        self.assertEqual(t[0].end, 3)\n",
    "        self.assertEqual(t[0].grammar_symbol, 'DATE')\n",
    "        self.assertEqual(t[0].start, 4)\n",
    "        self.assertEqual(t[0].end, 8)\n",
    "        self.assertEqual(t[0].grammar_symbol, 'NUMBER')\n",
    "        self.assertEqual(t[0].start, 10)\n",
    "        self.assertEqual(t[0].end, 14)\n",
    "        #for thing in t:\n",
    "        #    if thing\n",
    "        #self.assertEqual(test_function('PSA 2012. 1,53'), ['2012', '1,53'])\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
