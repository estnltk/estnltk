{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VabamorfAnalyzer that allows multiple variants of a normalized word (spelling corrections)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import MutableMapping\n",
    "\n",
    "from estnltk import Annotation\n",
    "from estnltk.text import Layer, Text\n",
    "from estnltk.layer.ambiguous_span import AmbiguousSpan\n",
    "\n",
    "from estnltk.taggers import Tagger\n",
    "from estnltk.vabamorf.morf import Vabamorf\n",
    "\n",
    "from estnltk.taggers.morph_analysis.morf_common import DEFAULT_PARAM_GUESS\n",
    "from estnltk.taggers.morph_analysis.morf_common import DEFAULT_PARAM_PROPERNAME\n",
    "from estnltk.taggers.morph_analysis.morf_common import DEFAULT_PARAM_PHONETIC\n",
    "from estnltk.taggers.morph_analysis.morf_common import DEFAULT_PARAM_COMPOUND\n",
    "from estnltk.taggers.morph_analysis.morf import VabamorfTagger\n",
    "\n",
    "from estnltk.taggers.morph_analysis.morf_common import _get_word_text\n",
    "from estnltk.taggers.morph_analysis.morf_common import _convert_vm_records_to_morph_analysis_records\n",
    "\n",
    "\n",
    "# ===============================\n",
    "#    VabamorfAnalyzer\n",
    "# ===============================\n",
    "\n",
    "class VabamorfAnalyzer( Tagger ):\n",
    "    \"\"\"Performs morphological analysis with Vabamorf's analyzer.\n",
    "       Note: resulting analyses will be ambiguous.\"\"\"\n",
    "    output_layer      = 'morph_analysis'\n",
    "    output_attributes = VabamorfTagger.output_attributes\n",
    "    input_layers      = ['words', 'sentences']\n",
    "    conf_param = [ # Configuration flags:\n",
    "                   \"guess\",\n",
    "                   \"propername\",\n",
    "                   \"compound\",\n",
    "                   \"phonetic\",\n",
    "                   # Internal stuff:\n",
    "                   '_vm_instance', \\\n",
    "                   # Names of the specific input layers:\n",
    "                   '_input_words_layer', \\\n",
    "                   '_input_sentences_layer', \\\n",
    "                   # For backward compatibility:\n",
    "                   'depends_on', 'layer_name', 'attributes',\n",
    "                   # Extra configuration flags:\n",
    "                   'extra_attributes', \\\n",
    "                 ]\n",
    "    layer_name = output_layer       # <- For backward compatibility ...\n",
    "    depends_on = input_layers       # <- For backward compatibility ...\n",
    "    attributes = output_attributes  # <- For backward compatibility ...\n",
    "    \n",
    "    def __init__(self,\n",
    "                 output_layer='morph_analysis',\n",
    "                 input_words_layer='words',\n",
    "                 input_sentences_layer='sentences',\n",
    "                 extra_attributes=None,\n",
    "                 vm_instance=None,\n",
    "                 guess = DEFAULT_PARAM_GUESS,\n",
    "                 propername = DEFAULT_PARAM_PROPERNAME,\n",
    "                 compound = DEFAULT_PARAM_COMPOUND,\n",
    "                 phonetic = DEFAULT_PARAM_PHONETIC ):\n",
    "        \"\"\"Initialize VabamorfAnalyzer class.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        layer_name: str (default: 'morph_analysis')\n",
    "            Name of the layer where morph analysis results \n",
    "            will be stored.\n",
    "        input_words_layer: str (default: 'words')\n",
    "            Name of the input words layer;\n",
    "        input_sentences_layer: str (default: 'sentences')\n",
    "            Name of the input sentences layer;\n",
    "        extra_attributes: list of str (default: None)\n",
    "            List containing names of extra attributes that will be \n",
    "            attached to Spans. All extra attributes will be \n",
    "            initialized to None.\n",
    "        vm_instance: estnltk.vabamorf.morf.Vabamorf\n",
    "            An instance of Vabamorf that is to be used for analysing\n",
    "            text morphologically.\n",
    "        propername: boolean (default: True)\n",
    "            Propose additional analysis variants for proper names \n",
    "            (a.k.a. proper name guessing).\n",
    "        guess: boolean (default: True)\n",
    "            Use guessing in case of unknown words.\n",
    "        compound: boolean (default: True)\n",
    "            Add compound word markers to root forms.\n",
    "        phonetic: boolean (default: False)\n",
    "            Add phonetic information to root forms.\n",
    "        \"\"\"\n",
    "        # Set input/output layer names\n",
    "        self.output_layer = output_layer\n",
    "        self._input_words_layer          = input_words_layer\n",
    "        self._input_sentences_layer      = input_sentences_layer\n",
    "        self.input_layers = [input_words_layer, input_sentences_layer]\n",
    "        self.extra_attributes = extra_attributes\n",
    "        if self.extra_attributes:\n",
    "            for extra_attr in self.extra_attributes:\n",
    "                self.output_attributes += (extra_attr,)\n",
    "            self.attributes = self.output_attributes  # <- For backward compatibility ...\n",
    "        if vm_instance:\n",
    "            self._vm_instance = vm_instance\n",
    "        else:\n",
    "            self._vm_instance = Vabamorf.instance()\n",
    "        # Set analysis parameters:\n",
    "        self.guess = guess\n",
    "        self.propername = propername\n",
    "        self.compound = compound\n",
    "        self.phonetic = phonetic\n",
    "        # Other stuff\n",
    "        self.layer_name = self.output_layer  # <- For backward compatibility ...\n",
    "        self.depends_on = self.input_layers  # <- For backward compatibility ...\n",
    "\n",
    "    def _make_layer(self, text: Text, layers, status: dict):\n",
    "        \"\"\"Analyses given Text object morphologically. \n",
    "        \n",
    "        Note: disambiguation is not performed, so the results of\n",
    "        analysis will (most likely) be ambiguous.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        text: estnltk.text.Text\n",
    "            Text object that is to be analysed morphologically.\n",
    "            The Text object must have layers 'words', 'sentences'.\n",
    "        \n",
    "        layers: MutableMapping[str, Layer]\n",
    "           Layers of the text. Contains mappings from the \n",
    "           name of the layer to the Layer object. Must contain\n",
    "           words, and sentences;\n",
    "          \n",
    "        status: dict\n",
    "           This can be used to store metadata on layer tagging.\n",
    "        \"\"\"\n",
    "        # Fetch parameters of the analysis\n",
    "        current_kwargs = {}\n",
    "        current_kwargs[\"disambiguate\"] = False # perform analysis without disambiguation\n",
    "        current_kwargs[\"guess\"]      = self.guess\n",
    "        current_kwargs[\"propername\"] = self.propername\n",
    "        current_kwargs[\"compound\"]   = self.compound\n",
    "        current_kwargs[\"phonetic\"]   = self.phonetic\n",
    "        # --------------------------------------------\n",
    "        #   Use Vabamorf for morphological analysis\n",
    "        # --------------------------------------------\n",
    "        # Perform morphological analysis sentence by sentence\n",
    "        word_layer = layers[self._input_words_layer]\n",
    "        word_span_id = 0\n",
    "        analysis_results = []\n",
    "        for sentence in layers[self._input_sentences_layer]:\n",
    "            # A) Collect all words inside the sentence\n",
    "            sentence_words = []\n",
    "            sentence_words_count = 0\n",
    "            while word_span_id < len(word_layer):\n",
    "                span = word_layer[word_span_id]\n",
    "                if sentence.start <= span.start and \\\n",
    "                    span.end <= sentence.end:\n",
    "                    # > Word is inside the sentence\n",
    "                    # Get the normalized variant(s)\n",
    "                    _word = _get_word_text( span )\n",
    "                    # If we have only one variant, \n",
    "                    # package it into a list\n",
    "                    if isinstance(_word, str):\n",
    "                        _word = [ _word ]\n",
    "                    assert isinstance(_word, list)\n",
    "                    sentence_words.append( _word )\n",
    "                    sentence_words_count += len( _word )\n",
    "                    word_span_id += 1\n",
    "                    if sentence_words_count > 15000:\n",
    "                        # if 149129 < len(wordlist) on Linux,\n",
    "                        # if  15000 < len(wordlist) < 17500 on Windows,\n",
    "                        # then self.instance.analyze(words=wordlist, **self.current_kwargs) raises\n",
    "                        # RuntimeError: CFSException: internal error with vabamorf\n",
    "                        # B) Therefore, we analyse approx 15000 words at time, and then empty the buffer\n",
    "                        res = self._perform_vm_analysis( sentence_words, current_kwargs )\n",
    "                        analysis_results.extend( res )\n",
    "                        sentence_words = []\n",
    "                        sentence_words_count = 0\n",
    "                elif sentence.end <= span.start:\n",
    "                    break\n",
    "            # B) Analyse what's left unanalysed in the sentence\n",
    "            if sentence_words_count > 0:\n",
    "                assert sentence_words_count < 15000, '(!) Unexpected amount of unanalysed words left: {}'.format(len(sentence_words_count))\n",
    "                res = self._perform_vm_analysis( sentence_words, current_kwargs )\n",
    "                analysis_results.extend( res )\n",
    "\n",
    "        # Assert that all words obtained an analysis \n",
    "        # ( Note: there must be empty analyses for unknown \n",
    "        #         words if guessing is not used )\n",
    "        assert len(layers[ self._input_words_layer ]) == len(analysis_results), \\\n",
    "            '(!) Unexpectedly the number words ('+str(len(layers[ self._input_words_layer ]))+') '+\\\n",
    "            'does not match the number of obtained morphological analyses ('+str(len(analysis_results))+').'\n",
    "\n",
    "        # --------------------------------------------\n",
    "        #   Store analysis results in a new layer     \n",
    "        # --------------------------------------------\n",
    "        # A) Create layer\n",
    "        morph_attributes   = self.output_attributes\n",
    "        current_attributes = morph_attributes\n",
    "        morph_layer = Layer(name  =self.output_layer,\n",
    "                            parent=self._input_words_layer,\n",
    "                            text_object=text,\n",
    "                            ambiguous=True,\n",
    "                            attributes=current_attributes )\n",
    "        morph_layer._base = self._input_words_layer\n",
    "        # B) Populate layer\n",
    "        for word, analyses_dict in zip(layers[ self._input_words_layer ], analysis_results):\n",
    "            # Convert from Vabamorf dict to a list of Spans\n",
    "            records = _convert_vm_records_to_morph_analysis_records(analyses_dict, layer_attributes=current_attributes,\n",
    "                                                                    sort_analyses=False)\n",
    "            # Attach spans (if word has morphological analyses)\n",
    "            for record in records:\n",
    "                # the analyses here are not always unique\n",
    "                morph_layer.add_annotation(word.base_span, **record)\n",
    "            if not records:\n",
    "                # if word has no morphological analyses (e.g.\n",
    "                # it is an unknown word), then attach an \n",
    "                # empty Span as a placeholder\n",
    "                morph_layer.add_annotation(word.base_span)\n",
    "\n",
    "        # C) Return the layer\n",
    "        return morph_layer\n",
    "\n",
    "\n",
    "    def _perform_vm_analysis( self, sentence_words, analysis_kwargs ):\n",
    "        \"\"\"Analyses given list of words with Vabamorf. (Only for class-internal usage) \"\"\"\n",
    "        # Unpack the words: flatten the input list\n",
    "        flat_words = [w for word_variants in sentence_words for w in word_variants]\n",
    "        # Analyse with Vabamorf\n",
    "        initial_results = self._vm_instance.analyze(words=flat_words, **analysis_kwargs)\n",
    "        # Pack the words: merge all analyses of a word into a single list of analyses\n",
    "        packed_results = self._pack_expanded_analysis_results( initial_results, sentence_words )\n",
    "        return packed_results\n",
    "\n",
    "\n",
    "    def _pack_expanded_analysis_results( self, analysis_results, initial_sentence_words, sort_analyses=True ):\n",
    "        \"\"\"Packs expanded analysis results. (Only for class-internal usage) \"\"\"\n",
    "        merged_analysis_results = []\n",
    "        analysis_index      = 0\n",
    "        initial_words_index = 0\n",
    "        while initial_words_index < len(initial_sentence_words):\n",
    "            merged_morph_record = { 'analysis':[] }\n",
    "            for initial_word in initial_sentence_words[initial_words_index]:\n",
    "                current_analysis_dict = analysis_results[analysis_index]\n",
    "                # Sanity check\n",
    "                assert current_analysis_dict['text'] == initial_word\n",
    "                if sort_analyses:\n",
    "                    # Sort analyses (to assure a fixed order, e.g. for testing purposes)\n",
    "                    current_analysis_dict['analysis'] = sorted(current_analysis_dict['analysis'],\n",
    "                                           key=lambda x: x['root']+x['ending']+x['clitic']+x['partofspeech']+x['form'],\n",
    "                                           reverse=False )\n",
    "                merged_morph_record['analysis'].extend( current_analysis_dict['analysis'] )\n",
    "                analysis_index += 1\n",
    "            merged_analysis_results.append( merged_morph_record )\n",
    "            initial_words_index += 1\n",
    "        return merged_analysis_results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Usage examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guessing switched on\n",
    "vm_analyser = VabamorfAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h4>Layer</h4>\n",
       "\n",
       "\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>layer name</th>\n",
       "      <th>attributes</th>\n",
       "      <th>parent</th>\n",
       "      <th>enveloping</th>\n",
       "      <th>ambiguous</th>\n",
       "      <th>span count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>morph_analysis</td>\n",
       "      <td>lemma, root, root_tokens, ending, clitic, form...</td>\n",
       "      <td>words</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>text</th>\n",
       "      <th>lemma</th>\n",
       "      <th>root</th>\n",
       "      <th>root_tokens</th>\n",
       "      <th>ending</th>\n",
       "      <th>clitic</th>\n",
       "      <th>form</th>\n",
       "      <th>partofspeech</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>isaand</td>\n",
       "      <td>isand</td>\n",
       "      <td>isand</td>\n",
       "      <td>('isand',)</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>sg n</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td></td>\n",
       "      <td>issand</td>\n",
       "      <td>issand</td>\n",
       "      <td>('issand',)</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>I</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td></td>\n",
       "      <td>issand</td>\n",
       "      <td>issand</td>\n",
       "      <td>('issand',)</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>sg n</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>kui</td>\n",
       "      <td>kui</td>\n",
       "      <td>kui</td>\n",
       "      <td>('kui',)</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td></td>\n",
       "      <td>kui</td>\n",
       "      <td>kui</td>\n",
       "      <td>('kui',)</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>J</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>juuuubbeee</td>\n",
       "      <td>jube</td>\n",
       "      <td>jube</td>\n",
       "      <td>('jube',)</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>sg n</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td></td>\n",
       "      <td>jube</td>\n",
       "      <td>jube</td>\n",
       "      <td>('jube',)</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>('...',)</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Z</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "Layer(name='morph_analysis', attributes=('lemma', 'root', 'root_tokens', 'ending', 'clitic', 'form', 'partofspeech'), spans=SL[AmbiguousSpan('isaand', [{'lemma': 'isand', 'root': 'isand', 'root_tokens': ('isand',), 'ending': '0', 'clitic': '', 'form': 'sg n', 'partofspeech': 'S'}, {'lemma': 'issand', 'root': 'issand', 'root_tokens': ('issand',), 'ending': '0', 'clitic': '', 'form': '', 'partofspeech': 'I'}, {'lemma': 'issand', 'root': 'issand', 'root_tokens': ('issand',), 'ending': '0', 'clitic': '', 'form': 'sg n', 'partofspeech': 'S'}]),\n",
       "AmbiguousSpan('kui', [{'lemma': 'kui', 'root': 'kui', 'root_tokens': ('kui',), 'ending': '0', 'clitic': '', 'form': '', 'partofspeech': 'D'}, {'lemma': 'kui', 'root': 'kui', 'root_tokens': ('kui',), 'ending': '0', 'clitic': '', 'form': '', 'partofspeech': 'J'}]),\n",
       "AmbiguousSpan('juuuubbeee', [{'lemma': 'jube', 'root': 'jube', 'root_tokens': ('jube',), 'ending': '0', 'clitic': '', 'form': 'sg n', 'partofspeech': 'A'}, {'lemma': 'jube', 'root': 'jube', 'root_tokens': ('jube',), 'ending': '0', 'clitic': '', 'form': '', 'partofspeech': 'D'}]),\n",
       "AmbiguousSpan('...', [{'lemma': '...', 'root': '...', 'root_tokens': ('...',), 'ending': '', 'clitic': '', 'form': '', 'partofspeech': 'Z'}])])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from estnltk import Text\n",
    "\n",
    "text = Text('''isaand kui juuuubbeee ... ''')\n",
    "text.tag_layer(['words', 'sentences'])\n",
    "\n",
    "for word in text.words:\n",
    "    if word.text == 'isaand':\n",
    "        word.annotations[0].normalized_form = ['isand', 'issand']\n",
    "    if word.text == 'juuuubbeee':\n",
    "        word.annotations[0].normalized_form = ['jube']\n",
    "\n",
    "vm_analyser.tag(text)\n",
    "text.morph_analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h4>Layer</h4>\n",
       "\n",
       "\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>layer name</th>\n",
       "      <th>attributes</th>\n",
       "      <th>parent</th>\n",
       "      <th>enveloping</th>\n",
       "      <th>ambiguous</th>\n",
       "      <th>span count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>morph_analysis</td>\n",
       "      <td>lemma, root, root_tokens, ending, clitic, form, partofspeech</td>\n",
       "      <td>words</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>text</th>\n",
       "      <th>lemma</th>\n",
       "      <th>root</th>\n",
       "      <th>root_tokens</th>\n",
       "      <th>ending</th>\n",
       "      <th>clitic</th>\n",
       "      <th>form</th>\n",
       "      <th>partofspeech</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>lihtsalt</td>\n",
       "      <td>lihtne</td>\n",
       "      <td>lihtne</td>\n",
       "      <td>('lihtne',)</td>\n",
       "      <td>lt</td>\n",
       "      <td></td>\n",
       "      <td>sg abl</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td></td>\n",
       "      <td>lihtsalt</td>\n",
       "      <td>lihtsalt</td>\n",
       "      <td>('lihtsalt',)</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>ei</td>\n",
       "      <td>ei</td>\n",
       "      <td>ei</td>\n",
       "      <td>('ei',)</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td></td>\n",
       "      <td>ei</td>\n",
       "      <td>ei</td>\n",
       "      <td>('ei',)</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>neg</td>\n",
       "      <td>V</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>teee</td>\n",
       "      <td>tee</td>\n",
       "      <td>tee</td>\n",
       "      <td>('tee',)</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>sg g</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td></td>\n",
       "      <td>tee</td>\n",
       "      <td>tee</td>\n",
       "      <td>('tee',)</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>sg n</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td></td>\n",
       "      <td>tegema</td>\n",
       "      <td>tege</td>\n",
       "      <td>('tege',)</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>o</td>\n",
       "      <td>V</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td></td>\n",
       "      <td>sina</td>\n",
       "      <td>sina</td>\n",
       "      <td>('sina',)</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>pl g</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td></td>\n",
       "      <td>sina</td>\n",
       "      <td>sina</td>\n",
       "      <td>('sina',)</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>pl n</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>välja</td>\n",
       "      <td>väli</td>\n",
       "      <td>väli</td>\n",
       "      <td>('väli',)</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>adt</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td></td>\n",
       "      <td>väli</td>\n",
       "      <td>väli</td>\n",
       "      <td>('väli',)</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>sg g</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td></td>\n",
       "      <td>väli</td>\n",
       "      <td>väli</td>\n",
       "      <td>('väli',)</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>sg p</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td></td>\n",
       "      <td>välja</td>\n",
       "      <td>välja</td>\n",
       "      <td>('välja',)</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td></td>\n",
       "      <td>väljama</td>\n",
       "      <td>välja</td>\n",
       "      <td>('välja',)</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>o</td>\n",
       "      <td>V</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>,</td>\n",
       "      <td>,</td>\n",
       "      <td>,</td>\n",
       "      <td>(',',)</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>see</td>\n",
       "      <td>see</td>\n",
       "      <td>see</td>\n",
       "      <td>('see',)</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>sg n</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>ppole</td>\n",
       "      <td>olema</td>\n",
       "      <td>ole</td>\n",
       "      <td>('ole',)</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>neg o</td>\n",
       "      <td>V</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>tema</td>\n",
       "      <td>tema</td>\n",
       "      <td>tema</td>\n",
       "      <td>('tema',)</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>sg g</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td></td>\n",
       "      <td>tema</td>\n",
       "      <td>tema</td>\n",
       "      <td>('tema',)</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>sg n</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>asi</td>\n",
       "      <td>asi</td>\n",
       "      <td>asi</td>\n",
       "      <td>('asi',)</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>sg n</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td></td>\n",
       "      <td>asima</td>\n",
       "      <td>asi</td>\n",
       "      <td>('asi',)</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>o</td>\n",
       "      <td>V</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>('...',)</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Z</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "Layer(name='morph_analysis', attributes=('lemma', 'root', 'root_tokens', 'ending', 'clitic', 'form', 'partofspeech'), spans=SL[AmbiguousSpan('lihtsalt', [{'lemma': 'lihtne', 'root': 'lihtne', 'root_tokens': ('lihtne',), 'ending': 'lt', 'clitic': '', 'form': 'sg abl', 'partofspeech': 'A'}, {'lemma': 'lihtsalt', 'root': 'lihtsalt', 'root_tokens': ('lihtsalt',), 'ending': '0', 'clitic': '', 'form': '', 'partofspeech': 'D'}]),\n",
       "AmbiguousSpan('ei', [{'lemma': 'ei', 'root': 'ei', 'root_tokens': ('ei',), 'ending': '0', 'clitic': '', 'form': '', 'partofspeech': 'D'}, {'lemma': 'ei', 'root': 'ei', 'root_tokens': ('ei',), 'ending': '0', 'clitic': '', 'form': 'neg', 'partofspeech': 'V'}]),\n",
       "AmbiguousSpan('teee', [{'lemma': 'tee', 'root': 'tee', 'root_tokens': ('tee',), 'ending': '0', 'clitic': '', 'form': 'sg g', 'partofspeech': 'S'}, {'lemma': 'tee', 'root': 'tee', 'root_tokens': ('tee',), 'ending': '0', 'clitic': '', 'form': 'sg n', 'partofspeech': 'S'}, {'lemma': 'tegema', 'root': 'tege', 'root_tokens': ('tege',), 'ending': '0', 'clitic': '', 'form': 'o', 'partofspeech': 'V'}, {'lemma': 'sina', 'root': 'sina', 'root_tokens': ('sina',), 'ending': '0', 'clitic': '', 'form': 'pl g', 'partofspeech': 'P'}, {'lemma': 'sina', 'root': 'sina', 'root_tokens': ('sina',), 'ending': '0', 'clitic': '', 'form': 'pl n', 'partofspeech': 'P'}]),\n",
       "AmbiguousSpan('välja', [{'lemma': 'väli', 'root': 'väli', 'root_tokens': ('väli',), 'ending': '0', 'clitic': '', 'form': 'adt', 'partofspeech': 'S'}, {'lemma': 'väli', 'root': 'väli', 'root_tokens': ('väli',), 'ending': '0', 'clitic': '', 'form': 'sg g', 'partofspeech': 'S'}, {'lemma': 'väli', 'root': 'väli', 'root_tokens': ('väli',), 'ending': '0', 'clitic': '', 'form': 'sg p', 'partofspeech': 'S'}, {'lemma': 'välja', 'root': 'välja', 'root_tokens': ('välja',), 'ending': '0', 'clitic': '', 'form': '', 'partofspeech': 'D'}, {'lemma': 'väljama', 'root': 'välja', 'root_tokens': ('välja',), 'ending': '0', 'clitic': '', 'form': 'o', 'partofspeech': 'V'}]),\n",
       "AmbiguousSpan(',', [{'lemma': ',', 'root': ',', 'root_tokens': (',',), 'ending': '', 'clitic': '', 'form': '', 'partofspeech': 'Z'}]),\n",
       "AmbiguousSpan('see', [{'lemma': 'see', 'root': 'see', 'root_tokens': ('see',), 'ending': '0', 'clitic': '', 'form': 'sg n', 'partofspeech': 'P'}]),\n",
       "AmbiguousSpan('ppole', [{'lemma': 'olema', 'root': 'ole', 'root_tokens': ('ole',), 'ending': '0', 'clitic': '', 'form': 'neg o', 'partofspeech': 'V'}]),\n",
       "AmbiguousSpan('tema', [{'lemma': 'tema', 'root': 'tema', 'root_tokens': ('tema',), 'ending': '0', 'clitic': '', 'form': 'sg g', 'partofspeech': 'P'}, {'lemma': 'tema', 'root': 'tema', 'root_tokens': ('tema',), 'ending': '0', 'clitic': '', 'form': 'sg n', 'partofspeech': 'P'}]),\n",
       "AmbiguousSpan('asi', [{'lemma': 'asi', 'root': 'asi', 'root_tokens': ('asi',), 'ending': '0', 'clitic': '', 'form': 'sg n', 'partofspeech': 'S'}, {'lemma': 'asima', 'root': 'asi', 'root_tokens': ('asi',), 'ending': '0', 'clitic': '', 'form': 'o', 'partofspeech': 'V'}]),\n",
       "AmbiguousSpan('...', [{'lemma': '...', 'root': '...', 'root_tokens': ('...',), 'ending': '', 'clitic': '', 'form': '', 'partofspeech': 'Z'}])])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from estnltk import Text\n",
    "\n",
    "text = Text('''lihtsalt ei teee välja , see ppole tema asi ...''')\n",
    "text.tag_layer(['words', 'sentences'])\n",
    "\n",
    "for word in text.words:\n",
    "    if word.text == 'teee':\n",
    "        word.annotations[0].normalized_form = ['tee', 'te']\n",
    "    if word.text == 'ppole':\n",
    "        word.annotations[0].normalized_form = ['pole']\n",
    "\n",
    "vm_analyser.tag(text)\n",
    "text.morph_analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h4>Layer</h4>\n",
       "\n",
       "\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>layer name</th>\n",
       "      <th>attributes</th>\n",
       "      <th>parent</th>\n",
       "      <th>enveloping</th>\n",
       "      <th>ambiguous</th>\n",
       "      <th>span count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>sentences</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>words</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>['neet', 'eesti', 'naised', ',', 'kes', 'lähevad', 'välismaaa', 'meestele', 'mehale', '...']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>['Ja', 'siis', 'on', 'oops', '....']</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "Layer(name='sentences', attributes=(), spans=SL[EnvelopingSpan(['neet', 'eesti', 'naised', ',', 'kes', 'lähevad', 'välismaaa', 'meestele', 'mehale', '...'], [{}]),\n",
       "EnvelopingSpan(['Ja', 'siis', 'on', 'oops', '....'], [{}])])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Text with multiple sentences\n",
    "from estnltk import Text\n",
    "\n",
    "text = Text('''neet eesti naised , kes lähevad välismaaa meestele mehale ... Ja siis on oops ....''')\n",
    "text.tag_layer(['words', 'sentences'])\n",
    "text.sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h4>Layer</h4>\n",
       "\n",
       "\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>layer name</th>\n",
       "      <th>attributes</th>\n",
       "      <th>parent</th>\n",
       "      <th>enveloping</th>\n",
       "      <th>ambiguous</th>\n",
       "      <th>span count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>morph_analysis</td>\n",
       "      <td>lemma, root, root_tokens, ending, clitic, form, partofspeech</td>\n",
       "      <td>words</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>text</th>\n",
       "      <th>lemma</th>\n",
       "      <th>root</th>\n",
       "      <th>root_tokens</th>\n",
       "      <th>ending</th>\n",
       "      <th>clitic</th>\n",
       "      <th>form</th>\n",
       "      <th>partofspeech</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>neet</td>\n",
       "      <td>neet</td>\n",
       "      <td>neet</td>\n",
       "      <td>('neet',)</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>sg n</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td></td>\n",
       "      <td>see</td>\n",
       "      <td>see</td>\n",
       "      <td>('see',)</td>\n",
       "      <td>d</td>\n",
       "      <td></td>\n",
       "      <td>pl n</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>eesti</td>\n",
       "      <td>eesti</td>\n",
       "      <td>eesti</td>\n",
       "      <td>('eesti',)</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>G</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>naised</td>\n",
       "      <td>naine</td>\n",
       "      <td>naine</td>\n",
       "      <td>('naine',)</td>\n",
       "      <td>d</td>\n",
       "      <td></td>\n",
       "      <td>pl n</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>,</td>\n",
       "      <td>,</td>\n",
       "      <td>,</td>\n",
       "      <td>(',',)</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>kes</td>\n",
       "      <td>kes</td>\n",
       "      <td>kes</td>\n",
       "      <td>('kes',)</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>pl n</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td></td>\n",
       "      <td>kes</td>\n",
       "      <td>kes</td>\n",
       "      <td>('kes',)</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>sg n</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>lähevad</td>\n",
       "      <td>minema</td>\n",
       "      <td>mine</td>\n",
       "      <td>('mine',)</td>\n",
       "      <td>vad</td>\n",
       "      <td></td>\n",
       "      <td>vad</td>\n",
       "      <td>V</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>välismaaa</td>\n",
       "      <td>välismaa</td>\n",
       "      <td>välis_maa</td>\n",
       "      <td>('välis', 'maa')</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>sg g</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td></td>\n",
       "      <td>välismaa</td>\n",
       "      <td>välis_maa</td>\n",
       "      <td>('välis', 'maa')</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>sg n</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>meestele</td>\n",
       "      <td>meene</td>\n",
       "      <td>meene</td>\n",
       "      <td>('meene',)</td>\n",
       "      <td>tele</td>\n",
       "      <td></td>\n",
       "      <td>pl all</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td></td>\n",
       "      <td>mees</td>\n",
       "      <td>mees</td>\n",
       "      <td>('mees',)</td>\n",
       "      <td>tele</td>\n",
       "      <td></td>\n",
       "      <td>pl all</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>mehale</td>\n",
       "      <td>mees</td>\n",
       "      <td>mees</td>\n",
       "      <td>('mees',)</td>\n",
       "      <td>le</td>\n",
       "      <td></td>\n",
       "      <td>sg all</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td></td>\n",
       "      <td>meha</td>\n",
       "      <td>meha</td>\n",
       "      <td>('meha',)</td>\n",
       "      <td>le</td>\n",
       "      <td></td>\n",
       "      <td>sg all</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>('...',)</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Ja</td>\n",
       "      <td>ja</td>\n",
       "      <td>ja</td>\n",
       "      <td>('ja',)</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>J</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>siis</td>\n",
       "      <td>siis</td>\n",
       "      <td>siis</td>\n",
       "      <td>('siis',)</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td></td>\n",
       "      <td>siis</td>\n",
       "      <td>siis</td>\n",
       "      <td>('siis',)</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>J</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>on</td>\n",
       "      <td>olema</td>\n",
       "      <td>ole</td>\n",
       "      <td>('ole',)</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>b</td>\n",
       "      <td>V</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td></td>\n",
       "      <td>olema</td>\n",
       "      <td>ole</td>\n",
       "      <td>('ole',)</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>vad</td>\n",
       "      <td>V</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>oops</td>\n",
       "      <td>ops</td>\n",
       "      <td>ops</td>\n",
       "      <td>('ops',)</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>sg n</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td></td>\n",
       "      <td>ups</td>\n",
       "      <td>ups</td>\n",
       "      <td>('ups',)</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>sg n</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>....</td>\n",
       "      <td>....</td>\n",
       "      <td>....</td>\n",
       "      <td>('....',)</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Z</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "Layer(name='morph_analysis', attributes=('lemma', 'root', 'root_tokens', 'ending', 'clitic', 'form', 'partofspeech'), spans=SL[AmbiguousSpan('neet', [{'lemma': 'neet', 'root': 'neet', 'root_tokens': ('neet',), 'ending': '0', 'clitic': '', 'form': 'sg n', 'partofspeech': 'S'}, {'lemma': 'see', 'root': 'see', 'root_tokens': ('see',), 'ending': 'd', 'clitic': '', 'form': 'pl n', 'partofspeech': 'P'}]),\n",
       "AmbiguousSpan('eesti', [{'lemma': 'eesti', 'root': 'eesti', 'root_tokens': ('eesti',), 'ending': '0', 'clitic': '', 'form': '', 'partofspeech': 'G'}]),\n",
       "AmbiguousSpan('naised', [{'lemma': 'naine', 'root': 'naine', 'root_tokens': ('naine',), 'ending': 'd', 'clitic': '', 'form': 'pl n', 'partofspeech': 'S'}]),\n",
       "AmbiguousSpan(',', [{'lemma': ',', 'root': ',', 'root_tokens': (',',), 'ending': '', 'clitic': '', 'form': '', 'partofspeech': 'Z'}]),\n",
       "AmbiguousSpan('kes', [{'lemma': 'kes', 'root': 'kes', 'root_tokens': ('kes',), 'ending': '0', 'clitic': '', 'form': 'pl n', 'partofspeech': 'P'}, {'lemma': 'kes', 'root': 'kes', 'root_tokens': ('kes',), 'ending': '0', 'clitic': '', 'form': 'sg n', 'partofspeech': 'P'}]),\n",
       "AmbiguousSpan('lähevad', [{'lemma': 'minema', 'root': 'mine', 'root_tokens': ('mine',), 'ending': 'vad', 'clitic': '', 'form': 'vad', 'partofspeech': 'V'}]),\n",
       "AmbiguousSpan('välismaaa', [{'lemma': 'välismaa', 'root': 'välis_maa', 'root_tokens': ('välis', 'maa'), 'ending': '0', 'clitic': '', 'form': 'sg g', 'partofspeech': 'S'}, {'lemma': 'välismaa', 'root': 'välis_maa', 'root_tokens': ('välis', 'maa'), 'ending': '0', 'clitic': '', 'form': 'sg n', 'partofspeech': 'S'}]),\n",
       "AmbiguousSpan('meestele', [{'lemma': 'meene', 'root': 'meene', 'root_tokens': ('meene',), 'ending': 'tele', 'clitic': '', 'form': 'pl all', 'partofspeech': 'A'}, {'lemma': 'mees', 'root': 'mees', 'root_tokens': ('mees',), 'ending': 'tele', 'clitic': '', 'form': 'pl all', 'partofspeech': 'S'}]),\n",
       "AmbiguousSpan('mehale', [{'lemma': 'mees', 'root': 'mees', 'root_tokens': ('mees',), 'ending': 'le', 'clitic': '', 'form': 'sg all', 'partofspeech': 'S'}, {'lemma': 'meha', 'root': 'meha', 'root_tokens': ('meha',), 'ending': 'le', 'clitic': '', 'form': 'sg all', 'partofspeech': 'S'}]),\n",
       "AmbiguousSpan('...', [{'lemma': '...', 'root': '...', 'root_tokens': ('...',), 'ending': '', 'clitic': '', 'form': '', 'partofspeech': 'Z'}]),\n",
       "AmbiguousSpan('Ja', [{'lemma': 'ja', 'root': 'ja', 'root_tokens': ('ja',), 'ending': '0', 'clitic': '', 'form': '', 'partofspeech': 'J'}]),\n",
       "AmbiguousSpan('siis', [{'lemma': 'siis', 'root': 'siis', 'root_tokens': ('siis',), 'ending': '0', 'clitic': '', 'form': '', 'partofspeech': 'D'}, {'lemma': 'siis', 'root': 'siis', 'root_tokens': ('siis',), 'ending': '0', 'clitic': '', 'form': '', 'partofspeech': 'J'}]),\n",
       "AmbiguousSpan('on', [{'lemma': 'olema', 'root': 'ole', 'root_tokens': ('ole',), 'ending': '0', 'clitic': '', 'form': 'b', 'partofspeech': 'V'}, {'lemma': 'olema', 'root': 'ole', 'root_tokens': ('ole',), 'ending': '0', 'clitic': '', 'form': 'vad', 'partofspeech': 'V'}]),\n",
       "AmbiguousSpan('oops', [{'lemma': 'ops', 'root': 'ops', 'root_tokens': ('ops',), 'ending': '0', 'clitic': '', 'form': 'sg n', 'partofspeech': 'S'}, {'lemma': 'ups', 'root': 'ups', 'root_tokens': ('ups',), 'ending': '0', 'clitic': '', 'form': 'sg n', 'partofspeech': 'S'}]),\n",
       "AmbiguousSpan('....', [{'lemma': '....', 'root': '....', 'root_tokens': ('....',), 'ending': '', 'clitic': '', 'form': '', 'partofspeech': 'Z'}])])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for word in text.words:\n",
    "    if word.text == 'neet':\n",
    "        word.annotations[0].normalized_form = ['neet', 'need']\n",
    "    if word.text == 'välismaaa':\n",
    "        word.annotations[0].normalized_form = ['välismaa']\n",
    "    if word.text == 'mehale':\n",
    "        word.annotations[0].normalized_form = ['mehele', 'mehale']\n",
    "    if word.text == 'oops':\n",
    "        word.annotations[0].normalized_form = ['ops', 'ups']\n",
    "vm_analyser.tag(text)\n",
    "text.morph_analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guessing switched off\n",
    "vm_analyser_wo_guesser = VabamorfAnalyzer(guess = False, propername=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h4>Layer</h4>\n",
       "\n",
       "\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>layer name</th>\n",
       "      <th>attributes</th>\n",
       "      <th>parent</th>\n",
       "      <th>enveloping</th>\n",
       "      <th>ambiguous</th>\n",
       "      <th>span count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>morph_analysis</td>\n",
       "      <td>lemma, root, root_tokens, ending, clitic, form, partofspeech</td>\n",
       "      <td>words</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>text</th>\n",
       "      <th>lemma</th>\n",
       "      <th>root</th>\n",
       "      <th>root_tokens</th>\n",
       "      <th>ending</th>\n",
       "      <th>clitic</th>\n",
       "      <th>form</th>\n",
       "      <th>partofspeech</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>appppi</td>\n",
       "      <td>abi</td>\n",
       "      <td>abi</td>\n",
       "      <td>('abi',)</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>adt</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td></td>\n",
       "      <td>appi</td>\n",
       "      <td>appi</td>\n",
       "      <td>('appi',)</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>I</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td></td>\n",
       "      <td>abi</td>\n",
       "      <td>abi</td>\n",
       "      <td>('abi',)</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>sg g</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td></td>\n",
       "      <td>abi</td>\n",
       "      <td>abi</td>\n",
       "      <td>('abi',)</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>sg n</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td></td>\n",
       "      <td>abi</td>\n",
       "      <td>abi</td>\n",
       "      <td>('abi',)</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>sg p</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>ma</td>\n",
       "      <td>mina</td>\n",
       "      <td>mina</td>\n",
       "      <td>('mina',)</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>sg n</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>niiiii</td>\n",
       "      <td>nii</td>\n",
       "      <td>nii</td>\n",
       "      <td>('nii',)</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>niiii</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>õnnnelik</td>\n",
       "      <td>õnnnelik</td>\n",
       "      <td>õnn_nelik</td>\n",
       "      <td>('õnn', 'nelik')</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>sg n</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>,</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>naq</td>\n",
       "      <td>nagu</td>\n",
       "      <td>nagu</td>\n",
       "      <td>('nagu',)</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td></td>\n",
       "      <td>nagu</td>\n",
       "      <td>nagu</td>\n",
       "      <td>('nagu',)</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>J</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>jessss</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>('...',)</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Z</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "Layer(name='morph_analysis', attributes=('lemma', 'root', 'root_tokens', 'ending', 'clitic', 'form', 'partofspeech'), spans=SL[AmbiguousSpan('appppi', [{'lemma': 'abi', 'root': 'abi', 'root_tokens': ('abi',), 'ending': '0', 'clitic': '', 'form': 'adt', 'partofspeech': 'S'}, {'lemma': 'appi', 'root': 'appi', 'root_tokens': ('appi',), 'ending': '0', 'clitic': '', 'form': '', 'partofspeech': 'I'}, {'lemma': 'abi', 'root': 'abi', 'root_tokens': ('abi',), 'ending': '0', 'clitic': '', 'form': 'sg g', 'partofspeech': 'S'}, {'lemma': 'abi', 'root': 'abi', 'root_tokens': ('abi',), 'ending': '0', 'clitic': '', 'form': 'sg n', 'partofspeech': 'S'}, {'lemma': 'abi', 'root': 'abi', 'root_tokens': ('abi',), 'ending': '0', 'clitic': '', 'form': 'sg p', 'partofspeech': 'S'}]),\n",
       "AmbiguousSpan('ma', [{'lemma': 'mina', 'root': 'mina', 'root_tokens': ('mina',), 'ending': '0', 'clitic': '', 'form': 'sg n', 'partofspeech': 'P'}]),\n",
       "AmbiguousSpan('niiiii', [{'lemma': 'nii', 'root': 'nii', 'root_tokens': ('nii',), 'ending': '0', 'clitic': '', 'form': '', 'partofspeech': 'D'}]),\n",
       "AmbiguousSpan('niiii', [{'lemma': None, 'root': None, 'root_tokens': None, 'ending': None, 'clitic': None, 'form': None, 'partofspeech': None}]),\n",
       "AmbiguousSpan('õnnnelik', [{'lemma': 'õnnnelik', 'root': 'õnn_nelik', 'root_tokens': ('õnn', 'nelik'), 'ending': '0', 'clitic': '', 'form': 'sg n', 'partofspeech': 'S'}]),\n",
       "AmbiguousSpan(',', [{'lemma': None, 'root': None, 'root_tokens': None, 'ending': None, 'clitic': None, 'form': None, 'partofspeech': None}]),\n",
       "AmbiguousSpan('naq', [{'lemma': 'nagu', 'root': 'nagu', 'root_tokens': ('nagu',), 'ending': '0', 'clitic': '', 'form': '', 'partofspeech': 'D'}, {'lemma': 'nagu', 'root': 'nagu', 'root_tokens': ('nagu',), 'ending': '0', 'clitic': '', 'form': '', 'partofspeech': 'J'}]),\n",
       "AmbiguousSpan('jessss', [{'lemma': None, 'root': None, 'root_tokens': None, 'ending': None, 'clitic': None, 'form': None, 'partofspeech': None}]),\n",
       "AmbiguousSpan('...', [{'lemma': '...', 'root': '...', 'root_tokens': ('...',), 'ending': '', 'clitic': '', 'form': '', 'partofspeech': 'Z'}])])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from estnltk import Text\n",
    "\n",
    "text = Text('''appppi ma niiiii niiii õnnnelik , naq jessss ...''')\n",
    "text.tag_layer(['words', 'sentences'])\n",
    "\n",
    "for word in text.words:\n",
    "    if word.text == 'appppi':\n",
    "        word.annotations[0].normalized_form = ['appi', 'abi']\n",
    "    if word.text == 'niiiii':\n",
    "        word.annotations[0].normalized_form = ['nii']\n",
    "    if word.text == 'naq':\n",
    "        word.annotations[0].normalized_form = ['nagu']\n",
    "vm_analyser_wo_guesser.tag(text)\n",
    "text.morph_analysis"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
