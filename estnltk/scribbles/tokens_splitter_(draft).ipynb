{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üõ†Ô∏è TokenSplitter "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import regex as re\n",
    "\n",
    "from estnltk import Text, Layer, Annotation\n",
    "from estnltk.taggers import Retagger\n",
    "\n",
    "class TokenSplitter( Retagger ):\n",
    "    \"\"\"Splits tokens into smaller tokens based on regular expression patterns.\"\"\" \n",
    "    conf_param = ['patterns', 'break_group_name']\n",
    "    \n",
    "    def __init__(self, patterns, break_group_name:str='end'):\n",
    "        # Set input/output layers\n",
    "        self.input_layers = ['tokens']\n",
    "        self.output_layer = 'tokens'\n",
    "        self.output_attributes = ()\n",
    "        # Set other configuration parameters\n",
    "        if not (isinstance(break_group_name, str) and len(break_group_name) > 0):\n",
    "            raise TypeError('(!) break_group_name should be a non-empty string.')\n",
    "        self.break_group_name = break_group_name\n",
    "        # Assert that all patterns are regular expressions in the valid format\n",
    "        if not isinstance(patterns, list):\n",
    "            raise TypeError('(!) patterns should be a list of compiled regular expressions.')\n",
    "        # TODO: we use an adhoc way to verify that patterns are regular expressions \n",
    "        #       because there seems to be no common way of doing it both in py35 \n",
    "        #       and py36\n",
    "        for pat in patterns:\n",
    "            # Check for the existence of methods/attributes\n",
    "            has_match   = callable(getattr(pat, \"match\", None))\n",
    "            has_search  = callable(getattr(pat, \"search\", None))\n",
    "            has_pattern = getattr(pat, \"pattern\", None) is not None\n",
    "            for (k,v) in (('method match()',has_match),\\\n",
    "                          ('method search()',has_search),\\\n",
    "                          ('attribute pattern',has_pattern)):\n",
    "                if v is False:\n",
    "                    raise TypeError('(!) Unexpected regex pattern: {!r} is missing {}.'.format(pat, k))\n",
    "            symbolic_groups = pat.groupindex\n",
    "            if self.break_group_name not in symbolic_groups.keys():\n",
    "                raise TypeError('(!) Pattern {!r} is missing symbolic group named {!r}.'.format(pat, self.break_group_name))\n",
    "        self.patterns = patterns\n",
    "\n",
    "    def _change_layer(self, text, layers, status):\n",
    "        # Get changeble layer\n",
    "        changeble_layer = layers[self.output_layer]\n",
    "        # Iterate over tokens\n",
    "        add_spans    = []\n",
    "        remove_spans = []\n",
    "        for span in changeble_layer:\n",
    "            token_str = text.text[span.start:span.end]\n",
    "            for pat in self.patterns:\n",
    "                m = pat.search(token_str)\n",
    "                if m:\n",
    "                    break_group_end = m.end( self.break_group_name )\n",
    "                    if break_group_end > -1 and \\\n",
    "                       break_group_end > 0  and \\\n",
    "                       break_group_end < len(token_str):\n",
    "                        # Make the split\n",
    "                        add_spans.append( (span.start, span.start+break_group_end) )\n",
    "                        add_spans.append( (span.start+break_group_end, span.end) )\n",
    "                        remove_spans.append( span )\n",
    "                        # Once a token has been split, then break and move on to \n",
    "                        # the next token ...\n",
    "                        break\n",
    "        if add_spans:\n",
    "            assert len(remove_spans) > 0\n",
    "            for old_span in remove_spans:\n",
    "                changeble_layer.remove_span( old_span )\n",
    "            for new_span in add_spans:\n",
    "                changeble_layer.add_annotation( new_span )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 1: applying TokenSplitter on old language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h4>Layer</h4>\n",
       "\n",
       "\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>layer name</th>\n",
       "      <th>attributes</th>\n",
       "      <th>parent</th>\n",
       "      <th>enveloping</th>\n",
       "      <th>ambiguous</th>\n",
       "      <th>span count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>tokens</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>Linnasekret√§r</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>U</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>J√µgi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>luges</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>linnawolikogu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>dets</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>koosoleku</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>protokolli</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>ette</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Too</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>oli</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>krahw</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Manteufelli</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>maat√ºki</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>m√º√ºgi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>asjas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "Layer(name='tokens', attributes=(), spans=SL[Span('Linnasekret√§r', [{}]),\n",
       "Span('U', [{}]),\n",
       "Span('.', [{}]),\n",
       "Span('J√µgi', [{}]),\n",
       "Span('luges', [{}]),\n",
       "Span('linnawolikogu', [{}]),\n",
       "Span('20', [{}]),\n",
       "Span('dets', [{}]),\n",
       "Span('.', [{}]),\n",
       "Span('1920', [{}]),\n",
       "Span('a', [{}]),\n",
       "Span('.', [{}]),\n",
       "Span('koosoleku', [{}]),\n",
       "Span('protokolli', [{}]),\n",
       "Span('ette', [{}]),\n",
       "Span('.', [{}]),\n",
       "Span('Too', [{}]),\n",
       "Span('oli', [{}]),\n",
       "Span('krahw', [{}]),\n",
       "Span('Manteufelli', [{}]),\n",
       "Span('maat√ºki', [{}]),\n",
       "Span('m√º√ºgi', [{}]),\n",
       "Span('asjas', [{}]),\n",
       "Span('.', [{}])])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_splitter = TokenSplitter(patterns=[re.compile('[0-9]*(?P<end>[0-9])[a-z√º√µ√∂√§]+'),\\\n",
    "                                         re.compile('[a-z√º√µ√∂√§]+(?P<end>[a-z√º√µ√∂√§])[A-Z√ú√ï√ñ√Ñ][a-z√º√µ√∂√§]+')])\n",
    "\n",
    "t=Text('Linnasekret√§r U.J√µgi luges linnawolikogu 20dets.1920a.koosoleku protokolli ette. '+\\\n",
    "       'Too oli krahwManteufelli maat√ºki m√º√ºgi asjas.')\n",
    "t.tag_layer(['tokens'])\n",
    "token_splitter.retag(t)\n",
    "t.tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 2: applying TokenSplitter on Internet language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h4>Layer</h4>\n",
       "\n",
       "\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>layer name</th>\n",
       "      <th>attributes</th>\n",
       "      <th>parent</th>\n",
       "      <th>enveloping</th>\n",
       "      <th>ambiguous</th>\n",
       "      <th>span count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>tokens</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>Ma</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>i</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>tea</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>v√§lja</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>valitud</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>ja</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>√ºmber</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>l√ºkatud</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>asjad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>ise</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>tead</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>mis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>teed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>nendega</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "Layer(name='tokens', attributes=(), spans=SL[Span('Ma', [{}]),\n",
       "Span('i', [{}]),\n",
       "Span('tea', [{}]),\n",
       "Span(',', [{}]),\n",
       "Span('v√§lja', [{}]),\n",
       "Span('valitud', [{}]),\n",
       "Span('ja', [{}]),\n",
       "Span('√ºmber', [{}]),\n",
       "Span('l√ºkatud', [{}]),\n",
       "Span('asjad', [{}]),\n",
       "Span('-', [{}]),\n",
       "Span('-', [{}]),\n",
       "Span('ise', [{}]),\n",
       "Span('tead', [{}]),\n",
       "Span('mis', [{}]),\n",
       "Span('teed', [{}]),\n",
       "Span('nendega', [{}])])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_splitter = TokenSplitter(patterns=[re.compile('(?P<end>ma|ise)[a-z√º√µ√∂√§]+', re.I),\\\n",
    "                                         re.compile('(?P<end>√ºmber|v√§lja)[a-z√º√µ√∂√§]+')])\n",
    "\n",
    "t=Text('Mai tea, v√§ljavalitud ja √ºmberl√ºkatud asjad -- isetead mis teed nendega'+\\\n",
    "       '')\n",
    "t.tag_layer(['tokens'])\n",
    "token_splitter.retag(t)\n",
    "t.tokens"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
