{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training CRF-NER model from CNLL-files\n",
    "To train a new model the following steps have to be carried out:\n",
    "* Loading NER-labellings from file\n",
    "* Training a new model\n",
    "* Measuring model performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading NER-labelings from files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from estnltk.converters.conll.conll_ner_importer import conll_to_ner_labelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td><div align = \"left\">Tallinna õhusaaste suureneb . Kuigi möödunud nädala ühel ööl ootamatult kõrgeks tõusnud õhusaaste oli pealinna jaoks haruldane rekord , liigub linnaõhu saastekõver järjekindlalt ülespoole , konkureerides teiste Euroopa pealinnadega . Nagu kirjutab Postimees , registreeriti Taksopargi õhuseirejaamas 11.märtsil Tallinna õhusaastumise rekord . Kuigi kümme aastat tagasi oli pealinna õhk praegusest märksa mustem , ei vabanda see linna keskkonnaspetsialistide sõnul linnaõhu taas halvemaks muutumist . Linna kolmes mõõtejaamas mõõdetakse paar-kolm korda aastas rekordilist õhusaastet , kuid aeglaselt ronib ülespoole ka keskmise saaste näit . Näiteks sisaldub linnaõhus mõõtmiste järgi keskmiselt ööpäevas täpselt sama palju peentolmu , kui näeb ette lubatud piirnorm . Norm , 24 tunni keskmine , on 50 mikrogrammi kuupmeetri kohta ja seda võib ületada 35 päeval aastas , mida seni pole õnneks ette tulnud . Tallinna keskkonnaameti keskkonnahoiu osakonna juhataja Madis Kõrvits ütles , et üksikud kõrged näidud ei muuda Tallinna õhku veel kõlbmatuks , kuid rõõmustada pole samuti millegi üle , sest 2000. aastal pealinnas olnud hea õhk on hakanud autode juurdevoolu tõttu taas saastuma . “ Samas pole paanikaks põhjust , ” sõnas Kõrvits . “ Kui saaste hetkeliselt tõuseb , tasub olla toas , pikaajalist ohtu aga pole. ” Ta tõi näiteks eelmise nädala rekordpäeva , mil tervisele kahjulik saaste oli õhus vaid mõne tunni  — nii vähe aega , et keskkonnaametnikel polnud seadusega ette nähtud inimesi hoiatada . Kui võrrelda Tallinna õhu saastatust naabruses asuvate suurlinnadega , selgub , et tulemused on üsna sarnased ja meie linn on õigusega Euroopa pealinnade seas . Kõrvits ütles , et kui Tallinnas tõuseb peentolmu sisaldus õhus taksopargi ristmikul õhtuti 250 mikrogrammini kuupmeetri kohta , siis Helsingis näitab mõõtur sama taset kesklinnas hommikusel tipptunnil . Stockholmi õhk on Tallinna omast tunduvalt puhtam , kuid Göteborgis kerkib saastenäitur kuni 200 mikrogrammini kuupmeetri kohta . Teiste Eesti linnadega on Tallinna raske võrrelda , näiteks Tartus mõõdetakse õhupuhtust vaid ajutiselt suvel . Nüüd on see paik juba suvest alates vaid jalakäijate päralt . Kõrvits ütles , et ööl vastu 11. märtsi toimunut võib nimetada õigusega ebasoodsate asjaolude kokkulangemiseks . Selle talve kohta üks käredama pakasega ilmu pani linlased ahje kütma , samas tossasid käivitamisel ja soojendamisel kindlasti rohkem ka õhtul koju minejate autod . Suure panuse rekordi sündimisele andsid ka peaaegu olematu tuul ning õhukihtide liikumatus . Kõrvitsa sõnul ongi just talv see aeg , mil õhusaaste linnas tõuseb . “ Kütmine ja autode soojendamine annab siin kindlasti suure osa , ” märkis Kõrvits . Keskkonnaametniku sõnul ei ole ametnikel ega keskkonnakaitsjatel mingit imejõudu pealinna õhu puhastamiseks . Aitab vaid autostumise kasvu piiramine , vähendades liiklust linnasüdames ning suurendades keskkonnasäästliku elektri-ühistranspordi osa linnas . “ Igaühel tasub iga päev mõelda , kas minna äkki tööle jalgratta või ühissõidukiga või hoopis kõndida veidi jala , ” nentis Kõrvits . Politseid vihastab pätiplaani avalikustamine . Politseid pahandab , et justiitsministeerium avalikustas nende asutusesiseseks kasutamiseks mõeldud kuritegevuse avastamise plaanid . Põhja politseiprefektuuris on tegeldud kriminaalasjade etteplaneerimisega , teatas justiitsministeeriumi reedel Delfile . Avalikustamine oli politseile halb üllatus , sest dokumentide sisu kaitseks oli neile löödud tempel “ asutusesiseseks kasutamiseks ” , kirjutab Eesti Päevaleht . “ Politsei lepingute valguses tundub , et meie viga on olnud see , et oleme asju ajanud avalikult ja püüdnud selgitada , ” ütles justiitsministeeriumi endine asekantsler , juhtiv riigiprokurör Margus Kurm . Riigi politseijuhi Robert Antropovi ja Põhja politseiprefekti Raivo Küüdi vahel selleks aastaks sõlmitud tulemusleping märgib , et kui eelmisel aastal avastati 13 grupiviisilist narkokuritegu , siis tänavu tuleb neid rohkem avastada . Põhja politseinikud peavad tänavu taotlema ja kohaldama ka rohkem areste narkokurjategijate jaoks . Sarnased punktid on ka 2004. aasta tulemuslepingus . “ Politsei peab aastas tegelema umbes 55 000 kriminaalasjaga ning me tahame , et meie tegevus muutuks iga aastaga endisest tõhusamaks , ” ütles eesmärkide kohta Antropov . “ Näiteks peab tapmiste avastamine protsentuaalselt kasvama , peab olema kinni peetud senisest rohkem roolijoodikuid , narkosuurdiilereid. ” Siseminister Margus Leivo sõnul pole talle alluva politsei tulemuslepingud ja justiitsminister Ken-Mart Vaherile alluva prokuratuuri mõõdikuteprojekt võrreldavad . “ Need ikka erinevad personaaliani viidud mõõdikutest , ” kaitses Leivo . “ Need erinevad juba suundumustelt ega ole seatud administratiivsete piirkondade kaupa. ” Samas on politseiameti koduleheküljel kirjas , et kõigepealt sõlmib politsei peadirektor tulemuslepingud keskkriminaalpolitsei , julgestuspolitsei ning nelja prefektuuri juhtidega ning seejärel sõlmivad prefektid omakorda tulemuslepingud neile alluvate piirkondlike osakondade juhtidega . Mees ajas ülekäigurajal naise alla . Keskealine naine jäi laupäeval Tallinnas reguleeritud ülekäigurajal auto alla ning sai vigastada . Klenski süüdistab Laari Estonia uputamises . Parvlaeva Estonia uppumise põhjustas tollase peaministri Mart Laari käsul saamatult avatud visiir , et salakaubast lahti saada , kirjutab Dimitri Klenski Kesknädalas . Klenski väidab , et üsna paljugi sellest , millest täna Rootsis kõneldakse , oli meile teada juba 1996. aasta sügisel . “ Pretendeerimata lõpliku tõe väljaütlemisele , tahan püstitada versiooni , millega tutvustas mind Eesti Vabariigi kaitsejõudude leitnant Tiit Uustalu. ” Uustalu väitel veeti parvlaeval salakaubana ühele Rootsi tehasele Venemaalt varastatud strateegilist toorainest . “ Selle tehase omanikuks oli firma , mille aktsiapakist üle poole kuulus Rootsi riigile . Selle tehingu vastu ilmutas oma huvi ka Eesti Kaitseministeerium , mille teisel korrusel “ räägiti üksnes inglise keeles ” . Teadaolevalt täitsid tol ajal meie kaitseasutuse kohalekomandeeritud natolased , ” nendib Klenski . Parvlaeva lossimisel aga afäär laadungiga paljastus , mistõttu laeva randumine Stockholmis ähvardas tekitada ulatusliku skandaali ja võis põhjustada Rootsi riigi prestiiži languse , kirjutab Klenski . Seejärel järgnenud Stockholmist telefonikõne tollasele Eesti peaministrile Mart Laarile . Selleks ajaks oli aga parvlaev juba tormisel merel . „ Leitnant Uustalu kinnitas , et kaitsejõudude staabis on tallel kaks-kolm tundi enne laevahukku tehtud kõnesalvestused peaminister Laari vestlusest Estonia kapteniga , ” kirjutab Klenski . „ Laar nõudis kategooriliselt lasti viskamist merre . Nii otsustatigi toimida . Ent keegi ei osanud arvata , et täiskäigul liikuva laeva avatud visiir rebeneb tormisel merel hirmsa jõuga lahti . Vesi tungis autotekile . Laev hakkas uppuma. ” Parvlaev Estonia hukkus 1994. aastal 28. septmebril tormisel Balti merel teel Tallinnast Stockholmi , viies koos endaga märga hauda 852 inimelu . Vene väed võivad Gruusiast lahkuda . Venemaa võib alustada vägede väljaviimist Gruusiast sel aastal , teatas välisminister Sergei Lavrov ajakirjanikele pärast kohtumist oma Gruusia kolleegiga . Lavrov kinnitas , et kahe riigi välisministri kohtumisel saavutati sisuline edasiminek Vene vägede Gruusiast väljaviimise osas , vahendab ETV Gazeta.ru uudist . Lavrovi kinnitusel jõuti üksmeelele , et vägede lahkumine on järk-järguline ning algab lõpliku kokkuleppe saavutamisel juba sel aastal . Läbirääkimised Vene vägede väljaviimise üle algasid 2001. aastal . Seni on Gruusia pakkunud väljaviimiseks kolmeaastast tähtaega , Venemaa aga ei soovi lahkuda enne kaheksat aastat . Praegu on Gruusias Batumi baasis 2,5 tuhat meest ja 74 tanki , 80 soomukit ja 120 suurtükki , Ahhalkalki baasis 2 tuhat meest , 40 tanki , 130 soomukit ja 50 suurtükki . Lisaks varustatakse Gruusia kaudu Armeenias Gjurmis asuvat 3000-mehelist Vene baasi . Verine kaklus </br></br>&lt;skipping 23482 characters&gt;</br></br>Blair esinedes ärimeestele . Juunis pani Blair veto ettepanekule , millega oleks külmutatud Briti tagasimakse suurus tulevikus . Kutsekoolide õpetajatel napib õiget haridust . Vähemalt veerandi kutsekoolide õpetajatest peaks haridusministeeriumi järelevalve tulemuste kohaselt saatma ümberõppele . Mullu 11 kutsekoolis tehtud järelevalve uuring näitas , et 14 protsenti erialase kutseõppe ja 22 protsenti üldhariduslikke aineid õpetavate pedagoogide teadmised ei vasta nõuetele , kirjutab Postimees . Järelevalvearuandes märgitakse , et probleemi lahendamiseks on äärmiselt oluline kutseõpetajate täiend - ja ümberõpe . Peaprobleem on haridusministeeriumi järelevalvetalituse juhataja Hille Vooremäe sõnul selles , et üldhariduses polnud õpetajatel kõrgharidust õpetatavas valdkonnas ja kutseõpetajatel konkreetse õppekava valdkonnas . “ Tulemuse viis alla ka see , et suur osa oli eraõppeasutusi — eriti mõjutas tulemusi halvemuse suunas üks konkreetne kool — R-Stamp Tallinnas , ” märkis Vooremäe .</div></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>layer name</th>\n",
       "      <th>attributes</th>\n",
       "      <th>parent</th>\n",
       "      <th>enveloping</th>\n",
       "      <th>ambiguous</th>\n",
       "      <th>span count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>sentences</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>words</td>\n",
       "      <td>False</td>\n",
       "      <td>270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>compound_tokens</td>\n",
       "      <td>type, normalized</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>words</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>4723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>morph_analysis</td>\n",
       "      <td>normalized_text, lemma, root, root_tokens, ending, clitic, form, partofspeech</td>\n",
       "      <td>words</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>4723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>wordner</td>\n",
       "      <td>nertag</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>4723</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "Text(text='Tallinna õhusaaste suureneb . Kuigi möödunud nädala ühel ööl ootamatult kõrgeks tõusnud õhusaaste oli pealinna jaoks haruldane rekord , liigub linnaõhu saastekõver järjekindlalt ülespoole , konkureerides teiste Euroopa pealinnadega . Nagu kirjutab Postimees , registreeriti Taksopargi õhuseirejaamas 11.märtsil Tallinna õhusaastumise rekord . Kuigi kümme aastat tagasi oli pealinna õhk praegusest märksa mustem , ei vabanda see linna keskkonnaspetsialistide sõnul linnaõhu taas halvemaks muutumist . Linna kolmes mõõtejaamas mõõdetakse paar-kolm korda aastas rekordilist õhusaastet , kuid aeglaselt ronib ülespoole ka keskmise saaste näit . Näiteks sisaldub linnaõhus mõõtmiste järgi keskmiselt ööpäevas täpselt sama palju peentolmu , kui näeb ette lubatud piirnorm . Norm , 24 tunni keskmine , on 50 mikrogrammi kuupmeetri kohta ja seda võib ületada 35 päeval aastas , mida seni pole õnneks ette tulnud . Tallinna keskkonnaameti keskkonnahoiu osakonna juhataja Madis Kõrvits ütles , et üksikud kõrged näidud ei muuda Tallinna õhku veel kõlbmatuks , kuid rõõmustada pole samuti millegi üle , sest 2000. aastal pealinnas olnud hea õhk on hakanud autode juurdevoolu tõttu taas saastuma . “ Samas pole paanikaks põhjust , ” sõnas Kõrvits . “ Kui saaste hetkeliselt tõuseb , tasub olla toas , pikaajalist ohtu aga pole. ” Ta tõi näiteks eelmise nädala rekordpäeva , mil tervisele kahjulik saaste oli õhus vaid mõne tunni\\xa0 — nii vähe aega , et keskkonnaametnikel polnud seadusega ette nähtud inimesi hoiatada . Kui võrrelda Tallinna õhu saastatust naabruses asuvate suurlinnadega , selgub , et tulemused on üsna sarnased ja meie linn on õigusega Euroopa pealinnade seas . Kõrvits ütles , et kui Tallinnas tõuseb peentolmu sisaldus õhus taksopargi ristmikul õhtuti 250 mikrogrammini kuupmeetri kohta , siis Helsingis näitab mõõtur sama taset kesklinnas hommikusel tipptunnil . Stockholmi õhk on Tallinna omast tunduvalt puhtam , kuid Göteborgis kerkib saastenäitur kuni 200 mikrogrammini kuupmeetri kohta . Teiste Eesti linnadega on Tallinna raske võrrelda , näiteks Tartus mõõdetakse õhupuhtust vaid ajutiselt suvel . Nüüd on see paik juba suvest alates vaid jalakäijate päralt . Kõrvits ütles , et ööl vastu 11. märtsi toimunut võib nimetada õigusega ebasoodsate asjaolude kokkulangemiseks . Selle talve kohta üks käredama pakasega ilmu pani linlased ahje kütma , samas tossasid käivitamisel ja soojendamisel kindlasti rohkem ka õhtul koju minejate autod . Suure panuse rekordi sündimisele andsid ka peaaegu olematu tuul ning õhukihtide liikumatus . Kõrvitsa sõnul ongi just talv see aeg , mil õhusaaste linnas tõuseb . “ Kütmine ja autode soojendamine annab siin kindlasti suure osa , ” märkis Kõrvits . Keskkonnaametniku sõnul ei ole ametnikel ega keskkonnakaitsjatel mingit imejõudu pealinna õhu puhastamiseks . Aitab vaid autostumise kasvu piiramine , vähendades liiklust linnasüdames ning suurendades keskkonnasäästliku elektri-ühistranspordi osa linnas . “ Igaühel tasub iga päev mõelda , kas minna äkki tööle jalgratta või ühissõidukiga või hoopis kõndida veidi jala , ” nentis Kõrvits . Politseid vihastab pätiplaani avalikustamine . Politseid pahandab , et justiitsministeerium avalikustas nende asutusesiseseks kasutamiseks mõeldud kuritegevuse avastamise plaanid . Põhja politseiprefektuuris on tegeldud kriminaalasjade etteplaneerimisega , teatas justiitsministeeriumi reedel Delfile . Avalikustamine oli politseile halb üllatus , sest dokumentide sisu kaitseks oli neile löödud tempel “ asutusesiseseks kasutamiseks ” , kirjutab Eesti Päevaleht . “ Politsei lepingute valguses tundub , et meie viga on olnud see , et oleme asju ajanud avalikult ja püüdnud selgitada , ” ütles justiitsministeeriumi endine asekantsler , juhtiv riigiprokurör Margus Kurm . Riigi politseijuhi Robert Antropovi ja Põhja politseiprefekti Raivo Küüdi vahel selleks aastaks sõlmitud tulemusleping märgib , et kui eelmisel aastal avastati 13 grupiviisilist narkokuritegu , siis tänavu tuleb neid rohkem avastada . Põhja politseinikud peavad tänavu taotlema ja kohaldama ka rohkem areste narkokurjategijate jaoks . Sarnased punktid on ka 2004. aasta tulemuslepingus . “ Politsei peab aastas tegelema umbes 55 000 kriminaalasjaga ning me tahame , et meie tegevus muutuks iga aastaga endisest tõhusamaks , ” ütles eesmärkide kohta Antropov . “ Näiteks peab tapmiste avastamine protsentuaalselt kasvama , peab olema kinni peetud senisest rohkem roolijoodikuid , narkosuurdiilereid. ” Siseminister Margus Leivo sõnul pole talle alluva politsei tulemuslepingud ja justiitsminister Ken-Mart Vaherile alluva prokuratuuri mõõdikuteprojekt võrreldavad . “ Need ikka erinevad personaaliani viidud mõõdikutest , ” kaitses Leivo . “ Need erinevad juba suundumustelt ega ole seatud administratiivsete piirkondade kaupa. ” Samas on politseiameti koduleheküljel kirjas , et kõigepealt sõlmib politsei peadirektor tulemuslepingud keskkriminaalpolitsei , julgestuspolitsei ning nelja prefektuuri juhtidega ning seejärel sõlmivad prefektid omakorda tulemuslepingud neile alluvate piirkondlike osakondade juhtidega . Mees ajas ülekäigurajal naise alla . Keskealine naine jäi laupäeval Tallinnas reguleeritud ülekäigurajal auto alla ning sai vigastada . Klenski süüdistab Laari Estonia uputamises . Parvlaeva Estonia uppumise põhjustas tollase peaministri Mart Laari käsul saamatult avatud visiir , et salakaubast lahti saada , kirjutab Dimitri Klenski Kesknädalas . Klenski väidab , et üsna paljugi sellest , millest täna Rootsis kõneldakse , oli meile teada juba 1996. aasta sügisel . “ Pretendeerimata lõpliku tõe väljaütlemisele , tahan püstitada versiooni , millega tutvustas mind Eesti Vabariigi kaitsejõudude leitnant Tiit Uustalu. ” Uustalu väitel veeti parvlaeval salakaubana ühele Rootsi tehasele Venemaalt varastatud strateegilist toorainest . “ Selle tehase omanikuks oli firma , mille aktsiapakist üle poole kuulus Rootsi riigile . Selle tehingu vastu ilmutas oma huvi ka Eesti Kaitseministeerium , mille teisel korrusel “ räägiti üksnes inglise keeles ” . Teadaolevalt täitsid tol ajal meie kaitseasutuse kohalekomandeeritud natolased , ” nendib Klenski . Parvlaeva lossimisel aga afäär laadungiga paljastus , mistõttu laeva randumine Stockholmis ähvardas tekitada ulatusliku skandaali ja võis põhjustada Rootsi riigi prestiiži languse , kirjutab Klenski . Seejärel järgnenud Stockholmist telefonikõne tollasele Eesti peaministrile Mart Laarile . Selleks ajaks oli aga parvlaev juba tormisel merel . „ Leitnant Uustalu kinnitas , et kaitsejõudude staabis on tallel kaks-kolm tundi enne laevahukku tehtud kõnesalvestused peaminister Laari vestlusest Estonia kapteniga , ” kirjutab Klenski . „ Laar nõudis kategooriliselt lasti viskamist merre . Nii otsustatigi toimida . Ent keegi ei osanud arvata , et täiskäigul liikuva laeva avatud visiir rebeneb tormisel merel hirmsa jõuga lahti . Vesi tungis autotekile . Laev hakkas uppuma. ” Parvlaev Estonia hukkus 1994. aastal 28. septmebril tormisel Balti merel teel Tallinnast Stockholmi , viies koos endaga märga hauda 852 inimelu . Vene väed võivad Gruusiast lahkuda . Venemaa võib alustada vägede väljaviimist Gruusiast sel aastal , teatas välisminister Sergei Lavrov ajakirjanikele pärast kohtumist oma Gruusia kolleegiga . Lavrov kinnitas , et kahe riigi välisministri kohtumisel saavutati sisuline edasiminek Vene vägede Gruusiast väljaviimise osas , vahendab ETV Gazeta.ru uudist . Lavrovi kinnitusel jõuti üksmeelele , et vägede lahkumine on järk-järguline ning algab lõpliku kokkuleppe saavutamisel juba sel aastal . Läbirääkimised Vene vägede väljaviimise üle algasid 2001. aastal . Seni on Gruusia pakkunud väljaviimiseks kolmeaastast tähtaega , Venemaa aga ei soovi lahkuda enne kaheksat aastat . Praegu on Gruusias Batumi baasis 2,5 tuhat meest ja 74 tanki , 80 soomukit ja 120 suurtükki , Ahhalkalki baasis 2 tuhat meest , 40 tanki , 130 soomukit ja 50 suurtükki . Lisaks varustatakse Gruusia kaudu Armeenias Gjurmis asuvat 3000-mehelist Vene baasi . Verine kaklus \\n\\n<skipping 23482 characters>\\n\\nBlair esinedes ärimeestele . Juunis pani Blair veto ettepanekule , millega oleks külmutatud Briti tagasimakse suurus tulevikus . Kutsekoolide õpetajatel napib õiget haridust . Vähemalt veerandi kutsekoolide õpetajatest peaks haridusministeeriumi järelevalve tulemuste kohaselt saatma ümberõppele . Mullu 11 kutsekoolis tehtud järelevalve uuring näitas , et 14 protsenti erialase kutseõppe ja 22 protsenti üldhariduslikke aineid õpetavate pedagoogide teadmised ei vasta nõuetele , kirjutab Postimees . Järelevalvearuandes märgitakse , et probleemi lahendamiseks on äärmiselt oluline kutseõpetajate täiend - ja ümberõpe . Peaprobleem on haridusministeeriumi järelevalvetalituse juhataja Hille Vooremäe sõnul selles , et üldhariduses polnud õpetajatel kõrgharidust õpetatavas valdkonnas ja kutseõpetajatel konkreetse õppekava valdkonnas . “ Tulemuse viis alla ka see , et suur osa oli eraõppeasutusi — eriti mõjutas tulemusi halvemuse suunas üks konkreetne kool — R-Stamp Tallinnas , ” märkis Vooremäe .')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = conll_to_ner_labelling(\"data/estner_train.cnll\")\n",
    "text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up model parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from estnltk.taggers.standard.ner.ner_trainer import NerTrainer\n",
    "from estnltk.taggers.standard.ner.model_storage_util import ModelStorageUtil\n",
    "from estnltk.common import DEFAULT_PY3_NER_MODEL_DIR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load CRFsuite model meta parameters. By default parameters are located in ... settings.py file which describes: \n",
    "* label classes (ORG, PER, LOC)\n",
    "* metaparameters for training (CRFSUITE_ALGORITHM, CRFSUITE_C2)\n",
    "* file of known entities (GAZETTEER_FILE)\n",
    "* basic features (TEMPLATES)\n",
    "* feature extractors (FEATURE_EXTRACTORS)\n",
    "\n",
    "For more details, look at CRFsuite documentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dir=DEFAULT_PY3_NER_MODEL_DIR\n",
    "modelUtil = ModelStorageUtil(model_dir)\n",
    "nersettings = modelUtil.load_settings()\n",
    "trainer = NerTrainer(nersettings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training a new model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model takes a long time to train."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature generation\n",
      "type: CRF1d\n",
      "feature.minfreq: 0.000000\n",
      "feature.possible_states: 0\n",
      "feature.possible_transitions: 0\n",
      "0....1....2....3....4....5....6....7....8....9....10\n",
      "Number of features: 24798\n",
      "Seconds required: 0.104\n",
      "\n",
      "Stochastic Gradient Descent (SGD)\n",
      "c2: 0.001000\n",
      "max_iterations: 1000\n",
      "period: 10\n",
      "delta: 0.000001\n",
      "\n",
      "Calibrating the learning rate (eta)\n",
      "calibration.eta: 0.100000\n",
      "calibration.rate: 2.000000\n",
      "calibration.samples: 270\n",
      "calibration.candidates: 10\n",
      "calibration.max_trials: 20\n",
      "Initial loss: 9190.533634\n",
      "Trial #1 (eta = 0.100000): 732.132874\n",
      "Trial #2 (eta = 0.200000): 915.204319\n",
      "Trial #3 (eta = 0.400000): 1513.678030\n",
      "Trial #4 (eta = 0.800000): 3453.184588\n",
      "Trial #5 (eta = 1.600000): 6554.839838\n",
      "Trial #6 (eta = 3.200000): 13791.726098 (worse)\n",
      "Trial #7 (eta = 0.050000): 770.178908\n",
      "Trial #8 (eta = 0.025000): 926.590375\n",
      "Trial #9 (eta = 0.012500): 1183.710466\n",
      "Trial #10 (eta = 0.006250): 1543.971301\n",
      "Trial #11 (eta = 0.003125): 2024.013267\n",
      "Trial #12 (eta = 0.001563): 2654.407046\n",
      "Trial #13 (eta = 0.000781): 3479.707624\n",
      "Trial #14 (eta = 0.000391): 4627.481258\n",
      "Trial #15 (eta = 0.000195): 6127.155526\n",
      "Trial #16 (eta = 0.000098): 7453.638654\n",
      "Best learning rate (eta): 0.100000\n",
      "Seconds required: 0.277\n",
      "\n",
      "***** Epoch #1 *****\n",
      "Loss: 703.795507\n",
      "Feature L2-norm: 11.065700\n",
      "Learning rate (eta): 0.099980\n",
      "Total number of feature updates: 270\n",
      "Seconds required for this iteration: 0.023\n",
      "\n",
      "***** Epoch #2 *****\n",
      "Loss: 195.468706\n",
      "Feature L2-norm: 13.710343\n",
      "Learning rate (eta): 0.099960\n",
      "Total number of feature updates: 540\n",
      "Seconds required for this iteration: 0.019\n",
      "\n",
      "***** Epoch #3 *****\n",
      "Loss: 93.777704\n",
      "Feature L2-norm: 15.164861\n",
      "Learning rate (eta): 0.099940\n",
      "Total number of feature updates: 810\n",
      "Seconds required for this iteration: 0.020\n",
      "\n",
      "***** Epoch #4 *****\n",
      "Loss: 54.875279\n",
      "Feature L2-norm: 16.145226\n",
      "Learning rate (eta): 0.099920\n",
      "Total number of feature updates: 1080\n",
      "Seconds required for this iteration: 0.019\n",
      "\n",
      "***** Epoch #5 *****\n",
      "Loss: 37.783523\n",
      "Feature L2-norm: 16.898648\n",
      "Learning rate (eta): 0.099900\n",
      "Total number of feature updates: 1350\n",
      "Seconds required for this iteration: 0.014\n",
      "\n",
      "***** Epoch #6 *****\n",
      "Loss: 28.746326\n",
      "Feature L2-norm: 17.495135\n",
      "Learning rate (eta): 0.099880\n",
      "Total number of feature updates: 1620\n",
      "Seconds required for this iteration: 0.029\n",
      "\n",
      "***** Epoch #7 *****\n",
      "Loss: 24.347368\n",
      "Feature L2-norm: 18.010766\n",
      "Learning rate (eta): 0.099860\n",
      "Total number of feature updates: 1890\n",
      "Seconds required for this iteration: 0.025\n",
      "\n",
      "***** Epoch #8 *****\n",
      "Loss: 20.849162\n",
      "Feature L2-norm: 18.450708\n",
      "Learning rate (eta): 0.099840\n",
      "Total number of feature updates: 2160\n",
      "Seconds required for this iteration: 0.011\n",
      "\n",
      "***** Epoch #9 *****\n",
      "Loss: 18.288427\n",
      "Feature L2-norm: 18.842744\n",
      "Learning rate (eta): 0.099820\n",
      "Total number of feature updates: 2430\n",
      "Seconds required for this iteration: 0.012\n",
      "\n",
      "***** Epoch #10 *****\n",
      "Loss: 16.539544\n",
      "Feature L2-norm: 19.192363\n",
      "Learning rate (eta): 0.099800\n",
      "Total number of feature updates: 2700\n",
      "Seconds required for this iteration: 0.016\n",
      "\n",
      "***** Epoch #11 *****\n",
      "Loss: 14.965882\n",
      "Improvement ratio: 46.026663\n",
      "Feature L2-norm: 19.514437\n",
      "Learning rate (eta): 0.099781\n",
      "Total number of feature updates: 2970\n",
      "Seconds required for this iteration: 0.030\n",
      "\n",
      "***** Epoch #12 *****\n",
      "Loss: 13.653066\n",
      "Improvement ratio: 13.316836\n",
      "Feature L2-norm: 19.808389\n",
      "Learning rate (eta): 0.099761\n",
      "Total number of feature updates: 3240\n",
      "Seconds required for this iteration: 0.016\n",
      "\n",
      "***** Epoch #13 *****\n",
      "Loss: 12.624028\n",
      "Improvement ratio: 6.428509\n",
      "Feature L2-norm: 20.077767\n",
      "Learning rate (eta): 0.099741\n",
      "Total number of feature updates: 3510\n",
      "Seconds required for this iteration: 0.016\n",
      "\n",
      "***** Epoch #14 *****\n",
      "Loss: 11.837557\n",
      "Improvement ratio: 3.635693\n",
      "Feature L2-norm: 20.327753\n",
      "Learning rate (eta): 0.099721\n",
      "Total number of feature updates: 3780\n",
      "Seconds required for this iteration: 0.014\n",
      "\n",
      "***** Epoch #15 *****\n",
      "Loss: 11.071586\n",
      "Improvement ratio: 2.412657\n",
      "Feature L2-norm: 20.564152\n",
      "Learning rate (eta): 0.099701\n",
      "Total number of feature updates: 4050\n",
      "Seconds required for this iteration: 0.021\n",
      "\n",
      "***** Epoch #16 *****\n",
      "Loss: 10.385355\n",
      "Improvement ratio: 1.767967\n",
      "Feature L2-norm: 20.784159\n",
      "Learning rate (eta): 0.099681\n",
      "Total number of feature updates: 4320\n",
      "Seconds required for this iteration: 0.021\n",
      "\n",
      "***** Epoch #17 *****\n",
      "Loss: 9.882367\n",
      "Improvement ratio: 1.463718\n",
      "Feature L2-norm: 20.992296\n",
      "Learning rate (eta): 0.099661\n",
      "Total number of feature updates: 4590\n",
      "Seconds required for this iteration: 0.012\n",
      "\n",
      "***** Epoch #18 *****\n",
      "Loss: 9.329256\n",
      "Improvement ratio: 1.234815\n",
      "Feature L2-norm: 21.188813\n",
      "Learning rate (eta): 0.099641\n",
      "Total number of feature updates: 4860\n",
      "Seconds required for this iteration: 0.017\n",
      "\n",
      "***** Epoch #19 *****\n",
      "Loss: 8.893055\n",
      "Improvement ratio: 1.056484\n",
      "Feature L2-norm: 21.374683\n",
      "Learning rate (eta): 0.099622\n",
      "Total number of feature updates: 5130\n",
      "Seconds required for this iteration: 0.019\n",
      "\n",
      "***** Epoch #20 *****\n",
      "Loss: 8.475589\n",
      "Improvement ratio: 0.951433\n",
      "Feature L2-norm: 21.552328\n",
      "Learning rate (eta): 0.099602\n",
      "Total number of feature updates: 5400\n",
      "Seconds required for this iteration: 0.017\n",
      "\n",
      "***** Epoch #21 *****\n",
      "Loss: 8.138855\n",
      "Improvement ratio: 0.838819\n",
      "Feature L2-norm: 21.721233\n",
      "Learning rate (eta): 0.099582\n",
      "Total number of feature updates: 5670\n",
      "Seconds required for this iteration: 0.022\n",
      "\n",
      "***** Epoch #22 *****\n",
      "Loss: 7.815750\n",
      "Improvement ratio: 0.746866\n",
      "Feature L2-norm: 21.882412\n",
      "Learning rate (eta): 0.099562\n",
      "Total number of feature updates: 5940\n",
      "Seconds required for this iteration: 0.008\n",
      "\n",
      "***** Epoch #23 *****\n",
      "Loss: 7.523452\n",
      "Improvement ratio: 0.677957\n",
      "Feature L2-norm: 22.036920\n",
      "Learning rate (eta): 0.099542\n",
      "Total number of feature updates: 6210\n",
      "Seconds required for this iteration: 0.010\n",
      "\n",
      "***** Epoch #24 *****\n",
      "Loss: 7.223476\n",
      "Improvement ratio: 0.638762\n",
      "Feature L2-norm: 22.184706\n",
      "Learning rate (eta): 0.099522\n",
      "Total number of feature updates: 6480\n",
      "Seconds required for this iteration: 0.010\n",
      "\n",
      "***** Epoch #25 *****\n",
      "Loss: 6.992215\n",
      "Improvement ratio: 0.583416\n",
      "Feature L2-norm: 22.327172\n",
      "Learning rate (eta): 0.099503\n",
      "Total number of feature updates: 6750\n",
      "Seconds required for this iteration: 0.005\n",
      "\n",
      "***** Epoch #26 *****\n",
      "Loss: 6.736322\n",
      "Improvement ratio: 0.541695\n",
      "Feature L2-norm: 22.464200\n",
      "Learning rate (eta): 0.099483\n",
      "Total number of feature updates: 7020\n",
      "Seconds required for this iteration: 0.006\n",
      "\n",
      "***** Epoch #27 *****\n",
      "Loss: 6.534800\n",
      "Improvement ratio: 0.512268\n",
      "Feature L2-norm: 22.595802\n",
      "Learning rate (eta): 0.099463\n",
      "Total number of feature updates: 7290\n",
      "Seconds required for this iteration: 0.007\n",
      "\n",
      "***** Epoch #28 *****\n",
      "Loss: 6.330133\n",
      "Improvement ratio: 0.473785\n",
      "Feature L2-norm: 22.722743\n",
      "Learning rate (eta): 0.099443\n",
      "Total number of feature updates: 7560\n",
      "Seconds required for this iteration: 0.009\n",
      "\n",
      "***** Epoch #29 *****\n",
      "Loss: 6.144006\n",
      "Improvement ratio: 0.447436\n",
      "Feature L2-norm: 22.846007\n",
      "Learning rate (eta): 0.099423\n",
      "Total number of feature updates: 7830\n",
      "Seconds required for this iteration: 0.009\n",
      "\n",
      "***** Epoch #30 *****\n",
      "Loss: 5.973568\n",
      "Improvement ratio: 0.418849\n",
      "Feature L2-norm: 22.964479\n",
      "Learning rate (eta): 0.099404\n",
      "Total number of feature updates: 8100\n",
      "Seconds required for this iteration: 0.010\n",
      "\n",
      "***** Epoch #31 *****\n",
      "Loss: 5.811636\n",
      "Improvement ratio: 0.400441\n",
      "Feature L2-norm: 23.079616\n",
      "Learning rate (eta): 0.099384\n",
      "Total number of feature updates: 8370\n",
      "Seconds required for this iteration: 0.010\n",
      "\n",
      "***** Epoch #32 *****\n",
      "Loss: 5.667138\n",
      "Improvement ratio: 0.379135\n",
      "Feature L2-norm: 23.191239\n",
      "Learning rate (eta): 0.099364\n",
      "Total number of feature updates: 8640\n",
      "Seconds required for this iteration: 0.018\n",
      "\n",
      "***** Epoch #33 *****\n",
      "Loss: 5.522697\n",
      "Improvement ratio: 0.362279\n",
      "Feature L2-norm: 23.299423\n",
      "Learning rate (eta): 0.099344\n",
      "Total number of feature updates: 8910\n",
      "Seconds required for this iteration: 0.007\n",
      "\n",
      "***** Epoch #34 *****\n",
      "Loss: 5.386826\n",
      "Improvement ratio: 0.340952\n",
      "Feature L2-norm: 23.404571\n",
      "Learning rate (eta): 0.099325\n",
      "Total number of feature updates: 9180\n",
      "Seconds required for this iteration: 0.010\n",
      "\n",
      "***** Epoch #35 *****\n",
      "Loss: 5.263753\n",
      "Improvement ratio: 0.328371\n",
      "Feature L2-norm: 23.506460\n",
      "Learning rate (eta): 0.099305\n",
      "Total number of feature updates: 9450\n",
      "Seconds required for this iteration: 0.010\n",
      "\n",
      "***** Epoch #36 *****\n",
      "Loss: 5.139265\n",
      "Improvement ratio: 0.310756\n",
      "Feature L2-norm: 23.605589\n",
      "Learning rate (eta): 0.099285\n",
      "Total number of feature updates: 9720\n",
      "Seconds required for this iteration: 0.010\n",
      "\n",
      "***** Epoch #37 *****\n",
      "Loss: 5.032333\n",
      "Improvement ratio: 0.298563\n",
      "Feature L2-norm: 23.702128\n",
      "Learning rate (eta): 0.099266\n",
      "Total number of feature updates: 9990\n",
      "Seconds required for this iteration: 0.011\n",
      "\n",
      "***** Epoch #38 *****\n",
      "Loss: 4.928221\n",
      "Improvement ratio: 0.284466\n",
      "Feature L2-norm: 23.796060\n",
      "Learning rate (eta): 0.099246\n",
      "Total number of feature updates: 10260\n",
      "Seconds required for this iteration: 0.023\n",
      "\n",
      "***** Epoch #39 *****\n",
      "Loss: 4.823235\n",
      "Improvement ratio: 0.273835\n",
      "Feature L2-norm: 23.887674\n",
      "Learning rate (eta): 0.099226\n",
      "Total number of feature updates: 10530\n",
      "Seconds required for this iteration: 0.020\n",
      "\n",
      "***** Epoch #40 *****\n",
      "Loss: 4.729210\n",
      "Improvement ratio: 0.263122\n",
      "Feature L2-norm: 23.977149\n",
      "Learning rate (eta): 0.099206\n",
      "Total number of feature updates: 10800\n",
      "Seconds required for this iteration: 0.013\n",
      "\n",
      "***** Epoch #41 *****\n",
      "Loss: 4.642874\n",
      "Improvement ratio: 0.251732\n",
      "Feature L2-norm: 24.064482\n",
      "Learning rate (eta): 0.099187\n",
      "Total number of feature updates: 11070\n",
      "Seconds required for this iteration: 0.014\n",
      "\n",
      "***** Epoch #42 *****\n",
      "Loss: 4.559690\n",
      "Improvement ratio: 0.242878\n",
      "Feature L2-norm: 24.149636\n",
      "Learning rate (eta): 0.099167\n",
      "Total number of feature updates: 11340\n",
      "Seconds required for this iteration: 0.015\n",
      "\n",
      "***** Epoch #43 *****\n",
      "Loss: 4.465024\n",
      "Improvement ratio: 0.236880\n",
      "Feature L2-norm: 24.232945\n",
      "Learning rate (eta): 0.099147\n",
      "Total number of feature updates: 11610\n",
      "Seconds required for this iteration: 0.007\n",
      "\n",
      "***** Epoch #44 *****\n",
      "Loss: 4.393926\n",
      "Improvement ratio: 0.225971\n",
      "Feature L2-norm: 24.314304\n",
      "Learning rate (eta): 0.099128\n",
      "Total number of feature updates: 11880\n",
      "Seconds required for this iteration: 0.019\n",
      "\n",
      "***** Epoch #45 *****\n",
      "Loss: 4.321020\n",
      "Improvement ratio: 0.218174\n",
      "Feature L2-norm: 24.393699\n",
      "Learning rate (eta): 0.099108\n",
      "Total number of feature updates: 12150\n",
      "Seconds required for this iteration: 0.017\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** Epoch #46 *****\n",
      "Loss: 4.248693\n",
      "Improvement ratio: 0.209611\n",
      "Feature L2-norm: 24.471572\n",
      "Learning rate (eta): 0.099088\n",
      "Total number of feature updates: 12420\n",
      "Seconds required for this iteration: 0.014\n",
      "\n",
      "***** Epoch #47 *****\n",
      "Loss: 4.175021\n",
      "Improvement ratio: 0.205343\n",
      "Feature L2-norm: 24.547756\n",
      "Learning rate (eta): 0.099069\n",
      "Total number of feature updates: 12690\n",
      "Seconds required for this iteration: 0.012\n",
      "\n",
      "***** Epoch #48 *****\n",
      "Loss: 4.116134\n",
      "Improvement ratio: 0.197294\n",
      "Feature L2-norm: 24.622088\n",
      "Learning rate (eta): 0.099049\n",
      "Total number of feature updates: 12960\n",
      "Seconds required for this iteration: 0.029\n",
      "\n",
      "***** Epoch #49 *****\n",
      "Loss: 4.046775\n",
      "Improvement ratio: 0.191871\n",
      "Feature L2-norm: 24.695014\n",
      "Learning rate (eta): 0.099030\n",
      "Total number of feature updates: 13230\n",
      "Seconds required for this iteration: 0.030\n",
      "\n",
      "***** Epoch #50 *****\n",
      "Loss: 3.984350\n",
      "Improvement ratio: 0.186946\n",
      "Feature L2-norm: 24.766677\n",
      "Learning rate (eta): 0.099010\n",
      "Total number of feature updates: 13500\n",
      "Seconds required for this iteration: 0.027\n",
      "\n",
      "***** Epoch #51 *****\n",
      "Loss: 3.933765\n",
      "Improvement ratio: 0.180262\n",
      "Feature L2-norm: 24.836822\n",
      "Learning rate (eta): 0.098990\n",
      "Total number of feature updates: 13770\n",
      "Seconds required for this iteration: 0.023\n",
      "\n",
      "***** Epoch #52 *****\n",
      "Loss: 3.879468\n",
      "Improvement ratio: 0.175339\n",
      "Feature L2-norm: 24.905594\n",
      "Learning rate (eta): 0.098971\n",
      "Total number of feature updates: 14040\n",
      "Seconds required for this iteration: 0.008\n",
      "\n",
      "***** Epoch #53 *****\n",
      "Loss: 3.821629\n",
      "Improvement ratio: 0.168356\n",
      "Feature L2-norm: 24.973086\n",
      "Learning rate (eta): 0.098951\n",
      "Total number of feature updates: 14310\n",
      "Seconds required for this iteration: 0.010\n",
      "\n",
      "***** Epoch #54 *****\n",
      "Loss: 3.774122\n",
      "Improvement ratio: 0.164225\n",
      "Feature L2-norm: 25.039183\n",
      "Learning rate (eta): 0.098932\n",
      "Total number of feature updates: 14580\n",
      "Seconds required for this iteration: 0.012\n",
      "\n",
      "***** Epoch #55 *****\n",
      "Loss: 3.720951\n",
      "Improvement ratio: 0.161268\n",
      "Feature L2-norm: 25.104199\n",
      "Learning rate (eta): 0.098912\n",
      "Total number of feature updates: 14850\n",
      "Seconds required for this iteration: 0.014\n",
      "\n",
      "***** Epoch #56 *****\n",
      "Loss: 3.672795\n",
      "Improvement ratio: 0.156801\n",
      "Feature L2-norm: 25.167772\n",
      "Learning rate (eta): 0.098892\n",
      "Total number of feature updates: 15120\n",
      "Seconds required for this iteration: 0.021\n",
      "\n",
      "***** Epoch #57 *****\n",
      "Loss: 3.625104\n",
      "Improvement ratio: 0.151697\n",
      "Feature L2-norm: 25.230596\n",
      "Learning rate (eta): 0.098873\n",
      "Total number of feature updates: 15390\n",
      "Seconds required for this iteration: 0.022\n",
      "\n",
      "***** Epoch #58 *****\n",
      "Loss: 3.586326\n",
      "Improvement ratio: 0.147730\n",
      "Feature L2-norm: 25.292192\n",
      "Learning rate (eta): 0.098853\n",
      "Total number of feature updates: 15660\n",
      "Seconds required for this iteration: 0.018\n",
      "\n",
      "***** Epoch #59 *****\n",
      "Loss: 3.541964\n",
      "Improvement ratio: 0.142523\n",
      "Feature L2-norm: 25.352815\n",
      "Learning rate (eta): 0.098834\n",
      "Total number of feature updates: 15930\n",
      "Seconds required for this iteration: 0.016\n",
      "\n",
      "***** Epoch #60 *****\n",
      "Loss: 3.501062\n",
      "Improvement ratio: 0.138040\n",
      "Feature L2-norm: 25.412244\n",
      "Learning rate (eta): 0.098814\n",
      "Total number of feature updates: 16200\n",
      "Seconds required for this iteration: 0.011\n",
      "\n",
      "***** Epoch #61 *****\n",
      "Loss: 3.455435\n",
      "Improvement ratio: 0.138428\n",
      "Feature L2-norm: 25.470624\n",
      "Learning rate (eta): 0.098795\n",
      "Total number of feature updates: 16470\n",
      "Seconds required for this iteration: 0.010\n",
      "\n",
      "***** Epoch #62 *****\n",
      "Loss: 3.424021\n",
      "Improvement ratio: 0.133015\n",
      "Feature L2-norm: 25.528253\n",
      "Learning rate (eta): 0.098775\n",
      "Total number of feature updates: 16740\n",
      "Seconds required for this iteration: 0.010\n",
      "\n",
      "***** Epoch #63 *****\n",
      "Loss: 3.384622\n",
      "Improvement ratio: 0.129116\n",
      "Feature L2-norm: 25.584979\n",
      "Learning rate (eta): 0.098756\n",
      "Total number of feature updates: 17010\n",
      "Seconds required for this iteration: 0.010\n",
      "\n",
      "***** Epoch #64 *****\n",
      "Loss: 3.348446\n",
      "Improvement ratio: 0.127127\n",
      "Feature L2-norm: 25.640724\n",
      "Learning rate (eta): 0.098736\n",
      "Total number of feature updates: 17280\n",
      "Seconds required for this iteration: 0.011\n",
      "\n",
      "***** Epoch #65 *****\n",
      "Loss: 3.312650\n",
      "Improvement ratio: 0.123255\n",
      "Feature L2-norm: 25.695657\n",
      "Learning rate (eta): 0.098717\n",
      "Total number of feature updates: 17550\n",
      "Seconds required for this iteration: 0.021\n",
      "\n",
      "***** Epoch #66 *****\n",
      "Loss: 3.278189\n",
      "Improvement ratio: 0.120373\n",
      "Feature L2-norm: 25.749752\n",
      "Learning rate (eta): 0.098697\n",
      "Total number of feature updates: 17820\n",
      "Seconds required for this iteration: 0.020\n",
      "\n",
      "***** Epoch #67 *****\n",
      "Loss: 3.246859\n",
      "Improvement ratio: 0.116496\n",
      "Feature L2-norm: 25.802870\n",
      "Learning rate (eta): 0.098678\n",
      "Total number of feature updates: 18090\n",
      "Seconds required for this iteration: 0.020\n",
      "\n",
      "***** Epoch #68 *****\n",
      "Loss: 3.214196\n",
      "Improvement ratio: 0.115777\n",
      "Feature L2-norm: 25.855285\n",
      "Learning rate (eta): 0.098658\n",
      "Total number of feature updates: 18360\n",
      "Seconds required for this iteration: 0.022\n",
      "\n",
      "***** Epoch #69 *****\n",
      "Loss: 3.183000\n",
      "Improvement ratio: 0.112775\n",
      "Feature L2-norm: 25.906951\n",
      "Learning rate (eta): 0.098639\n",
      "Total number of feature updates: 18630\n",
      "Seconds required for this iteration: 0.021\n",
      "\n",
      "***** Epoch #70 *****\n",
      "Loss: 3.152789\n",
      "Improvement ratio: 0.110465\n",
      "Feature L2-norm: 25.957810\n",
      "Learning rate (eta): 0.098619\n",
      "Total number of feature updates: 18900\n",
      "Seconds required for this iteration: 0.020\n",
      "\n",
      "***** Epoch #71 *****\n",
      "Loss: 3.125382\n",
      "Improvement ratio: 0.105604\n",
      "Feature L2-norm: 26.007938\n",
      "Learning rate (eta): 0.098600\n",
      "Total number of feature updates: 19170\n",
      "Seconds required for this iteration: 0.011\n",
      "\n",
      "***** Epoch #72 *****\n",
      "Loss: 3.095478\n",
      "Improvement ratio: 0.106137\n",
      "Feature L2-norm: 26.057406\n",
      "Learning rate (eta): 0.098581\n",
      "Total number of feature updates: 19440\n",
      "Seconds required for this iteration: 0.024\n",
      "\n",
      "***** Epoch #73 *****\n",
      "Loss: 3.067855\n",
      "Improvement ratio: 0.103254\n",
      "Feature L2-norm: 26.106075\n",
      "Learning rate (eta): 0.098561\n",
      "Total number of feature updates: 19710\n",
      "Seconds required for this iteration: 0.023\n",
      "\n",
      "***** Epoch #74 *****\n",
      "Loss: 3.040376\n",
      "Improvement ratio: 0.101326\n",
      "Feature L2-norm: 26.154178\n",
      "Learning rate (eta): 0.098542\n",
      "Total number of feature updates: 19980\n",
      "Seconds required for this iteration: 0.021\n",
      "\n",
      "***** Epoch #75 *****\n",
      "Loss: 3.013458\n",
      "Improvement ratio: 0.099285\n",
      "Feature L2-norm: 26.201570\n",
      "Learning rate (eta): 0.098522\n",
      "Total number of feature updates: 20250\n",
      "Seconds required for this iteration: 0.012\n",
      "\n",
      "***** Epoch #76 *****\n",
      "Loss: 2.990366\n",
      "Improvement ratio: 0.096250\n",
      "Feature L2-norm: 26.248258\n",
      "Learning rate (eta): 0.098503\n",
      "Total number of feature updates: 20520\n",
      "Seconds required for this iteration: 0.005\n",
      "\n",
      "***** Epoch #77 *****\n",
      "Loss: 2.965961\n",
      "Improvement ratio: 0.094707\n",
      "Feature L2-norm: 26.294354\n",
      "Learning rate (eta): 0.098483\n",
      "Total number of feature updates: 20790\n",
      "Seconds required for this iteration: 0.006\n",
      "\n",
      "***** Epoch #78 *****\n",
      "Loss: 2.941149\n",
      "Improvement ratio: 0.092837\n",
      "Feature L2-norm: 26.339823\n",
      "Learning rate (eta): 0.098464\n",
      "Total number of feature updates: 21060\n",
      "Seconds required for this iteration: 0.008\n",
      "\n",
      "***** Epoch #79 *****\n",
      "Loss: 2.918512\n",
      "Improvement ratio: 0.090624\n",
      "Feature L2-norm: 26.384750\n",
      "Learning rate (eta): 0.098445\n",
      "Total number of feature updates: 21330\n",
      "Seconds required for this iteration: 0.022\n",
      "\n",
      "***** Epoch #80 *****\n",
      "Loss: 2.894233\n",
      "Improvement ratio: 0.089335\n",
      "Feature L2-norm: 26.429028\n",
      "Learning rate (eta): 0.098425\n",
      "Total number of feature updates: 21600\n",
      "Seconds required for this iteration: 0.023\n",
      "\n",
      "***** Epoch #81 *****\n",
      "Loss: 2.872153\n",
      "Improvement ratio: 0.088167\n",
      "Feature L2-norm: 26.472817\n",
      "Learning rate (eta): 0.098406\n",
      "Total number of feature updates: 21870\n",
      "Seconds required for this iteration: 0.018\n",
      "\n",
      "***** Epoch #82 *****\n",
      "Loss: 2.851256\n",
      "Improvement ratio: 0.085654\n",
      "Feature L2-norm: 26.516074\n",
      "Learning rate (eta): 0.098387\n",
      "Total number of feature updates: 22140\n",
      "Seconds required for this iteration: 0.019\n",
      "\n",
      "***** Epoch #83 *****\n",
      "Loss: 2.830833\n",
      "Improvement ratio: 0.083729\n",
      "Feature L2-norm: 26.558764\n",
      "Learning rate (eta): 0.098367\n",
      "Total number of feature updates: 22410\n",
      "Seconds required for this iteration: 0.025\n",
      "\n",
      "***** Epoch #84 *****\n",
      "Loss: 2.809101\n",
      "Improvement ratio: 0.082331\n",
      "Feature L2-norm: 26.600793\n",
      "Learning rate (eta): 0.098348\n",
      "Total number of feature updates: 22680\n",
      "Seconds required for this iteration: 0.017\n",
      "\n",
      "***** Epoch #85 *****\n",
      "Loss: 2.788982\n",
      "Improvement ratio: 0.080487\n",
      "Feature L2-norm: 26.642457\n",
      "Learning rate (eta): 0.098328\n",
      "Total number of feature updates: 22950\n",
      "Seconds required for this iteration: 0.020\n",
      "\n",
      "***** Epoch #86 *****\n",
      "Loss: 2.770030\n",
      "Improvement ratio: 0.079543\n",
      "Feature L2-norm: 26.683590\n",
      "Learning rate (eta): 0.098309\n",
      "Total number of feature updates: 23220\n",
      "Seconds required for this iteration: 0.019\n",
      "\n",
      "***** Epoch #87 *****\n",
      "Loss: 2.750898\n",
      "Improvement ratio: 0.078179\n",
      "Feature L2-norm: 26.724185\n",
      "Learning rate (eta): 0.098290\n",
      "Total number of feature updates: 23490\n",
      "Seconds required for this iteration: 0.012\n",
      "\n",
      "***** Epoch #88 *****\n",
      "Loss: 2.731989\n",
      "Improvement ratio: 0.076560\n",
      "Feature L2-norm: 26.764314\n",
      "Learning rate (eta): 0.098271\n",
      "Total number of feature updates: 23760\n",
      "Seconds required for this iteration: 0.033\n",
      "\n",
      "***** Epoch #89 *****\n",
      "Loss: 2.714140\n",
      "Improvement ratio: 0.075299\n",
      "Feature L2-norm: 26.804000\n",
      "Learning rate (eta): 0.098251\n",
      "Total number of feature updates: 24030\n",
      "Seconds required for this iteration: 0.019\n",
      "\n",
      "***** Epoch #90 *****\n",
      "Loss: 2.696315\n",
      "Improvement ratio: 0.073403\n",
      "Feature L2-norm: 26.843207\n",
      "Learning rate (eta): 0.098232\n",
      "Total number of feature updates: 24300\n",
      "Seconds required for this iteration: 0.020\n",
      "\n",
      "***** Epoch #91 *****\n",
      "Loss: 2.679155\n",
      "Improvement ratio: 0.072037\n",
      "Feature L2-norm: 26.881944\n",
      "Learning rate (eta): 0.098213\n",
      "Total number of feature updates: 24570\n",
      "Seconds required for this iteration: 0.022\n",
      "\n",
      "***** Epoch #92 *****\n",
      "Loss: 2.662570\n",
      "Improvement ratio: 0.070866\n",
      "Feature L2-norm: 26.920257\n",
      "Learning rate (eta): 0.098193\n",
      "Total number of feature updates: 24840\n",
      "Seconds required for this iteration: 0.021\n",
      "\n",
      "***** Epoch #93 *****\n",
      "Loss: 2.645947\n",
      "Improvement ratio: 0.069875\n",
      "Feature L2-norm: 26.958122\n",
      "Learning rate (eta): 0.098174\n",
      "Total number of feature updates: 25110\n",
      "Seconds required for this iteration: 0.011\n",
      "\n",
      "***** Epoch #94 *****\n",
      "Loss: 2.629573\n",
      "Improvement ratio: 0.068273\n",
      "Feature L2-norm: 26.995535\n",
      "Learning rate (eta): 0.098155\n",
      "Total number of feature updates: 25380\n",
      "Seconds required for this iteration: 0.013\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** Epoch #95 *****\n",
      "Loss: 2.612817\n",
      "Improvement ratio: 0.067423\n",
      "Feature L2-norm: 27.032607\n",
      "Learning rate (eta): 0.098135\n",
      "Total number of feature updates: 25650\n",
      "Seconds required for this iteration: 0.023\n",
      "\n",
      "***** Epoch #96 *****\n",
      "Loss: 2.597769\n",
      "Improvement ratio: 0.066311\n",
      "Feature L2-norm: 27.069256\n",
      "Learning rate (eta): 0.098116\n",
      "Total number of feature updates: 25920\n",
      "Seconds required for this iteration: 0.022\n",
      "\n",
      "***** Epoch #97 *****\n",
      "Loss: 2.582925\n",
      "Improvement ratio: 0.065032\n",
      "Feature L2-norm: 27.105521\n",
      "Learning rate (eta): 0.098097\n",
      "Total number of feature updates: 26190\n",
      "Seconds required for this iteration: 0.023\n",
      "\n",
      "***** Epoch #98 *****\n",
      "Loss: 2.567861\n",
      "Improvement ratio: 0.063916\n",
      "Feature L2-norm: 27.141383\n",
      "Learning rate (eta): 0.098078\n",
      "Total number of feature updates: 26460\n",
      "Seconds required for this iteration: 0.027\n",
      "\n",
      "***** Epoch #99 *****\n",
      "Loss: 2.553516\n",
      "Improvement ratio: 0.062903\n",
      "Feature L2-norm: 27.176861\n",
      "Learning rate (eta): 0.098059\n",
      "Total number of feature updates: 26730\n",
      "Seconds required for this iteration: 0.025\n",
      "\n",
      "***** Epoch #100 *****\n",
      "Loss: 2.538306\n",
      "Improvement ratio: 0.062250\n",
      "Feature L2-norm: 27.211921\n",
      "Learning rate (eta): 0.098039\n",
      "Total number of feature updates: 27000\n",
      "Seconds required for this iteration: 0.020\n",
      "\n",
      "***** Epoch #101 *****\n",
      "Loss: 2.524865\n",
      "Improvement ratio: 0.061108\n",
      "Feature L2-norm: 27.246632\n",
      "Learning rate (eta): 0.098020\n",
      "Total number of feature updates: 27270\n",
      "Seconds required for this iteration: 0.014\n",
      "\n",
      "***** Epoch #102 *****\n",
      "Loss: 2.510739\n",
      "Improvement ratio: 0.060473\n",
      "Feature L2-norm: 27.280996\n",
      "Learning rate (eta): 0.098001\n",
      "Total number of feature updates: 27540\n",
      "Seconds required for this iteration: 0.017\n",
      "\n",
      "***** Epoch #103 *****\n",
      "Loss: 2.497863\n",
      "Improvement ratio: 0.059285\n",
      "Feature L2-norm: 27.314998\n",
      "Learning rate (eta): 0.097982\n",
      "Total number of feature updates: 27810\n",
      "Seconds required for this iteration: 0.018\n",
      "\n",
      "***** Epoch #104 *****\n",
      "Loss: 2.485003\n",
      "Improvement ratio: 0.058177\n",
      "Feature L2-norm: 27.348668\n",
      "Learning rate (eta): 0.097962\n",
      "Total number of feature updates: 28080\n",
      "Seconds required for this iteration: 0.014\n",
      "\n",
      "***** Epoch #105 *****\n",
      "Loss: 2.471849\n",
      "Improvement ratio: 0.057029\n",
      "Feature L2-norm: 27.381999\n",
      "Learning rate (eta): 0.097943\n",
      "Total number of feature updates: 28350\n",
      "Seconds required for this iteration: 0.024\n",
      "\n",
      "***** Epoch #106 *****\n",
      "Loss: 2.460269\n",
      "Improvement ratio: 0.055888\n",
      "Feature L2-norm: 27.414957\n",
      "Learning rate (eta): 0.097924\n",
      "Total number of feature updates: 28620\n",
      "Seconds required for this iteration: 0.016\n",
      "\n",
      "***** Epoch #107 *****\n",
      "Loss: 2.447208\n",
      "Improvement ratio: 0.055458\n",
      "Feature L2-norm: 27.447612\n",
      "Learning rate (eta): 0.097905\n",
      "Total number of feature updates: 28890\n",
      "Seconds required for this iteration: 0.013\n",
      "\n",
      "***** Epoch #108 *****\n",
      "Loss: 2.435300\n",
      "Improvement ratio: 0.054433\n",
      "Feature L2-norm: 27.479862\n",
      "Learning rate (eta): 0.097886\n",
      "Total number of feature updates: 29160\n",
      "Seconds required for this iteration: 0.016\n",
      "\n",
      "***** Epoch #109 *****\n",
      "Loss: 2.423326\n",
      "Improvement ratio: 0.053724\n",
      "Feature L2-norm: 27.511826\n",
      "Learning rate (eta): 0.097867\n",
      "Total number of feature updates: 29430\n",
      "Seconds required for this iteration: 0.016\n",
      "\n",
      "***** Epoch #110 *****\n",
      "Loss: 2.411934\n",
      "Improvement ratio: 0.052394\n",
      "Feature L2-norm: 27.543546\n",
      "Learning rate (eta): 0.097847\n",
      "Total number of feature updates: 29700\n",
      "Seconds required for this iteration: 0.022\n",
      "\n",
      "***** Epoch #111 *****\n",
      "Loss: 2.400663\n",
      "Improvement ratio: 0.051736\n",
      "Feature L2-norm: 27.574940\n",
      "Learning rate (eta): 0.097828\n",
      "Total number of feature updates: 29970\n",
      "Seconds required for this iteration: 0.018\n",
      "\n",
      "***** Epoch #112 *****\n",
      "Loss: 2.388562\n",
      "Improvement ratio: 0.051151\n",
      "Feature L2-norm: 27.606068\n",
      "Learning rate (eta): 0.097809\n",
      "Total number of feature updates: 30240\n",
      "Seconds required for this iteration: 0.017\n",
      "\n",
      "***** Epoch #113 *****\n",
      "Loss: 2.378094\n",
      "Improvement ratio: 0.050363\n",
      "Feature L2-norm: 27.636839\n",
      "Learning rate (eta): 0.097790\n",
      "Total number of feature updates: 30510\n",
      "Seconds required for this iteration: 0.022\n",
      "\n",
      "***** Epoch #114 *****\n",
      "Loss: 2.366472\n",
      "Improvement ratio: 0.050088\n",
      "Feature L2-norm: 27.667314\n",
      "Learning rate (eta): 0.097771\n",
      "Total number of feature updates: 30780\n",
      "Seconds required for this iteration: 0.006\n",
      "\n",
      "***** Epoch #115 *****\n",
      "Loss: 2.356935\n",
      "Improvement ratio: 0.048756\n",
      "Feature L2-norm: 27.697595\n",
      "Learning rate (eta): 0.097752\n",
      "Total number of feature updates: 31050\n",
      "Seconds required for this iteration: 0.011\n",
      "\n",
      "***** Epoch #116 *****\n",
      "Loss: 2.346370\n",
      "Improvement ratio: 0.048543\n",
      "Feature L2-norm: 27.727541\n",
      "Learning rate (eta): 0.097733\n",
      "Total number of feature updates: 31320\n",
      "Seconds required for this iteration: 0.010\n",
      "\n",
      "***** Epoch #117 *****\n",
      "Loss: 2.336598\n",
      "Improvement ratio: 0.047338\n",
      "Feature L2-norm: 27.757186\n",
      "Learning rate (eta): 0.097714\n",
      "Total number of feature updates: 31590\n",
      "Seconds required for this iteration: 0.018\n",
      "\n",
      "***** Epoch #118 *****\n",
      "Loss: 2.326026\n",
      "Improvement ratio: 0.046979\n",
      "Feature L2-norm: 27.786560\n",
      "Learning rate (eta): 0.097694\n",
      "Total number of feature updates: 31860\n",
      "Seconds required for this iteration: 0.011\n",
      "\n",
      "***** Epoch #119 *****\n",
      "Loss: 2.316700\n",
      "Improvement ratio: 0.046025\n",
      "Feature L2-norm: 27.815680\n",
      "Learning rate (eta): 0.097675\n",
      "Total number of feature updates: 32130\n",
      "Seconds required for this iteration: 0.022\n",
      "\n",
      "***** Epoch #120 *****\n",
      "Loss: 2.306589\n",
      "Improvement ratio: 0.045672\n",
      "Feature L2-norm: 27.844577\n",
      "Learning rate (eta): 0.097656\n",
      "Total number of feature updates: 32400\n",
      "Seconds required for this iteration: 0.021\n",
      "\n",
      "***** Epoch #121 *****\n",
      "Loss: 2.297637\n",
      "Improvement ratio: 0.044840\n",
      "Feature L2-norm: 27.873157\n",
      "Learning rate (eta): 0.097637\n",
      "Total number of feature updates: 32670\n",
      "Seconds required for this iteration: 0.022\n",
      "\n",
      "***** Epoch #122 *****\n",
      "Loss: 2.287932\n",
      "Improvement ratio: 0.043983\n",
      "Feature L2-norm: 27.901538\n",
      "Learning rate (eta): 0.097618\n",
      "Total number of feature updates: 32940\n",
      "Seconds required for this iteration: 0.020\n",
      "\n",
      "***** Epoch #123 *****\n",
      "Loss: 2.278986\n",
      "Improvement ratio: 0.043488\n",
      "Feature L2-norm: 27.929635\n",
      "Learning rate (eta): 0.097599\n",
      "Total number of feature updates: 33210\n",
      "Seconds required for this iteration: 0.011\n",
      "\n",
      "***** Epoch #124 *****\n",
      "Loss: 2.270234\n",
      "Improvement ratio: 0.042391\n",
      "Feature L2-norm: 27.957510\n",
      "Learning rate (eta): 0.097580\n",
      "Total number of feature updates: 33480\n",
      "Seconds required for this iteration: 0.011\n",
      "\n",
      "***** Epoch #125 *****\n",
      "Loss: 2.261357\n",
      "Improvement ratio: 0.042266\n",
      "Feature L2-norm: 27.985132\n",
      "Learning rate (eta): 0.097561\n",
      "Total number of feature updates: 33750\n",
      "Seconds required for this iteration: 0.010\n",
      "\n",
      "***** Epoch #126 *****\n",
      "Loss: 2.252725\n",
      "Improvement ratio: 0.041570\n",
      "Feature L2-norm: 28.012485\n",
      "Learning rate (eta): 0.097542\n",
      "Total number of feature updates: 34020\n",
      "Seconds required for this iteration: 0.010\n",
      "\n",
      "***** Epoch #127 *****\n",
      "Loss: 2.244301\n",
      "Improvement ratio: 0.041125\n",
      "Feature L2-norm: 28.039611\n",
      "Learning rate (eta): 0.097523\n",
      "Total number of feature updates: 34290\n",
      "Seconds required for this iteration: 0.010\n",
      "\n",
      "***** Epoch #128 *****\n",
      "Loss: 2.235766\n",
      "Improvement ratio: 0.040371\n",
      "Feature L2-norm: 28.066539\n",
      "Learning rate (eta): 0.097504\n",
      "Total number of feature updates: 34560\n",
      "Seconds required for this iteration: 0.012\n",
      "\n",
      "***** Epoch #129 *****\n",
      "Loss: 2.227315\n",
      "Improvement ratio: 0.040131\n",
      "Feature L2-norm: 28.093227\n",
      "Learning rate (eta): 0.097485\n",
      "Total number of feature updates: 34830\n",
      "Seconds required for this iteration: 0.022\n",
      "\n",
      "***** Epoch #130 *****\n",
      "Loss: 2.219147\n",
      "Improvement ratio: 0.039403\n",
      "Feature L2-norm: 28.119707\n",
      "Learning rate (eta): 0.097466\n",
      "Total number of feature updates: 35100\n",
      "Seconds required for this iteration: 0.024\n",
      "\n",
      "***** Epoch #131 *****\n",
      "Loss: 2.211001\n",
      "Improvement ratio: 0.039184\n",
      "Feature L2-norm: 28.145971\n",
      "Learning rate (eta): 0.097447\n",
      "Total number of feature updates: 35370\n",
      "Seconds required for this iteration: 0.024\n",
      "\n",
      "***** Epoch #132 *****\n",
      "Loss: 2.203669\n",
      "Improvement ratio: 0.038238\n",
      "Feature L2-norm: 28.171976\n",
      "Learning rate (eta): 0.097428\n",
      "Total number of feature updates: 35640\n",
      "Seconds required for this iteration: 0.019\n",
      "\n",
      "***** Epoch #133 *****\n",
      "Loss: 2.195899\n",
      "Improvement ratio: 0.037837\n",
      "Feature L2-norm: 28.197776\n",
      "Learning rate (eta): 0.097409\n",
      "Total number of feature updates: 35910\n",
      "Seconds required for this iteration: 0.017\n",
      "\n",
      "***** Epoch #134 *****\n",
      "Loss: 2.187924\n",
      "Improvement ratio: 0.037620\n",
      "Feature L2-norm: 28.223383\n",
      "Learning rate (eta): 0.097390\n",
      "Total number of feature updates: 36180\n",
      "Seconds required for this iteration: 0.032\n",
      "\n",
      "***** Epoch #135 *****\n",
      "Loss: 2.180788\n",
      "Improvement ratio: 0.036945\n",
      "Feature L2-norm: 28.248765\n",
      "Learning rate (eta): 0.097371\n",
      "Total number of feature updates: 36450\n",
      "Seconds required for this iteration: 0.022\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** Epoch #136 *****\n",
      "Loss: 2.173355\n",
      "Improvement ratio: 0.036520\n",
      "Feature L2-norm: 28.273929\n",
      "Learning rate (eta): 0.097352\n",
      "Total number of feature updates: 36720\n",
      "Seconds required for this iteration: 0.030\n",
      "\n",
      "***** Epoch #137 *****\n",
      "Loss: 2.165940\n",
      "Improvement ratio: 0.036179\n",
      "Feature L2-norm: 28.298894\n",
      "Learning rate (eta): 0.097333\n",
      "Total number of feature updates: 36990\n",
      "Seconds required for this iteration: 0.016\n",
      "\n",
      "***** Epoch #138 *****\n",
      "Loss: 2.159342\n",
      "Improvement ratio: 0.035392\n",
      "Feature L2-norm: 28.323667\n",
      "Learning rate (eta): 0.097314\n",
      "Total number of feature updates: 37260\n",
      "Seconds required for this iteration: 0.021\n",
      "\n",
      "***** Epoch #139 *****\n",
      "Loss: 2.151336\n",
      "Improvement ratio: 0.035317\n",
      "Feature L2-norm: 28.348280\n",
      "Learning rate (eta): 0.097295\n",
      "Total number of feature updates: 37530\n",
      "Seconds required for this iteration: 0.020\n",
      "\n",
      "***** Epoch #140 *****\n",
      "Loss: 2.145298\n",
      "Improvement ratio: 0.034424\n",
      "Feature L2-norm: 28.372654\n",
      "Learning rate (eta): 0.097276\n",
      "Total number of feature updates: 37800\n",
      "Seconds required for this iteration: 0.014\n",
      "\n",
      "***** Epoch #141 *****\n",
      "Loss: 2.138022\n",
      "Improvement ratio: 0.034134\n",
      "Feature L2-norm: 28.396819\n",
      "Learning rate (eta): 0.097257\n",
      "Total number of feature updates: 38070\n",
      "Seconds required for this iteration: 0.013\n",
      "\n",
      "***** Epoch #142 *****\n",
      "Loss: 2.131677\n",
      "Improvement ratio: 0.033772\n",
      "Feature L2-norm: 28.420855\n",
      "Learning rate (eta): 0.097238\n",
      "Total number of feature updates: 38340\n",
      "Seconds required for this iteration: 0.023\n",
      "\n",
      "***** Epoch #143 *****\n",
      "Loss: 2.124933\n",
      "Improvement ratio: 0.033397\n",
      "Feature L2-norm: 28.444678\n",
      "Learning rate (eta): 0.097220\n",
      "Total number of feature updates: 38610\n",
      "Seconds required for this iteration: 0.019\n",
      "\n",
      "***** Epoch #144 *****\n",
      "Loss: 2.118348\n",
      "Improvement ratio: 0.032844\n",
      "Feature L2-norm: 28.468300\n",
      "Learning rate (eta): 0.097201\n",
      "Total number of feature updates: 38880\n",
      "Seconds required for this iteration: 0.018\n",
      "\n",
      "***** Epoch #145 *****\n",
      "Loss: 2.112112\n",
      "Improvement ratio: 0.032515\n",
      "Feature L2-norm: 28.491767\n",
      "Learning rate (eta): 0.097182\n",
      "Total number of feature updates: 39150\n",
      "Seconds required for this iteration: 0.020\n",
      "\n",
      "***** Epoch #146 *****\n",
      "Loss: 2.105741\n",
      "Improvement ratio: 0.032109\n",
      "Feature L2-norm: 28.515043\n",
      "Learning rate (eta): 0.097163\n",
      "Total number of feature updates: 39420\n",
      "Seconds required for this iteration: 0.009\n",
      "\n",
      "***** Epoch #147 *****\n",
      "Loss: 2.099626\n",
      "Improvement ratio: 0.031584\n",
      "Feature L2-norm: 28.538168\n",
      "Learning rate (eta): 0.097144\n",
      "Total number of feature updates: 39690\n",
      "Seconds required for this iteration: 0.008\n",
      "\n",
      "***** Epoch #148 *****\n",
      "Loss: 2.093332\n",
      "Improvement ratio: 0.031533\n",
      "Feature L2-norm: 28.561116\n",
      "Learning rate (eta): 0.097125\n",
      "Total number of feature updates: 39960\n",
      "Seconds required for this iteration: 0.010\n",
      "\n",
      "***** Epoch #149 *****\n",
      "Loss: 2.087755\n",
      "Improvement ratio: 0.030454\n",
      "Feature L2-norm: 28.583862\n",
      "Learning rate (eta): 0.097106\n",
      "Total number of feature updates: 40230\n",
      "Seconds required for this iteration: 0.017\n",
      "\n",
      "***** Epoch #150 *****\n",
      "Loss: 2.081698\n",
      "Improvement ratio: 0.030552\n",
      "Feature L2-norm: 28.606442\n",
      "Learning rate (eta): 0.097087\n",
      "Total number of feature updates: 40500\n",
      "Seconds required for this iteration: 0.021\n",
      "\n",
      "***** Epoch #151 *****\n",
      "Loss: 2.075889\n",
      "Improvement ratio: 0.029931\n",
      "Feature L2-norm: 28.628856\n",
      "Learning rate (eta): 0.097069\n",
      "Total number of feature updates: 40770\n",
      "Seconds required for this iteration: 0.020\n",
      "\n",
      "***** Epoch #152 *****\n",
      "Loss: 2.070198\n",
      "Improvement ratio: 0.029697\n",
      "Feature L2-norm: 28.651131\n",
      "Learning rate (eta): 0.097050\n",
      "Total number of feature updates: 41040\n",
      "Seconds required for this iteration: 0.022\n",
      "\n",
      "***** Epoch #153 *****\n",
      "Loss: 2.064236\n",
      "Improvement ratio: 0.029404\n",
      "Feature L2-norm: 28.673234\n",
      "Learning rate (eta): 0.097031\n",
      "Total number of feature updates: 41310\n",
      "Seconds required for this iteration: 0.021\n",
      "\n",
      "***** Epoch #154 *****\n",
      "Loss: 2.058408\n",
      "Improvement ratio: 0.029119\n",
      "Feature L2-norm: 28.695155\n",
      "Learning rate (eta): 0.097012\n",
      "Total number of feature updates: 41580\n",
      "Seconds required for this iteration: 0.020\n",
      "\n",
      "***** Epoch #155 *****\n",
      "Loss: 2.053238\n",
      "Improvement ratio: 0.028674\n",
      "Feature L2-norm: 28.716927\n",
      "Learning rate (eta): 0.096993\n",
      "Total number of feature updates: 41850\n",
      "Seconds required for this iteration: 0.016\n",
      "\n",
      "***** Epoch #156 *****\n",
      "Loss: 2.047957\n",
      "Improvement ratio: 0.028216\n",
      "Feature L2-norm: 28.738540\n",
      "Learning rate (eta): 0.096974\n",
      "Total number of feature updates: 42120\n",
      "Seconds required for this iteration: 0.023\n",
      "\n",
      "***** Epoch #157 *****\n",
      "Loss: 2.042242\n",
      "Improvement ratio: 0.028099\n",
      "Feature L2-norm: 28.760041\n",
      "Learning rate (eta): 0.096956\n",
      "Total number of feature updates: 42390\n",
      "Seconds required for this iteration: 0.011\n",
      "\n",
      "***** Epoch #158 *****\n",
      "Loss: 2.037190\n",
      "Improvement ratio: 0.027558\n",
      "Feature L2-norm: 28.781348\n",
      "Learning rate (eta): 0.096937\n",
      "Total number of feature updates: 42660\n",
      "Seconds required for this iteration: 0.021\n",
      "\n",
      "***** Epoch #159 *****\n",
      "Loss: 2.031844\n",
      "Improvement ratio: 0.027517\n",
      "Feature L2-norm: 28.802529\n",
      "Learning rate (eta): 0.096918\n",
      "Total number of feature updates: 42930\n",
      "Seconds required for this iteration: 0.021\n",
      "\n",
      "***** Epoch #160 *****\n",
      "Loss: 2.026653\n",
      "Improvement ratio: 0.027160\n",
      "Feature L2-norm: 28.823541\n",
      "Learning rate (eta): 0.096899\n",
      "Total number of feature updates: 43200\n",
      "Seconds required for this iteration: 0.014\n",
      "\n",
      "***** Epoch #161 *****\n",
      "Loss: 2.021596\n",
      "Improvement ratio: 0.026857\n",
      "Feature L2-norm: 28.844394\n",
      "Learning rate (eta): 0.096881\n",
      "Total number of feature updates: 43470\n",
      "Seconds required for this iteration: 0.010\n",
      "\n",
      "***** Epoch #162 *****\n",
      "Loss: 2.016786\n",
      "Improvement ratio: 0.026484\n",
      "Feature L2-norm: 28.865132\n",
      "Learning rate (eta): 0.096862\n",
      "Total number of feature updates: 43740\n",
      "Seconds required for this iteration: 0.010\n",
      "\n",
      "***** Epoch #163 *****\n",
      "Loss: 2.011873\n",
      "Improvement ratio: 0.026027\n",
      "Feature L2-norm: 28.885699\n",
      "Learning rate (eta): 0.096843\n",
      "Total number of feature updates: 44010\n",
      "Seconds required for this iteration: 0.010\n",
      "\n",
      "***** Epoch #164 *****\n",
      "Loss: 2.006645\n",
      "Improvement ratio: 0.025796\n",
      "Feature L2-norm: 28.906092\n",
      "Learning rate (eta): 0.096824\n",
      "Total number of feature updates: 44280\n",
      "Seconds required for this iteration: 0.010\n",
      "\n",
      "***** Epoch #165 *****\n",
      "Loss: 2.001853\n",
      "Improvement ratio: 0.025669\n",
      "Feature L2-norm: 28.926393\n",
      "Learning rate (eta): 0.096805\n",
      "Total number of feature updates: 44550\n",
      "Seconds required for this iteration: 0.011\n",
      "\n",
      "***** Epoch #166 *****\n",
      "Loss: 1.997372\n",
      "Improvement ratio: 0.025326\n",
      "Feature L2-norm: 28.946562\n",
      "Learning rate (eta): 0.096787\n",
      "Total number of feature updates: 44820\n",
      "Seconds required for this iteration: 0.010\n",
      "\n",
      "***** Epoch #167 *****\n",
      "Loss: 1.992633\n",
      "Improvement ratio: 0.024896\n",
      "Feature L2-norm: 28.966600\n",
      "Learning rate (eta): 0.096768\n",
      "Total number of feature updates: 45090\n",
      "Seconds required for this iteration: 0.010\n",
      "\n",
      "***** Epoch #168 *****\n",
      "Loss: 1.987926\n",
      "Improvement ratio: 0.024782\n",
      "Feature L2-norm: 28.986489\n",
      "Learning rate (eta): 0.096749\n",
      "Total number of feature updates: 45360\n",
      "Seconds required for this iteration: 0.015\n",
      "\n",
      "***** Epoch #169 *****\n",
      "Loss: 1.983574\n",
      "Improvement ratio: 0.024335\n",
      "Feature L2-norm: 29.006258\n",
      "Learning rate (eta): 0.096731\n",
      "Total number of feature updates: 45630\n",
      "Seconds required for this iteration: 0.021\n",
      "\n",
      "***** Epoch #170 *****\n",
      "Loss: 1.979126\n",
      "Improvement ratio: 0.024014\n",
      "Feature L2-norm: 29.025884\n",
      "Learning rate (eta): 0.096712\n",
      "Total number of feature updates: 45900\n",
      "Seconds required for this iteration: 0.023\n",
      "\n",
      "***** Epoch #171 *****\n",
      "Loss: 1.974608\n",
      "Improvement ratio: 0.023796\n",
      "Feature L2-norm: 29.045376\n",
      "Learning rate (eta): 0.096693\n",
      "Total number of feature updates: 46170\n",
      "Seconds required for this iteration: 0.010\n",
      "\n",
      "***** Epoch #172 *****\n",
      "Loss: 1.970356\n",
      "Improvement ratio: 0.023564\n",
      "Feature L2-norm: 29.064738\n",
      "Learning rate (eta): 0.096674\n",
      "Total number of feature updates: 46440\n",
      "Seconds required for this iteration: 0.017\n",
      "\n",
      "***** Epoch #173 *****\n",
      "Loss: 1.965973\n",
      "Improvement ratio: 0.023347\n",
      "Feature L2-norm: 29.083979\n",
      "Learning rate (eta): 0.096656\n",
      "Total number of feature updates: 46710\n",
      "Seconds required for this iteration: 0.020\n",
      "\n",
      "***** Epoch #174 *****\n",
      "Loss: 1.961656\n",
      "Improvement ratio: 0.022934\n",
      "Feature L2-norm: 29.103097\n",
      "Learning rate (eta): 0.096637\n",
      "Total number of feature updates: 46980\n",
      "Seconds required for this iteration: 0.019\n",
      "\n",
      "***** Epoch #175 *****\n",
      "Loss: 1.957548\n",
      "Improvement ratio: 0.022633\n",
      "Feature L2-norm: 29.122069\n",
      "Learning rate (eta): 0.096618\n",
      "Total number of feature updates: 47250\n",
      "Seconds required for this iteration: 0.019\n",
      "\n",
      "***** Epoch #176 *****\n",
      "Loss: 1.953425\n",
      "Improvement ratio: 0.022497\n",
      "Feature L2-norm: 29.140930\n",
      "Learning rate (eta): 0.096600\n",
      "Total number of feature updates: 47520\n",
      "Seconds required for this iteration: 0.008\n",
      "\n",
      "***** Epoch #177 *****\n",
      "Loss: 1.949259\n",
      "Improvement ratio: 0.022251\n",
      "Feature L2-norm: 29.159678\n",
      "Learning rate (eta): 0.096581\n",
      "Total number of feature updates: 47790\n",
      "Seconds required for this iteration: 0.010\n",
      "\n",
      "***** Epoch #178 *****\n",
      "Loss: 1.945127\n",
      "Improvement ratio: 0.022003\n",
      "Feature L2-norm: 29.178292\n",
      "Learning rate (eta): 0.096562\n",
      "Total number of feature updates: 48060\n",
      "Seconds required for this iteration: 0.016\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** Epoch #179 *****\n",
      "Loss: 1.941071\n",
      "Improvement ratio: 0.021897\n",
      "Feature L2-norm: 29.196808\n",
      "Learning rate (eta): 0.096544\n",
      "Total number of feature updates: 48330\n",
      "Seconds required for this iteration: 0.021\n",
      "\n",
      "***** Epoch #180 *****\n",
      "Loss: 1.937204\n",
      "Improvement ratio: 0.021641\n",
      "Feature L2-norm: 29.215190\n",
      "Learning rate (eta): 0.096525\n",
      "Total number of feature updates: 48600\n",
      "Seconds required for this iteration: 0.018\n",
      "\n",
      "***** Epoch #181 *****\n",
      "Loss: 1.933237\n",
      "Improvement ratio: 0.021400\n",
      "Feature L2-norm: 29.233454\n",
      "Learning rate (eta): 0.096507\n",
      "Total number of feature updates: 48870\n",
      "Seconds required for this iteration: 0.013\n",
      "\n",
      "***** Epoch #182 *****\n",
      "Loss: 1.929401\n",
      "Improvement ratio: 0.021227\n",
      "Feature L2-norm: 29.251602\n",
      "Learning rate (eta): 0.096488\n",
      "Total number of feature updates: 49140\n",
      "Seconds required for this iteration: 0.013\n",
      "\n",
      "***** Epoch #183 *****\n",
      "Loss: 1.925632\n",
      "Improvement ratio: 0.020949\n",
      "Feature L2-norm: 29.269634\n",
      "Learning rate (eta): 0.096469\n",
      "Total number of feature updates: 49410\n",
      "Seconds required for this iteration: 0.015\n",
      "\n",
      "***** Epoch #184 *****\n",
      "Loss: 1.922019\n",
      "Improvement ratio: 0.020623\n",
      "Feature L2-norm: 29.287555\n",
      "Learning rate (eta): 0.096451\n",
      "Total number of feature updates: 49680\n",
      "Seconds required for this iteration: 0.016\n",
      "\n",
      "***** Epoch #185 *****\n",
      "Loss: 1.918178\n",
      "Improvement ratio: 0.020525\n",
      "Feature L2-norm: 29.305364\n",
      "Learning rate (eta): 0.096432\n",
      "Total number of feature updates: 49950\n",
      "Seconds required for this iteration: 0.021\n",
      "\n",
      "***** Epoch #186 *****\n",
      "Loss: 1.914663\n",
      "Improvement ratio: 0.020245\n",
      "Feature L2-norm: 29.323058\n",
      "Learning rate (eta): 0.096413\n",
      "Total number of feature updates: 50220\n",
      "Seconds required for this iteration: 0.011\n",
      "\n",
      "***** Epoch #187 *****\n",
      "Loss: 1.910927\n",
      "Improvement ratio: 0.020059\n",
      "Feature L2-norm: 29.340647\n",
      "Learning rate (eta): 0.096395\n",
      "Total number of feature updates: 50490\n",
      "Seconds required for this iteration: 0.008\n",
      "\n",
      "***** Epoch #188 *****\n",
      "Loss: 1.907162\n",
      "Improvement ratio: 0.019906\n",
      "Feature L2-norm: 29.358130\n",
      "Learning rate (eta): 0.096376\n",
      "Total number of feature updates: 50760\n",
      "Seconds required for this iteration: 0.010\n",
      "\n",
      "***** Epoch #189 *****\n",
      "Loss: 1.903537\n",
      "Improvement ratio: 0.019718\n",
      "Feature L2-norm: 29.375488\n",
      "Learning rate (eta): 0.096358\n",
      "Total number of feature updates: 51030\n",
      "Seconds required for this iteration: 0.021\n",
      "\n",
      "***** Epoch #190 *****\n",
      "Loss: 1.900270\n",
      "Improvement ratio: 0.019437\n",
      "Feature L2-norm: 29.392748\n",
      "Learning rate (eta): 0.096339\n",
      "Total number of feature updates: 51300\n",
      "Seconds required for this iteration: 0.021\n",
      "\n",
      "***** Epoch #191 *****\n",
      "Loss: 1.896977\n",
      "Improvement ratio: 0.019115\n",
      "Feature L2-norm: 29.409921\n",
      "Learning rate (eta): 0.096321\n",
      "Total number of feature updates: 51570\n",
      "Seconds required for this iteration: 0.022\n",
      "\n",
      "***** Epoch #192 *****\n",
      "Loss: 1.893453\n",
      "Improvement ratio: 0.018986\n",
      "Feature L2-norm: 29.426975\n",
      "Learning rate (eta): 0.096302\n",
      "Total number of feature updates: 51840\n",
      "Seconds required for this iteration: 0.021\n",
      "\n",
      "***** Epoch #193 *****\n",
      "Loss: 1.889925\n",
      "Improvement ratio: 0.018893\n",
      "Feature L2-norm: 29.443920\n",
      "Learning rate (eta): 0.096284\n",
      "Total number of feature updates: 52110\n",
      "Seconds required for this iteration: 0.020\n",
      "\n",
      "***** Epoch #194 *****\n",
      "Loss: 1.886522\n",
      "Improvement ratio: 0.018816\n",
      "Feature L2-norm: 29.460754\n",
      "Learning rate (eta): 0.096265\n",
      "Total number of feature updates: 52380\n",
      "Seconds required for this iteration: 0.007\n",
      "\n",
      "***** Epoch #195 *****\n",
      "Loss: 1.883211\n",
      "Improvement ratio: 0.018568\n",
      "Feature L2-norm: 29.477523\n",
      "Learning rate (eta): 0.096246\n",
      "Total number of feature updates: 52650\n",
      "Seconds required for this iteration: 0.008\n",
      "\n",
      "***** Epoch #196 *****\n",
      "Loss: 1.880150\n",
      "Improvement ratio: 0.018357\n",
      "Feature L2-norm: 29.494187\n",
      "Learning rate (eta): 0.096228\n",
      "Total number of feature updates: 52920\n",
      "Seconds required for this iteration: 0.020\n",
      "\n",
      "***** Epoch #197 *****\n",
      "Loss: 1.876865\n",
      "Improvement ratio: 0.018148\n",
      "Feature L2-norm: 29.510748\n",
      "Learning rate (eta): 0.096209\n",
      "Total number of feature updates: 53190\n",
      "Seconds required for this iteration: 0.016\n",
      "\n",
      "***** Epoch #198 *****\n",
      "Loss: 1.873595\n",
      "Improvement ratio: 0.017916\n",
      "Feature L2-norm: 29.527185\n",
      "Learning rate (eta): 0.096191\n",
      "Total number of feature updates: 53460\n",
      "Seconds required for this iteration: 0.024\n",
      "\n",
      "***** Epoch #199 *****\n",
      "Loss: 1.870479\n",
      "Improvement ratio: 0.017674\n",
      "Feature L2-norm: 29.543563\n",
      "Learning rate (eta): 0.096172\n",
      "Total number of feature updates: 53730\n",
      "Seconds required for this iteration: 0.023\n",
      "\n",
      "***** Epoch #200 *****\n",
      "Loss: 1.867537\n",
      "Improvement ratio: 0.017527\n",
      "Feature L2-norm: 29.559816\n",
      "Learning rate (eta): 0.096154\n",
      "Total number of feature updates: 54000\n",
      "Seconds required for this iteration: 0.025\n",
      "\n",
      "***** Epoch #201 *****\n",
      "Loss: 1.864407\n",
      "Improvement ratio: 0.017469\n",
      "Feature L2-norm: 29.575984\n",
      "Learning rate (eta): 0.096135\n",
      "Total number of feature updates: 54270\n",
      "Seconds required for this iteration: 0.020\n",
      "\n",
      "***** Epoch #202 *****\n",
      "Loss: 1.861365\n",
      "Improvement ratio: 0.017239\n",
      "Feature L2-norm: 29.592074\n",
      "Learning rate (eta): 0.096117\n",
      "Total number of feature updates: 54540\n",
      "Seconds required for this iteration: 0.021\n",
      "\n",
      "***** Epoch #203 *****\n",
      "Loss: 1.858463\n",
      "Improvement ratio: 0.016929\n",
      "Feature L2-norm: 29.608058\n",
      "Learning rate (eta): 0.096098\n",
      "Total number of feature updates: 54810\n",
      "Seconds required for this iteration: 0.012\n",
      "\n",
      "***** Epoch #204 *****\n",
      "Loss: 1.855367\n",
      "Improvement ratio: 0.016791\n",
      "Feature L2-norm: 29.623956\n",
      "Learning rate (eta): 0.096080\n",
      "Total number of feature updates: 55080\n",
      "Seconds required for this iteration: 0.021\n",
      "\n",
      "***** Epoch #205 *****\n",
      "Loss: 1.852458\n",
      "Improvement ratio: 0.016601\n",
      "Feature L2-norm: 29.639745\n",
      "Learning rate (eta): 0.096062\n",
      "Total number of feature updates: 55350\n",
      "Seconds required for this iteration: 0.012\n",
      "\n",
      "***** Epoch #206 *****\n",
      "Loss: 1.849641\n",
      "Improvement ratio: 0.016494\n",
      "Feature L2-norm: 29.655457\n",
      "Learning rate (eta): 0.096043\n",
      "Total number of feature updates: 55620\n",
      "Seconds required for this iteration: 0.021\n",
      "\n",
      "***** Epoch #207 *****\n",
      "Loss: 1.846710\n",
      "Improvement ratio: 0.016329\n",
      "Feature L2-norm: 29.671082\n",
      "Learning rate (eta): 0.096025\n",
      "Total number of feature updates: 55890\n",
      "Seconds required for this iteration: 0.019\n",
      "\n",
      "***** Epoch #208 *****\n",
      "Loss: 1.843861\n",
      "Improvement ratio: 0.016126\n",
      "Feature L2-norm: 29.686622\n",
      "Learning rate (eta): 0.096006\n",
      "Total number of feature updates: 56160\n",
      "Seconds required for this iteration: 0.021\n",
      "\n",
      "***** Epoch #209 *****\n",
      "Loss: 1.840948\n",
      "Improvement ratio: 0.016041\n",
      "Feature L2-norm: 29.702069\n",
      "Learning rate (eta): 0.095988\n",
      "Total number of feature updates: 56430\n",
      "Seconds required for this iteration: 0.023\n",
      "\n",
      "***** Epoch #210 *****\n",
      "Loss: 1.838212\n",
      "Improvement ratio: 0.015953\n",
      "Feature L2-norm: 29.717422\n",
      "Learning rate (eta): 0.095969\n",
      "Total number of feature updates: 56700\n",
      "Seconds required for this iteration: 0.022\n",
      "\n",
      "***** Epoch #211 *****\n",
      "Loss: 1.835441\n",
      "Improvement ratio: 0.015781\n",
      "Feature L2-norm: 29.732685\n",
      "Learning rate (eta): 0.095951\n",
      "Total number of feature updates: 56970\n",
      "Seconds required for this iteration: 0.013\n",
      "\n",
      "***** Epoch #212 *****\n",
      "Loss: 1.832766\n",
      "Improvement ratio: 0.015604\n",
      "Feature L2-norm: 29.747871\n",
      "Learning rate (eta): 0.095933\n",
      "Total number of feature updates: 57240\n",
      "Seconds required for this iteration: 0.015\n",
      "\n",
      "***** Epoch #213 *****\n",
      "Loss: 1.830046\n",
      "Improvement ratio: 0.015528\n",
      "Feature L2-norm: 29.762971\n",
      "Learning rate (eta): 0.095914\n",
      "Total number of feature updates: 57510\n",
      "Seconds required for this iteration: 0.021\n",
      "\n",
      "***** Epoch #214 *****\n",
      "Loss: 1.827294\n",
      "Improvement ratio: 0.015363\n",
      "Feature L2-norm: 29.777999\n",
      "Learning rate (eta): 0.095896\n",
      "Total number of feature updates: 57780\n",
      "Seconds required for this iteration: 0.022\n",
      "\n",
      "***** Epoch #215 *****\n",
      "Loss: 1.824777\n",
      "Improvement ratio: 0.015170\n",
      "Feature L2-norm: 29.792930\n",
      "Learning rate (eta): 0.095877\n",
      "Total number of feature updates: 58050\n",
      "Seconds required for this iteration: 0.021\n",
      "\n",
      "***** Epoch #216 *****\n",
      "Loss: 1.822180\n",
      "Improvement ratio: 0.015071\n",
      "Feature L2-norm: 29.807786\n",
      "Learning rate (eta): 0.095859\n",
      "Total number of feature updates: 58320\n",
      "Seconds required for this iteration: 0.019\n",
      "\n",
      "***** Epoch #217 *****\n",
      "Loss: 1.819290\n",
      "Improvement ratio: 0.015072\n",
      "Feature L2-norm: 29.822569\n",
      "Learning rate (eta): 0.095841\n",
      "Total number of feature updates: 58590\n",
      "Seconds required for this iteration: 0.022\n",
      "\n",
      "***** Epoch #218 *****\n",
      "Loss: 1.817143\n",
      "Improvement ratio: 0.014703\n",
      "Feature L2-norm: 29.837257\n",
      "Learning rate (eta): 0.095822\n",
      "Total number of feature updates: 58860\n",
      "Seconds required for this iteration: 0.012\n",
      "\n",
      "***** Epoch #219 *****\n",
      "Loss: 1.814575\n",
      "Improvement ratio: 0.014534\n",
      "Feature L2-norm: 29.851863\n",
      "Learning rate (eta): 0.095804\n",
      "Total number of feature updates: 59130\n",
      "Seconds required for this iteration: 0.023\n",
      "\n",
      "***** Epoch #220 *****\n",
      "Loss: 1.811909\n",
      "Improvement ratio: 0.014517\n",
      "Feature L2-norm: 29.866400\n",
      "Learning rate (eta): 0.095786\n",
      "Total number of feature updates: 59400\n",
      "Seconds required for this iteration: 0.014\n",
      "\n",
      "***** Epoch #221 *****\n",
      "Loss: 1.809669\n",
      "Improvement ratio: 0.014241\n",
      "Feature L2-norm: 29.880851\n",
      "Learning rate (eta): 0.095767\n",
      "Total number of feature updates: 59670\n",
      "Seconds required for this iteration: 0.015\n",
      "\n",
      "***** Epoch #222 *****\n",
      "Loss: 1.807106\n",
      "Improvement ratio: 0.014199\n",
      "Feature L2-norm: 29.895230\n",
      "Learning rate (eta): 0.095749\n",
      "Total number of feature updates: 59940\n",
      "Seconds required for this iteration: 0.017\n",
      "\n",
      "***** Epoch #223 *****\n",
      "Loss: 1.804710\n",
      "Improvement ratio: 0.014039\n",
      "Feature L2-norm: 29.909531\n",
      "Learning rate (eta): 0.095730\n",
      "Total number of feature updates: 60210\n",
      "Seconds required for this iteration: 0.021\n",
      "\n",
      "***** Epoch #224 *****\n",
      "Loss: 1.802369\n",
      "Improvement ratio: 0.013829\n",
      "Feature L2-norm: 29.923752\n",
      "Learning rate (eta): 0.095712\n",
      "Total number of feature updates: 60480\n",
      "Seconds required for this iteration: 0.020\n",
      "\n",
      "***** Epoch #225 *****\n",
      "Loss: 1.799882\n",
      "Improvement ratio: 0.013832\n",
      "Feature L2-norm: 29.937906\n",
      "Learning rate (eta): 0.095694\n",
      "Total number of feature updates: 60750\n",
      "Seconds required for this iteration: 0.022\n",
      "\n",
      "***** Epoch #226 *****\n",
      "Loss: 1.797647\n",
      "Improvement ratio: 0.013647\n",
      "Feature L2-norm: 29.951977\n",
      "Learning rate (eta): 0.095676\n",
      "Total number of feature updates: 61020\n",
      "Seconds required for this iteration: 0.032\n",
      "\n",
      "***** Epoch #227 *****\n",
      "Loss: 1.795344\n",
      "Improvement ratio: 0.013338\n",
      "Feature L2-norm: 29.965959\n",
      "Learning rate (eta): 0.095657\n",
      "Total number of feature updates: 61290\n",
      "Seconds required for this iteration: 0.025\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** Epoch #228 *****\n",
      "Loss: 1.792991\n",
      "Improvement ratio: 0.013470\n",
      "Feature L2-norm: 29.979884\n",
      "Learning rate (eta): 0.095639\n",
      "Total number of feature updates: 61560\n",
      "Seconds required for this iteration: 0.020\n",
      "\n",
      "***** Epoch #229 *****\n",
      "Loss: 1.790660\n",
      "Improvement ratio: 0.013355\n",
      "Feature L2-norm: 29.993731\n",
      "Learning rate (eta): 0.095621\n",
      "Total number of feature updates: 61830\n",
      "Seconds required for this iteration: 0.021\n",
      "\n",
      "***** Epoch #230 *****\n",
      "Loss: 1.788415\n",
      "Improvement ratio: 0.013136\n",
      "Feature L2-norm: 30.007518\n",
      "Learning rate (eta): 0.095602\n",
      "Total number of feature updates: 62100\n",
      "Seconds required for this iteration: 0.027\n",
      "\n",
      "***** Epoch #231 *****\n",
      "Loss: 1.786311\n",
      "Improvement ratio: 0.013076\n",
      "Feature L2-norm: 30.021216\n",
      "Learning rate (eta): 0.095584\n",
      "Total number of feature updates: 62370\n",
      "Seconds required for this iteration: 0.020\n",
      "\n",
      "***** Epoch #232 *****\n",
      "Loss: 1.784039\n",
      "Improvement ratio: 0.012930\n",
      "Feature L2-norm: 30.034847\n",
      "Learning rate (eta): 0.095566\n",
      "Total number of feature updates: 62640\n",
      "Seconds required for this iteration: 0.015\n",
      "\n",
      "***** Epoch #233 *****\n",
      "Loss: 1.781925\n",
      "Improvement ratio: 0.012787\n",
      "Feature L2-norm: 30.048403\n",
      "Learning rate (eta): 0.095548\n",
      "Total number of feature updates: 62910\n",
      "Seconds required for this iteration: 0.015\n",
      "\n",
      "***** Epoch #234 *****\n",
      "Loss: 1.779569\n",
      "Improvement ratio: 0.012812\n",
      "Feature L2-norm: 30.061899\n",
      "Learning rate (eta): 0.095529\n",
      "Total number of feature updates: 63180\n",
      "Seconds required for this iteration: 0.030\n",
      "\n",
      "***** Epoch #235 *****\n",
      "Loss: 1.777533\n",
      "Improvement ratio: 0.012573\n",
      "Feature L2-norm: 30.075322\n",
      "Learning rate (eta): 0.095511\n",
      "Total number of feature updates: 63450\n",
      "Seconds required for this iteration: 0.023\n",
      "\n",
      "***** Epoch #236 *****\n",
      "Loss: 1.775405\n",
      "Improvement ratio: 0.012527\n",
      "Feature L2-norm: 30.088663\n",
      "Learning rate (eta): 0.095493\n",
      "Total number of feature updates: 63720\n",
      "Seconds required for this iteration: 0.012\n",
      "\n",
      "***** Epoch #237 *****\n",
      "Loss: 1.773282\n",
      "Improvement ratio: 0.012442\n",
      "Feature L2-norm: 30.101942\n",
      "Learning rate (eta): 0.095475\n",
      "Total number of feature updates: 63990\n",
      "Seconds required for this iteration: 0.012\n",
      "\n",
      "***** Epoch #238 *****\n",
      "Loss: 1.771212\n",
      "Improvement ratio: 0.012296\n",
      "Feature L2-norm: 30.115164\n",
      "Learning rate (eta): 0.095456\n",
      "Total number of feature updates: 64260\n",
      "Seconds required for this iteration: 0.018\n",
      "\n",
      "***** Epoch #239 *****\n",
      "Loss: 1.769281\n",
      "Improvement ratio: 0.012084\n",
      "Feature L2-norm: 30.128313\n",
      "Learning rate (eta): 0.095438\n",
      "Total number of feature updates: 64530\n",
      "Seconds required for this iteration: 0.010\n",
      "\n",
      "***** Epoch #240 *****\n",
      "Loss: 1.767099\n",
      "Improvement ratio: 0.012063\n",
      "Feature L2-norm: 30.141394\n",
      "Learning rate (eta): 0.095420\n",
      "Total number of feature updates: 64800\n",
      "Seconds required for this iteration: 0.009\n",
      "\n",
      "***** Epoch #241 *****\n",
      "Loss: 1.765120\n",
      "Improvement ratio: 0.012006\n",
      "Feature L2-norm: 30.154418\n",
      "Learning rate (eta): 0.095402\n",
      "Total number of feature updates: 65070\n",
      "Seconds required for this iteration: 0.012\n",
      "\n",
      "***** Epoch #242 *****\n",
      "Loss: 1.763135\n",
      "Improvement ratio: 0.011856\n",
      "Feature L2-norm: 30.167375\n",
      "Learning rate (eta): 0.095384\n",
      "Total number of feature updates: 65340\n",
      "Seconds required for this iteration: 0.015\n",
      "\n",
      "***** Epoch #243 *****\n",
      "Loss: 1.761109\n",
      "Improvement ratio: 0.011820\n",
      "Feature L2-norm: 30.180255\n",
      "Learning rate (eta): 0.095365\n",
      "Total number of feature updates: 65610\n",
      "Seconds required for this iteration: 0.010\n",
      "\n",
      "***** Epoch #244 *****\n",
      "Loss: 1.759094\n",
      "Improvement ratio: 0.011640\n",
      "Feature L2-norm: 30.193084\n",
      "Learning rate (eta): 0.095347\n",
      "Total number of feature updates: 65880\n",
      "Seconds required for this iteration: 0.016\n",
      "\n",
      "***** Epoch #245 *****\n",
      "Loss: 1.757276\n",
      "Improvement ratio: 0.011527\n",
      "Feature L2-norm: 30.205835\n",
      "Learning rate (eta): 0.095329\n",
      "Total number of feature updates: 66150\n",
      "Seconds required for this iteration: 0.034\n",
      "\n",
      "***** Epoch #246 *****\n",
      "Loss: 1.755377\n",
      "Improvement ratio: 0.011409\n",
      "Feature L2-norm: 30.218531\n",
      "Learning rate (eta): 0.095311\n",
      "Total number of feature updates: 66420\n",
      "Seconds required for this iteration: 0.021\n",
      "\n",
      "***** Epoch #247 *****\n",
      "Loss: 1.753460\n",
      "Improvement ratio: 0.011304\n",
      "Feature L2-norm: 30.231158\n",
      "Learning rate (eta): 0.095293\n",
      "Total number of feature updates: 66690\n",
      "Seconds required for this iteration: 0.014\n",
      "\n",
      "***** Epoch #248 *****\n",
      "Loss: 1.751599\n",
      "Improvement ratio: 0.011197\n",
      "Feature L2-norm: 30.243727\n",
      "Learning rate (eta): 0.095274\n",
      "Total number of feature updates: 66960\n",
      "Seconds required for this iteration: 0.011\n",
      "\n",
      "***** Epoch #249 *****\n",
      "Loss: 1.749689\n",
      "Improvement ratio: 0.011198\n",
      "Feature L2-norm: 30.256236\n",
      "Learning rate (eta): 0.095256\n",
      "Total number of feature updates: 67230\n",
      "Seconds required for this iteration: 0.014\n",
      "\n",
      "***** Epoch #250 *****\n",
      "Loss: 1.747837\n",
      "Improvement ratio: 0.011020\n",
      "Feature L2-norm: 30.268677\n",
      "Learning rate (eta): 0.095238\n",
      "Total number of feature updates: 67500\n",
      "Seconds required for this iteration: 0.016\n",
      "\n",
      "***** Epoch #251 *****\n",
      "Loss: 1.745998\n",
      "Improvement ratio: 0.010952\n",
      "Feature L2-norm: 30.281060\n",
      "Learning rate (eta): 0.095220\n",
      "Total number of feature updates: 67770\n",
      "Seconds required for this iteration: 0.023\n",
      "\n",
      "***** Epoch #252 *****\n",
      "Loss: 1.744213\n",
      "Improvement ratio: 0.010848\n",
      "Feature L2-norm: 30.293389\n",
      "Learning rate (eta): 0.095202\n",
      "Total number of feature updates: 68040\n",
      "Seconds required for this iteration: 0.026\n",
      "\n",
      "***** Epoch #253 *****\n",
      "Loss: 1.742406\n",
      "Improvement ratio: 0.010734\n",
      "Feature L2-norm: 30.305653\n",
      "Learning rate (eta): 0.095184\n",
      "Total number of feature updates: 68310\n",
      "Seconds required for this iteration: 0.016\n",
      "\n",
      "***** Epoch #254 *****\n",
      "Loss: 1.740653\n",
      "Improvement ratio: 0.010594\n",
      "Feature L2-norm: 30.317859\n",
      "Learning rate (eta): 0.095166\n",
      "Total number of feature updates: 68580\n",
      "Seconds required for this iteration: 0.019\n",
      "\n",
      "***** Epoch #255 *****\n",
      "Loss: 1.738681\n",
      "Improvement ratio: 0.010695\n",
      "Feature L2-norm: 30.330013\n",
      "Learning rate (eta): 0.095148\n",
      "Total number of feature updates: 68850\n",
      "Seconds required for this iteration: 0.020\n",
      "\n",
      "***** Epoch #256 *****\n",
      "Loss: 1.737054\n",
      "Improvement ratio: 0.010548\n",
      "Feature L2-norm: 30.342093\n",
      "Learning rate (eta): 0.095129\n",
      "Total number of feature updates: 69120\n",
      "Seconds required for this iteration: 0.028\n",
      "\n",
      "***** Epoch #257 *****\n",
      "Loss: 1.735390\n",
      "Improvement ratio: 0.010413\n",
      "Feature L2-norm: 30.354117\n",
      "Learning rate (eta): 0.095111\n",
      "Total number of feature updates: 69390\n",
      "Seconds required for this iteration: 0.025\n",
      "\n",
      "***** Epoch #258 *****\n",
      "Loss: 1.733661\n",
      "Improvement ratio: 0.010347\n",
      "Feature L2-norm: 30.366081\n",
      "Learning rate (eta): 0.095093\n",
      "Total number of feature updates: 69660\n",
      "Seconds required for this iteration: 0.021\n",
      "\n",
      "***** Epoch #259 *****\n",
      "Loss: 1.731818\n",
      "Improvement ratio: 0.010319\n",
      "Feature L2-norm: 30.377995\n",
      "Learning rate (eta): 0.095075\n",
      "Total number of feature updates: 69930\n",
      "Seconds required for this iteration: 0.012\n",
      "\n",
      "***** Epoch #260 *****\n",
      "Loss: 1.730217\n",
      "Improvement ratio: 0.010184\n",
      "Feature L2-norm: 30.389846\n",
      "Learning rate (eta): 0.095057\n",
      "Total number of feature updates: 70200\n",
      "Seconds required for this iteration: 0.027\n",
      "\n",
      "***** Epoch #261 *****\n",
      "Loss: 1.728671\n",
      "Improvement ratio: 0.010023\n",
      "Feature L2-norm: 30.401653\n",
      "Learning rate (eta): 0.095039\n",
      "Total number of feature updates: 70470\n",
      "Seconds required for this iteration: 0.016\n",
      "\n",
      "***** Epoch #262 *****\n",
      "Loss: 1.726862\n",
      "Improvement ratio: 0.010048\n",
      "Feature L2-norm: 30.413410\n",
      "Learning rate (eta): 0.095021\n",
      "Total number of feature updates: 70740\n",
      "Seconds required for this iteration: 0.020\n",
      "\n",
      "***** Epoch #263 *****\n",
      "Loss: 1.725314\n",
      "Improvement ratio: 0.009907\n",
      "Feature L2-norm: 30.425104\n",
      "Learning rate (eta): 0.095003\n",
      "Total number of feature updates: 71010\n",
      "Seconds required for this iteration: 0.019\n",
      "\n",
      "***** Epoch #264 *****\n",
      "Loss: 1.723656\n",
      "Improvement ratio: 0.009861\n",
      "Feature L2-norm: 30.436736\n",
      "Learning rate (eta): 0.094985\n",
      "Total number of feature updates: 71280\n",
      "Seconds required for this iteration: 0.014\n",
      "\n",
      "***** Epoch #265 *****\n",
      "Loss: 1.722056\n",
      "Improvement ratio: 0.009654\n",
      "Feature L2-norm: 30.448315\n",
      "Learning rate (eta): 0.094967\n",
      "Total number of feature updates: 71550\n",
      "Seconds required for this iteration: 0.009\n",
      "\n",
      "***** Epoch #266 *****\n",
      "Loss: 1.720512\n",
      "Improvement ratio: 0.009615\n",
      "Feature L2-norm: 30.459848\n",
      "Learning rate (eta): 0.094949\n",
      "Total number of feature updates: 71820\n",
      "Seconds required for this iteration: 0.023\n",
      "\n",
      "***** Epoch #267 *****\n",
      "Loss: 1.718771\n",
      "Improvement ratio: 0.009669\n",
      "Feature L2-norm: 30.471316\n",
      "Learning rate (eta): 0.094931\n",
      "Total number of feature updates: 72090\n",
      "Seconds required for this iteration: 0.023\n",
      "\n",
      "***** Epoch #268 *****\n",
      "Loss: 1.717315\n",
      "Improvement ratio: 0.009519\n",
      "Feature L2-norm: 30.482747\n",
      "Learning rate (eta): 0.094913\n",
      "Total number of feature updates: 72360\n",
      "Seconds required for this iteration: 0.011\n",
      "\n",
      "***** Epoch #269 *****\n",
      "Loss: 1.715879\n",
      "Improvement ratio: 0.009289\n",
      "Feature L2-norm: 30.494110\n",
      "Learning rate (eta): 0.094895\n",
      "Total number of feature updates: 72630\n",
      "Seconds required for this iteration: 0.015\n",
      "\n",
      "***** Epoch #270 *****\n",
      "Loss: 1.714230\n",
      "Improvement ratio: 0.009326\n",
      "Feature L2-norm: 30.505434\n",
      "Learning rate (eta): 0.094877\n",
      "Total number of feature updates: 72900\n",
      "Seconds required for this iteration: 0.015\n",
      "\n",
      "***** Epoch #271 *****\n",
      "Loss: 1.712748\n",
      "Improvement ratio: 0.009297\n",
      "Feature L2-norm: 30.516698\n",
      "Learning rate (eta): 0.094859\n",
      "Total number of feature updates: 73170\n",
      "Seconds required for this iteration: 0.020\n",
      "\n",
      "***** Epoch #272 *****\n",
      "Loss: 1.711195\n",
      "Improvement ratio: 0.009156\n",
      "Feature L2-norm: 30.527912\n",
      "Learning rate (eta): 0.094841\n",
      "Total number of feature updates: 73440\n",
      "Seconds required for this iteration: 0.021\n",
      "\n",
      "***** Epoch #273 *****\n",
      "Loss: 1.709780\n",
      "Improvement ratio: 0.009085\n",
      "Feature L2-norm: 30.539066\n",
      "Learning rate (eta): 0.094823\n",
      "Total number of feature updates: 73710\n",
      "Seconds required for this iteration: 0.022\n",
      "\n",
      "***** Epoch #274 *****\n",
      "Loss: 1.708239\n",
      "Improvement ratio: 0.009025\n",
      "Feature L2-norm: 30.550175\n",
      "Learning rate (eta): 0.094805\n",
      "Total number of feature updates: 73980\n",
      "Seconds required for this iteration: 0.013\n",
      "\n",
      "***** Epoch #275 *****\n",
      "Loss: 1.706751\n",
      "Improvement ratio: 0.008968\n",
      "Feature L2-norm: 30.561231\n",
      "Learning rate (eta): 0.094787\n",
      "Total number of feature updates: 74250\n",
      "Seconds required for this iteration: 0.012\n",
      "\n",
      "***** Epoch #276 *****\n",
      "Loss: 1.705297\n",
      "Improvement ratio: 0.008922\n",
      "Feature L2-norm: 30.572242\n",
      "Learning rate (eta): 0.094769\n",
      "Total number of feature updates: 74520\n",
      "Seconds required for this iteration: 0.021\n",
      "\n",
      "***** Epoch #277 *****\n",
      "Loss: 1.703858\n",
      "Improvement ratio: 0.008752\n",
      "Feature L2-norm: 30.583192\n",
      "Learning rate (eta): 0.094751\n",
      "Total number of feature updates: 74790\n",
      "Seconds required for this iteration: 0.011\n",
      "\n",
      "***** Epoch #278 *****\n",
      "Loss: 1.702217\n",
      "Improvement ratio: 0.008869\n",
      "Feature L2-norm: 30.594107\n",
      "Learning rate (eta): 0.094733\n",
      "Total number of feature updates: 75060\n",
      "Seconds required for this iteration: 0.010\n",
      "\n",
      "***** Epoch #279 *****\n",
      "Loss: 1.700982\n",
      "Improvement ratio: 0.008758\n",
      "Feature L2-norm: 30.604960\n",
      "Learning rate (eta): 0.094715\n",
      "Total number of feature updates: 75330\n",
      "Seconds required for this iteration: 0.024\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** Epoch #280 *****\n",
      "Loss: 1.699620\n",
      "Improvement ratio: 0.008596\n",
      "Feature L2-norm: 30.615759\n",
      "Learning rate (eta): 0.094697\n",
      "Total number of feature updates: 75600\n",
      "Seconds required for this iteration: 0.020\n",
      "\n",
      "***** Epoch #281 *****\n",
      "Loss: 1.698200\n",
      "Improvement ratio: 0.008567\n",
      "Feature L2-norm: 30.626511\n",
      "Learning rate (eta): 0.094679\n",
      "Total number of feature updates: 75870\n",
      "Seconds required for this iteration: 0.023\n",
      "\n",
      "***** Epoch #282 *****\n",
      "Loss: 1.696822\n",
      "Improvement ratio: 0.008470\n",
      "Feature L2-norm: 30.637222\n",
      "Learning rate (eta): 0.094661\n",
      "Total number of feature updates: 76140\n",
      "Seconds required for this iteration: 0.016\n",
      "\n",
      "***** Epoch #283 *****\n",
      "Loss: 1.695456\n",
      "Improvement ratio: 0.008448\n",
      "Feature L2-norm: 30.647883\n",
      "Learning rate (eta): 0.094643\n",
      "Total number of feature updates: 76410\n",
      "Seconds required for this iteration: 0.015\n",
      "\n",
      "***** Epoch #284 *****\n",
      "Loss: 1.694079\n",
      "Improvement ratio: 0.008359\n",
      "Feature L2-norm: 30.658495\n",
      "Learning rate (eta): 0.094625\n",
      "Total number of feature updates: 76680\n",
      "Seconds required for this iteration: 0.014\n",
      "\n",
      "***** Epoch #285 *****\n",
      "Loss: 1.692759\n",
      "Improvement ratio: 0.008266\n",
      "Feature L2-norm: 30.669060\n",
      "Learning rate (eta): 0.094607\n",
      "Total number of feature updates: 76950\n",
      "Seconds required for this iteration: 0.026\n",
      "\n",
      "***** Epoch #286 *****\n",
      "Loss: 1.691324\n",
      "Improvement ratio: 0.008261\n",
      "Feature L2-norm: 30.679588\n",
      "Learning rate (eta): 0.094590\n",
      "Total number of feature updates: 77220\n",
      "Seconds required for this iteration: 0.022\n",
      "\n",
      "***** Epoch #287 *****\n",
      "Loss: 1.690049\n",
      "Improvement ratio: 0.008171\n",
      "Feature L2-norm: 30.690069\n",
      "Learning rate (eta): 0.094572\n",
      "Total number of feature updates: 77490\n",
      "Seconds required for this iteration: 0.030\n",
      "\n",
      "***** Epoch #288 *****\n",
      "Loss: 1.688729\n",
      "Improvement ratio: 0.007987\n",
      "Feature L2-norm: 30.700504\n",
      "Learning rate (eta): 0.094554\n",
      "Total number of feature updates: 77760\n",
      "Seconds required for this iteration: 0.016\n",
      "\n",
      "***** Epoch #289 *****\n",
      "Loss: 1.687409\n",
      "Improvement ratio: 0.008043\n",
      "Feature L2-norm: 30.710891\n",
      "Learning rate (eta): 0.094536\n",
      "Total number of feature updates: 78030\n",
      "Seconds required for this iteration: 0.013\n",
      "\n",
      "***** Epoch #290 *****\n",
      "Loss: 1.686178\n",
      "Improvement ratio: 0.007972\n",
      "Feature L2-norm: 30.721227\n",
      "Learning rate (eta): 0.094518\n",
      "Total number of feature updates: 78300\n",
      "Seconds required for this iteration: 0.010\n",
      "\n",
      "***** Epoch #291 *****\n",
      "Loss: 1.684872\n",
      "Improvement ratio: 0.007910\n",
      "Feature L2-norm: 30.731522\n",
      "Learning rate (eta): 0.094500\n",
      "Total number of feature updates: 78570\n",
      "Seconds required for this iteration: 0.012\n",
      "\n",
      "***** Epoch #292 *****\n",
      "Loss: 1.683602\n",
      "Improvement ratio: 0.007852\n",
      "Feature L2-norm: 30.741765\n",
      "Learning rate (eta): 0.094482\n",
      "Total number of feature updates: 78840\n",
      "Seconds required for this iteration: 0.019\n",
      "\n",
      "***** Epoch #293 *****\n",
      "Loss: 1.682282\n",
      "Improvement ratio: 0.007831\n",
      "Feature L2-norm: 30.751966\n",
      "Learning rate (eta): 0.094464\n",
      "Total number of feature updates: 79110\n",
      "Seconds required for this iteration: 0.012\n",
      "\n",
      "***** Epoch #294 *****\n",
      "Loss: 1.681057\n",
      "Improvement ratio: 0.007746\n",
      "Feature L2-norm: 30.762131\n",
      "Learning rate (eta): 0.094447\n",
      "Total number of feature updates: 79380\n",
      "Seconds required for this iteration: 0.019\n",
      "\n",
      "***** Epoch #295 *****\n",
      "Loss: 1.679857\n",
      "Improvement ratio: 0.007680\n",
      "Feature L2-norm: 30.772242\n",
      "Learning rate (eta): 0.094429\n",
      "Total number of feature updates: 79650\n",
      "Seconds required for this iteration: 0.019\n",
      "\n",
      "***** Epoch #296 *****\n",
      "Loss: 1.678599\n",
      "Improvement ratio: 0.007581\n",
      "Feature L2-norm: 30.782315\n",
      "Learning rate (eta): 0.094411\n",
      "Total number of feature updates: 79920\n",
      "Seconds required for this iteration: 0.023\n",
      "\n",
      "***** Epoch #297 *****\n",
      "Loss: 1.677397\n",
      "Improvement ratio: 0.007542\n",
      "Feature L2-norm: 30.792343\n",
      "Learning rate (eta): 0.094393\n",
      "Total number of feature updates: 80190\n",
      "Seconds required for this iteration: 0.010\n",
      "\n",
      "***** Epoch #298 *****\n",
      "Loss: 1.676192\n",
      "Improvement ratio: 0.007479\n",
      "Feature L2-norm: 30.802332\n",
      "Learning rate (eta): 0.094375\n",
      "Total number of feature updates: 80460\n",
      "Seconds required for this iteration: 0.011\n",
      "\n",
      "***** Epoch #299 *****\n",
      "Loss: 1.675009\n",
      "Improvement ratio: 0.007403\n",
      "Feature L2-norm: 30.812272\n",
      "Learning rate (eta): 0.094357\n",
      "Total number of feature updates: 80730\n",
      "Seconds required for this iteration: 0.010\n",
      "\n",
      "***** Epoch #300 *****\n",
      "Loss: 1.673748\n",
      "Improvement ratio: 0.007427\n",
      "Feature L2-norm: 30.822171\n",
      "Learning rate (eta): 0.094340\n",
      "Total number of feature updates: 81000\n",
      "Seconds required for this iteration: 0.015\n",
      "\n",
      "***** Epoch #301 *****\n",
      "Loss: 1.672513\n",
      "Improvement ratio: 0.007389\n",
      "Feature L2-norm: 30.832033\n",
      "Learning rate (eta): 0.094322\n",
      "Total number of feature updates: 81270\n",
      "Seconds required for this iteration: 0.015\n",
      "\n",
      "***** Epoch #302 *****\n",
      "Loss: 1.671466\n",
      "Improvement ratio: 0.007261\n",
      "Feature L2-norm: 30.841845\n",
      "Learning rate (eta): 0.094304\n",
      "Total number of feature updates: 81540\n",
      "Seconds required for this iteration: 0.014\n",
      "\n",
      "***** Epoch #303 *****\n",
      "Loss: 1.670259\n",
      "Improvement ratio: 0.007198\n",
      "Feature L2-norm: 30.851618\n",
      "Learning rate (eta): 0.094286\n",
      "Total number of feature updates: 81810\n",
      "Seconds required for this iteration: 0.013\n",
      "\n",
      "***** Epoch #304 *****\n",
      "Loss: 1.669139\n",
      "Improvement ratio: 0.007140\n",
      "Feature L2-norm: 30.861349\n",
      "Learning rate (eta): 0.094269\n",
      "Total number of feature updates: 82080\n",
      "Seconds required for this iteration: 0.014\n",
      "\n",
      "***** Epoch #305 *****\n",
      "Loss: 1.667942\n",
      "Improvement ratio: 0.007144\n",
      "Feature L2-norm: 30.871041\n",
      "Learning rate (eta): 0.094251\n",
      "Total number of feature updates: 82350\n",
      "Seconds required for this iteration: 0.013\n",
      "\n",
      "***** Epoch #306 *****\n",
      "Loss: 1.666831\n",
      "Improvement ratio: 0.007060\n",
      "Feature L2-norm: 30.880684\n",
      "Learning rate (eta): 0.094233\n",
      "Total number of feature updates: 82620\n",
      "Seconds required for this iteration: 0.017\n",
      "\n",
      "***** Epoch #307 *****\n",
      "Loss: 1.665699\n",
      "Improvement ratio: 0.007023\n",
      "Feature L2-norm: 30.890291\n",
      "Learning rate (eta): 0.094215\n",
      "Total number of feature updates: 82890\n",
      "Seconds required for this iteration: 0.019\n",
      "\n",
      "***** Epoch #308 *****\n",
      "Loss: 1.664573\n",
      "Improvement ratio: 0.006980\n",
      "Feature L2-norm: 30.899856\n",
      "Learning rate (eta): 0.094198\n",
      "Total number of feature updates: 83160\n",
      "Seconds required for this iteration: 0.020\n",
      "\n",
      "***** Epoch #309 *****\n",
      "Loss: 1.663446\n",
      "Improvement ratio: 0.006951\n",
      "Feature L2-norm: 30.909386\n",
      "Learning rate (eta): 0.094180\n",
      "Total number of feature updates: 83430\n",
      "Seconds required for this iteration: 0.016\n",
      "\n",
      "***** Epoch #310 *****\n",
      "Loss: 1.662354\n",
      "Improvement ratio: 0.006854\n",
      "Feature L2-norm: 30.918877\n",
      "Learning rate (eta): 0.094162\n",
      "Total number of feature updates: 83700\n",
      "Seconds required for this iteration: 0.023\n",
      "\n",
      "***** Epoch #311 *****\n",
      "Loss: 1.661279\n",
      "Improvement ratio: 0.006762\n",
      "Feature L2-norm: 30.928325\n",
      "Learning rate (eta): 0.094144\n",
      "Total number of feature updates: 83970\n",
      "Seconds required for this iteration: 0.016\n",
      "\n",
      "***** Epoch #312 *****\n",
      "Loss: 1.660204\n",
      "Improvement ratio: 0.006783\n",
      "Feature L2-norm: 30.937736\n",
      "Learning rate (eta): 0.094127\n",
      "Total number of feature updates: 84240\n",
      "Seconds required for this iteration: 0.010\n",
      "\n",
      "***** Epoch #313 *****\n",
      "Loss: 1.659142\n",
      "Improvement ratio: 0.006701\n",
      "Feature L2-norm: 30.947108\n",
      "Learning rate (eta): 0.094109\n",
      "Total number of feature updates: 84510\n",
      "Seconds required for this iteration: 0.010\n",
      "\n",
      "***** Epoch #314 *****\n",
      "Loss: 1.658008\n",
      "Improvement ratio: 0.006713\n",
      "Feature L2-norm: 30.956446\n",
      "Learning rate (eta): 0.094091\n",
      "Total number of feature updates: 84780\n",
      "Seconds required for this iteration: 0.006\n",
      "\n",
      "***** Epoch #315 *****\n",
      "Loss: 1.656963\n",
      "Improvement ratio: 0.006626\n",
      "Feature L2-norm: 30.965747\n",
      "Learning rate (eta): 0.094073\n",
      "Total number of feature updates: 85050\n",
      "Seconds required for this iteration: 0.013\n",
      "\n",
      "***** Epoch #316 *****\n",
      "Loss: 1.656045\n",
      "Improvement ratio: 0.006513\n",
      "Feature L2-norm: 30.974998\n",
      "Learning rate (eta): 0.094056\n",
      "Total number of feature updates: 85320\n",
      "Seconds required for this iteration: 0.015\n",
      "\n",
      "***** Epoch #317 *****\n",
      "Loss: 1.654902\n",
      "Improvement ratio: 0.006524\n",
      "Feature L2-norm: 30.984208\n",
      "Learning rate (eta): 0.094038\n",
      "Total number of feature updates: 85590\n",
      "Seconds required for this iteration: 0.022\n",
      "\n",
      "***** Epoch #318 *****\n",
      "Loss: 1.653931\n",
      "Improvement ratio: 0.006434\n",
      "Feature L2-norm: 30.993387\n",
      "Learning rate (eta): 0.094020\n",
      "Total number of feature updates: 85860\n",
      "Seconds required for this iteration: 0.024\n",
      "\n",
      "***** Epoch #319 *****\n",
      "Loss: 1.652875\n",
      "Improvement ratio: 0.006396\n",
      "Feature L2-norm: 31.002526\n",
      "Learning rate (eta): 0.094003\n",
      "Total number of feature updates: 86130\n",
      "Seconds required for this iteration: 0.021\n",
      "\n",
      "***** Epoch #320 *****\n",
      "Loss: 1.651890\n",
      "Improvement ratio: 0.006335\n",
      "Feature L2-norm: 31.011630\n",
      "Learning rate (eta): 0.093985\n",
      "Total number of feature updates: 86400\n",
      "Seconds required for this iteration: 0.012\n",
      "\n",
      "***** Epoch #321 *****\n",
      "Loss: 1.650842\n",
      "Improvement ratio: 0.006322\n",
      "Feature L2-norm: 31.020698\n",
      "Learning rate (eta): 0.093967\n",
      "Total number of feature updates: 86670\n",
      "Seconds required for this iteration: 0.027\n",
      "\n",
      "***** Epoch #322 *****\n",
      "Loss: 1.649822\n",
      "Improvement ratio: 0.006293\n",
      "Feature L2-norm: 31.029732\n",
      "Learning rate (eta): 0.093950\n",
      "Total number of feature updates: 86940\n",
      "Seconds required for this iteration: 0.023\n",
      "\n",
      "***** Epoch #323 *****\n",
      "Loss: 1.648892\n",
      "Improvement ratio: 0.006216\n",
      "Feature L2-norm: 31.038722\n",
      "Learning rate (eta): 0.093932\n",
      "Total number of feature updates: 87210\n",
      "Seconds required for this iteration: 0.016\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** Epoch #324 *****\n",
      "Loss: 1.647815\n",
      "Improvement ratio: 0.006186\n",
      "Feature L2-norm: 31.047682\n",
      "Learning rate (eta): 0.093914\n",
      "Total number of feature updates: 87480\n",
      "Seconds required for this iteration: 0.015\n",
      "\n",
      "***** Epoch #325 *****\n",
      "Loss: 1.646882\n",
      "Improvement ratio: 0.006121\n",
      "Feature L2-norm: 31.056598\n",
      "Learning rate (eta): 0.093897\n",
      "Total number of feature updates: 87750\n",
      "Seconds required for this iteration: 0.014\n",
      "\n",
      "***** Epoch #326 *****\n",
      "Loss: 1.645895\n",
      "Improvement ratio: 0.006167\n",
      "Feature L2-norm: 31.065485\n",
      "Learning rate (eta): 0.093879\n",
      "Total number of feature updates: 88020\n",
      "Seconds required for this iteration: 0.021\n",
      "\n",
      "***** Epoch #327 *****\n",
      "Loss: 1.644982\n",
      "Improvement ratio: 0.006031\n",
      "Feature L2-norm: 31.074333\n",
      "Learning rate (eta): 0.093862\n",
      "Total number of feature updates: 88290\n",
      "Seconds required for this iteration: 0.016\n",
      "\n",
      "***** Epoch #328 *****\n",
      "Loss: 1.644030\n",
      "Improvement ratio: 0.006022\n",
      "Feature L2-norm: 31.083140\n",
      "Learning rate (eta): 0.093844\n",
      "Total number of feature updates: 88560\n",
      "Seconds required for this iteration: 0.020\n",
      "\n",
      "***** Epoch #329 *****\n",
      "Loss: 1.643025\n",
      "Improvement ratio: 0.005995\n",
      "Feature L2-norm: 31.091921\n",
      "Learning rate (eta): 0.093826\n",
      "Total number of feature updates: 88830\n",
      "Seconds required for this iteration: 0.020\n",
      "\n",
      "***** Epoch #330 *****\n",
      "Loss: 1.642105\n",
      "Improvement ratio: 0.005959\n",
      "Feature L2-norm: 31.100668\n",
      "Learning rate (eta): 0.093809\n",
      "Total number of feature updates: 89100\n",
      "Seconds required for this iteration: 0.010\n",
      "\n",
      "***** Epoch #331 *****\n",
      "Loss: 1.641182\n",
      "Improvement ratio: 0.005886\n",
      "Feature L2-norm: 31.109378\n",
      "Learning rate (eta): 0.093791\n",
      "Total number of feature updates: 89370\n",
      "Seconds required for this iteration: 0.013\n",
      "\n",
      "***** Epoch #332 *****\n",
      "Loss: 1.640246\n",
      "Improvement ratio: 0.005838\n",
      "Feature L2-norm: 31.118049\n",
      "Learning rate (eta): 0.093774\n",
      "Total number of feature updates: 89640\n",
      "Seconds required for this iteration: 0.011\n",
      "\n",
      "***** Epoch #333 *****\n",
      "Loss: 1.639355\n",
      "Improvement ratio: 0.005817\n",
      "Feature L2-norm: 31.126692\n",
      "Learning rate (eta): 0.093756\n",
      "Total number of feature updates: 89910\n",
      "Seconds required for this iteration: 0.011\n",
      "\n",
      "***** Epoch #334 *****\n",
      "Loss: 1.638478\n",
      "Improvement ratio: 0.005699\n",
      "Feature L2-norm: 31.135301\n",
      "Learning rate (eta): 0.093738\n",
      "Total number of feature updates: 90180\n",
      "Seconds required for this iteration: 0.013\n",
      "\n",
      "***** Epoch #335 *****\n",
      "Loss: 1.637462\n",
      "Improvement ratio: 0.005753\n",
      "Feature L2-norm: 31.143874\n",
      "Learning rate (eta): 0.093721\n",
      "Total number of feature updates: 90450\n",
      "Seconds required for this iteration: 0.023\n",
      "\n",
      "***** Epoch #336 *****\n",
      "Loss: 1.636641\n",
      "Improvement ratio: 0.005655\n",
      "Feature L2-norm: 31.152410\n",
      "Learning rate (eta): 0.093703\n",
      "Total number of feature updates: 90720\n",
      "Seconds required for this iteration: 0.012\n",
      "\n",
      "***** Epoch #337 *****\n",
      "Loss: 1.635723\n",
      "Improvement ratio: 0.005660\n",
      "Feature L2-norm: 31.160914\n",
      "Learning rate (eta): 0.093686\n",
      "Total number of feature updates: 90990\n",
      "Seconds required for this iteration: 0.015\n",
      "\n",
      "***** Epoch #338 *****\n",
      "Loss: 1.634854\n",
      "Improvement ratio: 0.005613\n",
      "Feature L2-norm: 31.169385\n",
      "Learning rate (eta): 0.093668\n",
      "Total number of feature updates: 91260\n",
      "Seconds required for this iteration: 0.022\n",
      "\n",
      "***** Epoch #339 *****\n",
      "Loss: 1.633966\n",
      "Improvement ratio: 0.005544\n",
      "Feature L2-norm: 31.177822\n",
      "Learning rate (eta): 0.093651\n",
      "Total number of feature updates: 91530\n",
      "Seconds required for this iteration: 0.012\n",
      "\n",
      "***** Epoch #340 *****\n",
      "Loss: 1.633145\n",
      "Improvement ratio: 0.005486\n",
      "Feature L2-norm: 31.186219\n",
      "Learning rate (eta): 0.093633\n",
      "Total number of feature updates: 91800\n",
      "Seconds required for this iteration: 0.016\n",
      "\n",
      "***** Epoch #341 *****\n",
      "Loss: 1.632201\n",
      "Improvement ratio: 0.005502\n",
      "Feature L2-norm: 31.194581\n",
      "Learning rate (eta): 0.093615\n",
      "Total number of feature updates: 92070\n",
      "Seconds required for this iteration: 0.027\n",
      "\n",
      "***** Epoch #342 *****\n",
      "Loss: 1.631389\n",
      "Improvement ratio: 0.005429\n",
      "Feature L2-norm: 31.202916\n",
      "Learning rate (eta): 0.093598\n",
      "Total number of feature updates: 92340\n",
      "Seconds required for this iteration: 0.011\n",
      "\n",
      "***** Epoch #343 *****\n",
      "Loss: 1.630551\n",
      "Improvement ratio: 0.005399\n",
      "Feature L2-norm: 31.211222\n",
      "Learning rate (eta): 0.093580\n",
      "Total number of feature updates: 92610\n",
      "Seconds required for this iteration: 0.018\n",
      "\n",
      "***** Epoch #344 *****\n",
      "Loss: 1.629629\n",
      "Improvement ratio: 0.005430\n",
      "Feature L2-norm: 31.219496\n",
      "Learning rate (eta): 0.093563\n",
      "Total number of feature updates: 92880\n",
      "Seconds required for this iteration: 0.018\n",
      "\n",
      "***** Epoch #345 *****\n",
      "Loss: 1.628852\n",
      "Improvement ratio: 0.005286\n",
      "Feature L2-norm: 31.227740\n",
      "Learning rate (eta): 0.093545\n",
      "Total number of feature updates: 93150\n",
      "Seconds required for this iteration: 0.011\n",
      "\n",
      "***** Epoch #346 *****\n",
      "Loss: 1.627983\n",
      "Improvement ratio: 0.005318\n",
      "Feature L2-norm: 31.235949\n",
      "Learning rate (eta): 0.093528\n",
      "Total number of feature updates: 93420\n",
      "Seconds required for this iteration: 0.015\n",
      "\n",
      "***** Epoch #347 *****\n",
      "Loss: 1.627181\n",
      "Improvement ratio: 0.005250\n",
      "Feature L2-norm: 31.244125\n",
      "Learning rate (eta): 0.093510\n",
      "Total number of feature updates: 93690\n",
      "Seconds required for this iteration: 0.022\n",
      "\n",
      "***** Epoch #348 *****\n",
      "Loss: 1.626354\n",
      "Improvement ratio: 0.005226\n",
      "Feature L2-norm: 31.252269\n",
      "Learning rate (eta): 0.093493\n",
      "Total number of feature updates: 93960\n",
      "Seconds required for this iteration: 0.027\n",
      "\n",
      "***** Epoch #349 *****\n",
      "Loss: 1.625520\n",
      "Improvement ratio: 0.005195\n",
      "Feature L2-norm: 31.260383\n",
      "Learning rate (eta): 0.093475\n",
      "Total number of feature updates: 94230\n",
      "Seconds required for this iteration: 0.032\n",
      "\n",
      "***** Epoch #350 *****\n",
      "Loss: 1.624711\n",
      "Improvement ratio: 0.005191\n",
      "Feature L2-norm: 31.268466\n",
      "Learning rate (eta): 0.093458\n",
      "Total number of feature updates: 94500\n",
      "Seconds required for this iteration: 0.025\n",
      "\n",
      "***** Epoch #351 *****\n",
      "Loss: 1.623928\n",
      "Improvement ratio: 0.005094\n",
      "Feature L2-norm: 31.276519\n",
      "Learning rate (eta): 0.093441\n",
      "Total number of feature updates: 94770\n",
      "Seconds required for this iteration: 0.017\n",
      "\n",
      "***** Epoch #352 *****\n",
      "Loss: 1.623101\n",
      "Improvement ratio: 0.005106\n",
      "Feature L2-norm: 31.284543\n",
      "Learning rate (eta): 0.093423\n",
      "Total number of feature updates: 95040\n",
      "Seconds required for this iteration: 0.023\n",
      "\n",
      "***** Epoch #353 *****\n",
      "Loss: 1.622281\n",
      "Improvement ratio: 0.005098\n",
      "Feature L2-norm: 31.292535\n",
      "Learning rate (eta): 0.093406\n",
      "Total number of feature updates: 95310\n",
      "Seconds required for this iteration: 0.019\n",
      "\n",
      "***** Epoch #354 *****\n",
      "Loss: 1.621543\n",
      "Improvement ratio: 0.004986\n",
      "Feature L2-norm: 31.300498\n",
      "Learning rate (eta): 0.093388\n",
      "Total number of feature updates: 95580\n",
      "Seconds required for this iteration: 0.016\n",
      "\n",
      "***** Epoch #355 *****\n",
      "Loss: 1.620776\n",
      "Improvement ratio: 0.004983\n",
      "Feature L2-norm: 31.308430\n",
      "Learning rate (eta): 0.093371\n",
      "Total number of feature updates: 95850\n",
      "Seconds required for this iteration: 0.020\n",
      "\n",
      "***** Epoch #356 *****\n",
      "Loss: 1.619998\n",
      "Improvement ratio: 0.004929\n",
      "Feature L2-norm: 31.316333\n",
      "Learning rate (eta): 0.093353\n",
      "Total number of feature updates: 96120\n",
      "Seconds required for this iteration: 0.017\n",
      "\n",
      "***** Epoch #357 *****\n",
      "Loss: 1.619191\n",
      "Improvement ratio: 0.004934\n",
      "Feature L2-norm: 31.324208\n",
      "Learning rate (eta): 0.093336\n",
      "Total number of feature updates: 96390\n",
      "Seconds required for this iteration: 0.012\n",
      "\n",
      "***** Epoch #358 *****\n",
      "Loss: 1.618436\n",
      "Improvement ratio: 0.004892\n",
      "Feature L2-norm: 31.332047\n",
      "Learning rate (eta): 0.093318\n",
      "Total number of feature updates: 96660\n",
      "Seconds required for this iteration: 0.009\n",
      "\n",
      "***** Epoch #359 *****\n",
      "Loss: 1.617675\n",
      "Improvement ratio: 0.004850\n",
      "Feature L2-norm: 31.339853\n",
      "Learning rate (eta): 0.093301\n",
      "Total number of feature updates: 96930\n",
      "Seconds required for this iteration: 0.011\n",
      "\n",
      "***** Epoch #360 *****\n",
      "Loss: 1.616934\n",
      "Improvement ratio: 0.004810\n",
      "Feature L2-norm: 31.347640\n",
      "Learning rate (eta): 0.093284\n",
      "Total number of feature updates: 97200\n",
      "Seconds required for this iteration: 0.010\n",
      "\n",
      "***** Epoch #361 *****\n",
      "Loss: 1.616179\n",
      "Improvement ratio: 0.004795\n",
      "Feature L2-norm: 31.355392\n",
      "Learning rate (eta): 0.093266\n",
      "Total number of feature updates: 97470\n",
      "Seconds required for this iteration: 0.017\n",
      "\n",
      "***** Epoch #362 *****\n",
      "Loss: 1.615417\n",
      "Improvement ratio: 0.004756\n",
      "Feature L2-norm: 31.363123\n",
      "Learning rate (eta): 0.093249\n",
      "Total number of feature updates: 97740\n",
      "Seconds required for this iteration: 0.021\n",
      "\n",
      "***** Epoch #363 *****\n",
      "Loss: 1.614706\n",
      "Improvement ratio: 0.004692\n",
      "Feature L2-norm: 31.370813\n",
      "Learning rate (eta): 0.093231\n",
      "Total number of feature updates: 98010\n",
      "Seconds required for this iteration: 0.012\n",
      "\n",
      "***** Epoch #364 *****\n",
      "Loss: 1.613960\n",
      "Improvement ratio: 0.004698\n",
      "Feature L2-norm: 31.378482\n",
      "Learning rate (eta): 0.093214\n",
      "Total number of feature updates: 98280\n",
      "Seconds required for this iteration: 0.019\n",
      "\n",
      "***** Epoch #365 *****\n",
      "Loss: 1.613192\n",
      "Improvement ratio: 0.004701\n",
      "Feature L2-norm: 31.386120\n",
      "Learning rate (eta): 0.093197\n",
      "Total number of feature updates: 98550\n",
      "Seconds required for this iteration: 0.024\n",
      "\n",
      "***** Epoch #366 *****\n",
      "Loss: 1.612500\n",
      "Improvement ratio: 0.004650\n",
      "Feature L2-norm: 31.393728\n",
      "Learning rate (eta): 0.093179\n",
      "Total number of feature updates: 98820\n",
      "Seconds required for this iteration: 0.025\n",
      "\n",
      "***** Epoch #367 *****\n",
      "Loss: 1.611799\n",
      "Improvement ratio: 0.004587\n",
      "Feature L2-norm: 31.401306\n",
      "Learning rate (eta): 0.093162\n",
      "Total number of feature updates: 99090\n",
      "Seconds required for this iteration: 0.022\n",
      "\n",
      "***** Epoch #368 *****\n",
      "Loss: 1.611108\n",
      "Improvement ratio: 0.004548\n",
      "Feature L2-norm: 31.408860\n",
      "Learning rate (eta): 0.093145\n",
      "Total number of feature updates: 99360\n",
      "Seconds required for this iteration: 0.013\n",
      "\n",
      "***** Epoch #369 *****\n",
      "Loss: 1.610368\n",
      "Improvement ratio: 0.004538\n",
      "Feature L2-norm: 31.416387\n",
      "Learning rate (eta): 0.093127\n",
      "Total number of feature updates: 99630\n",
      "Seconds required for this iteration: 0.019\n",
      "\n",
      "***** Epoch #370 *****\n",
      "Loss: 1.609665\n",
      "Improvement ratio: 0.004516\n",
      "Feature L2-norm: 31.423882\n",
      "Learning rate (eta): 0.093110\n",
      "Total number of feature updates: 99900\n",
      "Seconds required for this iteration: 0.015\n",
      "\n",
      "***** Epoch #371 *****\n",
      "Loss: 1.608956\n",
      "Improvement ratio: 0.004489\n",
      "Feature L2-norm: 31.431357\n",
      "Learning rate (eta): 0.093093\n",
      "Total number of feature updates: 100170\n",
      "Seconds required for this iteration: 0.010\n",
      "\n",
      "***** Epoch #372 *****\n",
      "Loss: 1.608271\n",
      "Improvement ratio: 0.004444\n",
      "Feature L2-norm: 31.438802\n",
      "Learning rate (eta): 0.093075\n",
      "Total number of feature updates: 100440\n",
      "Seconds required for this iteration: 0.011\n",
      "\n",
      "***** Epoch #373 *****\n",
      "Loss: 1.607593\n",
      "Improvement ratio: 0.004424\n",
      "Feature L2-norm: 31.446221\n",
      "Learning rate (eta): 0.093058\n",
      "Total number of feature updates: 100710\n",
      "Seconds required for this iteration: 0.014\n",
      "\n",
      "***** Epoch #374 *****\n",
      "Loss: 1.606881\n",
      "Improvement ratio: 0.004405\n",
      "Feature L2-norm: 31.453612\n",
      "Learning rate (eta): 0.093041\n",
      "Total number of feature updates: 100980\n",
      "Seconds required for this iteration: 0.022\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** Epoch #375 *****\n",
      "Loss: 1.606234\n",
      "Improvement ratio: 0.004332\n",
      "Feature L2-norm: 31.460974\n",
      "Learning rate (eta): 0.093023\n",
      "Total number of feature updates: 101250\n",
      "Seconds required for this iteration: 0.025\n",
      "\n",
      "***** Epoch #376 *****\n",
      "Loss: 1.605569\n",
      "Improvement ratio: 0.004317\n",
      "Feature L2-norm: 31.468306\n",
      "Learning rate (eta): 0.093006\n",
      "Total number of feature updates: 101520\n",
      "Seconds required for this iteration: 0.024\n",
      "\n",
      "***** Epoch #377 *****\n",
      "Loss: 1.604850\n",
      "Improvement ratio: 0.004330\n",
      "Feature L2-norm: 31.475609\n",
      "Learning rate (eta): 0.092989\n",
      "Total number of feature updates: 101790\n",
      "Seconds required for this iteration: 0.017\n",
      "\n",
      "***** Epoch #378 *****\n",
      "Loss: 1.604216\n",
      "Improvement ratio: 0.004297\n",
      "Feature L2-norm: 31.482891\n",
      "Learning rate (eta): 0.092971\n",
      "Total number of feature updates: 102060\n",
      "Seconds required for this iteration: 0.021\n",
      "\n",
      "***** Epoch #379 *****\n",
      "Loss: 1.603524\n",
      "Improvement ratio: 0.004268\n",
      "Feature L2-norm: 31.490147\n",
      "Learning rate (eta): 0.092954\n",
      "Total number of feature updates: 102330\n",
      "Seconds required for this iteration: 0.027\n",
      "\n",
      "***** Epoch #380 *****\n",
      "Loss: 1.602887\n",
      "Improvement ratio: 0.004229\n",
      "Feature L2-norm: 31.497373\n",
      "Learning rate (eta): 0.092937\n",
      "Total number of feature updates: 102600\n",
      "Seconds required for this iteration: 0.024\n",
      "\n",
      "***** Epoch #381 *****\n",
      "Loss: 1.602234\n",
      "Improvement ratio: 0.004195\n",
      "Feature L2-norm: 31.504579\n",
      "Learning rate (eta): 0.092920\n",
      "Total number of feature updates: 102870\n",
      "Seconds required for this iteration: 0.018\n",
      "\n",
      "***** Epoch #382 *****\n",
      "Loss: 1.601581\n",
      "Improvement ratio: 0.004177\n",
      "Feature L2-norm: 31.511758\n",
      "Learning rate (eta): 0.092902\n",
      "Total number of feature updates: 103140\n",
      "Seconds required for this iteration: 0.021\n",
      "\n",
      "***** Epoch #383 *****\n",
      "Loss: 1.600938\n",
      "Improvement ratio: 0.004157\n",
      "Feature L2-norm: 31.518909\n",
      "Learning rate (eta): 0.092885\n",
      "Total number of feature updates: 103410\n",
      "Seconds required for this iteration: 0.012\n",
      "\n",
      "***** Epoch #384 *****\n",
      "Loss: 1.600339\n",
      "Improvement ratio: 0.004088\n",
      "Feature L2-norm: 31.526029\n",
      "Learning rate (eta): 0.092868\n",
      "Total number of feature updates: 103680\n",
      "Seconds required for this iteration: 0.010\n",
      "\n",
      "***** Epoch #385 *****\n",
      "Loss: 1.599671\n",
      "Improvement ratio: 0.004102\n",
      "Feature L2-norm: 31.533124\n",
      "Learning rate (eta): 0.092851\n",
      "Total number of feature updates: 103950\n",
      "Seconds required for this iteration: 0.009\n",
      "\n",
      "***** Epoch #386 *****\n",
      "Loss: 1.599043\n",
      "Improvement ratio: 0.004081\n",
      "Feature L2-norm: 31.540196\n",
      "Learning rate (eta): 0.092833\n",
      "Total number of feature updates: 104220\n",
      "Seconds required for this iteration: 0.009\n",
      "\n",
      "***** Epoch #387 *****\n",
      "Loss: 1.598437\n",
      "Improvement ratio: 0.004012\n",
      "Feature L2-norm: 31.547248\n",
      "Learning rate (eta): 0.092816\n",
      "Total number of feature updates: 104490\n",
      "Seconds required for this iteration: 0.009\n",
      "\n",
      "***** Epoch #388 *****\n",
      "Loss: 1.597811\n",
      "Improvement ratio: 0.004008\n",
      "Feature L2-norm: 31.554275\n",
      "Learning rate (eta): 0.092799\n",
      "Total number of feature updates: 104760\n",
      "Seconds required for this iteration: 0.010\n",
      "\n",
      "***** Epoch #389 *****\n",
      "Loss: 1.597156\n",
      "Improvement ratio: 0.003987\n",
      "Feature L2-norm: 31.561274\n",
      "Learning rate (eta): 0.092782\n",
      "Total number of feature updates: 105030\n",
      "Seconds required for this iteration: 0.010\n",
      "\n",
      "***** Epoch #390 *****\n",
      "Loss: 1.596582\n",
      "Improvement ratio: 0.003949\n",
      "Feature L2-norm: 31.568247\n",
      "Learning rate (eta): 0.092764\n",
      "Total number of feature updates: 105300\n",
      "Seconds required for this iteration: 0.022\n",
      "\n",
      "***** Epoch #391 *****\n",
      "Loss: 1.595938\n",
      "Improvement ratio: 0.003945\n",
      "Feature L2-norm: 31.575195\n",
      "Learning rate (eta): 0.092747\n",
      "Total number of feature updates: 105570\n",
      "Seconds required for this iteration: 0.020\n",
      "\n",
      "***** Epoch #392 *****\n",
      "Loss: 1.595357\n",
      "Improvement ratio: 0.003901\n",
      "Feature L2-norm: 31.582120\n",
      "Learning rate (eta): 0.092730\n",
      "Total number of feature updates: 105840\n",
      "Seconds required for this iteration: 0.021\n",
      "\n",
      "***** Epoch #393 *****\n",
      "Loss: 1.594761\n",
      "Improvement ratio: 0.003873\n",
      "Feature L2-norm: 31.589018\n",
      "Learning rate (eta): 0.092713\n",
      "Total number of feature updates: 106110\n",
      "Seconds required for this iteration: 0.017\n",
      "\n",
      "***** Epoch #394 *****\n",
      "Loss: 1.594145\n",
      "Improvement ratio: 0.003885\n",
      "Feature L2-norm: 31.595889\n",
      "Learning rate (eta): 0.092696\n",
      "Total number of feature updates: 106380\n",
      "Seconds required for this iteration: 0.010\n",
      "\n",
      "***** Epoch #395 *****\n",
      "Loss: 1.593574\n",
      "Improvement ratio: 0.003826\n",
      "Feature L2-norm: 31.602740\n",
      "Learning rate (eta): 0.092678\n",
      "Total number of feature updates: 106650\n",
      "Seconds required for this iteration: 0.020\n",
      "\n",
      "***** Epoch #396 *****\n",
      "Loss: 1.592978\n",
      "Improvement ratio: 0.003807\n",
      "Feature L2-norm: 31.609569\n",
      "Learning rate (eta): 0.092661\n",
      "Total number of feature updates: 106920\n",
      "Seconds required for this iteration: 0.018\n",
      "\n",
      "***** Epoch #397 *****\n",
      "Loss: 1.592388\n",
      "Improvement ratio: 0.003799\n",
      "Feature L2-norm: 31.616373\n",
      "Learning rate (eta): 0.092644\n",
      "Total number of feature updates: 107190\n",
      "Seconds required for this iteration: 0.024\n",
      "\n",
      "***** Epoch #398 *****\n",
      "Loss: 1.591848\n",
      "Improvement ratio: 0.003746\n",
      "Feature L2-norm: 31.623150\n",
      "Learning rate (eta): 0.092627\n",
      "Total number of feature updates: 107460\n",
      "Seconds required for this iteration: 0.022\n",
      "\n",
      "***** Epoch #399 *****\n",
      "Loss: 1.591231\n",
      "Improvement ratio: 0.003724\n",
      "Feature L2-norm: 31.629908\n",
      "Learning rate (eta): 0.092610\n",
      "Total number of feature updates: 107730\n",
      "Seconds required for this iteration: 0.013\n",
      "\n",
      "***** Epoch #400 *****\n",
      "Loss: 1.590643\n",
      "Improvement ratio: 0.003734\n",
      "Feature L2-norm: 31.636639\n",
      "Learning rate (eta): 0.092593\n",
      "Total number of feature updates: 108000\n",
      "Seconds required for this iteration: 0.009\n",
      "\n",
      "***** Epoch #401 *****\n",
      "Loss: 1.590099\n",
      "Improvement ratio: 0.003672\n",
      "Feature L2-norm: 31.643347\n",
      "Learning rate (eta): 0.092576\n",
      "Total number of feature updates: 108270\n",
      "Seconds required for this iteration: 0.019\n",
      "\n",
      "***** Epoch #402 *****\n",
      "Loss: 1.589515\n",
      "Improvement ratio: 0.003675\n",
      "Feature L2-norm: 31.650031\n",
      "Learning rate (eta): 0.092558\n",
      "Total number of feature updates: 108540\n",
      "Seconds required for this iteration: 0.014\n",
      "\n",
      "***** Epoch #403 *****\n",
      "Loss: 1.588956\n",
      "Improvement ratio: 0.003653\n",
      "Feature L2-norm: 31.656693\n",
      "Learning rate (eta): 0.092541\n",
      "Total number of feature updates: 108810\n",
      "Seconds required for this iteration: 0.015\n",
      "\n",
      "***** Epoch #404 *****\n",
      "Loss: 1.588398\n",
      "Improvement ratio: 0.003618\n",
      "Feature L2-norm: 31.663333\n",
      "Learning rate (eta): 0.092524\n",
      "Total number of feature updates: 109080\n",
      "Seconds required for this iteration: 0.017\n",
      "\n",
      "***** Epoch #405 *****\n",
      "Loss: 1.587812\n",
      "Improvement ratio: 0.003629\n",
      "Feature L2-norm: 31.669947\n",
      "Learning rate (eta): 0.092507\n",
      "Total number of feature updates: 109350\n",
      "Seconds required for this iteration: 0.025\n",
      "\n",
      "***** Epoch #406 *****\n",
      "Loss: 1.587290\n",
      "Improvement ratio: 0.003584\n",
      "Feature L2-norm: 31.676539\n",
      "Learning rate (eta): 0.092490\n",
      "Total number of feature updates: 109620\n",
      "Seconds required for this iteration: 0.018\n",
      "\n",
      "***** Epoch #407 *****\n",
      "Loss: 1.586699\n",
      "Improvement ratio: 0.003585\n",
      "Feature L2-norm: 31.683107\n",
      "Learning rate (eta): 0.092473\n",
      "Total number of feature updates: 109890\n",
      "Seconds required for this iteration: 0.021\n",
      "\n",
      "***** Epoch #408 *****\n",
      "Loss: 1.586173\n",
      "Improvement ratio: 0.003578\n",
      "Feature L2-norm: 31.689654\n",
      "Learning rate (eta): 0.092456\n",
      "Total number of feature updates: 110160\n",
      "Seconds required for this iteration: 0.020\n",
      "\n",
      "***** Epoch #409 *****\n",
      "Loss: 1.585645\n",
      "Improvement ratio: 0.003523\n",
      "Feature L2-norm: 31.696180\n",
      "Learning rate (eta): 0.092439\n",
      "Total number of feature updates: 110430\n",
      "Seconds required for this iteration: 0.022\n",
      "\n",
      "***** Epoch #410 *****\n",
      "Loss: 1.585097\n",
      "Improvement ratio: 0.003498\n",
      "Feature L2-norm: 31.702678\n",
      "Learning rate (eta): 0.092422\n",
      "Total number of feature updates: 110700\n",
      "Seconds required for this iteration: 0.013\n",
      "\n",
      "***** Epoch #411 *****\n",
      "Loss: 1.584562\n",
      "Improvement ratio: 0.003494\n",
      "Feature L2-norm: 31.709158\n",
      "Learning rate (eta): 0.092404\n",
      "Total number of feature updates: 110970\n",
      "Seconds required for this iteration: 0.023\n",
      "\n",
      "***** Epoch #412 *****\n",
      "Loss: 1.584027\n",
      "Improvement ratio: 0.003465\n",
      "Feature L2-norm: 31.715614\n",
      "Learning rate (eta): 0.092387\n",
      "Total number of feature updates: 111240\n",
      "Seconds required for this iteration: 0.012\n",
      "\n",
      "***** Epoch #413 *****\n",
      "Loss: 1.583505\n",
      "Improvement ratio: 0.003443\n",
      "Feature L2-norm: 31.722051\n",
      "Learning rate (eta): 0.092370\n",
      "Total number of feature updates: 111510\n",
      "Seconds required for this iteration: 0.013\n",
      "\n",
      "***** Epoch #414 *****\n",
      "Loss: 1.583013\n",
      "Improvement ratio: 0.003401\n",
      "Feature L2-norm: 31.728466\n",
      "Learning rate (eta): 0.092353\n",
      "Total number of feature updates: 111780\n",
      "Seconds required for this iteration: 0.008\n",
      "\n",
      "***** Epoch #415 *****\n",
      "Loss: 1.582480\n",
      "Improvement ratio: 0.003370\n",
      "Feature L2-norm: 31.734856\n",
      "Learning rate (eta): 0.092336\n",
      "Total number of feature updates: 112050\n",
      "Seconds required for this iteration: 0.010\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** Epoch #416 *****\n",
      "Loss: 1.581946\n",
      "Improvement ratio: 0.003378\n",
      "Feature L2-norm: 31.741226\n",
      "Learning rate (eta): 0.092319\n",
      "Total number of feature updates: 112320\n",
      "Seconds required for this iteration: 0.015\n",
      "\n",
      "***** Epoch #417 *****\n",
      "Loss: 1.581430\n",
      "Improvement ratio: 0.003332\n",
      "Feature L2-norm: 31.747575\n",
      "Learning rate (eta): 0.092302\n",
      "Total number of feature updates: 112590\n",
      "Seconds required for this iteration: 0.011\n",
      "\n",
      "***** Epoch #418 *****\n",
      "Loss: 1.580929\n",
      "Improvement ratio: 0.003317\n",
      "Feature L2-norm: 31.753901\n",
      "Learning rate (eta): 0.092285\n",
      "Total number of feature updates: 112860\n",
      "Seconds required for this iteration: 0.012\n",
      "\n",
      "***** Epoch #419 *****\n",
      "Loss: 1.580400\n",
      "Improvement ratio: 0.003319\n",
      "Feature L2-norm: 31.760208\n",
      "Learning rate (eta): 0.092268\n",
      "Total number of feature updates: 113130\n",
      "Seconds required for this iteration: 0.010\n",
      "\n",
      "***** Epoch #420 *****\n",
      "Loss: 1.579920\n",
      "Improvement ratio: 0.003277\n",
      "Feature L2-norm: 31.766491\n",
      "Learning rate (eta): 0.092251\n",
      "Total number of feature updates: 113400\n",
      "Seconds required for this iteration: 0.011\n",
      "\n",
      "***** Epoch #421 *****\n",
      "Loss: 1.579413\n",
      "Improvement ratio: 0.003260\n",
      "Feature L2-norm: 31.772754\n",
      "Learning rate (eta): 0.092234\n",
      "Total number of feature updates: 113670\n",
      "Seconds required for this iteration: 0.010\n",
      "\n",
      "***** Epoch #422 *****\n",
      "Loss: 1.578907\n",
      "Improvement ratio: 0.003243\n",
      "Feature L2-norm: 31.778993\n",
      "Learning rate (eta): 0.092217\n",
      "Total number of feature updates: 113940\n",
      "Seconds required for this iteration: 0.013\n",
      "\n",
      "***** Epoch #423 *****\n",
      "Loss: 1.578385\n",
      "Improvement ratio: 0.003244\n",
      "Feature L2-norm: 31.785211\n",
      "Learning rate (eta): 0.092200\n",
      "Total number of feature updates: 114210\n",
      "Seconds required for this iteration: 0.011\n",
      "\n",
      "***** Epoch #424 *****\n",
      "Loss: 1.577904\n",
      "Improvement ratio: 0.003238\n",
      "Feature L2-norm: 31.791407\n",
      "Learning rate (eta): 0.092183\n",
      "Total number of feature updates: 114480\n",
      "Seconds required for this iteration: 0.011\n",
      "\n",
      "***** Epoch #425 *****\n",
      "Loss: 1.577436\n",
      "Improvement ratio: 0.003197\n",
      "Feature L2-norm: 31.797586\n",
      "Learning rate (eta): 0.092166\n",
      "Total number of feature updates: 114750\n",
      "Seconds required for this iteration: 0.010\n",
      "\n",
      "***** Epoch #426 *****\n",
      "Loss: 1.576932\n",
      "Improvement ratio: 0.003180\n",
      "Feature L2-norm: 31.803743\n",
      "Learning rate (eta): 0.092149\n",
      "Total number of feature updates: 115020\n",
      "Seconds required for this iteration: 0.013\n",
      "\n",
      "***** Epoch #427 *****\n",
      "Loss: 1.576460\n",
      "Improvement ratio: 0.003153\n",
      "Feature L2-norm: 31.809878\n",
      "Learning rate (eta): 0.092132\n",
      "Total number of feature updates: 115290\n",
      "Seconds required for this iteration: 0.017\n",
      "\n",
      "***** Epoch #428 *****\n",
      "Loss: 1.575980\n",
      "Improvement ratio: 0.003140\n",
      "Feature L2-norm: 31.815993\n",
      "Learning rate (eta): 0.092115\n",
      "Total number of feature updates: 115560\n",
      "Seconds required for this iteration: 0.015\n",
      "\n",
      "***** Epoch #429 *****\n",
      "Loss: 1.575512\n",
      "Improvement ratio: 0.003102\n",
      "Feature L2-norm: 31.822088\n",
      "Learning rate (eta): 0.092098\n",
      "Total number of feature updates: 115830\n",
      "Seconds required for this iteration: 0.015\n",
      "\n",
      "***** Epoch #430 *****\n",
      "Loss: 1.575008\n",
      "Improvement ratio: 0.003118\n",
      "Feature L2-norm: 31.828165\n",
      "Learning rate (eta): 0.092081\n",
      "Total number of feature updates: 116100\n",
      "Seconds required for this iteration: 0.020\n",
      "\n",
      "***** Epoch #431 *****\n",
      "Loss: 1.574552\n",
      "Improvement ratio: 0.003087\n",
      "Feature L2-norm: 31.834222\n",
      "Learning rate (eta): 0.092064\n",
      "Total number of feature updates: 116370\n",
      "Seconds required for this iteration: 0.013\n",
      "\n",
      "***** Epoch #432 *****\n",
      "Loss: 1.574067\n",
      "Improvement ratio: 0.003075\n",
      "Feature L2-norm: 31.840250\n",
      "Learning rate (eta): 0.092047\n",
      "Total number of feature updates: 116640\n",
      "Seconds required for this iteration: 0.011\n",
      "\n",
      "***** Epoch #433 *****\n",
      "Loss: 1.573622\n",
      "Improvement ratio: 0.003027\n",
      "Feature L2-norm: 31.846264\n",
      "Learning rate (eta): 0.092030\n",
      "Total number of feature updates: 116910\n",
      "Seconds required for this iteration: 0.011\n",
      "\n",
      "***** Epoch #434 *****\n",
      "Loss: 1.573136\n",
      "Improvement ratio: 0.003031\n",
      "Feature L2-norm: 31.852256\n",
      "Learning rate (eta): 0.092013\n",
      "Total number of feature updates: 117180\n",
      "Seconds required for this iteration: 0.019\n",
      "\n",
      "***** Epoch #435 *****\n",
      "Loss: 1.572704\n",
      "Improvement ratio: 0.003009\n",
      "Feature L2-norm: 31.858234\n",
      "Learning rate (eta): 0.091996\n",
      "Total number of feature updates: 117450\n",
      "Seconds required for this iteration: 0.021\n",
      "\n",
      "***** Epoch #436 *****\n",
      "Loss: 1.572246\n",
      "Improvement ratio: 0.002980\n",
      "Feature L2-norm: 31.864190\n",
      "Learning rate (eta): 0.091979\n",
      "Total number of feature updates: 117720\n",
      "Seconds required for this iteration: 0.027\n",
      "\n",
      "***** Epoch #437 *****\n",
      "Loss: 1.571771\n",
      "Improvement ratio: 0.002984\n",
      "Feature L2-norm: 31.870127\n",
      "Learning rate (eta): 0.091963\n",
      "Total number of feature updates: 117990\n",
      "Seconds required for this iteration: 0.021\n",
      "\n",
      "***** Epoch #438 *****\n",
      "Loss: 1.571313\n",
      "Improvement ratio: 0.002970\n",
      "Feature L2-norm: 31.876041\n",
      "Learning rate (eta): 0.091946\n",
      "Total number of feature updates: 118260\n",
      "Seconds required for this iteration: 0.013\n",
      "\n",
      "***** Epoch #439 *****\n",
      "Loss: 1.570891\n",
      "Improvement ratio: 0.002942\n",
      "Feature L2-norm: 31.881937\n",
      "Learning rate (eta): 0.091929\n",
      "Total number of feature updates: 118530\n",
      "Seconds required for this iteration: 0.023\n",
      "\n",
      "***** Epoch #440 *****\n",
      "Loss: 1.570401\n",
      "Improvement ratio: 0.002934\n",
      "Feature L2-norm: 31.887816\n",
      "Learning rate (eta): 0.091912\n",
      "Total number of feature updates: 118800\n",
      "Seconds required for this iteration: 0.019\n",
      "\n",
      "***** Epoch #441 *****\n",
      "Loss: 1.569978\n",
      "Improvement ratio: 0.002914\n",
      "Feature L2-norm: 31.893674\n",
      "Learning rate (eta): 0.091895\n",
      "Total number of feature updates: 119070\n",
      "Seconds required for this iteration: 0.011\n",
      "\n",
      "***** Epoch #442 *****\n",
      "Loss: 1.569531\n",
      "Improvement ratio: 0.002890\n",
      "Feature L2-norm: 31.899512\n",
      "Learning rate (eta): 0.091878\n",
      "Total number of feature updates: 119340\n",
      "Seconds required for this iteration: 0.011\n",
      "\n",
      "***** Epoch #443 *****\n",
      "Loss: 1.569106\n",
      "Improvement ratio: 0.002878\n",
      "Feature L2-norm: 31.905330\n",
      "Learning rate (eta): 0.091861\n",
      "Total number of feature updates: 119610\n",
      "Seconds required for this iteration: 0.005\n",
      "\n",
      "***** Epoch #444 *****\n",
      "Loss: 1.568668\n",
      "Improvement ratio: 0.002849\n",
      "Feature L2-norm: 31.911131\n",
      "Learning rate (eta): 0.091844\n",
      "Total number of feature updates: 119880\n",
      "Seconds required for this iteration: 0.006\n",
      "\n",
      "***** Epoch #445 *****\n",
      "Loss: 1.568242\n",
      "Improvement ratio: 0.002845\n",
      "Feature L2-norm: 31.916915\n",
      "Learning rate (eta): 0.091827\n",
      "Total number of feature updates: 120150\n",
      "Seconds required for this iteration: 0.006\n",
      "\n",
      "***** Epoch #446 *****\n",
      "Loss: 1.567806\n",
      "Improvement ratio: 0.002832\n",
      "Feature L2-norm: 31.922677\n",
      "Learning rate (eta): 0.091811\n",
      "Total number of feature updates: 120420\n",
      "Seconds required for this iteration: 0.010\n",
      "\n",
      "***** Epoch #447 *****\n",
      "Loss: 1.567379\n",
      "Improvement ratio: 0.002802\n",
      "Feature L2-norm: 31.928420\n",
      "Learning rate (eta): 0.091794\n",
      "Total number of feature updates: 120690\n",
      "Seconds required for this iteration: 0.018\n",
      "\n",
      "***** Epoch #448 *****\n",
      "Loss: 1.566937\n",
      "Improvement ratio: 0.002792\n",
      "Feature L2-norm: 31.934142\n",
      "Learning rate (eta): 0.091777\n",
      "Total number of feature updates: 120960\n",
      "Seconds required for this iteration: 0.022\n",
      "\n",
      "***** Epoch #449 *****\n",
      "Loss: 1.566533\n",
      "Improvement ratio: 0.002782\n",
      "Feature L2-norm: 31.939850\n",
      "Learning rate (eta): 0.091760\n",
      "Total number of feature updates: 121230\n",
      "Seconds required for this iteration: 0.020\n",
      "\n",
      "***** Epoch #450 *****\n",
      "Loss: 1.566129\n",
      "Improvement ratio: 0.002727\n",
      "Feature L2-norm: 31.945536\n",
      "Learning rate (eta): 0.091743\n",
      "Total number of feature updates: 121500\n",
      "Seconds required for this iteration: 0.023\n",
      "\n",
      "***** Epoch #451 *****\n",
      "Loss: 1.565683\n",
      "Improvement ratio: 0.002743\n",
      "Feature L2-norm: 31.951207\n",
      "Learning rate (eta): 0.091726\n",
      "Total number of feature updates: 121770\n",
      "Seconds required for this iteration: 0.019\n",
      "\n",
      "***** Epoch #452 *****\n",
      "Loss: 1.565294\n",
      "Improvement ratio: 0.002707\n",
      "Feature L2-norm: 31.956859\n",
      "Learning rate (eta): 0.091710\n",
      "Total number of feature updates: 122040\n",
      "Seconds required for this iteration: 0.022\n",
      "\n",
      "***** Epoch #453 *****\n",
      "Loss: 1.564857\n",
      "Improvement ratio: 0.002715\n",
      "Feature L2-norm: 31.962492\n",
      "Learning rate (eta): 0.091693\n",
      "Total number of feature updates: 122310\n",
      "Seconds required for this iteration: 0.012\n",
      "\n",
      "***** Epoch #454 *****\n",
      "Loss: 1.564454\n",
      "Improvement ratio: 0.002693\n",
      "Feature L2-norm: 31.968107\n",
      "Learning rate (eta): 0.091676\n",
      "Total number of feature updates: 122580\n",
      "Seconds required for this iteration: 0.012\n",
      "\n",
      "***** Epoch #455 *****\n",
      "Loss: 1.564074\n",
      "Improvement ratio: 0.002665\n",
      "Feature L2-norm: 31.973705\n",
      "Learning rate (eta): 0.091659\n",
      "Total number of feature updates: 122850\n",
      "Seconds required for this iteration: 0.010\n",
      "\n",
      "***** Epoch #456 *****\n",
      "Loss: 1.563655\n",
      "Improvement ratio: 0.002655\n",
      "Feature L2-norm: 31.979284\n",
      "Learning rate (eta): 0.091642\n",
      "Total number of feature updates: 123120\n",
      "Seconds required for this iteration: 0.010\n",
      "\n",
      "***** Epoch #457 *****\n",
      "Loss: 1.563230\n",
      "Improvement ratio: 0.002654\n",
      "Feature L2-norm: 31.984842\n",
      "Learning rate (eta): 0.091625\n",
      "Total number of feature updates: 123390\n",
      "Seconds required for this iteration: 0.012\n",
      "\n",
      "***** Epoch #458 *****\n",
      "Loss: 1.562814\n",
      "Improvement ratio: 0.002639\n",
      "Feature L2-norm: 31.990390\n",
      "Learning rate (eta): 0.091609\n",
      "Total number of feature updates: 123660\n",
      "Seconds required for this iteration: 0.014\n",
      "\n",
      "***** Epoch #459 *****\n",
      "Loss: 1.562446\n",
      "Improvement ratio: 0.002616\n",
      "Feature L2-norm: 31.995913\n",
      "Learning rate (eta): 0.091592\n",
      "Total number of feature updates: 123930\n",
      "Seconds required for this iteration: 0.013\n",
      "\n",
      "***** Epoch #460 *****\n",
      "Loss: 1.562051\n",
      "Improvement ratio: 0.002611\n",
      "Feature L2-norm: 32.001423\n",
      "Learning rate (eta): 0.091575\n",
      "Total number of feature updates: 124200\n",
      "Seconds required for this iteration: 0.021\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** Epoch #461 *****\n",
      "Loss: 1.561657\n",
      "Improvement ratio: 0.002578\n",
      "Feature L2-norm: 32.006915\n",
      "Learning rate (eta): 0.091558\n",
      "Total number of feature updates: 124470\n",
      "Seconds required for this iteration: 0.021\n",
      "\n",
      "***** Epoch #462 *****\n",
      "Loss: 1.561262\n",
      "Improvement ratio: 0.002582\n",
      "Feature L2-norm: 32.012390\n",
      "Learning rate (eta): 0.091542\n",
      "Total number of feature updates: 124740\n",
      "Seconds required for this iteration: 0.020\n",
      "\n",
      "***** Epoch #463 *****\n",
      "Loss: 1.560891\n",
      "Improvement ratio: 0.002541\n",
      "Feature L2-norm: 32.017846\n",
      "Learning rate (eta): 0.091525\n",
      "Total number of feature updates: 125010\n",
      "Seconds required for this iteration: 0.019\n",
      "\n",
      "***** Epoch #464 *****\n",
      "Loss: 1.560478\n",
      "Improvement ratio: 0.002548\n",
      "Feature L2-norm: 32.023279\n",
      "Learning rate (eta): 0.091508\n",
      "Total number of feature updates: 125280\n",
      "Seconds required for this iteration: 0.010\n",
      "\n",
      "***** Epoch #465 *****\n",
      "Loss: 1.560075\n",
      "Improvement ratio: 0.002564\n",
      "Feature L2-norm: 32.028695\n",
      "Learning rate (eta): 0.091491\n",
      "Total number of feature updates: 125550\n",
      "Seconds required for this iteration: 0.010\n",
      "\n",
      "***** Epoch #466 *****\n",
      "Loss: 1.559730\n",
      "Improvement ratio: 0.002516\n",
      "Feature L2-norm: 32.034098\n",
      "Learning rate (eta): 0.091475\n",
      "Total number of feature updates: 125820\n",
      "Seconds required for this iteration: 0.010\n",
      "\n",
      "***** Epoch #467 *****\n",
      "Loss: 1.559377\n",
      "Improvement ratio: 0.002471\n",
      "Feature L2-norm: 32.039483\n",
      "Learning rate (eta): 0.091458\n",
      "Total number of feature updates: 126090\n",
      "Seconds required for this iteration: 0.009\n",
      "\n",
      "***** Epoch #468 *****\n",
      "Loss: 1.558942\n",
      "Improvement ratio: 0.002484\n",
      "Feature L2-norm: 32.044855\n",
      "Learning rate (eta): 0.091441\n",
      "Total number of feature updates: 126360\n",
      "Seconds required for this iteration: 0.006\n",
      "\n",
      "***** Epoch #469 *****\n",
      "Loss: 1.558575\n",
      "Improvement ratio: 0.002483\n",
      "Feature L2-norm: 32.050206\n",
      "Learning rate (eta): 0.091424\n",
      "Total number of feature updates: 126630\n",
      "Seconds required for this iteration: 0.005\n",
      "\n",
      "***** Epoch #470 *****\n",
      "Loss: 1.558218\n",
      "Improvement ratio: 0.002460\n",
      "Feature L2-norm: 32.055541\n",
      "Learning rate (eta): 0.091408\n",
      "Total number of feature updates: 126900\n",
      "Seconds required for this iteration: 0.006\n",
      "\n",
      "***** Epoch #471 *****\n",
      "Loss: 1.557811\n",
      "Improvement ratio: 0.002469\n",
      "Feature L2-norm: 32.060862\n",
      "Learning rate (eta): 0.091391\n",
      "Total number of feature updates: 127170\n",
      "Seconds required for this iteration: 0.010\n",
      "\n",
      "***** Epoch #472 *****\n",
      "Loss: 1.557426\n",
      "Improvement ratio: 0.002463\n",
      "Feature L2-norm: 32.066169\n",
      "Learning rate (eta): 0.091374\n",
      "Total number of feature updates: 127440\n",
      "Seconds required for this iteration: 0.010\n",
      "\n",
      "***** Epoch #473 *****\n",
      "Loss: 1.557107\n",
      "Improvement ratio: 0.002430\n",
      "Feature L2-norm: 32.071454\n",
      "Learning rate (eta): 0.091358\n",
      "Total number of feature updates: 127710\n",
      "Seconds required for this iteration: 0.011\n",
      "\n",
      "***** Epoch #474 *****\n",
      "Loss: 1.556733\n",
      "Improvement ratio: 0.002406\n",
      "Feature L2-norm: 32.076721\n",
      "Learning rate (eta): 0.091341\n",
      "Total number of feature updates: 127980\n",
      "Seconds required for this iteration: 0.015\n",
      "\n",
      "***** Epoch #475 *****\n",
      "Loss: 1.556387\n",
      "Improvement ratio: 0.002369\n",
      "Feature L2-norm: 32.081972\n",
      "Learning rate (eta): 0.091324\n",
      "Total number of feature updates: 128250\n",
      "Seconds required for this iteration: 0.009\n",
      "\n",
      "***** Epoch #476 *****\n",
      "Loss: 1.556014\n",
      "Improvement ratio: 0.002388\n",
      "Feature L2-norm: 32.087210\n",
      "Learning rate (eta): 0.091308\n",
      "Total number of feature updates: 128520\n",
      "Seconds required for this iteration: 0.019\n",
      "\n",
      "***** Epoch #477 *****\n",
      "Loss: 1.555643\n",
      "Improvement ratio: 0.002401\n",
      "Feature L2-norm: 32.092429\n",
      "Learning rate (eta): 0.091291\n",
      "Total number of feature updates: 128790\n",
      "Seconds required for this iteration: 0.019\n",
      "\n",
      "***** Epoch #478 *****\n",
      "Loss: 1.555295\n",
      "Improvement ratio: 0.002345\n",
      "Feature L2-norm: 32.097628\n",
      "Learning rate (eta): 0.091274\n",
      "Total number of feature updates: 129060\n",
      "Seconds required for this iteration: 0.013\n",
      "\n",
      "***** Epoch #479 *****\n",
      "Loss: 1.554946\n",
      "Improvement ratio: 0.002334\n",
      "Feature L2-norm: 32.102817\n",
      "Learning rate (eta): 0.091258\n",
      "Total number of feature updates: 129330\n",
      "Seconds required for this iteration: 0.010\n",
      "\n",
      "***** Epoch #480 *****\n",
      "Loss: 1.554570\n",
      "Improvement ratio: 0.002347\n",
      "Feature L2-norm: 32.107987\n",
      "Learning rate (eta): 0.091241\n",
      "Total number of feature updates: 129600\n",
      "Seconds required for this iteration: 0.010\n",
      "\n",
      "***** Epoch #481 *****\n",
      "Loss: 1.554248\n",
      "Improvement ratio: 0.002292\n",
      "Feature L2-norm: 32.113141\n",
      "Learning rate (eta): 0.091224\n",
      "Total number of feature updates: 129870\n",
      "Seconds required for this iteration: 0.010\n",
      "\n",
      "***** Epoch #482 *****\n",
      "Loss: 1.553912\n",
      "Improvement ratio: 0.002262\n",
      "Feature L2-norm: 32.118281\n",
      "Learning rate (eta): 0.091208\n",
      "Total number of feature updates: 130140\n",
      "Seconds required for this iteration: 0.020\n",
      "\n",
      "***** Epoch #483 *****\n",
      "Loss: 1.553534\n",
      "Improvement ratio: 0.002300\n",
      "Feature L2-norm: 32.123400\n",
      "Learning rate (eta): 0.091191\n",
      "Total number of feature updates: 130410\n",
      "Seconds required for this iteration: 0.024\n",
      "\n",
      "***** Epoch #484 *****\n",
      "Loss: 1.553210\n",
      "Improvement ratio: 0.002268\n",
      "Feature L2-norm: 32.128511\n",
      "Learning rate (eta): 0.091174\n",
      "Total number of feature updates: 130680\n",
      "Seconds required for this iteration: 0.012\n",
      "\n",
      "***** Epoch #485 *****\n",
      "Loss: 1.552868\n",
      "Improvement ratio: 0.002266\n",
      "Feature L2-norm: 32.133603\n",
      "Learning rate (eta): 0.091158\n",
      "Total number of feature updates: 130950\n",
      "Seconds required for this iteration: 0.012\n",
      "\n",
      "***** Epoch #486 *****\n",
      "Loss: 1.552502\n",
      "Improvement ratio: 0.002263\n",
      "Feature L2-norm: 32.138683\n",
      "Learning rate (eta): 0.091141\n",
      "Total number of feature updates: 131220\n",
      "Seconds required for this iteration: 0.007\n",
      "\n",
      "***** Epoch #487 *****\n",
      "Loss: 1.552153\n",
      "Improvement ratio: 0.002248\n",
      "Feature L2-norm: 32.143745\n",
      "Learning rate (eta): 0.091125\n",
      "Total number of feature updates: 131490\n",
      "Seconds required for this iteration: 0.010\n",
      "\n",
      "***** Epoch #488 *****\n",
      "Loss: 1.551835\n",
      "Improvement ratio: 0.002229\n",
      "Feature L2-norm: 32.148790\n",
      "Learning rate (eta): 0.091108\n",
      "Total number of feature updates: 131760\n",
      "Seconds required for this iteration: 0.011\n",
      "\n",
      "***** Epoch #489 *****\n",
      "Loss: 1.551530\n",
      "Improvement ratio: 0.002202\n",
      "Feature L2-norm: 32.153818\n",
      "Learning rate (eta): 0.091091\n",
      "Total number of feature updates: 132030\n",
      "Seconds required for this iteration: 0.023\n",
      "\n",
      "***** Epoch #490 *****\n",
      "Loss: 1.551149\n",
      "Improvement ratio: 0.002206\n",
      "Feature L2-norm: 32.158826\n",
      "Learning rate (eta): 0.091075\n",
      "Total number of feature updates: 132300\n",
      "Seconds required for this iteration: 0.023\n",
      "\n",
      "***** Epoch #491 *****\n",
      "Loss: 1.550821\n",
      "Improvement ratio: 0.002210\n",
      "Feature L2-norm: 32.163824\n",
      "Learning rate (eta): 0.091058\n",
      "Total number of feature updates: 132570\n",
      "Seconds required for this iteration: 0.018\n",
      "\n",
      "***** Epoch #492 *****\n",
      "Loss: 1.550514\n",
      "Improvement ratio: 0.002191\n",
      "Feature L2-norm: 32.168807\n",
      "Learning rate (eta): 0.091042\n",
      "Total number of feature updates: 132840\n",
      "Seconds required for this iteration: 0.019\n",
      "\n",
      "***** Epoch #493 *****\n",
      "Loss: 1.550189\n",
      "Improvement ratio: 0.002158\n",
      "Feature L2-norm: 32.173777\n",
      "Learning rate (eta): 0.091025\n",
      "Total number of feature updates: 133110\n",
      "Seconds required for this iteration: 0.013\n",
      "\n",
      "***** Epoch #494 *****\n",
      "Loss: 1.549846\n",
      "Improvement ratio: 0.002170\n",
      "Feature L2-norm: 32.178729\n",
      "Learning rate (eta): 0.091008\n",
      "Total number of feature updates: 133380\n",
      "Seconds required for this iteration: 0.025\n",
      "\n",
      "***** Epoch #495 *****\n",
      "Loss: 1.549545\n",
      "Improvement ratio: 0.002144\n",
      "Feature L2-norm: 32.183665\n",
      "Learning rate (eta): 0.090992\n",
      "Total number of feature updates: 133650\n",
      "Seconds required for this iteration: 0.019\n",
      "\n",
      "***** Epoch #496 *****\n",
      "Loss: 1.549240\n",
      "Improvement ratio: 0.002105\n",
      "Feature L2-norm: 32.188587\n",
      "Learning rate (eta): 0.090975\n",
      "Total number of feature updates: 133920\n",
      "Seconds required for this iteration: 0.011\n",
      "\n",
      "***** Epoch #497 *****\n",
      "Loss: 1.548890\n",
      "Improvement ratio: 0.002107\n",
      "Feature L2-norm: 32.193493\n",
      "Learning rate (eta): 0.090959\n",
      "Total number of feature updates: 134190\n",
      "Seconds required for this iteration: 0.021\n",
      "\n",
      "***** Epoch #498 *****\n",
      "Loss: 1.548561\n",
      "Improvement ratio: 0.002115\n",
      "Feature L2-norm: 32.198384\n",
      "Learning rate (eta): 0.090942\n",
      "Total number of feature updates: 134460\n",
      "Seconds required for this iteration: 0.015\n",
      "\n",
      "***** Epoch #499 *****\n",
      "Loss: 1.548266\n",
      "Improvement ratio: 0.002108\n",
      "Feature L2-norm: 32.203262\n",
      "Learning rate (eta): 0.090926\n",
      "Total number of feature updates: 134730\n",
      "Seconds required for this iteration: 0.018\n",
      "\n",
      "***** Epoch #500 *****\n",
      "Loss: 1.547917\n",
      "Improvement ratio: 0.002088\n",
      "Feature L2-norm: 32.208128\n",
      "Learning rate (eta): 0.090909\n",
      "Total number of feature updates: 135000\n",
      "Seconds required for this iteration: 0.010\n",
      "\n",
      "***** Epoch #501 *****\n",
      "Loss: 1.547637\n",
      "Improvement ratio: 0.002057\n",
      "Feature L2-norm: 32.212977\n",
      "Learning rate (eta): 0.090893\n",
      "Total number of feature updates: 135270\n",
      "Seconds required for this iteration: 0.016\n",
      "\n",
      "***** Epoch #502 *****\n",
      "Loss: 1.547329\n",
      "Improvement ratio: 0.002059\n",
      "Feature L2-norm: 32.217811\n",
      "Learning rate (eta): 0.090876\n",
      "Total number of feature updates: 135540\n",
      "Seconds required for this iteration: 0.023\n",
      "\n",
      "***** Epoch #503 *****\n",
      "Loss: 1.546955\n",
      "Improvement ratio: 0.002090\n",
      "Feature L2-norm: 32.222633\n",
      "Learning rate (eta): 0.090860\n",
      "Total number of feature updates: 135810\n",
      "Seconds required for this iteration: 0.024\n",
      "\n",
      "***** Epoch #504 *****\n",
      "Loss: 1.546693\n",
      "Improvement ratio: 0.002039\n",
      "Feature L2-norm: 32.227437\n",
      "Learning rate (eta): 0.090843\n",
      "Total number of feature updates: 136080\n",
      "Seconds required for this iteration: 0.025\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** Epoch #505 *****\n",
      "Loss: 1.546367\n",
      "Improvement ratio: 0.002055\n",
      "Feature L2-norm: 32.232224\n",
      "Learning rate (eta): 0.090827\n",
      "Total number of feature updates: 136350\n",
      "Seconds required for this iteration: 0.020\n",
      "\n",
      "***** Epoch #506 *****\n",
      "Loss: 1.546089\n",
      "Improvement ratio: 0.002038\n",
      "Feature L2-norm: 32.236997\n",
      "Learning rate (eta): 0.090810\n",
      "Total number of feature updates: 136620\n",
      "Seconds required for this iteration: 0.019\n",
      "\n",
      "***** Epoch #507 *****\n",
      "Loss: 1.545757\n",
      "Improvement ratio: 0.002027\n",
      "Feature L2-norm: 32.241756\n",
      "Learning rate (eta): 0.090794\n",
      "Total number of feature updates: 136890\n",
      "Seconds required for this iteration: 0.024\n",
      "\n",
      "***** Epoch #508 *****\n",
      "Loss: 1.545465\n",
      "Improvement ratio: 0.002003\n",
      "Feature L2-norm: 32.246502\n",
      "Learning rate (eta): 0.090777\n",
      "Total number of feature updates: 137160\n",
      "Seconds required for this iteration: 0.026\n",
      "\n",
      "***** Epoch #509 *****\n",
      "Loss: 1.545150\n",
      "Improvement ratio: 0.002016\n",
      "Feature L2-norm: 32.251238\n",
      "Learning rate (eta): 0.090761\n",
      "Total number of feature updates: 137430\n",
      "Seconds required for this iteration: 0.018\n",
      "\n",
      "***** Epoch #510 *****\n",
      "Loss: 1.544893\n",
      "Improvement ratio: 0.001957\n",
      "Feature L2-norm: 32.255956\n",
      "Learning rate (eta): 0.090744\n",
      "Total number of feature updates: 137700\n",
      "Seconds required for this iteration: 0.010\n",
      "\n",
      "***** Epoch #511 *****\n",
      "Loss: 1.544578\n",
      "Improvement ratio: 0.001981\n",
      "Feature L2-norm: 32.260662\n",
      "Learning rate (eta): 0.090728\n",
      "Total number of feature updates: 137970\n",
      "Seconds required for this iteration: 0.020\n",
      "\n",
      "***** Epoch #512 *****\n",
      "Loss: 1.544259\n",
      "Improvement ratio: 0.001988\n",
      "Feature L2-norm: 32.265354\n",
      "Learning rate (eta): 0.090711\n",
      "Total number of feature updates: 138240\n",
      "Seconds required for this iteration: 0.014\n",
      "\n",
      "***** Epoch #513 *****\n",
      "Loss: 1.543964\n",
      "Improvement ratio: 0.001937\n",
      "Feature L2-norm: 32.270032\n",
      "Learning rate (eta): 0.090695\n",
      "Total number of feature updates: 138510\n",
      "Seconds required for this iteration: 0.023\n",
      "\n",
      "***** Epoch #514 *****\n",
      "Loss: 1.543714\n",
      "Improvement ratio: 0.001930\n",
      "Feature L2-norm: 32.274691\n",
      "Learning rate (eta): 0.090678\n",
      "Total number of feature updates: 138780\n",
      "Seconds required for this iteration: 0.017\n",
      "\n",
      "***** Epoch #515 *****\n",
      "Loss: 1.543428\n",
      "Improvement ratio: 0.001904\n",
      "Feature L2-norm: 32.279338\n",
      "Learning rate (eta): 0.090662\n",
      "Total number of feature updates: 139050\n",
      "Seconds required for this iteration: 0.011\n",
      "\n",
      "***** Epoch #516 *****\n",
      "Loss: 1.543138\n",
      "Improvement ratio: 0.001912\n",
      "Feature L2-norm: 32.283975\n",
      "Learning rate (eta): 0.090645\n",
      "Total number of feature updates: 139320\n",
      "Seconds required for this iteration: 0.019\n",
      "\n",
      "***** Epoch #517 *****\n",
      "Loss: 1.542865\n",
      "Improvement ratio: 0.001874\n",
      "Feature L2-norm: 32.288592\n",
      "Learning rate (eta): 0.090629\n",
      "Total number of feature updates: 139590\n",
      "Seconds required for this iteration: 0.013\n",
      "\n",
      "***** Epoch #518 *****\n",
      "Loss: 1.542533\n",
      "Improvement ratio: 0.001901\n",
      "Feature L2-norm: 32.293199\n",
      "Learning rate (eta): 0.090613\n",
      "Total number of feature updates: 139860\n",
      "Seconds required for this iteration: 0.021\n",
      "\n",
      "***** Epoch #519 *****\n",
      "Loss: 1.542298\n",
      "Improvement ratio: 0.001850\n",
      "Feature L2-norm: 32.297791\n",
      "Learning rate (eta): 0.090596\n",
      "Total number of feature updates: 140130\n",
      "Seconds required for this iteration: 0.018\n",
      "\n",
      "***** Epoch #520 *****\n",
      "Loss: 1.541997\n",
      "Improvement ratio: 0.001878\n",
      "Feature L2-norm: 32.302372\n",
      "Learning rate (eta): 0.090580\n",
      "Total number of feature updates: 140400\n",
      "Seconds required for this iteration: 0.022\n",
      "\n",
      "***** Epoch #521 *****\n",
      "Loss: 1.541727\n",
      "Improvement ratio: 0.001849\n",
      "Feature L2-norm: 32.306940\n",
      "Learning rate (eta): 0.090563\n",
      "Total number of feature updates: 140670\n",
      "Seconds required for this iteration: 0.018\n",
      "\n",
      "***** Epoch #522 *****\n",
      "Loss: 1.541423\n",
      "Improvement ratio: 0.001840\n",
      "Feature L2-norm: 32.311495\n",
      "Learning rate (eta): 0.090547\n",
      "Total number of feature updates: 140940\n",
      "Seconds required for this iteration: 0.013\n",
      "\n",
      "***** Epoch #523 *****\n",
      "Loss: 1.541139\n",
      "Improvement ratio: 0.001833\n",
      "Feature L2-norm: 32.316037\n",
      "Learning rate (eta): 0.090531\n",
      "Total number of feature updates: 141210\n",
      "Seconds required for this iteration: 0.017\n",
      "\n",
      "***** Epoch #524 *****\n",
      "Loss: 1.540879\n",
      "Improvement ratio: 0.001840\n",
      "Feature L2-norm: 32.320564\n",
      "Learning rate (eta): 0.090514\n",
      "Total number of feature updates: 141480\n",
      "Seconds required for this iteration: 0.017\n",
      "\n",
      "***** Epoch #525 *****\n",
      "Loss: 1.540574\n",
      "Improvement ratio: 0.001853\n",
      "Feature L2-norm: 32.325078\n",
      "Learning rate (eta): 0.090498\n",
      "Total number of feature updates: 141750\n",
      "Seconds required for this iteration: 0.025\n",
      "\n",
      "***** Epoch #526 *****\n",
      "Loss: 1.540315\n",
      "Improvement ratio: 0.001833\n",
      "Feature L2-norm: 32.329575\n",
      "Learning rate (eta): 0.090481\n",
      "Total number of feature updates: 142020\n",
      "Seconds required for this iteration: 0.022\n",
      "\n",
      "***** Epoch #527 *****\n",
      "Loss: 1.540038\n",
      "Improvement ratio: 0.001835\n",
      "Feature L2-norm: 32.334059\n",
      "Learning rate (eta): 0.090465\n",
      "Total number of feature updates: 142290\n",
      "Seconds required for this iteration: 0.013\n",
      "\n",
      "***** Epoch #528 *****\n",
      "Loss: 1.539761\n",
      "Improvement ratio: 0.001800\n",
      "Feature L2-norm: 32.338529\n",
      "Learning rate (eta): 0.090449\n",
      "Total number of feature updates: 142560\n",
      "Seconds required for this iteration: 0.014\n",
      "\n",
      "***** Epoch #529 *****\n",
      "Loss: 1.539518\n",
      "Improvement ratio: 0.001805\n",
      "Feature L2-norm: 32.342992\n",
      "Learning rate (eta): 0.090432\n",
      "Total number of feature updates: 142830\n",
      "Seconds required for this iteration: 0.020\n",
      "\n",
      "***** Epoch #530 *****\n",
      "Loss: 1.539241\n",
      "Improvement ratio: 0.001790\n",
      "Feature L2-norm: 32.347439\n",
      "Learning rate (eta): 0.090416\n",
      "Total number of feature updates: 143100\n",
      "Seconds required for this iteration: 0.018\n",
      "\n",
      "***** Epoch #531 *****\n",
      "Loss: 1.538994\n",
      "Improvement ratio: 0.001776\n",
      "Feature L2-norm: 32.351875\n",
      "Learning rate (eta): 0.090400\n",
      "Total number of feature updates: 143370\n",
      "Seconds required for this iteration: 0.009\n",
      "\n",
      "***** Epoch #532 *****\n",
      "Loss: 1.538697\n",
      "Improvement ratio: 0.001772\n",
      "Feature L2-norm: 32.356297\n",
      "Learning rate (eta): 0.090383\n",
      "Total number of feature updates: 143640\n",
      "Seconds required for this iteration: 0.013\n",
      "\n",
      "***** Epoch #533 *****\n",
      "Loss: 1.538449\n",
      "Improvement ratio: 0.001749\n",
      "Feature L2-norm: 32.360704\n",
      "Learning rate (eta): 0.090367\n",
      "Total number of feature updates: 143910\n",
      "Seconds required for this iteration: 0.023\n",
      "\n",
      "***** Epoch #534 *****\n",
      "Loss: 1.538164\n",
      "Improvement ratio: 0.001765\n",
      "Feature L2-norm: 32.365099\n",
      "Learning rate (eta): 0.090351\n",
      "Total number of feature updates: 144180\n",
      "Seconds required for this iteration: 0.012\n",
      "\n",
      "***** Epoch #535 *****\n",
      "Loss: 1.537926\n",
      "Improvement ratio: 0.001722\n",
      "Feature L2-norm: 32.369482\n",
      "Learning rate (eta): 0.090334\n",
      "Total number of feature updates: 144450\n",
      "Seconds required for this iteration: 0.021\n",
      "\n",
      "***** Epoch #536 *****\n",
      "Loss: 1.537658\n",
      "Improvement ratio: 0.001728\n",
      "Feature L2-norm: 32.373851\n",
      "Learning rate (eta): 0.090318\n",
      "Total number of feature updates: 144720\n",
      "Seconds required for this iteration: 0.023\n",
      "\n",
      "***** Epoch #537 *****\n",
      "Loss: 1.537429\n",
      "Improvement ratio: 0.001697\n",
      "Feature L2-norm: 32.378208\n",
      "Learning rate (eta): 0.090302\n",
      "Total number of feature updates: 144990\n",
      "Seconds required for this iteration: 0.026\n",
      "\n",
      "***** Epoch #538 *****\n",
      "Loss: 1.537167\n",
      "Improvement ratio: 0.001688\n",
      "Feature L2-norm: 32.382552\n",
      "Learning rate (eta): 0.090285\n",
      "Total number of feature updates: 145260\n",
      "Seconds required for this iteration: 0.018\n",
      "\n",
      "***** Epoch #539 *****\n",
      "Loss: 1.536898\n",
      "Improvement ratio: 0.001705\n",
      "Feature L2-norm: 32.386882\n",
      "Learning rate (eta): 0.090269\n",
      "Total number of feature updates: 145530\n",
      "Seconds required for this iteration: 0.012\n",
      "\n",
      "***** Epoch #540 *****\n",
      "Loss: 1.536639\n",
      "Improvement ratio: 0.001693\n",
      "Feature L2-norm: 32.391198\n",
      "Learning rate (eta): 0.090253\n",
      "Total number of feature updates: 145800\n",
      "Seconds required for this iteration: 0.021\n",
      "\n",
      "***** Epoch #541 *****\n",
      "Loss: 1.536404\n",
      "Improvement ratio: 0.001686\n",
      "Feature L2-norm: 32.395504\n",
      "Learning rate (eta): 0.090236\n",
      "Total number of feature updates: 146070\n",
      "Seconds required for this iteration: 0.011\n",
      "\n",
      "***** Epoch #542 *****\n",
      "Loss: 1.536147\n",
      "Improvement ratio: 0.001660\n",
      "Feature L2-norm: 32.399800\n",
      "Learning rate (eta): 0.090220\n",
      "Total number of feature updates: 146340\n",
      "Seconds required for this iteration: 0.010\n",
      "\n",
      "***** Epoch #543 *****\n",
      "Loss: 1.535874\n",
      "Improvement ratio: 0.001676\n",
      "Feature L2-norm: 32.404081\n",
      "Learning rate (eta): 0.090204\n",
      "Total number of feature updates: 146610\n",
      "Seconds required for this iteration: 0.010\n",
      "\n",
      "***** Epoch #544 *****\n",
      "Loss: 1.535640\n",
      "Improvement ratio: 0.001644\n",
      "Feature L2-norm: 32.408353\n",
      "Learning rate (eta): 0.090188\n",
      "Total number of feature updates: 146880\n",
      "Seconds required for this iteration: 0.010\n",
      "\n",
      "***** Epoch #545 *****\n",
      "Loss: 1.535371\n",
      "Improvement ratio: 0.001664\n",
      "Feature L2-norm: 32.412607\n",
      "Learning rate (eta): 0.090171\n",
      "Total number of feature updates: 147150\n",
      "Seconds required for this iteration: 0.006\n",
      "\n",
      "***** Epoch #546 *****\n",
      "Loss: 1.535129\n",
      "Improvement ratio: 0.001647\n",
      "Feature L2-norm: 32.416852\n",
      "Learning rate (eta): 0.090155\n",
      "Total number of feature updates: 147420\n",
      "Seconds required for this iteration: 0.010\n",
      "\n",
      "***** Epoch #547 *****\n",
      "Loss: 1.534892\n",
      "Improvement ratio: 0.001653\n",
      "Feature L2-norm: 32.421085\n",
      "Learning rate (eta): 0.090139\n",
      "Total number of feature updates: 147690\n",
      "Seconds required for this iteration: 0.012\n",
      "\n",
      "***** Epoch #548 *****\n",
      "Loss: 1.534646\n",
      "Improvement ratio: 0.001643\n",
      "Feature L2-norm: 32.425306\n",
      "Learning rate (eta): 0.090123\n",
      "Total number of feature updates: 147960\n",
      "Seconds required for this iteration: 0.023\n",
      "\n",
      "***** Epoch #549 *****\n",
      "Loss: 1.534395\n",
      "Improvement ratio: 0.001632\n",
      "Feature L2-norm: 32.429518\n",
      "Learning rate (eta): 0.090106\n",
      "Total number of feature updates: 148230\n",
      "Seconds required for this iteration: 0.012\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** Epoch #550 *****\n",
      "Loss: 1.534158\n",
      "Improvement ratio: 0.001618\n",
      "Feature L2-norm: 32.433715\n",
      "Learning rate (eta): 0.090090\n",
      "Total number of feature updates: 148500\n",
      "Seconds required for this iteration: 0.013\n",
      "\n",
      "***** Epoch #551 *****\n",
      "Loss: 1.533916\n",
      "Improvement ratio: 0.001622\n",
      "Feature L2-norm: 32.437899\n",
      "Learning rate (eta): 0.090074\n",
      "Total number of feature updates: 148770\n",
      "Seconds required for this iteration: 0.014\n",
      "\n",
      "***** Epoch #552 *****\n",
      "Loss: 1.533675\n",
      "Improvement ratio: 0.001611\n",
      "Feature L2-norm: 32.442071\n",
      "Learning rate (eta): 0.090058\n",
      "Total number of feature updates: 149040\n",
      "Seconds required for this iteration: 0.011\n",
      "\n",
      "***** Epoch #553 *****\n",
      "Loss: 1.533426\n",
      "Improvement ratio: 0.001596\n",
      "Feature L2-norm: 32.446231\n",
      "Learning rate (eta): 0.090041\n",
      "Total number of feature updates: 149310\n",
      "Seconds required for this iteration: 0.022\n",
      "\n",
      "***** Epoch #554 *****\n",
      "Loss: 1.533215\n",
      "Improvement ratio: 0.001582\n",
      "Feature L2-norm: 32.450382\n",
      "Learning rate (eta): 0.090025\n",
      "Total number of feature updates: 149580\n",
      "Seconds required for this iteration: 0.016\n",
      "\n",
      "***** Epoch #555 *****\n",
      "Loss: 1.532961\n",
      "Improvement ratio: 0.001572\n",
      "Feature L2-norm: 32.454516\n",
      "Learning rate (eta): 0.090009\n",
      "Total number of feature updates: 149850\n",
      "Seconds required for this iteration: 0.011\n",
      "\n",
      "***** Epoch #556 *****\n",
      "Loss: 1.532726\n",
      "Improvement ratio: 0.001568\n",
      "Feature L2-norm: 32.458643\n",
      "Learning rate (eta): 0.089993\n",
      "Total number of feature updates: 150120\n",
      "Seconds required for this iteration: 0.013\n",
      "\n",
      "***** Epoch #557 *****\n",
      "Loss: 1.532511\n",
      "Improvement ratio: 0.001554\n",
      "Feature L2-norm: 32.462756\n",
      "Learning rate (eta): 0.089977\n",
      "Total number of feature updates: 150390\n",
      "Seconds required for this iteration: 0.015\n",
      "\n",
      "***** Epoch #558 *****\n",
      "Loss: 1.532274\n",
      "Improvement ratio: 0.001548\n",
      "Feature L2-norm: 32.466855\n",
      "Learning rate (eta): 0.089960\n",
      "Total number of feature updates: 150660\n",
      "Seconds required for this iteration: 0.014\n",
      "\n",
      "***** Epoch #559 *****\n",
      "Loss: 1.532032\n",
      "Improvement ratio: 0.001542\n",
      "Feature L2-norm: 32.470948\n",
      "Learning rate (eta): 0.089944\n",
      "Total number of feature updates: 150930\n",
      "Seconds required for this iteration: 0.024\n",
      "\n",
      "***** Epoch #560 *****\n",
      "Loss: 1.531819\n",
      "Improvement ratio: 0.001527\n",
      "Feature L2-norm: 32.475027\n",
      "Learning rate (eta): 0.089928\n",
      "Total number of feature updates: 151200\n",
      "Seconds required for this iteration: 0.017\n",
      "\n",
      "***** Epoch #561 *****\n",
      "Loss: 1.531570\n",
      "Improvement ratio: 0.001532\n",
      "Feature L2-norm: 32.479092\n",
      "Learning rate (eta): 0.089912\n",
      "Total number of feature updates: 151470\n",
      "Seconds required for this iteration: 0.023\n",
      "\n",
      "***** Epoch #562 *****\n",
      "Loss: 1.531348\n",
      "Improvement ratio: 0.001520\n",
      "Feature L2-norm: 32.483149\n",
      "Learning rate (eta): 0.089896\n",
      "Total number of feature updates: 151740\n",
      "Seconds required for this iteration: 0.017\n",
      "\n",
      "***** Epoch #563 *****\n",
      "Loss: 1.531119\n",
      "Improvement ratio: 0.001507\n",
      "Feature L2-norm: 32.487193\n",
      "Learning rate (eta): 0.089880\n",
      "Total number of feature updates: 152010\n",
      "Seconds required for this iteration: 0.022\n",
      "\n",
      "***** Epoch #564 *****\n",
      "Loss: 1.530899\n",
      "Improvement ratio: 0.001513\n",
      "Feature L2-norm: 32.491225\n",
      "Learning rate (eta): 0.089863\n",
      "Total number of feature updates: 152280\n",
      "Seconds required for this iteration: 0.014\n",
      "\n",
      "***** Epoch #565 *****\n",
      "Loss: 1.530674\n",
      "Improvement ratio: 0.001494\n",
      "Feature L2-norm: 32.495247\n",
      "Learning rate (eta): 0.089847\n",
      "Total number of feature updates: 152550\n",
      "Seconds required for this iteration: 0.011\n",
      "\n",
      "***** Epoch #566 *****\n",
      "Loss: 1.530470\n",
      "Improvement ratio: 0.001474\n",
      "Feature L2-norm: 32.499255\n",
      "Learning rate (eta): 0.089831\n",
      "Total number of feature updates: 152820\n",
      "Seconds required for this iteration: 0.010\n",
      "\n",
      "***** Epoch #567 *****\n",
      "Loss: 1.530232\n",
      "Improvement ratio: 0.001489\n",
      "Feature L2-norm: 32.503252\n",
      "Learning rate (eta): 0.089815\n",
      "Total number of feature updates: 153090\n",
      "Seconds required for this iteration: 0.010\n",
      "\n",
      "***** Epoch #568 *****\n",
      "Loss: 1.529995\n",
      "Improvement ratio: 0.001490\n",
      "Feature L2-norm: 32.507242\n",
      "Learning rate (eta): 0.089799\n",
      "Total number of feature updates: 153360\n",
      "Seconds required for this iteration: 0.012\n",
      "\n",
      "***** Epoch #569 *****\n",
      "Loss: 1.529782\n",
      "Improvement ratio: 0.001471\n",
      "Feature L2-norm: 32.511221\n",
      "Learning rate (eta): 0.089783\n",
      "Total number of feature updates: 153630\n",
      "Seconds required for this iteration: 0.013\n",
      "\n",
      "***** Epoch #570 *****\n",
      "Loss: 1.529581\n",
      "Improvement ratio: 0.001463\n",
      "Feature L2-norm: 32.515186\n",
      "Learning rate (eta): 0.089767\n",
      "Total number of feature updates: 153900\n",
      "Seconds required for this iteration: 0.012\n",
      "\n",
      "***** Epoch #571 *****\n",
      "Loss: 1.529363\n",
      "Improvement ratio: 0.001443\n",
      "Feature L2-norm: 32.519140\n",
      "Learning rate (eta): 0.089751\n",
      "Total number of feature updates: 154170\n",
      "Seconds required for this iteration: 0.010\n",
      "\n",
      "***** Epoch #572 *****\n",
      "Loss: 1.529124\n",
      "Improvement ratio: 0.001455\n",
      "Feature L2-norm: 32.523080\n",
      "Learning rate (eta): 0.089734\n",
      "Total number of feature updates: 154440\n",
      "Seconds required for this iteration: 0.010\n",
      "\n",
      "***** Epoch #573 *****\n",
      "Loss: 1.528938\n",
      "Improvement ratio: 0.001426\n",
      "Feature L2-norm: 32.527014\n",
      "Learning rate (eta): 0.089718\n",
      "Total number of feature updates: 154710\n",
      "Seconds required for this iteration: 0.011\n",
      "\n",
      "***** Epoch #574 *****\n",
      "Loss: 1.528705\n",
      "Improvement ratio: 0.001435\n",
      "Feature L2-norm: 32.530935\n",
      "Learning rate (eta): 0.089702\n",
      "Total number of feature updates: 154980\n",
      "Seconds required for this iteration: 0.021\n",
      "\n",
      "***** Epoch #575 *****\n",
      "Loss: 1.528501\n",
      "Improvement ratio: 0.001421\n",
      "Feature L2-norm: 32.534844\n",
      "Learning rate (eta): 0.089686\n",
      "Total number of feature updates: 155250\n",
      "Seconds required for this iteration: 0.020\n",
      "\n",
      "***** Epoch #576 *****\n",
      "Loss: 1.528289\n",
      "Improvement ratio: 0.001427\n",
      "Feature L2-norm: 32.538742\n",
      "Learning rate (eta): 0.089670\n",
      "Total number of feature updates: 155520\n",
      "Seconds required for this iteration: 0.021\n",
      "\n",
      "***** Epoch #577 *****\n",
      "Loss: 1.528092\n",
      "Improvement ratio: 0.001401\n",
      "Feature L2-norm: 32.542630\n",
      "Learning rate (eta): 0.089654\n",
      "Total number of feature updates: 155790\n",
      "Seconds required for this iteration: 0.015\n",
      "\n",
      "***** Epoch #578 *****\n",
      "Loss: 1.527884\n",
      "Improvement ratio: 0.001382\n",
      "Feature L2-norm: 32.546508\n",
      "Learning rate (eta): 0.089638\n",
      "Total number of feature updates: 156060\n",
      "Seconds required for this iteration: 0.010\n",
      "\n",
      "***** Epoch #579 *****\n",
      "Loss: 1.527659\n",
      "Improvement ratio: 0.001390\n",
      "Feature L2-norm: 32.550373\n",
      "Learning rate (eta): 0.089622\n",
      "Total number of feature updates: 156330\n",
      "Seconds required for this iteration: 0.010\n",
      "\n",
      "***** Epoch #580 *****\n",
      "Loss: 1.527467\n",
      "Improvement ratio: 0.001384\n",
      "Feature L2-norm: 32.554228\n",
      "Learning rate (eta): 0.089606\n",
      "Total number of feature updates: 156600\n",
      "Seconds required for this iteration: 0.013\n",
      "\n",
      "***** Epoch #581 *****\n",
      "Loss: 1.527221\n",
      "Improvement ratio: 0.001403\n",
      "Feature L2-norm: 32.558072\n",
      "Learning rate (eta): 0.089590\n",
      "Total number of feature updates: 156870\n",
      "Seconds required for this iteration: 0.022\n",
      "\n",
      "***** Epoch #582 *****\n",
      "Loss: 1.527057\n",
      "Improvement ratio: 0.001354\n",
      "Feature L2-norm: 32.561906\n",
      "Learning rate (eta): 0.089574\n",
      "Total number of feature updates: 157140\n",
      "Seconds required for this iteration: 0.016\n",
      "\n",
      "***** Epoch #583 *****\n",
      "Loss: 1.526835\n",
      "Improvement ratio: 0.001378\n",
      "Feature L2-norm: 32.565730\n",
      "Learning rate (eta): 0.089558\n",
      "Total number of feature updates: 157410\n",
      "Seconds required for this iteration: 0.020\n",
      "\n",
      "***** Epoch #584 *****\n",
      "Loss: 1.526656\n",
      "Improvement ratio: 0.001342\n",
      "Feature L2-norm: 32.569543\n",
      "Learning rate (eta): 0.089542\n",
      "Total number of feature updates: 157680\n",
      "Seconds required for this iteration: 0.012\n",
      "\n",
      "***** Epoch #585 *****\n",
      "Loss: 1.526449\n",
      "Improvement ratio: 0.001345\n",
      "Feature L2-norm: 32.573346\n",
      "Learning rate (eta): 0.089526\n",
      "Total number of feature updates: 157950\n",
      "Seconds required for this iteration: 0.012\n",
      "\n",
      "***** Epoch #586 *****\n",
      "Loss: 1.526221\n",
      "Improvement ratio: 0.001355\n",
      "Feature L2-norm: 32.577140\n",
      "Learning rate (eta): 0.089510\n",
      "Total number of feature updates: 158220\n",
      "Seconds required for this iteration: 0.012\n",
      "\n",
      "***** Epoch #587 *****\n",
      "Loss: 1.526039\n",
      "Improvement ratio: 0.001345\n",
      "Feature L2-norm: 32.580921\n",
      "Learning rate (eta): 0.089494\n",
      "Total number of feature updates: 158490\n",
      "Seconds required for this iteration: 0.011\n",
      "\n",
      "***** Epoch #588 *****\n",
      "Loss: 1.525834\n",
      "Improvement ratio: 0.001343\n",
      "Feature L2-norm: 32.584694\n",
      "Learning rate (eta): 0.089478\n",
      "Total number of feature updates: 158760\n",
      "Seconds required for this iteration: 0.010\n",
      "\n",
      "***** Epoch #589 *****\n",
      "Loss: 1.525639\n",
      "Improvement ratio: 0.001324\n",
      "Feature L2-norm: 32.588457\n",
      "Learning rate (eta): 0.089462\n",
      "Total number of feature updates: 159030\n",
      "Seconds required for this iteration: 0.011\n",
      "\n",
      "***** Epoch #590 *****\n",
      "Loss: 1.525440\n",
      "Improvement ratio: 0.001329\n",
      "Feature L2-norm: 32.592208\n",
      "Learning rate (eta): 0.089445\n",
      "Total number of feature updates: 159300\n",
      "Seconds required for this iteration: 0.010\n",
      "\n",
      "***** Epoch #591 *****\n",
      "Loss: 1.525234\n",
      "Improvement ratio: 0.001303\n",
      "Feature L2-norm: 32.595949\n",
      "Learning rate (eta): 0.089429\n",
      "Total number of feature updates: 159570\n",
      "Seconds required for this iteration: 0.010\n",
      "\n",
      "***** Epoch #592 *****\n",
      "Loss: 1.525038\n",
      "Improvement ratio: 0.001323\n",
      "Feature L2-norm: 32.599678\n",
      "Learning rate (eta): 0.089414\n",
      "Total number of feature updates: 159840\n",
      "Seconds required for this iteration: 0.010\n",
      "\n",
      "***** Epoch #593 *****\n",
      "Loss: 1.524850\n",
      "Improvement ratio: 0.001302\n",
      "Feature L2-norm: 32.603400\n",
      "Learning rate (eta): 0.089398\n",
      "Total number of feature updates: 160110\n",
      "Seconds required for this iteration: 0.010\n",
      "\n",
      "***** Epoch #594 *****\n",
      "Loss: 1.524646\n",
      "Improvement ratio: 0.001318\n",
      "Feature L2-norm: 32.607110\n",
      "Learning rate (eta): 0.089382\n",
      "Total number of feature updates: 160380\n",
      "Seconds required for this iteration: 0.019\n",
      "\n",
      "***** Epoch #595 *****\n",
      "Loss: 1.524469\n",
      "Improvement ratio: 0.001299\n",
      "Feature L2-norm: 32.610809\n",
      "Learning rate (eta): 0.089366\n",
      "Total number of feature updates: 160650\n",
      "Seconds required for this iteration: 0.021\n",
      "\n",
      "***** Epoch #596 *****\n",
      "Loss: 1.524282\n",
      "Improvement ratio: 0.001272\n",
      "Feature L2-norm: 32.614501\n",
      "Learning rate (eta): 0.089350\n",
      "Total number of feature updates: 160920\n",
      "Seconds required for this iteration: 0.021\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** Epoch #597 *****\n",
      "Loss: 1.524085\n",
      "Improvement ratio: 0.001283\n",
      "Feature L2-norm: 32.618179\n",
      "Learning rate (eta): 0.089334\n",
      "Total number of feature updates: 161190\n",
      "Seconds required for this iteration: 0.021\n",
      "\n",
      "***** Epoch #598 *****\n",
      "Loss: 1.523885\n",
      "Improvement ratio: 0.001279\n",
      "Feature L2-norm: 32.621845\n",
      "Learning rate (eta): 0.089318\n",
      "Total number of feature updates: 161460\n",
      "Seconds required for this iteration: 0.019\n",
      "\n",
      "***** Epoch #599 *****\n",
      "Loss: 1.523690\n",
      "Improvement ratio: 0.001279\n",
      "Feature L2-norm: 32.625506\n",
      "Learning rate (eta): 0.089302\n",
      "Total number of feature updates: 161730\n",
      "Seconds required for this iteration: 0.013\n",
      "\n",
      "***** Epoch #600 *****\n",
      "Loss: 1.523516\n",
      "Improvement ratio: 0.001262\n",
      "Feature L2-norm: 32.629156\n",
      "Learning rate (eta): 0.089286\n",
      "Total number of feature updates: 162000\n",
      "Seconds required for this iteration: 0.013\n",
      "\n",
      "***** Epoch #601 *****\n",
      "Loss: 1.523315\n",
      "Improvement ratio: 0.001260\n",
      "Feature L2-norm: 32.632795\n",
      "Learning rate (eta): 0.089270\n",
      "Total number of feature updates: 162270\n",
      "Seconds required for this iteration: 0.014\n",
      "\n",
      "***** Epoch #602 *****\n",
      "Loss: 1.523115\n",
      "Improvement ratio: 0.001263\n",
      "Feature L2-norm: 32.636422\n",
      "Learning rate (eta): 0.089254\n",
      "Total number of feature updates: 162540\n",
      "Seconds required for this iteration: 0.015\n",
      "\n",
      "***** Epoch #603 *****\n",
      "Loss: 1.522955\n",
      "Improvement ratio: 0.001244\n",
      "Feature L2-norm: 32.640043\n",
      "Learning rate (eta): 0.089238\n",
      "Total number of feature updates: 162810\n",
      "Seconds required for this iteration: 0.013\n",
      "\n",
      "***** Epoch #604 *****\n",
      "Loss: 1.522771\n",
      "Improvement ratio: 0.001231\n",
      "Feature L2-norm: 32.643654\n",
      "Learning rate (eta): 0.089222\n",
      "Total number of feature updates: 163080\n",
      "Seconds required for this iteration: 0.011\n",
      "\n",
      "***** Epoch #605 *****\n",
      "Loss: 1.522565\n",
      "Improvement ratio: 0.001250\n",
      "Feature L2-norm: 32.647255\n",
      "Learning rate (eta): 0.089206\n",
      "Total number of feature updates: 163350\n",
      "Seconds required for this iteration: 0.006\n",
      "\n",
      "***** Epoch #606 *****\n",
      "Loss: 1.522399\n",
      "Improvement ratio: 0.001237\n",
      "Feature L2-norm: 32.650845\n",
      "Learning rate (eta): 0.089190\n",
      "Total number of feature updates: 163620\n",
      "Seconds required for this iteration: 0.012\n",
      "\n",
      "***** Epoch #607 *****\n",
      "Loss: 1.522209\n",
      "Improvement ratio: 0.001232\n",
      "Feature L2-norm: 32.654424\n",
      "Learning rate (eta): 0.089174\n",
      "Total number of feature updates: 163890\n",
      "Seconds required for this iteration: 0.014\n",
      "\n",
      "***** Epoch #608 *****\n",
      "Loss: 1.522073\n",
      "Improvement ratio: 0.001190\n",
      "Feature L2-norm: 32.657994\n",
      "Learning rate (eta): 0.089158\n",
      "Total number of feature updates: 164160\n",
      "Seconds required for this iteration: 0.012\n",
      "\n",
      "***** Epoch #609 *****\n",
      "Loss: 1.521854\n",
      "Improvement ratio: 0.001207\n",
      "Feature L2-norm: 32.661556\n",
      "Learning rate (eta): 0.089143\n",
      "Total number of feature updates: 164430\n",
      "Seconds required for this iteration: 0.015\n",
      "\n",
      "***** Epoch #610 *****\n",
      "Loss: 1.521696\n",
      "Improvement ratio: 0.001196\n",
      "Feature L2-norm: 32.665106\n",
      "Learning rate (eta): 0.089127\n",
      "Total number of feature updates: 164700\n",
      "Seconds required for this iteration: 0.021\n",
      "\n",
      "***** Epoch #611 *****\n",
      "Loss: 1.521514\n",
      "Improvement ratio: 0.001184\n",
      "Feature L2-norm: 32.668650\n",
      "Learning rate (eta): 0.089111\n",
      "Total number of feature updates: 164970\n",
      "Seconds required for this iteration: 0.016\n",
      "\n",
      "***** Epoch #612 *****\n",
      "Loss: 1.521325\n",
      "Improvement ratio: 0.001177\n",
      "Feature L2-norm: 32.672182\n",
      "Learning rate (eta): 0.089095\n",
      "Total number of feature updates: 165240\n",
      "Seconds required for this iteration: 0.013\n",
      "\n",
      "***** Epoch #613 *****\n",
      "Loss: 1.521132\n",
      "Improvement ratio: 0.001198\n",
      "Feature L2-norm: 32.675707\n",
      "Learning rate (eta): 0.089079\n",
      "Total number of feature updates: 165510\n",
      "Seconds required for this iteration: 0.019\n",
      "\n",
      "***** Epoch #614 *****\n",
      "Loss: 1.520951\n",
      "Improvement ratio: 0.001197\n",
      "Feature L2-norm: 32.679222\n",
      "Learning rate (eta): 0.089063\n",
      "Total number of feature updates: 165780\n",
      "Seconds required for this iteration: 0.013\n",
      "\n",
      "***** Epoch #615 *****\n",
      "Loss: 1.520785\n",
      "Improvement ratio: 0.001171\n",
      "Feature L2-norm: 32.682727\n",
      "Learning rate (eta): 0.089047\n",
      "Total number of feature updates: 166050\n",
      "Seconds required for this iteration: 0.021\n",
      "\n",
      "***** Epoch #616 *****\n",
      "Loss: 1.520633\n",
      "Improvement ratio: 0.001162\n",
      "Feature L2-norm: 32.686220\n",
      "Learning rate (eta): 0.089031\n",
      "Total number of feature updates: 166320\n",
      "Seconds required for this iteration: 0.014\n",
      "\n",
      "***** Epoch #617 *****\n",
      "Loss: 1.520461\n",
      "Improvement ratio: 0.001150\n",
      "Feature L2-norm: 32.689705\n",
      "Learning rate (eta): 0.089016\n",
      "Total number of feature updates: 166590\n",
      "Seconds required for this iteration: 0.021\n",
      "\n",
      "***** Epoch #618 *****\n",
      "Loss: 1.520246\n",
      "Improvement ratio: 0.001201\n",
      "Feature L2-norm: 32.693183\n",
      "Learning rate (eta): 0.089000\n",
      "Total number of feature updates: 166860\n",
      "Seconds required for this iteration: 0.028\n",
      "\n",
      "***** Epoch #619 *****\n",
      "Loss: 1.520120\n",
      "Improvement ratio: 0.001141\n",
      "Feature L2-norm: 32.696650\n",
      "Learning rate (eta): 0.088984\n",
      "Total number of feature updates: 167130\n",
      "Seconds required for this iteration: 0.017\n",
      "\n",
      "***** Epoch #620 *****\n",
      "Loss: 1.519927\n",
      "Improvement ratio: 0.001164\n",
      "Feature L2-norm: 32.700107\n",
      "Learning rate (eta): 0.088968\n",
      "Total number of feature updates: 167400\n",
      "Seconds required for this iteration: 0.014\n",
      "\n",
      "***** Epoch #621 *****\n",
      "Loss: 1.519752\n",
      "Improvement ratio: 0.001159\n",
      "Feature L2-norm: 32.703557\n",
      "Learning rate (eta): 0.088952\n",
      "Total number of feature updates: 167670\n",
      "Seconds required for this iteration: 0.012\n",
      "\n",
      "***** Epoch #622 *****\n",
      "Loss: 1.519587\n",
      "Improvement ratio: 0.001144\n",
      "Feature L2-norm: 32.706996\n",
      "Learning rate (eta): 0.088936\n",
      "Total number of feature updates: 167940\n",
      "Seconds required for this iteration: 0.011\n",
      "\n",
      "***** Epoch #623 *****\n",
      "Loss: 1.519419\n",
      "Improvement ratio: 0.001127\n",
      "Feature L2-norm: 32.710426\n",
      "Learning rate (eta): 0.088921\n",
      "Total number of feature updates: 168210\n",
      "Seconds required for this iteration: 0.013\n",
      "\n",
      "***** Epoch #624 *****\n",
      "Loss: 1.519253\n",
      "Improvement ratio: 0.001117\n",
      "Feature L2-norm: 32.713846\n",
      "Learning rate (eta): 0.088905\n",
      "Total number of feature updates: 168480\n",
      "Seconds required for this iteration: 0.014\n",
      "\n",
      "***** Epoch #625 *****\n",
      "Loss: 1.519093\n",
      "Improvement ratio: 0.001114\n",
      "Feature L2-norm: 32.717256\n",
      "Learning rate (eta): 0.088889\n",
      "Total number of feature updates: 168750\n",
      "Seconds required for this iteration: 0.014\n",
      "\n",
      "***** Epoch #626 *****\n",
      "Loss: 1.518914\n",
      "Improvement ratio: 0.001131\n",
      "Feature L2-norm: 32.720661\n",
      "Learning rate (eta): 0.088873\n",
      "Total number of feature updates: 169020\n",
      "Seconds required for this iteration: 0.014\n",
      "\n",
      "***** Epoch #627 *****\n",
      "Loss: 1.518762\n",
      "Improvement ratio: 0.001119\n",
      "Feature L2-norm: 32.724055\n",
      "Learning rate (eta): 0.088857\n",
      "Total number of feature updates: 169290\n",
      "Seconds required for this iteration: 0.013\n",
      "\n",
      "***** Epoch #628 *****\n",
      "Loss: 1.518595\n",
      "Improvement ratio: 0.001087\n",
      "Feature L2-norm: 32.727439\n",
      "Learning rate (eta): 0.088842\n",
      "Total number of feature updates: 169560\n",
      "Seconds required for this iteration: 0.015\n",
      "\n",
      "***** Epoch #629 *****\n",
      "Loss: 1.518418\n",
      "Improvement ratio: 0.001121\n",
      "Feature L2-norm: 32.730814\n",
      "Learning rate (eta): 0.088826\n",
      "Total number of feature updates: 169830\n",
      "Seconds required for this iteration: 0.018\n",
      "\n",
      "***** Epoch #630 *****\n",
      "Loss: 1.518252\n",
      "Improvement ratio: 0.001103\n",
      "Feature L2-norm: 32.734179\n",
      "Learning rate (eta): 0.088810\n",
      "Total number of feature updates: 170100\n",
      "Seconds required for this iteration: 0.014\n",
      "\n",
      "***** Epoch #631 *****\n",
      "Loss: 1.518113\n",
      "Improvement ratio: 0.001080\n",
      "Feature L2-norm: 32.737536\n",
      "Learning rate (eta): 0.088794\n",
      "Total number of feature updates: 170370\n",
      "Seconds required for this iteration: 0.027\n",
      "\n",
      "***** Epoch #632 *****\n",
      "Loss: 1.517933\n",
      "Improvement ratio: 0.001090\n",
      "Feature L2-norm: 32.740885\n",
      "Learning rate (eta): 0.088778\n",
      "Total number of feature updates: 170640\n",
      "Seconds required for this iteration: 0.018\n",
      "\n",
      "***** Epoch #633 *****\n",
      "Loss: 1.517758\n",
      "Improvement ratio: 0.001095\n",
      "Feature L2-norm: 32.744226\n",
      "Learning rate (eta): 0.088763\n",
      "Total number of feature updates: 170910\n",
      "Seconds required for this iteration: 0.020\n",
      "\n",
      "***** Epoch #634 *****\n",
      "Loss: 1.517598\n",
      "Improvement ratio: 0.001091\n",
      "Feature L2-norm: 32.747557\n",
      "Learning rate (eta): 0.088747\n",
      "Total number of feature updates: 171180\n",
      "Seconds required for this iteration: 0.025\n",
      "\n",
      "***** Epoch #635 *****\n",
      "Loss: 1.517438\n",
      "Improvement ratio: 0.001091\n",
      "Feature L2-norm: 32.750881\n",
      "Learning rate (eta): 0.088731\n",
      "Total number of feature updates: 171450\n",
      "Seconds required for this iteration: 0.020\n",
      "\n",
      "***** Epoch #636 *****\n",
      "Loss: 1.517301\n",
      "Improvement ratio: 0.001063\n",
      "Feature L2-norm: 32.754195\n",
      "Learning rate (eta): 0.088715\n",
      "Total number of feature updates: 171720\n",
      "Seconds required for this iteration: 0.017\n",
      "\n",
      "***** Epoch #637 *****\n",
      "Loss: 1.517149\n",
      "Improvement ratio: 0.001063\n",
      "Feature L2-norm: 32.757500\n",
      "Learning rate (eta): 0.088700\n",
      "Total number of feature updates: 171990\n",
      "Seconds required for this iteration: 0.020\n",
      "\n",
      "***** Epoch #638 *****\n",
      "Loss: 1.516977\n",
      "Improvement ratio: 0.001066\n",
      "Feature L2-norm: 32.760797\n",
      "Learning rate (eta): 0.088684\n",
      "Total number of feature updates: 172260\n",
      "Seconds required for this iteration: 0.017\n",
      "\n",
      "***** Epoch #639 *****\n",
      "Loss: 1.516808\n",
      "Improvement ratio: 0.001061\n",
      "Feature L2-norm: 32.764085\n",
      "Learning rate (eta): 0.088668\n",
      "Total number of feature updates: 172530\n",
      "Seconds required for this iteration: 0.024\n",
      "\n",
      "***** Epoch #640 *****\n",
      "Loss: 1.516672\n",
      "Improvement ratio: 0.001042\n",
      "Feature L2-norm: 32.767365\n",
      "Learning rate (eta): 0.088653\n",
      "Total number of feature updates: 172800\n",
      "Seconds required for this iteration: 0.022\n",
      "\n",
      "***** Epoch #641 *****\n",
      "Loss: 1.516513\n",
      "Improvement ratio: 0.001055\n",
      "Feature L2-norm: 32.770634\n",
      "Learning rate (eta): 0.088637\n",
      "Total number of feature updates: 173070\n",
      "Seconds required for this iteration: 0.018\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** Epoch #642 *****\n",
      "Loss: 1.516361\n",
      "Improvement ratio: 0.001037\n",
      "Feature L2-norm: 32.773895\n",
      "Learning rate (eta): 0.088621\n",
      "Total number of feature updates: 173340\n",
      "Seconds required for this iteration: 0.022\n",
      "\n",
      "***** Epoch #643 *****\n",
      "Loss: 1.516196\n",
      "Improvement ratio: 0.001030\n",
      "Feature L2-norm: 32.777148\n",
      "Learning rate (eta): 0.088605\n",
      "Total number of feature updates: 173610\n",
      "Seconds required for this iteration: 0.013\n",
      "\n",
      "***** Epoch #644 *****\n",
      "Loss: 1.516048\n",
      "Improvement ratio: 0.001023\n",
      "Feature L2-norm: 32.780393\n",
      "Learning rate (eta): 0.088590\n",
      "Total number of feature updates: 173880\n",
      "Seconds required for this iteration: 0.014\n",
      "\n",
      "***** Epoch #645 *****\n",
      "Loss: 1.515908\n",
      "Improvement ratio: 0.001009\n",
      "Feature L2-norm: 32.783627\n",
      "Learning rate (eta): 0.088574\n",
      "Total number of feature updates: 174150\n",
      "Seconds required for this iteration: 0.014\n",
      "\n",
      "***** Epoch #646 *****\n",
      "Loss: 1.515751\n",
      "Improvement ratio: 0.001023\n",
      "Feature L2-norm: 32.786853\n",
      "Learning rate (eta): 0.088558\n",
      "Total number of feature updates: 174420\n",
      "Seconds required for this iteration: 0.019\n",
      "\n",
      "***** Epoch #647 *****\n",
      "Loss: 1.515606\n",
      "Improvement ratio: 0.001018\n",
      "Feature L2-norm: 32.790072\n",
      "Learning rate (eta): 0.088543\n",
      "Total number of feature updates: 174690\n",
      "Seconds required for this iteration: 0.013\n",
      "\n",
      "***** Epoch #648 *****\n",
      "Loss: 1.515459\n",
      "Improvement ratio: 0.001002\n",
      "Feature L2-norm: 32.793284\n",
      "Learning rate (eta): 0.088527\n",
      "Total number of feature updates: 174960\n",
      "Seconds required for this iteration: 0.015\n",
      "\n",
      "***** Epoch #649 *****\n",
      "Loss: 1.515305\n",
      "Improvement ratio: 0.000991\n",
      "Feature L2-norm: 32.796485\n",
      "Learning rate (eta): 0.088511\n",
      "Total number of feature updates: 175230\n",
      "Seconds required for this iteration: 0.016\n",
      "\n",
      "***** Epoch #650 *****\n",
      "Loss: 1.515160\n",
      "Improvement ratio: 0.000998\n",
      "Feature L2-norm: 32.799679\n",
      "Learning rate (eta): 0.088496\n",
      "Total number of feature updates: 175500\n",
      "Seconds required for this iteration: 0.019\n",
      "\n",
      "***** Epoch #651 *****\n",
      "Loss: 1.514992\n",
      "Improvement ratio: 0.001004\n",
      "Feature L2-norm: 32.802865\n",
      "Learning rate (eta): 0.088480\n",
      "Total number of feature updates: 175770\n",
      "Seconds required for this iteration: 0.012\n",
      "\n",
      "***** Epoch #652 *****\n",
      "Loss: 1.514848\n",
      "Improvement ratio: 0.000999\n",
      "Feature L2-norm: 32.806043\n",
      "Learning rate (eta): 0.088464\n",
      "Total number of feature updates: 176040\n",
      "Seconds required for this iteration: 0.023\n",
      "\n",
      "***** Epoch #653 *****\n",
      "Loss: 1.514717\n",
      "Improvement ratio: 0.000977\n",
      "Feature L2-norm: 32.809213\n",
      "Learning rate (eta): 0.088449\n",
      "Total number of feature updates: 176310\n",
      "Seconds required for this iteration: 0.016\n",
      "\n",
      "***** Epoch #654 *****\n",
      "Loss: 1.514566\n",
      "Improvement ratio: 0.000978\n",
      "Feature L2-norm: 32.812374\n",
      "Learning rate (eta): 0.088433\n",
      "Total number of feature updates: 176580\n",
      "Seconds required for this iteration: 0.010\n",
      "\n",
      "***** Epoch #655 *****\n",
      "Loss: 1.514392\n",
      "Improvement ratio: 0.001001\n",
      "Feature L2-norm: 32.815529\n",
      "Learning rate (eta): 0.088417\n",
      "Total number of feature updates: 176850\n",
      "Seconds required for this iteration: 0.013\n",
      "\n",
      "***** Epoch #656 *****\n",
      "Loss: 1.514290\n",
      "Improvement ratio: 0.000965\n",
      "Feature L2-norm: 32.818673\n",
      "Learning rate (eta): 0.088402\n",
      "Total number of feature updates: 177120\n",
      "Seconds required for this iteration: 0.024\n",
      "\n",
      "***** Epoch #657 *****\n",
      "Loss: 1.514131\n",
      "Improvement ratio: 0.000974\n",
      "Feature L2-norm: 32.821810\n",
      "Learning rate (eta): 0.088386\n",
      "Total number of feature updates: 177390\n",
      "Seconds required for this iteration: 0.020\n",
      "\n",
      "***** Epoch #658 *****\n",
      "Loss: 1.513995\n",
      "Improvement ratio: 0.000966\n",
      "Feature L2-norm: 32.824939\n",
      "Learning rate (eta): 0.088371\n",
      "Total number of feature updates: 177660\n",
      "Seconds required for this iteration: 0.010\n",
      "\n",
      "***** Epoch #659 *****\n",
      "Loss: 1.513825\n",
      "Improvement ratio: 0.000978\n",
      "Feature L2-norm: 32.828059\n",
      "Learning rate (eta): 0.088355\n",
      "Total number of feature updates: 177930\n",
      "Seconds required for this iteration: 0.012\n",
      "\n",
      "***** Epoch #660 *****\n",
      "Loss: 1.513701\n",
      "Improvement ratio: 0.000964\n",
      "Feature L2-norm: 32.831171\n",
      "Learning rate (eta): 0.088339\n",
      "Total number of feature updates: 178200\n",
      "Seconds required for this iteration: 0.027\n",
      "\n",
      "***** Epoch #661 *****\n",
      "Loss: 1.513570\n",
      "Improvement ratio: 0.000939\n",
      "Feature L2-norm: 32.834274\n",
      "Learning rate (eta): 0.088324\n",
      "Total number of feature updates: 178470\n",
      "Seconds required for this iteration: 0.025\n",
      "\n",
      "***** Epoch #662 *****\n",
      "Loss: 1.513413\n",
      "Improvement ratio: 0.000948\n",
      "Feature L2-norm: 32.837369\n",
      "Learning rate (eta): 0.088308\n",
      "Total number of feature updates: 178740\n",
      "Seconds required for this iteration: 0.016\n",
      "\n",
      "***** Epoch #663 *****\n",
      "Loss: 1.513293\n",
      "Improvement ratio: 0.000941\n",
      "Feature L2-norm: 32.840458\n",
      "Learning rate (eta): 0.088292\n",
      "Total number of feature updates: 179010\n",
      "Seconds required for this iteration: 0.021\n",
      "\n",
      "***** Epoch #664 *****\n",
      "Loss: 1.513147\n",
      "Improvement ratio: 0.000938\n",
      "Feature L2-norm: 32.843540\n",
      "Learning rate (eta): 0.088277\n",
      "Total number of feature updates: 179280\n",
      "Seconds required for this iteration: 0.015\n",
      "\n",
      "***** Epoch #665 *****\n",
      "Loss: 1.513012\n",
      "Improvement ratio: 0.000912\n",
      "Feature L2-norm: 32.846614\n",
      "Learning rate (eta): 0.088261\n",
      "Total number of feature updates: 179550\n",
      "Seconds required for this iteration: 0.010\n",
      "\n",
      "***** Epoch #666 *****\n",
      "Loss: 1.512882\n",
      "Improvement ratio: 0.000930\n",
      "Feature L2-norm: 32.849677\n",
      "Learning rate (eta): 0.088246\n",
      "Total number of feature updates: 179820\n",
      "Seconds required for this iteration: 0.011\n",
      "\n",
      "***** Epoch #667 *****\n",
      "Loss: 1.512722\n",
      "Improvement ratio: 0.000932\n",
      "Feature L2-norm: 32.852733\n",
      "Learning rate (eta): 0.088230\n",
      "Total number of feature updates: 180090\n",
      "Seconds required for this iteration: 0.020\n",
      "\n",
      "***** Epoch #668 *****\n",
      "Loss: 1.512606\n",
      "Improvement ratio: 0.000919\n",
      "Feature L2-norm: 32.855782\n",
      "Learning rate (eta): 0.088215\n",
      "Total number of feature updates: 180360\n",
      "Seconds required for this iteration: 0.014\n",
      "\n",
      "***** Epoch #669 *****\n",
      "Loss: 1.512447\n",
      "Improvement ratio: 0.000911\n",
      "Feature L2-norm: 32.858822\n",
      "Learning rate (eta): 0.088199\n",
      "Total number of feature updates: 180630\n",
      "Seconds required for this iteration: 0.017\n",
      "\n",
      "***** Epoch #670 *****\n",
      "Loss: 1.512304\n",
      "Improvement ratio: 0.000924\n",
      "Feature L2-norm: 32.861855\n",
      "Learning rate (eta): 0.088183\n",
      "Total number of feature updates: 180900\n",
      "Seconds required for this iteration: 0.021\n",
      "\n",
      "***** Epoch #671 *****\n",
      "Loss: 1.512171\n",
      "Improvement ratio: 0.000926\n",
      "Feature L2-norm: 32.864879\n",
      "Learning rate (eta): 0.088168\n",
      "Total number of feature updates: 181170\n",
      "Seconds required for this iteration: 0.022\n",
      "\n",
      "***** Epoch #672 *****\n",
      "Loss: 1.512046\n",
      "Improvement ratio: 0.000904\n",
      "Feature L2-norm: 32.867899\n",
      "Learning rate (eta): 0.088152\n",
      "Total number of feature updates: 181440\n",
      "Seconds required for this iteration: 0.019\n",
      "\n",
      "***** Epoch #673 *****\n",
      "Loss: 1.511926\n",
      "Improvement ratio: 0.000904\n",
      "Feature L2-norm: 32.870910\n",
      "Learning rate (eta): 0.088137\n",
      "Total number of feature updates: 181710\n",
      "Seconds required for this iteration: 0.010\n",
      "\n",
      "***** Epoch #674 *****\n",
      "Loss: 1.511772\n",
      "Improvement ratio: 0.000910\n",
      "Feature L2-norm: 32.873913\n",
      "Learning rate (eta): 0.088121\n",
      "Total number of feature updates: 181980\n",
      "Seconds required for this iteration: 0.013\n",
      "\n",
      "***** Epoch #675 *****\n",
      "Loss: 1.511620\n",
      "Improvement ratio: 0.000920\n",
      "Feature L2-norm: 32.876908\n",
      "Learning rate (eta): 0.088106\n",
      "Total number of feature updates: 182250\n",
      "Seconds required for this iteration: 0.023\n",
      "\n",
      "***** Epoch #676 *****\n",
      "Loss: 1.511514\n",
      "Improvement ratio: 0.000905\n",
      "Feature L2-norm: 32.879895\n",
      "Learning rate (eta): 0.088090\n",
      "Total number of feature updates: 182520\n",
      "Seconds required for this iteration: 0.018\n",
      "\n",
      "***** Epoch #677 *****\n",
      "Loss: 1.511388\n",
      "Improvement ratio: 0.000883\n",
      "Feature L2-norm: 32.882874\n",
      "Learning rate (eta): 0.088075\n",
      "Total number of feature updates: 182790\n",
      "Seconds required for this iteration: 0.011\n",
      "\n",
      "***** Epoch #678 *****\n",
      "Loss: 1.511241\n",
      "Improvement ratio: 0.000903\n",
      "Feature L2-norm: 32.885846\n",
      "Learning rate (eta): 0.088059\n",
      "Total number of feature updates: 183060\n",
      "Seconds required for this iteration: 0.005\n",
      "\n",
      "***** Epoch #679 *****\n",
      "Loss: 1.511120\n",
      "Improvement ratio: 0.000878\n",
      "Feature L2-norm: 32.888810\n",
      "Learning rate (eta): 0.088044\n",
      "Total number of feature updates: 183330\n",
      "Seconds required for this iteration: 0.005\n",
      "\n",
      "***** Epoch #680 *****\n",
      "Loss: 1.510972\n",
      "Improvement ratio: 0.000882\n",
      "Feature L2-norm: 32.891766\n",
      "Learning rate (eta): 0.088028\n",
      "Total number of feature updates: 183600\n",
      "Seconds required for this iteration: 0.006\n",
      "\n",
      "***** Epoch #681 *****\n",
      "Loss: 1.510839\n",
      "Improvement ratio: 0.000881\n",
      "Feature L2-norm: 32.894717\n",
      "Learning rate (eta): 0.088013\n",
      "Total number of feature updates: 183870\n",
      "Seconds required for this iteration: 0.010\n",
      "\n",
      "***** Epoch #682 *****\n",
      "Loss: 1.510723\n",
      "Improvement ratio: 0.000876\n",
      "Feature L2-norm: 32.897660\n",
      "Learning rate (eta): 0.087997\n",
      "Total number of feature updates: 184140\n",
      "Seconds required for this iteration: 0.010\n",
      "\n",
      "***** Epoch #683 *****\n",
      "Loss: 1.510603\n",
      "Improvement ratio: 0.000876\n",
      "Feature L2-norm: 32.900593\n",
      "Learning rate (eta): 0.087982\n",
      "Total number of feature updates: 184410\n",
      "Seconds required for this iteration: 0.012\n",
      "\n",
      "***** Epoch #684 *****\n",
      "Loss: 1.510466\n",
      "Improvement ratio: 0.000865\n",
      "Feature L2-norm: 32.903521\n",
      "Learning rate (eta): 0.087966\n",
      "Total number of feature updates: 184680\n",
      "Seconds required for this iteration: 0.011\n",
      "\n",
      "***** Epoch #685 *****\n",
      "Loss: 1.510347\n",
      "Improvement ratio: 0.000843\n",
      "Feature L2-norm: 32.906441\n",
      "Learning rate (eta): 0.087951\n",
      "Total number of feature updates: 184950\n",
      "Seconds required for this iteration: 0.021\n",
      "\n",
      "***** Epoch #686 *****\n",
      "Loss: 1.510210\n",
      "Improvement ratio: 0.000864\n",
      "Feature L2-norm: 32.909354\n",
      "Learning rate (eta): 0.087935\n",
      "Total number of feature updates: 185220\n",
      "Seconds required for this iteration: 0.019\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** Epoch #687 *****\n",
      "Loss: 1.510065\n",
      "Improvement ratio: 0.000876\n",
      "Feature L2-norm: 32.912261\n",
      "Learning rate (eta): 0.087920\n",
      "Total number of feature updates: 185490\n",
      "Seconds required for this iteration: 0.022\n",
      "\n",
      "***** Epoch #688 *****\n",
      "Loss: 1.509953\n",
      "Improvement ratio: 0.000853\n",
      "Feature L2-norm: 32.915156\n",
      "Learning rate (eta): 0.087904\n",
      "Total number of feature updates: 185760\n",
      "Seconds required for this iteration: 0.020\n",
      "\n",
      "***** Epoch #689 *****\n",
      "Loss: 1.509817\n",
      "Improvement ratio: 0.000863\n",
      "Feature L2-norm: 32.918045\n",
      "Learning rate (eta): 0.087889\n",
      "Total number of feature updates: 186030\n",
      "Seconds required for this iteration: 0.017\n",
      "\n",
      "***** Epoch #690 *****\n",
      "Loss: 1.509698\n",
      "Improvement ratio: 0.000843\n",
      "Feature L2-norm: 32.920929\n",
      "Learning rate (eta): 0.087874\n",
      "Total number of feature updates: 186300\n",
      "Seconds required for this iteration: 0.022\n",
      "\n",
      "***** Epoch #691 *****\n",
      "Loss: 1.509582\n",
      "Improvement ratio: 0.000833\n",
      "Feature L2-norm: 32.923805\n",
      "Learning rate (eta): 0.087858\n",
      "Total number of feature updates: 186570\n",
      "Seconds required for this iteration: 0.012\n",
      "\n",
      "***** Epoch #692 *****\n",
      "Loss: 1.509447\n",
      "Improvement ratio: 0.000845\n",
      "Feature L2-norm: 32.926672\n",
      "Learning rate (eta): 0.087843\n",
      "Total number of feature updates: 186840\n",
      "Seconds required for this iteration: 0.022\n",
      "\n",
      "***** Epoch #693 *****\n",
      "Loss: 1.509321\n",
      "Improvement ratio: 0.000850\n",
      "Feature L2-norm: 32.929532\n",
      "Learning rate (eta): 0.087827\n",
      "Total number of feature updates: 187110\n",
      "Seconds required for this iteration: 0.018\n",
      "\n",
      "***** Epoch #694 *****\n",
      "Loss: 1.509211\n",
      "Improvement ratio: 0.000832\n",
      "Feature L2-norm: 32.932386\n",
      "Learning rate (eta): 0.087812\n",
      "Total number of feature updates: 187380\n",
      "Seconds required for this iteration: 0.011\n",
      "\n",
      "***** Epoch #695 *****\n",
      "Loss: 1.509088\n",
      "Improvement ratio: 0.000834\n",
      "Feature L2-norm: 32.935233\n",
      "Learning rate (eta): 0.087796\n",
      "Total number of feature updates: 187650\n",
      "Seconds required for this iteration: 0.012\n",
      "\n",
      "***** Epoch #696 *****\n",
      "Loss: 1.508962\n",
      "Improvement ratio: 0.000827\n",
      "Feature L2-norm: 32.938071\n",
      "Learning rate (eta): 0.087781\n",
      "Total number of feature updates: 187920\n",
      "Seconds required for this iteration: 0.017\n",
      "\n",
      "***** Epoch #697 *****\n",
      "Loss: 1.508844\n",
      "Improvement ratio: 0.000809\n",
      "Feature L2-norm: 32.940904\n",
      "Learning rate (eta): 0.087766\n",
      "Total number of feature updates: 188190\n",
      "Seconds required for this iteration: 0.007\n",
      "\n",
      "***** Epoch #698 *****\n",
      "Loss: 1.508723\n",
      "Improvement ratio: 0.000815\n",
      "Feature L2-norm: 32.943729\n",
      "Learning rate (eta): 0.087750\n",
      "Total number of feature updates: 188460\n",
      "Seconds required for this iteration: 0.008\n",
      "\n",
      "***** Epoch #699 *****\n",
      "Loss: 1.508612\n",
      "Improvement ratio: 0.000798\n",
      "Feature L2-norm: 32.946546\n",
      "Learning rate (eta): 0.087735\n",
      "Total number of feature updates: 188730\n",
      "Seconds required for this iteration: 0.006\n",
      "\n",
      "***** Epoch #700 *****\n",
      "Loss: 1.508494\n",
      "Improvement ratio: 0.000799\n",
      "Feature L2-norm: 32.949359\n",
      "Learning rate (eta): 0.087719\n",
      "Total number of feature updates: 189000\n",
      "Seconds required for this iteration: 0.005\n",
      "\n",
      "***** Epoch #701 *****\n",
      "Loss: 1.508378\n",
      "Improvement ratio: 0.000798\n",
      "Feature L2-norm: 32.952163\n",
      "Learning rate (eta): 0.087704\n",
      "Total number of feature updates: 189270\n",
      "Seconds required for this iteration: 0.006\n",
      "\n",
      "***** Epoch #702 *****\n",
      "Loss: 1.508261\n",
      "Improvement ratio: 0.000787\n",
      "Feature L2-norm: 32.954959\n",
      "Learning rate (eta): 0.087689\n",
      "Total number of feature updates: 189540\n",
      "Seconds required for this iteration: 0.010\n",
      "\n",
      "***** Epoch #703 *****\n",
      "Loss: 1.508152\n",
      "Improvement ratio: 0.000775\n",
      "Feature L2-norm: 32.957747\n",
      "Learning rate (eta): 0.087673\n",
      "Total number of feature updates: 189810\n",
      "Seconds required for this iteration: 0.010\n",
      "\n",
      "***** Epoch #704 *****\n",
      "Loss: 1.508030\n",
      "Improvement ratio: 0.000783\n",
      "Feature L2-norm: 32.960532\n",
      "Learning rate (eta): 0.087658\n",
      "Total number of feature updates: 190080\n",
      "Seconds required for this iteration: 0.013\n",
      "\n",
      "***** Epoch #705 *****\n",
      "Loss: 1.507898\n",
      "Improvement ratio: 0.000789\n",
      "Feature L2-norm: 32.963309\n",
      "Learning rate (eta): 0.087642\n",
      "Total number of feature updates: 190350\n",
      "Seconds required for this iteration: 0.019\n",
      "\n",
      "***** Epoch #706 *****\n",
      "Loss: 1.507773\n",
      "Improvement ratio: 0.000789\n",
      "Feature L2-norm: 32.966080\n",
      "Learning rate (eta): 0.087627\n",
      "Total number of feature updates: 190620\n",
      "Seconds required for this iteration: 0.025\n",
      "\n",
      "***** Epoch #707 *****\n",
      "Loss: 1.507652\n",
      "Improvement ratio: 0.000791\n",
      "Feature L2-norm: 32.968845\n",
      "Learning rate (eta): 0.087612\n",
      "Total number of feature updates: 190890\n",
      "Seconds required for this iteration: 0.023\n",
      "\n",
      "***** Epoch #708 *****\n",
      "Loss: 1.507535\n",
      "Improvement ratio: 0.000788\n",
      "Feature L2-norm: 32.971598\n",
      "Learning rate (eta): 0.087596\n",
      "Total number of feature updates: 191160\n",
      "Seconds required for this iteration: 0.020\n",
      "\n",
      "***** Epoch #709 *****\n",
      "Loss: 1.507427\n",
      "Improvement ratio: 0.000786\n",
      "Feature L2-norm: 32.974345\n",
      "Learning rate (eta): 0.087581\n",
      "Total number of feature updates: 191430\n",
      "Seconds required for this iteration: 0.014\n",
      "\n",
      "***** Epoch #710 *****\n",
      "Loss: 1.507303\n",
      "Improvement ratio: 0.000790\n",
      "Feature L2-norm: 32.977087\n",
      "Learning rate (eta): 0.087566\n",
      "Total number of feature updates: 191700\n",
      "Seconds required for this iteration: 0.024\n",
      "\n",
      "***** Epoch #711 *****\n",
      "Loss: 1.507200\n",
      "Improvement ratio: 0.000781\n",
      "Feature L2-norm: 32.979822\n",
      "Learning rate (eta): 0.087550\n",
      "Total number of feature updates: 191970\n",
      "Seconds required for this iteration: 0.014\n",
      "\n",
      "***** Epoch #712 *****\n",
      "Loss: 1.507090\n",
      "Improvement ratio: 0.000777\n",
      "Feature L2-norm: 32.982550\n",
      "Learning rate (eta): 0.087535\n",
      "Total number of feature updates: 192240\n",
      "Seconds required for this iteration: 0.005\n",
      "\n",
      "***** Epoch #713 *****\n",
      "Loss: 1.506987\n",
      "Improvement ratio: 0.000773\n",
      "Feature L2-norm: 32.985274\n",
      "Learning rate (eta): 0.087520\n",
      "Total number of feature updates: 192510\n",
      "Seconds required for this iteration: 0.005\n",
      "\n",
      "***** Epoch #714 *****\n",
      "Loss: 1.506872\n",
      "Improvement ratio: 0.000769\n",
      "Feature L2-norm: 32.987989\n",
      "Learning rate (eta): 0.087504\n",
      "Total number of feature updates: 192780\n",
      "Seconds required for this iteration: 0.006\n",
      "\n",
      "***** Epoch #715 *****\n",
      "Loss: 1.506764\n",
      "Improvement ratio: 0.000752\n",
      "Feature L2-norm: 32.990697\n",
      "Learning rate (eta): 0.087489\n",
      "Total number of feature updates: 193050\n",
      "Seconds required for this iteration: 0.006\n",
      "\n",
      "***** Epoch #716 *****\n",
      "Loss: 1.506639\n",
      "Improvement ratio: 0.000753\n",
      "Feature L2-norm: 32.993399\n",
      "Learning rate (eta): 0.087474\n",
      "Total number of feature updates: 193320\n",
      "Seconds required for this iteration: 0.018\n",
      "\n",
      "***** Epoch #717 *****\n",
      "Loss: 1.506530\n",
      "Improvement ratio: 0.000745\n",
      "Feature L2-norm: 32.996093\n",
      "Learning rate (eta): 0.087459\n",
      "Total number of feature updates: 193590\n",
      "Seconds required for this iteration: 0.010\n",
      "\n",
      "***** Epoch #718 *****\n",
      "Loss: 1.506437\n",
      "Improvement ratio: 0.000729\n",
      "Feature L2-norm: 32.998782\n",
      "Learning rate (eta): 0.087443\n",
      "Total number of feature updates: 193860\n",
      "Seconds required for this iteration: 0.017\n",
      "\n",
      "***** Epoch #719 *****\n",
      "Loss: 1.506315\n",
      "Improvement ratio: 0.000738\n",
      "Feature L2-norm: 33.001461\n",
      "Learning rate (eta): 0.087428\n",
      "Total number of feature updates: 194130\n",
      "Seconds required for this iteration: 0.030\n",
      "\n",
      "***** Epoch #720 *****\n",
      "Loss: 1.506208\n",
      "Improvement ratio: 0.000727\n",
      "Feature L2-norm: 33.004135\n",
      "Learning rate (eta): 0.087413\n",
      "Total number of feature updates: 194400\n",
      "Seconds required for this iteration: 0.031\n",
      "\n",
      "***** Epoch #721 *****\n",
      "Loss: 1.506079\n",
      "Improvement ratio: 0.000745\n",
      "Feature L2-norm: 33.006805\n",
      "Learning rate (eta): 0.087397\n",
      "Total number of feature updates: 194670\n",
      "Seconds required for this iteration: 0.024\n",
      "\n",
      "***** Epoch #722 *****\n",
      "Loss: 1.505982\n",
      "Improvement ratio: 0.000736\n",
      "Feature L2-norm: 33.009468\n",
      "Learning rate (eta): 0.087382\n",
      "Total number of feature updates: 194940\n",
      "Seconds required for this iteration: 0.018\n",
      "\n",
      "***** Epoch #723 *****\n",
      "Loss: 1.505881\n",
      "Improvement ratio: 0.000734\n",
      "Feature L2-norm: 33.012124\n",
      "Learning rate (eta): 0.087367\n",
      "Total number of feature updates: 195210\n",
      "Seconds required for this iteration: 0.032\n",
      "\n",
      "***** Epoch #724 *****\n",
      "Loss: 1.505761\n",
      "Improvement ratio: 0.000738\n",
      "Feature L2-norm: 33.014770\n",
      "Learning rate (eta): 0.087352\n",
      "Total number of feature updates: 195480\n",
      "Seconds required for this iteration: 0.029\n",
      "\n",
      "***** Epoch #725 *****\n",
      "Loss: 1.505652\n",
      "Improvement ratio: 0.000739\n",
      "Feature L2-norm: 33.017412\n",
      "Learning rate (eta): 0.087336\n",
      "Total number of feature updates: 195750\n",
      "Seconds required for this iteration: 0.027\n",
      "\n",
      "***** Epoch #726 *****\n",
      "Loss: 1.505538\n",
      "Improvement ratio: 0.000731\n",
      "Feature L2-norm: 33.020050\n",
      "Learning rate (eta): 0.087321\n",
      "Total number of feature updates: 196020\n",
      "Seconds required for this iteration: 0.018\n",
      "\n",
      "***** Epoch #727 *****\n",
      "Loss: 1.505450\n",
      "Improvement ratio: 0.000718\n",
      "Feature L2-norm: 33.022678\n",
      "Learning rate (eta): 0.087306\n",
      "Total number of feature updates: 196290\n",
      "Seconds required for this iteration: 0.016\n",
      "\n",
      "***** Epoch #728 *****\n",
      "Loss: 1.505352\n",
      "Improvement ratio: 0.000721\n",
      "Feature L2-norm: 33.025302\n",
      "Learning rate (eta): 0.087291\n",
      "Total number of feature updates: 196560\n",
      "Seconds required for this iteration: 0.020\n",
      "\n",
      "***** Epoch #729 *****\n",
      "Loss: 1.505232\n",
      "Improvement ratio: 0.000720\n",
      "Feature L2-norm: 33.027918\n",
      "Learning rate (eta): 0.087275\n",
      "Total number of feature updates: 196830\n",
      "Seconds required for this iteration: 0.012\n",
      "\n",
      "***** Epoch #730 *****\n",
      "Loss: 1.505117\n",
      "Improvement ratio: 0.000725\n",
      "Feature L2-norm: 33.030526\n",
      "Learning rate (eta): 0.087260\n",
      "Total number of feature updates: 197100\n",
      "Seconds required for this iteration: 0.024\n",
      "\n",
      "***** Epoch #731 *****\n",
      "Loss: 1.505030\n",
      "Improvement ratio: 0.000697\n",
      "Feature L2-norm: 33.033129\n",
      "Learning rate (eta): 0.087245\n",
      "Total number of feature updates: 197370\n",
      "Seconds required for this iteration: 0.011\n",
      "\n",
      "***** Epoch #732 *****\n",
      "Loss: 1.504908\n",
      "Improvement ratio: 0.000714\n",
      "Feature L2-norm: 33.035726\n",
      "Learning rate (eta): 0.087230\n",
      "Total number of feature updates: 197640\n",
      "Seconds required for this iteration: 0.009\n",
      "\n",
      "***** Epoch #733 *****\n",
      "Loss: 1.504805\n",
      "Improvement ratio: 0.000715\n",
      "Feature L2-norm: 33.038317\n",
      "Learning rate (eta): 0.087214\n",
      "Total number of feature updates: 197910\n",
      "Seconds required for this iteration: 0.015\n",
      "\n",
      "***** Epoch #734 *****\n",
      "Loss: 1.504707\n",
      "Improvement ratio: 0.000700\n",
      "Feature L2-norm: 33.040903\n",
      "Learning rate (eta): 0.087199\n",
      "Total number of feature updates: 198180\n",
      "Seconds required for this iteration: 0.017\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** Epoch #735 *****\n",
      "Loss: 1.504604\n",
      "Improvement ratio: 0.000697\n",
      "Feature L2-norm: 33.043481\n",
      "Learning rate (eta): 0.087184\n",
      "Total number of feature updates: 198450\n",
      "Seconds required for this iteration: 0.023\n",
      "\n",
      "***** Epoch #736 *****\n",
      "Loss: 1.504494\n",
      "Improvement ratio: 0.000694\n",
      "Feature L2-norm: 33.046054\n",
      "Learning rate (eta): 0.087169\n",
      "Total number of feature updates: 198720\n",
      "Seconds required for this iteration: 0.022\n",
      "\n",
      "***** Epoch #737 *****\n",
      "Loss: 1.504399\n",
      "Improvement ratio: 0.000699\n",
      "Feature L2-norm: 33.048619\n",
      "Learning rate (eta): 0.087154\n",
      "Total number of feature updates: 198990\n",
      "Seconds required for this iteration: 0.019\n",
      "\n",
      "***** Epoch #738 *****\n",
      "Loss: 1.504308\n",
      "Improvement ratio: 0.000694\n",
      "Feature L2-norm: 33.051179\n",
      "Learning rate (eta): 0.087138\n",
      "Total number of feature updates: 199260\n",
      "Seconds required for this iteration: 0.020\n",
      "\n",
      "***** Epoch #739 *****\n",
      "Loss: 1.504189\n",
      "Improvement ratio: 0.000693\n",
      "Feature L2-norm: 33.053732\n",
      "Learning rate (eta): 0.087123\n",
      "Total number of feature updates: 199530\n",
      "Seconds required for this iteration: 0.012\n",
      "\n",
      "***** Epoch #740 *****\n",
      "Loss: 1.504104\n",
      "Improvement ratio: 0.000673\n",
      "Feature L2-norm: 33.056277\n",
      "Learning rate (eta): 0.087108\n",
      "Total number of feature updates: 199800\n",
      "Seconds required for this iteration: 0.028\n",
      "\n",
      "***** Epoch #741 *****\n",
      "Loss: 1.504000\n",
      "Improvement ratio: 0.000684\n",
      "Feature L2-norm: 33.058817\n",
      "Learning rate (eta): 0.087093\n",
      "Total number of feature updates: 200070\n",
      "Seconds required for this iteration: 0.018\n",
      "\n",
      "***** Epoch #742 *****\n",
      "Loss: 1.503889\n",
      "Improvement ratio: 0.000678\n",
      "Feature L2-norm: 33.061353\n",
      "Learning rate (eta): 0.087078\n",
      "Total number of feature updates: 200340\n",
      "Seconds required for this iteration: 0.013\n",
      "\n",
      "***** Epoch #743 *****\n",
      "Loss: 1.503783\n",
      "Improvement ratio: 0.000680\n",
      "Feature L2-norm: 33.063882\n",
      "Learning rate (eta): 0.087063\n",
      "Total number of feature updates: 200610\n",
      "Seconds required for this iteration: 0.012\n",
      "\n",
      "***** Epoch #744 *****\n",
      "Loss: 1.503713\n",
      "Improvement ratio: 0.000662\n",
      "Feature L2-norm: 33.066404\n",
      "Learning rate (eta): 0.087047\n",
      "Total number of feature updates: 200880\n",
      "Seconds required for this iteration: 0.009\n",
      "\n",
      "***** Epoch #745 *****\n",
      "Loss: 1.503628\n",
      "Improvement ratio: 0.000649\n",
      "Feature L2-norm: 33.068920\n",
      "Learning rate (eta): 0.087032\n",
      "Total number of feature updates: 201150\n",
      "Seconds required for this iteration: 0.011\n",
      "\n",
      "***** Epoch #746 *****\n",
      "Loss: 1.503502\n",
      "Improvement ratio: 0.000660\n",
      "Feature L2-norm: 33.071429\n",
      "Learning rate (eta): 0.087017\n",
      "Total number of feature updates: 201420\n",
      "Seconds required for this iteration: 0.011\n",
      "\n",
      "***** Epoch #747 *****\n",
      "Loss: 1.503415\n",
      "Improvement ratio: 0.000654\n",
      "Feature L2-norm: 33.073932\n",
      "Learning rate (eta): 0.087002\n",
      "Total number of feature updates: 201690\n",
      "Seconds required for this iteration: 0.009\n",
      "\n",
      "***** Epoch #748 *****\n",
      "Loss: 1.503316\n",
      "Improvement ratio: 0.000660\n",
      "Feature L2-norm: 33.076431\n",
      "Learning rate (eta): 0.086987\n",
      "Total number of feature updates: 201960\n",
      "Seconds required for this iteration: 0.018\n",
      "\n",
      "***** Epoch #749 *****\n",
      "Loss: 1.503212\n",
      "Improvement ratio: 0.000650\n",
      "Feature L2-norm: 33.078923\n",
      "Learning rate (eta): 0.086972\n",
      "Total number of feature updates: 202230\n",
      "Seconds required for this iteration: 0.027\n",
      "\n",
      "***** Epoch #750 *****\n",
      "Loss: 1.503106\n",
      "Improvement ratio: 0.000664\n",
      "Feature L2-norm: 33.081410\n",
      "Learning rate (eta): 0.086957\n",
      "Total number of feature updates: 202500\n",
      "Seconds required for this iteration: 0.018\n",
      "\n",
      "***** Epoch #751 *****\n",
      "Loss: 1.503024\n",
      "Improvement ratio: 0.000649\n",
      "Feature L2-norm: 33.083890\n",
      "Learning rate (eta): 0.086941\n",
      "Total number of feature updates: 202770\n",
      "Seconds required for this iteration: 0.021\n",
      "\n",
      "***** Epoch #752 *****\n",
      "Loss: 1.502912\n",
      "Improvement ratio: 0.000650\n",
      "Feature L2-norm: 33.086361\n",
      "Learning rate (eta): 0.086926\n",
      "Total number of feature updates: 203040\n",
      "Seconds required for this iteration: 0.018\n",
      "\n",
      "***** Epoch #753 *****\n",
      "Loss: 1.502811\n",
      "Improvement ratio: 0.000647\n",
      "Feature L2-norm: 33.088829\n",
      "Learning rate (eta): 0.086911\n",
      "Total number of feature updates: 203310\n",
      "Seconds required for this iteration: 0.021\n",
      "\n",
      "***** Epoch #754 *****\n",
      "Loss: 1.502731\n",
      "Improvement ratio: 0.000653\n",
      "Feature L2-norm: 33.091290\n",
      "Learning rate (eta): 0.086896\n",
      "Total number of feature updates: 203580\n",
      "Seconds required for this iteration: 0.014\n",
      "\n",
      "***** Epoch #755 *****\n",
      "Loss: 1.502633\n",
      "Improvement ratio: 0.000662\n",
      "Feature L2-norm: 33.093746\n",
      "Learning rate (eta): 0.086881\n",
      "Total number of feature updates: 203850\n",
      "Seconds required for this iteration: 0.024\n",
      "\n",
      "***** Epoch #756 *****\n",
      "Loss: 1.502510\n",
      "Improvement ratio: 0.000660\n",
      "Feature L2-norm: 33.096193\n",
      "Learning rate (eta): 0.086866\n",
      "Total number of feature updates: 204120\n",
      "Seconds required for this iteration: 0.016\n",
      "\n",
      "***** Epoch #757 *****\n",
      "Loss: 1.502447\n",
      "Improvement ratio: 0.000645\n",
      "Feature L2-norm: 33.098638\n",
      "Learning rate (eta): 0.086851\n",
      "Total number of feature updates: 204390\n",
      "Seconds required for this iteration: 0.020\n",
      "\n",
      "***** Epoch #758 *****\n",
      "Loss: 1.502349\n",
      "Improvement ratio: 0.000643\n",
      "Feature L2-norm: 33.101078\n",
      "Learning rate (eta): 0.086836\n",
      "Total number of feature updates: 204660\n",
      "Seconds required for this iteration: 0.010\n",
      "\n",
      "***** Epoch #759 *****\n",
      "Loss: 1.502250\n",
      "Improvement ratio: 0.000640\n",
      "Feature L2-norm: 33.103510\n",
      "Learning rate (eta): 0.086821\n",
      "Total number of feature updates: 204930\n",
      "Seconds required for this iteration: 0.020\n",
      "\n",
      "***** Epoch #760 *****\n",
      "Loss: 1.502153\n",
      "Improvement ratio: 0.000635\n",
      "Feature L2-norm: 33.105937\n",
      "Learning rate (eta): 0.086806\n",
      "Total number of feature updates: 205200\n",
      "Seconds required for this iteration: 0.011\n",
      "\n",
      "***** Epoch #761 *****\n",
      "Loss: 1.502068\n",
      "Improvement ratio: 0.000637\n",
      "Feature L2-norm: 33.108355\n",
      "Learning rate (eta): 0.086791\n",
      "Total number of feature updates: 205470\n",
      "Seconds required for this iteration: 0.015\n",
      "\n",
      "***** Epoch #762 *****\n",
      "Loss: 1.501982\n",
      "Improvement ratio: 0.000619\n",
      "Feature L2-norm: 33.110770\n",
      "Learning rate (eta): 0.086775\n",
      "Total number of feature updates: 205740\n",
      "Seconds required for this iteration: 0.011\n",
      "\n",
      "***** Epoch #763 *****\n",
      "Loss: 1.501873\n",
      "Improvement ratio: 0.000624\n",
      "Feature L2-norm: 33.113180\n",
      "Learning rate (eta): 0.086760\n",
      "Total number of feature updates: 206010\n",
      "Seconds required for this iteration: 0.017\n",
      "\n",
      "***** Epoch #764 *****\n",
      "Loss: 1.501783\n",
      "Improvement ratio: 0.000631\n",
      "Feature L2-norm: 33.115584\n",
      "Learning rate (eta): 0.086745\n",
      "Total number of feature updates: 206280\n",
      "Seconds required for this iteration: 0.017\n",
      "\n",
      "***** Epoch #765 *****\n",
      "Loss: 1.501708\n",
      "Improvement ratio: 0.000616\n",
      "Feature L2-norm: 33.117981\n",
      "Learning rate (eta): 0.086730\n",
      "Total number of feature updates: 206550\n",
      "Seconds required for this iteration: 0.029\n",
      "\n",
      "***** Epoch #766 *****\n",
      "Loss: 1.501593\n",
      "Improvement ratio: 0.000611\n",
      "Feature L2-norm: 33.120371\n",
      "Learning rate (eta): 0.086715\n",
      "Total number of feature updates: 206820\n",
      "Seconds required for this iteration: 0.021\n",
      "\n",
      "***** Epoch #767 *****\n",
      "Loss: 1.501531\n",
      "Improvement ratio: 0.000610\n",
      "Feature L2-norm: 33.122759\n",
      "Learning rate (eta): 0.086700\n",
      "Total number of feature updates: 207090\n",
      "Seconds required for this iteration: 0.013\n",
      "\n",
      "***** Epoch #768 *****\n",
      "Loss: 1.501429\n",
      "Improvement ratio: 0.000613\n",
      "Feature L2-norm: 33.125139\n",
      "Learning rate (eta): 0.086685\n",
      "Total number of feature updates: 207360\n",
      "Seconds required for this iteration: 0.016\n",
      "\n",
      "***** Epoch #769 *****\n",
      "Loss: 1.501325\n",
      "Improvement ratio: 0.000616\n",
      "Feature L2-norm: 33.127514\n",
      "Learning rate (eta): 0.086670\n",
      "Total number of feature updates: 207630\n",
      "Seconds required for this iteration: 0.011\n",
      "\n",
      "***** Epoch #770 *****\n",
      "Loss: 1.501235\n",
      "Improvement ratio: 0.000611\n",
      "Feature L2-norm: 33.129885\n",
      "Learning rate (eta): 0.086655\n",
      "Total number of feature updates: 207900\n",
      "Seconds required for this iteration: 0.013\n",
      "\n",
      "***** Epoch #771 *****\n",
      "Loss: 1.501167\n",
      "Improvement ratio: 0.000600\n",
      "Feature L2-norm: 33.132248\n",
      "Learning rate (eta): 0.086640\n",
      "Total number of feature updates: 208170\n",
      "Seconds required for this iteration: 0.017\n",
      "\n",
      "***** Epoch #772 *****\n",
      "Loss: 1.501067\n",
      "Improvement ratio: 0.000610\n",
      "Feature L2-norm: 33.134606\n",
      "Learning rate (eta): 0.086625\n",
      "Total number of feature updates: 208440\n",
      "Seconds required for this iteration: 0.021\n",
      "\n",
      "***** Epoch #773 *****\n",
      "Loss: 1.500983\n",
      "Improvement ratio: 0.000593\n",
      "Feature L2-norm: 33.136958\n",
      "Learning rate (eta): 0.086610\n",
      "Total number of feature updates: 208710\n",
      "Seconds required for this iteration: 0.013\n",
      "\n",
      "***** Epoch #774 *****\n",
      "Loss: 1.500895\n",
      "Improvement ratio: 0.000592\n",
      "Feature L2-norm: 33.139307\n",
      "Learning rate (eta): 0.086595\n",
      "Total number of feature updates: 208980\n",
      "Seconds required for this iteration: 0.022\n",
      "\n",
      "***** Epoch #775 *****\n",
      "Loss: 1.500813\n",
      "Improvement ratio: 0.000597\n",
      "Feature L2-norm: 33.141649\n",
      "Learning rate (eta): 0.086580\n",
      "Total number of feature updates: 209250\n",
      "Seconds required for this iteration: 0.008\n",
      "\n",
      "***** Epoch #776 *****\n",
      "Loss: 1.500722\n",
      "Improvement ratio: 0.000581\n",
      "Feature L2-norm: 33.143986\n",
      "Learning rate (eta): 0.086565\n",
      "Total number of feature updates: 209520\n",
      "Seconds required for this iteration: 0.007\n",
      "\n",
      "***** Epoch #777 *****\n",
      "Loss: 1.500624\n",
      "Improvement ratio: 0.000605\n",
      "Feature L2-norm: 33.146316\n",
      "Learning rate (eta): 0.086550\n",
      "Total number of feature updates: 209790\n",
      "Seconds required for this iteration: 0.011\n",
      "\n",
      "***** Epoch #778 *****\n",
      "Loss: 1.500542\n",
      "Improvement ratio: 0.000591\n",
      "Feature L2-norm: 33.148641\n",
      "Learning rate (eta): 0.086535\n",
      "Total number of feature updates: 210060\n",
      "Seconds required for this iteration: 0.019\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** Epoch #779 *****\n",
      "Loss: 1.500465\n",
      "Improvement ratio: 0.000573\n",
      "Feature L2-norm: 33.150962\n",
      "Learning rate (eta): 0.086520\n",
      "Total number of feature updates: 210330\n",
      "Seconds required for this iteration: 0.018\n",
      "\n",
      "***** Epoch #780 *****\n",
      "Loss: 1.500375\n",
      "Improvement ratio: 0.000573\n",
      "Feature L2-norm: 33.153275\n",
      "Learning rate (eta): 0.086505\n",
      "Total number of feature updates: 210600\n",
      "Seconds required for this iteration: 0.013\n",
      "\n",
      "***** Epoch #781 *****\n",
      "Loss: 1.500289\n",
      "Improvement ratio: 0.000585\n",
      "Feature L2-norm: 33.155585\n",
      "Learning rate (eta): 0.086490\n",
      "Total number of feature updates: 210870\n",
      "Seconds required for this iteration: 0.023\n",
      "\n",
      "***** Epoch #782 *****\n",
      "Loss: 1.500203\n",
      "Improvement ratio: 0.000576\n",
      "Feature L2-norm: 33.157888\n",
      "Learning rate (eta): 0.086475\n",
      "Total number of feature updates: 211140\n",
      "Seconds required for this iteration: 0.017\n",
      "\n",
      "***** Epoch #783 *****\n",
      "Loss: 1.500122\n",
      "Improvement ratio: 0.000574\n",
      "Feature L2-norm: 33.160185\n",
      "Learning rate (eta): 0.086460\n",
      "Total number of feature updates: 211410\n",
      "Seconds required for this iteration: 0.015\n",
      "\n",
      "***** Epoch #784 *****\n",
      "Loss: 1.500040\n",
      "Improvement ratio: 0.000570\n",
      "Feature L2-norm: 33.162479\n",
      "Learning rate (eta): 0.086445\n",
      "Total number of feature updates: 211680\n",
      "Seconds required for this iteration: 0.014\n",
      "\n",
      "***** Epoch #785 *****\n",
      "Loss: 1.499946\n",
      "Improvement ratio: 0.000578\n",
      "Feature L2-norm: 33.164766\n",
      "Learning rate (eta): 0.086430\n",
      "Total number of feature updates: 211950\n",
      "Seconds required for this iteration: 0.012\n",
      "\n",
      "***** Epoch #786 *****\n",
      "Loss: 1.499859\n",
      "Improvement ratio: 0.000575\n",
      "Feature L2-norm: 33.167046\n",
      "Learning rate (eta): 0.086416\n",
      "Total number of feature updates: 212220\n",
      "Seconds required for this iteration: 0.006\n",
      "\n",
      "***** Epoch #787 *****\n",
      "Loss: 1.499771\n",
      "Improvement ratio: 0.000569\n",
      "Feature L2-norm: 33.169318\n",
      "Learning rate (eta): 0.086401\n",
      "Total number of feature updates: 212490\n",
      "Seconds required for this iteration: 0.006\n",
      "\n",
      "***** Epoch #788 *****\n",
      "Loss: 1.499704\n",
      "Improvement ratio: 0.000558\n",
      "Feature L2-norm: 33.171589\n",
      "Learning rate (eta): 0.086386\n",
      "Total number of feature updates: 212760\n",
      "Seconds required for this iteration: 0.011\n",
      "\n",
      "***** Epoch #789 *****\n",
      "Loss: 1.499612\n",
      "Improvement ratio: 0.000569\n",
      "Feature L2-norm: 33.173855\n",
      "Learning rate (eta): 0.086371\n",
      "Total number of feature updates: 213030\n",
      "Seconds required for this iteration: 0.010\n",
      "\n",
      "***** Epoch #790 *****\n",
      "Loss: 1.499549\n",
      "Improvement ratio: 0.000551\n",
      "Feature L2-norm: 33.176114\n",
      "Learning rate (eta): 0.086356\n",
      "Total number of feature updates: 213300\n",
      "Seconds required for this iteration: 0.012\n",
      "\n",
      "***** Epoch #791 *****\n",
      "Loss: 1.499450\n",
      "Improvement ratio: 0.000560\n",
      "Feature L2-norm: 33.178369\n",
      "Learning rate (eta): 0.086341\n",
      "Total number of feature updates: 213570\n",
      "Seconds required for this iteration: 0.006\n",
      "\n",
      "***** Epoch #792 *****\n",
      "Loss: 1.499347\n",
      "Improvement ratio: 0.000571\n",
      "Feature L2-norm: 33.180616\n",
      "Learning rate (eta): 0.086326\n",
      "Total number of feature updates: 213840\n",
      "Seconds required for this iteration: 0.011\n",
      "\n",
      "***** Epoch #793 *****\n",
      "Loss: 1.499276\n",
      "Improvement ratio: 0.000564\n",
      "Feature L2-norm: 33.182858\n",
      "Learning rate (eta): 0.086311\n",
      "Total number of feature updates: 214110\n",
      "Seconds required for this iteration: 0.006\n",
      "\n",
      "***** Epoch #794 *****\n",
      "Loss: 1.499190\n",
      "Improvement ratio: 0.000567\n",
      "Feature L2-norm: 33.185099\n",
      "Learning rate (eta): 0.086296\n",
      "Total number of feature updates: 214380\n",
      "Seconds required for this iteration: 0.006\n",
      "\n",
      "***** Epoch #795 *****\n",
      "Loss: 1.499146\n",
      "Improvement ratio: 0.000534\n",
      "Feature L2-norm: 33.187332\n",
      "Learning rate (eta): 0.086281\n",
      "Total number of feature updates: 214650\n",
      "Seconds required for this iteration: 0.016\n",
      "\n",
      "***** Epoch #796 *****\n",
      "Loss: 1.499035\n",
      "Improvement ratio: 0.000550\n",
      "Feature L2-norm: 33.189559\n",
      "Learning rate (eta): 0.086266\n",
      "Total number of feature updates: 214920\n",
      "Seconds required for this iteration: 0.010\n",
      "\n",
      "***** Epoch #797 *****\n",
      "Loss: 1.498950\n",
      "Improvement ratio: 0.000548\n",
      "Feature L2-norm: 33.191781\n",
      "Learning rate (eta): 0.086252\n",
      "Total number of feature updates: 215190\n",
      "Seconds required for this iteration: 0.011\n",
      "\n",
      "***** Epoch #798 *****\n",
      "Loss: 1.498885\n",
      "Improvement ratio: 0.000547\n",
      "Feature L2-norm: 33.193999\n",
      "Learning rate (eta): 0.086237\n",
      "Total number of feature updates: 215460\n",
      "Seconds required for this iteration: 0.010\n",
      "\n",
      "***** Epoch #799 *****\n",
      "Loss: 1.498783\n",
      "Improvement ratio: 0.000553\n",
      "Feature L2-norm: 33.196213\n",
      "Learning rate (eta): 0.086222\n",
      "Total number of feature updates: 215730\n",
      "Seconds required for this iteration: 0.024\n",
      "\n",
      "***** Epoch #800 *****\n",
      "Loss: 1.498715\n",
      "Improvement ratio: 0.000557\n",
      "Feature L2-norm: 33.198420\n",
      "Learning rate (eta): 0.086207\n",
      "Total number of feature updates: 216000\n",
      "Seconds required for this iteration: 0.020\n",
      "\n",
      "***** Epoch #801 *****\n",
      "Loss: 1.498625\n",
      "Improvement ratio: 0.000550\n",
      "Feature L2-norm: 33.200619\n",
      "Learning rate (eta): 0.086192\n",
      "Total number of feature updates: 216270\n",
      "Seconds required for this iteration: 0.010\n",
      "\n",
      "***** Epoch #802 *****\n",
      "Loss: 1.498573\n",
      "Improvement ratio: 0.000516\n",
      "Feature L2-norm: 33.202816\n",
      "Learning rate (eta): 0.086177\n",
      "Total number of feature updates: 216540\n",
      "Seconds required for this iteration: 0.010\n",
      "\n",
      "***** Epoch #803 *****\n",
      "Loss: 1.498498\n",
      "Improvement ratio: 0.000519\n",
      "Feature L2-norm: 33.205007\n",
      "Learning rate (eta): 0.086162\n",
      "Total number of feature updates: 216810\n",
      "Seconds required for this iteration: 0.011\n",
      "\n",
      "***** Epoch #804 *****\n",
      "Loss: 1.498391\n",
      "Improvement ratio: 0.000533\n",
      "Feature L2-norm: 33.207194\n",
      "Learning rate (eta): 0.086148\n",
      "Total number of feature updates: 217080\n",
      "Seconds required for this iteration: 0.011\n",
      "\n",
      "***** Epoch #805 *****\n",
      "Loss: 1.498327\n",
      "Improvement ratio: 0.000546\n",
      "Feature L2-norm: 33.209374\n",
      "Learning rate (eta): 0.086133\n",
      "Total number of feature updates: 217350\n",
      "Seconds required for this iteration: 0.010\n",
      "\n",
      "***** Epoch #806 *****\n",
      "Loss: 1.498251\n",
      "Improvement ratio: 0.000523\n",
      "Feature L2-norm: 33.211551\n",
      "Learning rate (eta): 0.086118\n",
      "Total number of feature updates: 217620\n",
      "Seconds required for this iteration: 0.009\n",
      "\n",
      "***** Epoch #807 *****\n",
      "Loss: 1.498180\n",
      "Improvement ratio: 0.000514\n",
      "Feature L2-norm: 33.213721\n",
      "Learning rate (eta): 0.086103\n",
      "Total number of feature updates: 217890\n",
      "Seconds required for this iteration: 0.010\n",
      "\n",
      "***** Epoch #808 *****\n",
      "Loss: 1.498093\n",
      "Improvement ratio: 0.000528\n",
      "Feature L2-norm: 33.215888\n",
      "Learning rate (eta): 0.086088\n",
      "Total number of feature updates: 218160\n",
      "Seconds required for this iteration: 0.009\n",
      "\n",
      "***** Epoch #809 *****\n",
      "Loss: 1.498022\n",
      "Improvement ratio: 0.000508\n",
      "Feature L2-norm: 33.218049\n",
      "Learning rate (eta): 0.086073\n",
      "Total number of feature updates: 218430\n",
      "Seconds required for this iteration: 0.020\n",
      "\n",
      "***** Epoch #810 *****\n",
      "Loss: 1.497933\n",
      "Improvement ratio: 0.000522\n",
      "Feature L2-norm: 33.220207\n",
      "Learning rate (eta): 0.086059\n",
      "Total number of feature updates: 218700\n",
      "Seconds required for this iteration: 0.014\n",
      "\n",
      "***** Epoch #811 *****\n",
      "Loss: 1.497868\n",
      "Improvement ratio: 0.000505\n",
      "Feature L2-norm: 33.222356\n",
      "Learning rate (eta): 0.086044\n",
      "Total number of feature updates: 218970\n",
      "Seconds required for this iteration: 0.020\n",
      "\n",
      "***** Epoch #812 *****\n",
      "Loss: 1.497795\n",
      "Improvement ratio: 0.000519\n",
      "Feature L2-norm: 33.224503\n",
      "Learning rate (eta): 0.086029\n",
      "Total number of feature updates: 219240\n",
      "Seconds required for this iteration: 0.011\n",
      "\n",
      "***** Epoch #813 *****\n",
      "Loss: 1.497716\n",
      "Improvement ratio: 0.000522\n",
      "Feature L2-norm: 33.226645\n",
      "Learning rate (eta): 0.086014\n",
      "Total number of feature updates: 219510\n",
      "Seconds required for this iteration: 0.011\n",
      "\n",
      "***** Epoch #814 *****\n",
      "Loss: 1.497635\n",
      "Improvement ratio: 0.000505\n",
      "Feature L2-norm: 33.228780\n",
      "Learning rate (eta): 0.085999\n",
      "Total number of feature updates: 219780\n",
      "Seconds required for this iteration: 0.015\n",
      "\n",
      "***** Epoch #815 *****\n",
      "Loss: 1.497578\n",
      "Improvement ratio: 0.000500\n",
      "Feature L2-norm: 33.230912\n",
      "Learning rate (eta): 0.085985\n",
      "Total number of feature updates: 220050\n",
      "Seconds required for this iteration: 0.022\n",
      "\n",
      "***** Epoch #816 *****\n",
      "Loss: 1.497487\n",
      "Improvement ratio: 0.000510\n",
      "Feature L2-norm: 33.233038\n",
      "Learning rate (eta): 0.085970\n",
      "Total number of feature updates: 220320\n",
      "Seconds required for this iteration: 0.009\n",
      "\n",
      "***** Epoch #817 *****\n",
      "Loss: 1.497402\n",
      "Improvement ratio: 0.000519\n",
      "Feature L2-norm: 33.235158\n",
      "Learning rate (eta): 0.085955\n",
      "Total number of feature updates: 220590\n",
      "Seconds required for this iteration: 0.016\n",
      "\n",
      "***** Epoch #818 *****\n",
      "Loss: 1.497318\n",
      "Improvement ratio: 0.000518\n",
      "Feature L2-norm: 33.237275\n",
      "Learning rate (eta): 0.085940\n",
      "Total number of feature updates: 220860\n",
      "Seconds required for this iteration: 0.006\n",
      "\n",
      "***** Epoch #819 *****\n",
      "Loss: 1.497262\n",
      "Improvement ratio: 0.000507\n",
      "Feature L2-norm: 33.239389\n",
      "Learning rate (eta): 0.085925\n",
      "Total number of feature updates: 221130\n",
      "Seconds required for this iteration: 0.008\n",
      "\n",
      "***** Epoch #820 *****\n",
      "Loss: 1.497191\n",
      "Improvement ratio: 0.000496\n",
      "Feature L2-norm: 33.241494\n",
      "Learning rate (eta): 0.085911\n",
      "Total number of feature updates: 221400\n",
      "Seconds required for this iteration: 0.020\n",
      "\n",
      "***** Epoch #821 *****\n",
      "Loss: 1.497125\n",
      "Improvement ratio: 0.000496\n",
      "Feature L2-norm: 33.243596\n",
      "Learning rate (eta): 0.085896\n",
      "Total number of feature updates: 221670\n",
      "Seconds required for this iteration: 0.018\n",
      "\n",
      "***** Epoch #822 *****\n",
      "Loss: 1.497023\n",
      "Improvement ratio: 0.000516\n",
      "Feature L2-norm: 33.245693\n",
      "Learning rate (eta): 0.085881\n",
      "Total number of feature updates: 221940\n",
      "Seconds required for this iteration: 0.011\n",
      "\n",
      "***** Epoch #823 *****\n",
      "Loss: 1.496985\n",
      "Improvement ratio: 0.000488\n",
      "Feature L2-norm: 33.247784\n",
      "Learning rate (eta): 0.085866\n",
      "Total number of feature updates: 222210\n",
      "Seconds required for this iteration: 0.010\n",
      "\n",
      "***** Epoch #824 *****\n",
      "Loss: 1.496893\n",
      "Improvement ratio: 0.000496\n",
      "Feature L2-norm: 33.249873\n",
      "Learning rate (eta): 0.085852\n",
      "Total number of feature updates: 222480\n",
      "Seconds required for this iteration: 0.011\n",
      "\n",
      "***** Epoch #825 *****\n",
      "Loss: 1.496814\n",
      "Improvement ratio: 0.000511\n",
      "Feature L2-norm: 33.251956\n",
      "Learning rate (eta): 0.085837\n",
      "Total number of feature updates: 222750\n",
      "Seconds required for this iteration: 0.021\n",
      "\n",
      "***** Epoch #826 *****\n",
      "Loss: 1.496754\n",
      "Improvement ratio: 0.000490\n",
      "Feature L2-norm: 33.254036\n",
      "Learning rate (eta): 0.085822\n",
      "Total number of feature updates: 223020\n",
      "Seconds required for this iteration: 0.021\n",
      "\n",
      "***** Epoch #827 *****\n",
      "Loss: 1.496672\n",
      "Improvement ratio: 0.000488\n",
      "Feature L2-norm: 33.256109\n",
      "Learning rate (eta): 0.085808\n",
      "Total number of feature updates: 223290\n",
      "Seconds required for this iteration: 0.018\n",
      "\n",
      "***** Epoch #828 *****\n",
      "Loss: 1.496607\n",
      "Improvement ratio: 0.000475\n",
      "Feature L2-norm: 33.258175\n",
      "Learning rate (eta): 0.085793\n",
      "Total number of feature updates: 223560\n",
      "Seconds required for this iteration: 0.018\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** Epoch #829 *****\n",
      "Loss: 1.496538\n",
      "Improvement ratio: 0.000484\n",
      "Feature L2-norm: 33.260238\n",
      "Learning rate (eta): 0.085778\n",
      "Total number of feature updates: 223830\n",
      "Seconds required for this iteration: 0.011\n",
      "\n",
      "***** Epoch #830 *****\n",
      "Loss: 1.496472\n",
      "Improvement ratio: 0.000480\n",
      "Feature L2-norm: 33.262297\n",
      "Learning rate (eta): 0.085763\n",
      "Total number of feature updates: 224100\n",
      "Seconds required for this iteration: 0.010\n",
      "\n",
      "***** Epoch #831 *****\n",
      "Loss: 1.496407\n",
      "Improvement ratio: 0.000480\n",
      "Feature L2-norm: 33.264352\n",
      "Learning rate (eta): 0.085749\n",
      "Total number of feature updates: 224370\n",
      "Seconds required for this iteration: 0.014\n",
      "\n",
      "***** Epoch #832 *****\n",
      "Loss: 1.496326\n",
      "Improvement ratio: 0.000466\n",
      "Feature L2-norm: 33.266399\n",
      "Learning rate (eta): 0.085734\n",
      "Total number of feature updates: 224640\n",
      "Seconds required for this iteration: 0.021\n",
      "\n",
      "***** Epoch #833 *****\n",
      "Loss: 1.496263\n",
      "Improvement ratio: 0.000483\n",
      "Feature L2-norm: 33.268443\n",
      "Learning rate (eta): 0.085719\n",
      "Total number of feature updates: 224910\n",
      "Seconds required for this iteration: 0.014\n",
      "\n",
      "***** Epoch #834 *****\n",
      "Loss: 1.496190\n",
      "Improvement ratio: 0.000470\n",
      "Feature L2-norm: 33.270483\n",
      "Learning rate (eta): 0.085705\n",
      "Total number of feature updates: 225180\n",
      "Seconds required for this iteration: 0.011\n",
      "\n",
      "***** Epoch #835 *****\n",
      "Loss: 1.496130\n",
      "Improvement ratio: 0.000457\n",
      "Feature L2-norm: 33.272518\n",
      "Learning rate (eta): 0.085690\n",
      "Total number of feature updates: 225450\n",
      "Seconds required for this iteration: 0.010\n",
      "\n",
      "***** Epoch #836 *****\n",
      "Loss: 1.496047\n",
      "Improvement ratio: 0.000473\n",
      "Feature L2-norm: 33.274550\n",
      "Learning rate (eta): 0.085675\n",
      "Total number of feature updates: 225720\n",
      "Seconds required for this iteration: 0.010\n",
      "\n",
      "***** Epoch #837 *****\n",
      "Loss: 1.495973\n",
      "Improvement ratio: 0.000467\n",
      "Feature L2-norm: 33.276576\n",
      "Learning rate (eta): 0.085660\n",
      "Total number of feature updates: 225990\n",
      "Seconds required for this iteration: 0.010\n",
      "\n",
      "***** Epoch #838 *****\n",
      "Loss: 1.495902\n",
      "Improvement ratio: 0.000471\n",
      "Feature L2-norm: 33.278597\n",
      "Learning rate (eta): 0.085646\n",
      "Total number of feature updates: 226260\n",
      "Seconds required for this iteration: 0.019\n",
      "\n",
      "***** Epoch #839 *****\n",
      "Loss: 1.495835\n",
      "Improvement ratio: 0.000470\n",
      "Feature L2-norm: 33.280613\n",
      "Learning rate (eta): 0.085631\n",
      "Total number of feature updates: 226530\n",
      "Seconds required for this iteration: 0.018\n",
      "\n",
      "***** Epoch #840 *****\n",
      "Loss: 1.495774\n",
      "Improvement ratio: 0.000467\n",
      "Feature L2-norm: 33.282626\n",
      "Learning rate (eta): 0.085616\n",
      "Total number of feature updates: 226800\n",
      "Seconds required for this iteration: 0.016\n",
      "\n",
      "***** Epoch #841 *****\n",
      "Loss: 1.495704\n",
      "Improvement ratio: 0.000470\n",
      "Feature L2-norm: 33.284635\n",
      "Learning rate (eta): 0.085602\n",
      "Total number of feature updates: 227070\n",
      "Seconds required for this iteration: 0.012\n",
      "\n",
      "***** Epoch #842 *****\n",
      "Loss: 1.495635\n",
      "Improvement ratio: 0.000462\n",
      "Feature L2-norm: 33.286638\n",
      "Learning rate (eta): 0.085587\n",
      "Total number of feature updates: 227340\n",
      "Seconds required for this iteration: 0.020\n",
      "\n",
      "***** Epoch #843 *****\n",
      "Loss: 1.495560\n",
      "Improvement ratio: 0.000470\n",
      "Feature L2-norm: 33.288636\n",
      "Learning rate (eta): 0.085573\n",
      "Total number of feature updates: 227610\n",
      "Seconds required for this iteration: 0.012\n",
      "\n",
      "***** Epoch #844 *****\n",
      "Loss: 1.495510\n",
      "Improvement ratio: 0.000455\n",
      "Feature L2-norm: 33.290629\n",
      "Learning rate (eta): 0.085558\n",
      "Total number of feature updates: 227880\n",
      "Seconds required for this iteration: 0.016\n",
      "\n",
      "***** Epoch #845 *****\n",
      "Loss: 1.495435\n",
      "Improvement ratio: 0.000465\n",
      "Feature L2-norm: 33.292619\n",
      "Learning rate (eta): 0.085543\n",
      "Total number of feature updates: 228150\n",
      "Seconds required for this iteration: 0.021\n",
      "\n",
      "***** Epoch #846 *****\n",
      "Loss: 1.495352\n",
      "Improvement ratio: 0.000464\n",
      "Feature L2-norm: 33.294606\n",
      "Learning rate (eta): 0.085529\n",
      "Total number of feature updates: 228420\n",
      "Seconds required for this iteration: 0.026\n",
      "\n",
      "***** Epoch #847 *****\n",
      "Loss: 1.495298\n",
      "Improvement ratio: 0.000451\n",
      "Feature L2-norm: 33.296586\n",
      "Learning rate (eta): 0.085514\n",
      "Total number of feature updates: 228690\n",
      "Seconds required for this iteration: 0.023\n",
      "\n",
      "***** Epoch #848 *****\n",
      "Loss: 1.495220\n",
      "Improvement ratio: 0.000456\n",
      "Feature L2-norm: 33.298561\n",
      "Learning rate (eta): 0.085499\n",
      "Total number of feature updates: 228960\n",
      "Seconds required for this iteration: 0.011\n",
      "\n",
      "***** Epoch #849 *****\n",
      "Loss: 1.495146\n",
      "Improvement ratio: 0.000461\n",
      "Feature L2-norm: 33.300531\n",
      "Learning rate (eta): 0.085485\n",
      "Total number of feature updates: 229230\n",
      "Seconds required for this iteration: 0.018\n",
      "\n",
      "***** Epoch #850 *****\n",
      "Loss: 1.495091\n",
      "Improvement ratio: 0.000457\n",
      "Feature L2-norm: 33.302498\n",
      "Learning rate (eta): 0.085470\n",
      "Total number of feature updates: 229500\n",
      "Seconds required for this iteration: 0.019\n",
      "\n",
      "***** Epoch #851 *****\n",
      "Loss: 1.495053\n",
      "Improvement ratio: 0.000435\n",
      "Feature L2-norm: 33.304459\n",
      "Learning rate (eta): 0.085456\n",
      "Total number of feature updates: 229770\n",
      "Seconds required for this iteration: 0.012\n",
      "\n",
      "***** Epoch #852 *****\n",
      "Loss: 1.494942\n",
      "Improvement ratio: 0.000464\n",
      "Feature L2-norm: 33.306417\n",
      "Learning rate (eta): 0.085441\n",
      "Total number of feature updates: 230040\n",
      "Seconds required for this iteration: 0.019\n",
      "\n",
      "***** Epoch #853 *****\n",
      "Loss: 1.494910\n",
      "Improvement ratio: 0.000435\n",
      "Feature L2-norm: 33.308370\n",
      "Learning rate (eta): 0.085426\n",
      "Total number of feature updates: 230310\n",
      "Seconds required for this iteration: 0.020\n",
      "\n",
      "***** Epoch #854 *****\n",
      "Loss: 1.494820\n",
      "Improvement ratio: 0.000462\n",
      "Feature L2-norm: 33.310317\n",
      "Learning rate (eta): 0.085412\n",
      "Total number of feature updates: 230580\n",
      "Seconds required for this iteration: 0.018\n",
      "\n",
      "***** Epoch #855 *****\n",
      "Loss: 1.494781\n",
      "Improvement ratio: 0.000438\n",
      "Feature L2-norm: 33.312262\n",
      "Learning rate (eta): 0.085397\n",
      "Total number of feature updates: 230850\n",
      "Seconds required for this iteration: 0.007\n",
      "\n",
      "***** Epoch #856 *****\n",
      "Loss: 1.494710\n",
      "Improvement ratio: 0.000430\n",
      "Feature L2-norm: 33.314202\n",
      "Learning rate (eta): 0.085383\n",
      "Total number of feature updates: 231120\n",
      "Seconds required for this iteration: 0.011\n",
      "\n",
      "***** Epoch #857 *****\n",
      "Loss: 1.494652\n",
      "Improvement ratio: 0.000433\n",
      "Feature L2-norm: 33.316137\n",
      "Learning rate (eta): 0.085368\n",
      "Total number of feature updates: 231390\n",
      "Seconds required for this iteration: 0.022\n",
      "\n",
      "***** Epoch #858 *****\n",
      "Loss: 1.494584\n",
      "Improvement ratio: 0.000425\n",
      "Feature L2-norm: 33.318069\n",
      "Learning rate (eta): 0.085353\n",
      "Total number of feature updates: 231660\n",
      "Seconds required for this iteration: 0.017\n",
      "\n",
      "***** Epoch #859 *****\n",
      "Loss: 1.494504\n",
      "Improvement ratio: 0.000429\n",
      "Feature L2-norm: 33.319994\n",
      "Learning rate (eta): 0.085339\n",
      "Total number of feature updates: 231930\n",
      "Seconds required for this iteration: 0.021\n",
      "\n",
      "***** Epoch #860 *****\n",
      "Loss: 1.494438\n",
      "Improvement ratio: 0.000437\n",
      "Feature L2-norm: 33.321915\n",
      "Learning rate (eta): 0.085324\n",
      "Total number of feature updates: 232200\n",
      "Seconds required for this iteration: 0.016\n",
      "\n",
      "***** Epoch #861 *****\n",
      "Loss: 1.494397\n",
      "Improvement ratio: 0.000439\n",
      "Feature L2-norm: 33.323834\n",
      "Learning rate (eta): 0.085310\n",
      "Total number of feature updates: 232470\n",
      "Seconds required for this iteration: 0.022\n",
      "\n",
      "***** Epoch #862 *****\n",
      "Loss: 1.494327\n",
      "Improvement ratio: 0.000411\n",
      "Feature L2-norm: 33.325749\n",
      "Learning rate (eta): 0.085295\n",
      "Total number of feature updates: 232740\n",
      "Seconds required for this iteration: 0.012\n",
      "\n",
      "***** Epoch #863 *****\n",
      "Loss: 1.494275\n",
      "Improvement ratio: 0.000425\n",
      "Feature L2-norm: 33.327657\n",
      "Learning rate (eta): 0.085281\n",
      "Total number of feature updates: 233010\n",
      "Seconds required for this iteration: 0.010\n",
      "\n",
      "***** Epoch #864 *****\n",
      "Loss: 1.494207\n",
      "Improvement ratio: 0.000410\n",
      "Feature L2-norm: 33.329562\n",
      "Learning rate (eta): 0.085266\n",
      "Total number of feature updates: 233280\n",
      "Seconds required for this iteration: 0.011\n",
      "\n",
      "***** Epoch #865 *****\n",
      "Loss: 1.494133\n",
      "Improvement ratio: 0.000433\n",
      "Feature L2-norm: 33.331463\n",
      "Learning rate (eta): 0.085252\n",
      "Total number of feature updates: 233550\n",
      "Seconds required for this iteration: 0.011\n",
      "\n",
      "***** Epoch #866 *****\n",
      "Loss: 1.494061\n",
      "Improvement ratio: 0.000434\n",
      "Feature L2-norm: 33.333358\n",
      "Learning rate (eta): 0.085237\n",
      "Total number of feature updates: 233820\n",
      "Seconds required for this iteration: 0.010\n",
      "\n",
      "***** Epoch #867 *****\n",
      "Loss: 1.493998\n",
      "Improvement ratio: 0.000438\n",
      "Feature L2-norm: 33.335252\n",
      "Learning rate (eta): 0.085222\n",
      "Total number of feature updates: 234090\n",
      "Seconds required for this iteration: 0.013\n",
      "\n",
      "***** Epoch #868 *****\n",
      "Loss: 1.493938\n",
      "Improvement ratio: 0.000433\n",
      "Feature L2-norm: 33.337141\n",
      "Learning rate (eta): 0.085208\n",
      "Total number of feature updates: 234360\n",
      "Seconds required for this iteration: 0.006\n",
      "\n",
      "***** Epoch #869 *****\n",
      "Loss: 1.493890\n",
      "Improvement ratio: 0.000411\n",
      "Feature L2-norm: 33.339025\n",
      "Learning rate (eta): 0.085193\n",
      "Total number of feature updates: 234630\n",
      "Seconds required for this iteration: 0.006\n",
      "\n",
      "***** Epoch #870 *****\n",
      "Loss: 1.493828\n",
      "Improvement ratio: 0.000409\n",
      "Feature L2-norm: 33.340906\n",
      "Learning rate (eta): 0.085179\n",
      "Total number of feature updates: 234900\n",
      "Seconds required for this iteration: 0.005\n",
      "\n",
      "***** Epoch #871 *****\n",
      "Loss: 1.493763\n",
      "Improvement ratio: 0.000424\n",
      "Feature L2-norm: 33.342782\n",
      "Learning rate (eta): 0.085164\n",
      "Total number of feature updates: 235170\n",
      "Seconds required for this iteration: 0.006\n",
      "\n",
      "***** Epoch #872 *****\n",
      "Loss: 1.493705\n",
      "Improvement ratio: 0.000416\n",
      "Feature L2-norm: 33.344652\n",
      "Learning rate (eta): 0.085150\n",
      "Total number of feature updates: 235440\n",
      "Seconds required for this iteration: 0.008\n",
      "\n",
      "***** Epoch #873 *****\n",
      "Loss: 1.493646\n",
      "Improvement ratio: 0.000421\n",
      "Feature L2-norm: 33.346518\n",
      "Learning rate (eta): 0.085135\n",
      "Total number of feature updates: 235710\n",
      "Seconds required for this iteration: 0.011\n",
      "\n",
      "***** Epoch #874 *****\n",
      "Loss: 1.493581\n",
      "Improvement ratio: 0.000419\n",
      "Feature L2-norm: 33.348380\n",
      "Learning rate (eta): 0.085121\n",
      "Total number of feature updates: 235980\n",
      "Seconds required for this iteration: 0.012\n",
      "\n",
      "***** Epoch #875 *****\n",
      "Loss: 1.493521\n",
      "Improvement ratio: 0.000410\n",
      "Feature L2-norm: 33.350238\n",
      "Learning rate (eta): 0.085106\n",
      "Total number of feature updates: 236250\n",
      "Seconds required for this iteration: 0.010\n",
      "\n",
      "***** Epoch #876 *****\n",
      "Loss: 1.493459\n",
      "Improvement ratio: 0.000403\n",
      "Feature L2-norm: 33.352094\n",
      "Learning rate (eta): 0.085092\n",
      "Total number of feature updates: 236520\n",
      "Seconds required for this iteration: 0.019\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** Epoch #877 *****\n",
      "Loss: 1.493381\n",
      "Improvement ratio: 0.000413\n",
      "Feature L2-norm: 33.353945\n",
      "Learning rate (eta): 0.085077\n",
      "Total number of feature updates: 236790\n",
      "Seconds required for this iteration: 0.018\n",
      "\n",
      "***** Epoch #878 *****\n",
      "Loss: 1.493347\n",
      "Improvement ratio: 0.000395\n",
      "Feature L2-norm: 33.355791\n",
      "Learning rate (eta): 0.085063\n",
      "Total number of feature updates: 237060\n",
      "Seconds required for this iteration: 0.011\n",
      "\n",
      "***** Epoch #879 *****\n",
      "Loss: 1.493288\n",
      "Improvement ratio: 0.000403\n",
      "Feature L2-norm: 33.357633\n",
      "Learning rate (eta): 0.085049\n",
      "Total number of feature updates: 237330\n",
      "Seconds required for this iteration: 0.012\n",
      "\n",
      "***** Epoch #880 *****\n",
      "Loss: 1.493227\n",
      "Improvement ratio: 0.000402\n",
      "Feature L2-norm: 33.359471\n",
      "Learning rate (eta): 0.085034\n",
      "Total number of feature updates: 237600\n",
      "Seconds required for this iteration: 0.011\n",
      "\n",
      "***** Epoch #881 *****\n",
      "Loss: 1.493175\n",
      "Improvement ratio: 0.000394\n",
      "Feature L2-norm: 33.361304\n",
      "Learning rate (eta): 0.085020\n",
      "Total number of feature updates: 237870\n",
      "Seconds required for this iteration: 0.011\n",
      "\n",
      "***** Epoch #882 *****\n",
      "Loss: 1.493100\n",
      "Improvement ratio: 0.000405\n",
      "Feature L2-norm: 33.363134\n",
      "Learning rate (eta): 0.085005\n",
      "Total number of feature updates: 238140\n",
      "Seconds required for this iteration: 0.027\n",
      "\n",
      "***** Epoch #883 *****\n",
      "Loss: 1.493036\n",
      "Improvement ratio: 0.000409\n",
      "Feature L2-norm: 33.364960\n",
      "Learning rate (eta): 0.084991\n",
      "Total number of feature updates: 238410\n",
      "Seconds required for this iteration: 0.014\n",
      "\n",
      "***** Epoch #884 *****\n",
      "Loss: 1.493001\n",
      "Improvement ratio: 0.000389\n",
      "Feature L2-norm: 33.366781\n",
      "Learning rate (eta): 0.084976\n",
      "Total number of feature updates: 238680\n",
      "Seconds required for this iteration: 0.011\n",
      "\n",
      "***** Epoch #885 *****\n",
      "Loss: 1.492937\n",
      "Improvement ratio: 0.000392\n",
      "Feature L2-norm: 33.368601\n",
      "Learning rate (eta): 0.084962\n",
      "Total number of feature updates: 238950\n",
      "Seconds required for this iteration: 0.013\n",
      "\n",
      "***** Epoch #886 *****\n",
      "Loss: 1.492883\n",
      "Improvement ratio: 0.000386\n",
      "Feature L2-norm: 33.370415\n",
      "Learning rate (eta): 0.084947\n",
      "Total number of feature updates: 239220\n",
      "Seconds required for this iteration: 0.022\n",
      "\n",
      "***** Epoch #887 *****\n",
      "Loss: 1.492803\n",
      "Improvement ratio: 0.000388\n",
      "Feature L2-norm: 33.372224\n",
      "Learning rate (eta): 0.084933\n",
      "Total number of feature updates: 239490\n",
      "Seconds required for this iteration: 0.007\n",
      "\n",
      "***** Epoch #888 *****\n",
      "Loss: 1.492760\n",
      "Improvement ratio: 0.000394\n",
      "Feature L2-norm: 33.374030\n",
      "Learning rate (eta): 0.084919\n",
      "Total number of feature updates: 239760\n",
      "Seconds required for this iteration: 0.007\n",
      "\n",
      "***** Epoch #889 *****\n",
      "Loss: 1.492712\n",
      "Improvement ratio: 0.000386\n",
      "Feature L2-norm: 33.375832\n",
      "Learning rate (eta): 0.084904\n",
      "Total number of feature updates: 240030\n",
      "Seconds required for this iteration: 0.006\n",
      "\n",
      "***** Epoch #890 *****\n",
      "Loss: 1.492655\n",
      "Improvement ratio: 0.000383\n",
      "Feature L2-norm: 33.377629\n",
      "Learning rate (eta): 0.084890\n",
      "Total number of feature updates: 240300\n",
      "Seconds required for this iteration: 0.011\n",
      "\n",
      "***** Epoch #891 *****\n",
      "Loss: 1.492581\n",
      "Improvement ratio: 0.000398\n",
      "Feature L2-norm: 33.379421\n",
      "Learning rate (eta): 0.084875\n",
      "Total number of feature updates: 240570\n",
      "Seconds required for this iteration: 0.011\n",
      "\n",
      "***** Epoch #892 *****\n",
      "Loss: 1.492518\n",
      "Improvement ratio: 0.000390\n",
      "Feature L2-norm: 33.381211\n",
      "Learning rate (eta): 0.084861\n",
      "Total number of feature updates: 240840\n",
      "Seconds required for this iteration: 0.013\n",
      "\n",
      "***** Epoch #893 *****\n",
      "Loss: 1.492478\n",
      "Improvement ratio: 0.000374\n",
      "Feature L2-norm: 33.382996\n",
      "Learning rate (eta): 0.084846\n",
      "Total number of feature updates: 241110\n",
      "Seconds required for this iteration: 0.011\n",
      "\n",
      "***** Epoch #894 *****\n",
      "Loss: 1.492420\n",
      "Improvement ratio: 0.000389\n",
      "Feature L2-norm: 33.384779\n",
      "Learning rate (eta): 0.084832\n",
      "Total number of feature updates: 241380\n",
      "Seconds required for this iteration: 0.010\n",
      "\n",
      "***** Epoch #895 *****\n",
      "Loss: 1.492362\n",
      "Improvement ratio: 0.000385\n",
      "Feature L2-norm: 33.386556\n",
      "Learning rate (eta): 0.084818\n",
      "Total number of feature updates: 241650\n",
      "Seconds required for this iteration: 0.010\n",
      "\n",
      "***** Epoch #896 *****\n",
      "Loss: 1.492321\n",
      "Improvement ratio: 0.000377\n",
      "Feature L2-norm: 33.388330\n",
      "Learning rate (eta): 0.084803\n",
      "Total number of feature updates: 241920\n",
      "Seconds required for this iteration: 0.011\n",
      "\n",
      "***** Epoch #897 *****\n",
      "Loss: 1.492246\n",
      "Improvement ratio: 0.000373\n",
      "Feature L2-norm: 33.390099\n",
      "Learning rate (eta): 0.084789\n",
      "Total number of feature updates: 242190\n",
      "Seconds required for this iteration: 0.010\n",
      "\n",
      "***** Epoch #898 *****\n",
      "Loss: 1.492201\n",
      "Improvement ratio: 0.000375\n",
      "Feature L2-norm: 33.391865\n",
      "Learning rate (eta): 0.084775\n",
      "Total number of feature updates: 242460\n",
      "Seconds required for this iteration: 0.018\n",
      "\n",
      "***** Epoch #899 *****\n",
      "Loss: 1.492128\n",
      "Improvement ratio: 0.000391\n",
      "Feature L2-norm: 33.393627\n",
      "Learning rate (eta): 0.084760\n",
      "Total number of feature updates: 242730\n",
      "Seconds required for this iteration: 0.013\n",
      "\n",
      "***** Epoch #900 *****\n",
      "Loss: 1.492075\n",
      "Improvement ratio: 0.000389\n",
      "Feature L2-norm: 33.395385\n",
      "Learning rate (eta): 0.084746\n",
      "Total number of feature updates: 243000\n",
      "Seconds required for this iteration: 0.022\n",
      "\n",
      "***** Epoch #901 *****\n",
      "Loss: 1.492036\n",
      "Improvement ratio: 0.000365\n",
      "Feature L2-norm: 33.397138\n",
      "Learning rate (eta): 0.084731\n",
      "Total number of feature updates: 243270\n",
      "Seconds required for this iteration: 0.012\n",
      "\n",
      "***** Epoch #902 *****\n",
      "Loss: 1.491973\n",
      "Improvement ratio: 0.000365\n",
      "Feature L2-norm: 33.398889\n",
      "Learning rate (eta): 0.084717\n",
      "Total number of feature updates: 243540\n",
      "Seconds required for this iteration: 0.015\n",
      "\n",
      "***** Epoch #903 *****\n",
      "Loss: 1.491906\n",
      "Improvement ratio: 0.000383\n",
      "Feature L2-norm: 33.400635\n",
      "Learning rate (eta): 0.084703\n",
      "Total number of feature updates: 243810\n",
      "Seconds required for this iteration: 0.022\n",
      "\n",
      "***** Epoch #904 *****\n",
      "Loss: 1.491853\n",
      "Improvement ratio: 0.000380\n",
      "Feature L2-norm: 33.402377\n",
      "Learning rate (eta): 0.084688\n",
      "Total number of feature updates: 244080\n",
      "Seconds required for this iteration: 0.011\n",
      "\n",
      "***** Epoch #905 *****\n",
      "Loss: 1.491804\n",
      "Improvement ratio: 0.000375\n",
      "Feature L2-norm: 33.404115\n",
      "Learning rate (eta): 0.084674\n",
      "Total number of feature updates: 244350\n",
      "Seconds required for this iteration: 0.017\n",
      "\n",
      "***** Epoch #906 *****\n",
      "Loss: 1.491760\n",
      "Improvement ratio: 0.000376\n",
      "Feature L2-norm: 33.405851\n",
      "Learning rate (eta): 0.084660\n",
      "Total number of feature updates: 244620\n",
      "Seconds required for this iteration: 0.020\n",
      "\n",
      "***** Epoch #907 *****\n",
      "Loss: 1.491708\n",
      "Improvement ratio: 0.000361\n",
      "Feature L2-norm: 33.407583\n",
      "Learning rate (eta): 0.084645\n",
      "Total number of feature updates: 244890\n",
      "Seconds required for this iteration: 0.022\n",
      "\n",
      "***** Epoch #908 *****\n",
      "Loss: 1.491639\n",
      "Improvement ratio: 0.000377\n",
      "Feature L2-norm: 33.409310\n",
      "Learning rate (eta): 0.084631\n",
      "Total number of feature updates: 245160\n",
      "Seconds required for this iteration: 0.021\n",
      "\n",
      "***** Epoch #909 *****\n",
      "Loss: 1.491602\n",
      "Improvement ratio: 0.000352\n",
      "Feature L2-norm: 33.411034\n",
      "Learning rate (eta): 0.084617\n",
      "Total number of feature updates: 245430\n",
      "Seconds required for this iteration: 0.012\n",
      "\n",
      "***** Epoch #910 *****\n",
      "Loss: 1.491532\n",
      "Improvement ratio: 0.000364\n",
      "Feature L2-norm: 33.412754\n",
      "Learning rate (eta): 0.084602\n",
      "Total number of feature updates: 245700\n",
      "Seconds required for this iteration: 0.026\n",
      "\n",
      "***** Epoch #911 *****\n",
      "Loss: 1.491492\n",
      "Improvement ratio: 0.000365\n",
      "Feature L2-norm: 33.414468\n",
      "Learning rate (eta): 0.084588\n",
      "Total number of feature updates: 245970\n",
      "Seconds required for this iteration: 0.023\n",
      "\n",
      "***** Epoch #912 *****\n",
      "Loss: 1.491421\n",
      "Improvement ratio: 0.000371\n",
      "Feature L2-norm: 33.416181\n",
      "Learning rate (eta): 0.084574\n",
      "Total number of feature updates: 246240\n",
      "Seconds required for this iteration: 0.021\n",
      "\n",
      "***** Epoch #913 *****\n",
      "Loss: 1.491381\n",
      "Improvement ratio: 0.000352\n",
      "Feature L2-norm: 33.417889\n",
      "Learning rate (eta): 0.084559\n",
      "Total number of feature updates: 246510\n",
      "Seconds required for this iteration: 0.018\n",
      "\n",
      "***** Epoch #914 *****\n",
      "Loss: 1.491327\n",
      "Improvement ratio: 0.000352\n",
      "Feature L2-norm: 33.419595\n",
      "Learning rate (eta): 0.084545\n",
      "Total number of feature updates: 246780\n",
      "Seconds required for this iteration: 0.016\n",
      "\n",
      "***** Epoch #915 *****\n",
      "Loss: 1.491267\n",
      "Improvement ratio: 0.000360\n",
      "Feature L2-norm: 33.421295\n",
      "Learning rate (eta): 0.084531\n",
      "Total number of feature updates: 247050\n",
      "Seconds required for this iteration: 0.020\n",
      "\n",
      "***** Epoch #916 *****\n",
      "Loss: 1.491224\n",
      "Improvement ratio: 0.000359\n",
      "Feature L2-norm: 33.422992\n",
      "Learning rate (eta): 0.084517\n",
      "Total number of feature updates: 247320\n",
      "Seconds required for this iteration: 0.013\n",
      "\n",
      "***** Epoch #917 *****\n",
      "Loss: 1.491163\n",
      "Improvement ratio: 0.000365\n",
      "Feature L2-norm: 33.424686\n",
      "Learning rate (eta): 0.084502\n",
      "Total number of feature updates: 247590\n",
      "Seconds required for this iteration: 0.006\n",
      "\n",
      "***** Epoch #918 *****\n",
      "Loss: 1.491127\n",
      "Improvement ratio: 0.000343\n",
      "Feature L2-norm: 33.426374\n",
      "Learning rate (eta): 0.084488\n",
      "Total number of feature updates: 247860\n",
      "Seconds required for this iteration: 0.010\n",
      "\n",
      "***** Epoch #919 *****\n",
      "Loss: 1.491045\n",
      "Improvement ratio: 0.000374\n",
      "Feature L2-norm: 33.428058\n",
      "Learning rate (eta): 0.084474\n",
      "Total number of feature updates: 248130\n",
      "Seconds required for this iteration: 0.010\n",
      "\n",
      "***** Epoch #920 *****\n",
      "Loss: 1.491004\n",
      "Improvement ratio: 0.000354\n",
      "Feature L2-norm: 33.429740\n",
      "Learning rate (eta): 0.084460\n",
      "Total number of feature updates: 248400\n",
      "Seconds required for this iteration: 0.023\n",
      "\n",
      "***** Epoch #921 *****\n",
      "Loss: 1.490953\n",
      "Improvement ratio: 0.000361\n",
      "Feature L2-norm: 33.431419\n",
      "Learning rate (eta): 0.084445\n",
      "Total number of feature updates: 248670\n",
      "Seconds required for this iteration: 0.015\n",
      "\n",
      "***** Epoch #922 *****\n",
      "Loss: 1.490907\n",
      "Improvement ratio: 0.000345\n",
      "Feature L2-norm: 33.433094\n",
      "Learning rate (eta): 0.084431\n",
      "Total number of feature updates: 248940\n",
      "Seconds required for this iteration: 0.015\n",
      "\n",
      "***** Epoch #923 *****\n",
      "Loss: 1.490856\n",
      "Improvement ratio: 0.000353\n",
      "Feature L2-norm: 33.434765\n",
      "Learning rate (eta): 0.084417\n",
      "Total number of feature updates: 249210\n",
      "Seconds required for this iteration: 0.010\n",
      "\n",
      "***** Epoch #924 *****\n",
      "Loss: 1.490798\n",
      "Improvement ratio: 0.000355\n",
      "Feature L2-norm: 33.436432\n",
      "Learning rate (eta): 0.084402\n",
      "Total number of feature updates: 249480\n",
      "Seconds required for this iteration: 0.009\n",
      "\n",
      "***** Epoch #925 *****\n",
      "Loss: 1.490761\n",
      "Improvement ratio: 0.000339\n",
      "Feature L2-norm: 33.438094\n",
      "Learning rate (eta): 0.084388\n",
      "Total number of feature updates: 249750\n",
      "Seconds required for this iteration: 0.017\n",
      "\n",
      "***** Epoch #926 *****\n",
      "Loss: 1.490703\n",
      "Improvement ratio: 0.000349\n",
      "Feature L2-norm: 33.439753\n",
      "Learning rate (eta): 0.084374\n",
      "Total number of feature updates: 250020\n",
      "Seconds required for this iteration: 0.020\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** Epoch #927 *****\n",
      "Loss: 1.490646\n",
      "Improvement ratio: 0.000347\n",
      "Feature L2-norm: 33.441408\n",
      "Learning rate (eta): 0.084360\n",
      "Total number of feature updates: 250290\n",
      "Seconds required for this iteration: 0.021\n",
      "\n",
      "***** Epoch #928 *****\n",
      "Loss: 1.490605\n",
      "Improvement ratio: 0.000350\n",
      "Feature L2-norm: 33.443062\n",
      "Learning rate (eta): 0.084346\n",
      "Total number of feature updates: 250560\n",
      "Seconds required for this iteration: 0.023\n",
      "\n",
      "***** Epoch #929 *****\n",
      "Loss: 1.490548\n",
      "Improvement ratio: 0.000334\n",
      "Feature L2-norm: 33.444710\n",
      "Learning rate (eta): 0.084331\n",
      "Total number of feature updates: 250830\n",
      "Seconds required for this iteration: 0.026\n",
      "\n",
      "***** Epoch #930 *****\n",
      "Loss: 1.490521\n",
      "Improvement ratio: 0.000324\n",
      "Feature L2-norm: 33.446357\n",
      "Learning rate (eta): 0.084317\n",
      "Total number of feature updates: 251100\n",
      "Seconds required for this iteration: 0.010\n",
      "\n",
      "***** Epoch #931 *****\n",
      "Loss: 1.490463\n",
      "Improvement ratio: 0.000329\n",
      "Feature L2-norm: 33.447999\n",
      "Learning rate (eta): 0.084303\n",
      "Total number of feature updates: 251370\n",
      "Seconds required for this iteration: 0.018\n",
      "\n",
      "***** Epoch #932 *****\n",
      "Loss: 1.490423\n",
      "Improvement ratio: 0.000325\n",
      "Feature L2-norm: 33.449638\n",
      "Learning rate (eta): 0.084289\n",
      "Total number of feature updates: 251640\n",
      "Seconds required for this iteration: 0.013\n",
      "\n",
      "***** Epoch #933 *****\n",
      "Loss: 1.490350\n",
      "Improvement ratio: 0.000339\n",
      "Feature L2-norm: 33.451274\n",
      "Learning rate (eta): 0.084274\n",
      "Total number of feature updates: 251910\n",
      "Seconds required for this iteration: 0.008\n",
      "\n",
      "***** Epoch #934 *****\n",
      "Loss: 1.490303\n",
      "Improvement ratio: 0.000332\n",
      "Feature L2-norm: 33.452904\n",
      "Learning rate (eta): 0.084260\n",
      "Total number of feature updates: 252180\n",
      "Seconds required for this iteration: 0.015\n",
      "\n",
      "***** Epoch #935 *****\n",
      "Loss: 1.490273\n",
      "Improvement ratio: 0.000328\n",
      "Feature L2-norm: 33.454532\n",
      "Learning rate (eta): 0.084246\n",
      "Total number of feature updates: 252450\n",
      "Seconds required for this iteration: 0.010\n",
      "\n",
      "***** Epoch #936 *****\n",
      "Loss: 1.490204\n",
      "Improvement ratio: 0.000335\n",
      "Feature L2-norm: 33.456155\n",
      "Learning rate (eta): 0.084232\n",
      "Total number of feature updates: 252720\n",
      "Seconds required for this iteration: 0.010\n",
      "\n",
      "***** Epoch #937 *****\n",
      "Loss: 1.490160\n",
      "Improvement ratio: 0.000326\n",
      "Feature L2-norm: 33.457776\n",
      "Learning rate (eta): 0.084218\n",
      "Total number of feature updates: 252990\n",
      "Seconds required for this iteration: 0.010\n",
      "\n",
      "***** Epoch #938 *****\n",
      "Loss: 1.490119\n",
      "Improvement ratio: 0.000326\n",
      "Feature L2-norm: 33.459394\n",
      "Learning rate (eta): 0.084203\n",
      "Total number of feature updates: 253260\n",
      "Seconds required for this iteration: 0.010\n",
      "\n",
      "***** Epoch #939 *****\n",
      "Loss: 1.490068\n",
      "Improvement ratio: 0.000322\n",
      "Feature L2-norm: 33.461007\n",
      "Learning rate (eta): 0.084189\n",
      "Total number of feature updates: 253530\n",
      "Seconds required for this iteration: 0.010\n",
      "\n",
      "***** Epoch #940 *****\n",
      "Loss: 1.490002\n",
      "Improvement ratio: 0.000349\n",
      "Feature L2-norm: 33.462619\n",
      "Learning rate (eta): 0.084175\n",
      "Total number of feature updates: 253800\n",
      "Seconds required for this iteration: 0.010\n",
      "\n",
      "***** Epoch #941 *****\n",
      "Loss: 1.489979\n",
      "Improvement ratio: 0.000325\n",
      "Feature L2-norm: 33.464226\n",
      "Learning rate (eta): 0.084161\n",
      "Total number of feature updates: 254070\n",
      "Seconds required for this iteration: 0.010\n",
      "\n",
      "***** Epoch #942 *****\n",
      "Loss: 1.489916\n",
      "Improvement ratio: 0.000341\n",
      "Feature L2-norm: 33.465829\n",
      "Learning rate (eta): 0.084147\n",
      "Total number of feature updates: 254340\n",
      "Seconds required for this iteration: 0.011\n",
      "\n",
      "***** Epoch #943 *****\n",
      "Loss: 1.489868\n",
      "Improvement ratio: 0.000323\n",
      "Feature L2-norm: 33.467428\n",
      "Learning rate (eta): 0.084133\n",
      "Total number of feature updates: 254610\n",
      "Seconds required for this iteration: 0.010\n",
      "\n",
      "***** Epoch #944 *****\n",
      "Loss: 1.489832\n",
      "Improvement ratio: 0.000316\n",
      "Feature L2-norm: 33.469024\n",
      "Learning rate (eta): 0.084118\n",
      "Total number of feature updates: 254880\n",
      "Seconds required for this iteration: 0.011\n",
      "\n",
      "***** Epoch #945 *****\n",
      "Loss: 1.489776\n",
      "Improvement ratio: 0.000333\n",
      "Feature L2-norm: 33.470617\n",
      "Learning rate (eta): 0.084104\n",
      "Total number of feature updates: 255150\n",
      "Seconds required for this iteration: 0.010\n",
      "\n",
      "***** Epoch #946 *****\n",
      "Loss: 1.489725\n",
      "Improvement ratio: 0.000321\n",
      "Feature L2-norm: 33.472208\n",
      "Learning rate (eta): 0.084090\n",
      "Total number of feature updates: 255420\n",
      "Seconds required for this iteration: 0.021\n",
      "\n",
      "***** Epoch #947 *****\n",
      "Loss: 1.489697\n",
      "Improvement ratio: 0.000310\n",
      "Feature L2-norm: 33.473793\n",
      "Learning rate (eta): 0.084076\n",
      "Total number of feature updates: 255690\n",
      "Seconds required for this iteration: 0.018\n",
      "\n",
      "***** Epoch #948 *****\n",
      "Loss: 1.489622\n",
      "Improvement ratio: 0.000334\n",
      "Feature L2-norm: 33.475375\n",
      "Learning rate (eta): 0.084062\n",
      "Total number of feature updates: 255960\n",
      "Seconds required for this iteration: 0.014\n",
      "\n",
      "***** Epoch #949 *****\n",
      "Loss: 1.489591\n",
      "Improvement ratio: 0.000320\n",
      "Feature L2-norm: 33.476956\n",
      "Learning rate (eta): 0.084048\n",
      "Total number of feature updates: 256230\n",
      "Seconds required for this iteration: 0.011\n",
      "\n",
      "***** Epoch #950 *****\n",
      "Loss: 1.489545\n",
      "Improvement ratio: 0.000306\n",
      "Feature L2-norm: 33.478530\n",
      "Learning rate (eta): 0.084034\n",
      "Total number of feature updates: 256500\n",
      "Seconds required for this iteration: 0.010\n",
      "\n",
      "***** Epoch #951 *****\n",
      "Loss: 1.489492\n",
      "Improvement ratio: 0.000327\n",
      "Feature L2-norm: 33.480101\n",
      "Learning rate (eta): 0.084020\n",
      "Total number of feature updates: 256770\n",
      "Seconds required for this iteration: 0.010\n",
      "\n",
      "***** Epoch #952 *****\n",
      "Loss: 1.489442\n",
      "Improvement ratio: 0.000318\n",
      "Feature L2-norm: 33.481669\n",
      "Learning rate (eta): 0.084005\n",
      "Total number of feature updates: 257040\n",
      "Seconds required for this iteration: 0.021\n",
      "\n",
      "***** Epoch #953 *****\n",
      "Loss: 1.489410\n",
      "Improvement ratio: 0.000308\n",
      "Feature L2-norm: 33.483235\n",
      "Learning rate (eta): 0.083991\n",
      "Total number of feature updates: 257310\n",
      "Seconds required for this iteration: 0.021\n",
      "\n",
      "***** Epoch #954 *****\n",
      "Loss: 1.489359\n",
      "Improvement ratio: 0.000318\n",
      "Feature L2-norm: 33.484797\n",
      "Learning rate (eta): 0.083977\n",
      "Total number of feature updates: 257580\n",
      "Seconds required for this iteration: 0.017\n",
      "\n",
      "***** Epoch #955 *****\n",
      "Loss: 1.489316\n",
      "Improvement ratio: 0.000309\n",
      "Feature L2-norm: 33.486356\n",
      "Learning rate (eta): 0.083963\n",
      "Total number of feature updates: 257850\n",
      "Seconds required for this iteration: 0.006\n",
      "\n",
      "***** Epoch #956 *****\n",
      "Loss: 1.489287\n",
      "Improvement ratio: 0.000294\n",
      "Feature L2-norm: 33.487913\n",
      "Learning rate (eta): 0.083949\n",
      "Total number of feature updates: 258120\n",
      "Seconds required for this iteration: 0.006\n",
      "\n",
      "***** Epoch #957 *****\n",
      "Loss: 1.489230\n",
      "Improvement ratio: 0.000314\n",
      "Feature L2-norm: 33.489467\n",
      "Learning rate (eta): 0.083935\n",
      "Total number of feature updates: 258390\n",
      "Seconds required for this iteration: 0.006\n",
      "\n",
      "***** Epoch #958 *****\n",
      "Loss: 1.489177\n",
      "Improvement ratio: 0.000299\n",
      "Feature L2-norm: 33.491014\n",
      "Learning rate (eta): 0.083921\n",
      "Total number of feature updates: 258660\n",
      "Seconds required for this iteration: 0.009\n",
      "\n",
      "***** Epoch #959 *****\n",
      "Loss: 1.489128\n",
      "Improvement ratio: 0.000311\n",
      "Feature L2-norm: 33.492561\n",
      "Learning rate (eta): 0.083907\n",
      "Total number of feature updates: 258930\n",
      "Seconds required for this iteration: 0.010\n",
      "\n",
      "***** Epoch #960 *****\n",
      "Loss: 1.489083\n",
      "Improvement ratio: 0.000311\n",
      "Feature L2-norm: 33.494103\n",
      "Learning rate (eta): 0.083893\n",
      "Total number of feature updates: 259200\n",
      "Seconds required for this iteration: 0.009\n",
      "\n",
      "***** Epoch #961 *****\n",
      "Loss: 1.489048\n",
      "Improvement ratio: 0.000298\n",
      "Feature L2-norm: 33.495641\n",
      "Learning rate (eta): 0.083879\n",
      "Total number of feature updates: 259470\n",
      "Seconds required for this iteration: 0.014\n",
      "\n",
      "***** Epoch #962 *****\n",
      "Loss: 1.488981\n",
      "Improvement ratio: 0.000310\n",
      "Feature L2-norm: 33.497176\n",
      "Learning rate (eta): 0.083865\n",
      "Total number of feature updates: 259740\n",
      "Seconds required for this iteration: 0.019\n",
      "\n",
      "***** Epoch #963 *****\n",
      "Loss: 1.488949\n",
      "Improvement ratio: 0.000310\n",
      "Feature L2-norm: 33.498708\n",
      "Learning rate (eta): 0.083850\n",
      "Total number of feature updates: 260010\n",
      "Seconds required for this iteration: 0.014\n",
      "\n",
      "***** Epoch #964 *****\n",
      "Loss: 1.488914\n",
      "Improvement ratio: 0.000299\n",
      "Feature L2-norm: 33.500236\n",
      "Learning rate (eta): 0.083836\n",
      "Total number of feature updates: 260280\n",
      "Seconds required for this iteration: 0.010\n",
      "\n",
      "***** Epoch #965 *****\n",
      "Loss: 1.488873\n",
      "Improvement ratio: 0.000298\n",
      "Feature L2-norm: 33.501763\n",
      "Learning rate (eta): 0.083822\n",
      "Total number of feature updates: 260550\n",
      "Seconds required for this iteration: 0.011\n",
      "\n",
      "***** Epoch #966 *****\n",
      "Loss: 1.488818\n",
      "Improvement ratio: 0.000315\n",
      "Feature L2-norm: 33.503286\n",
      "Learning rate (eta): 0.083808\n",
      "Total number of feature updates: 260820\n",
      "Seconds required for this iteration: 0.020\n",
      "\n",
      "***** Epoch #967 *****\n",
      "Loss: 1.488775\n",
      "Improvement ratio: 0.000305\n",
      "Feature L2-norm: 33.504804\n",
      "Learning rate (eta): 0.083794\n",
      "Total number of feature updates: 261090\n",
      "Seconds required for this iteration: 0.027\n",
      "\n",
      "***** Epoch #968 *****\n",
      "Loss: 1.488731\n",
      "Improvement ratio: 0.000299\n",
      "Feature L2-norm: 33.506320\n",
      "Learning rate (eta): 0.083780\n",
      "Total number of feature updates: 261360\n",
      "Seconds required for this iteration: 0.012\n",
      "\n",
      "***** Epoch #969 *****\n",
      "Loss: 1.488705\n",
      "Improvement ratio: 0.000284\n",
      "Feature L2-norm: 33.507832\n",
      "Learning rate (eta): 0.083766\n",
      "Total number of feature updates: 261630\n",
      "Seconds required for this iteration: 0.019\n",
      "\n",
      "***** Epoch #970 *****\n",
      "Loss: 1.488632\n",
      "Improvement ratio: 0.000303\n",
      "Feature L2-norm: 33.509343\n",
      "Learning rate (eta): 0.083752\n",
      "Total number of feature updates: 261900\n",
      "Seconds required for this iteration: 0.023\n",
      "\n",
      "***** Epoch #971 *****\n",
      "Loss: 1.488601\n",
      "Improvement ratio: 0.000300\n",
      "Feature L2-norm: 33.510849\n",
      "Learning rate (eta): 0.083738\n",
      "Total number of feature updates: 262170\n",
      "Seconds required for this iteration: 0.020\n",
      "\n",
      "***** Epoch #972 *****\n",
      "Loss: 1.488556\n",
      "Improvement ratio: 0.000286\n",
      "Feature L2-norm: 33.512352\n",
      "Learning rate (eta): 0.083724\n",
      "Total number of feature updates: 262440\n",
      "Seconds required for this iteration: 0.013\n",
      "\n",
      "***** Epoch #973 *****\n",
      "Loss: 1.488517\n",
      "Improvement ratio: 0.000290\n",
      "Feature L2-norm: 33.513852\n",
      "Learning rate (eta): 0.083710\n",
      "Total number of feature updates: 262710\n",
      "Seconds required for this iteration: 0.022\n",
      "\n",
      "***** Epoch #974 *****\n",
      "Loss: 1.488469\n",
      "Improvement ratio: 0.000299\n",
      "Feature L2-norm: 33.515348\n",
      "Learning rate (eta): 0.083696\n",
      "Total number of feature updates: 262980\n",
      "Seconds required for this iteration: 0.019\n",
      "\n",
      "***** Epoch #975 *****\n",
      "Loss: 1.488431\n",
      "Improvement ratio: 0.000297\n",
      "Feature L2-norm: 33.516841\n",
      "Learning rate (eta): 0.083682\n",
      "Total number of feature updates: 263250\n",
      "Seconds required for this iteration: 0.024\n",
      "\n",
      "***** Epoch #976 *****\n",
      "Loss: 1.488376\n",
      "Improvement ratio: 0.000297\n",
      "Feature L2-norm: 33.518332\n",
      "Learning rate (eta): 0.083668\n",
      "Total number of feature updates: 263520\n",
      "Seconds required for this iteration: 0.025\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** Epoch #977 *****\n",
      "Loss: 1.488322\n",
      "Improvement ratio: 0.000304\n",
      "Feature L2-norm: 33.519817\n",
      "Learning rate (eta): 0.083654\n",
      "Total number of feature updates: 263790\n",
      "Seconds required for this iteration: 0.017\n",
      "\n",
      "***** Epoch #978 *****\n",
      "Loss: 1.488292\n",
      "Improvement ratio: 0.000295\n",
      "Feature L2-norm: 33.521302\n",
      "Learning rate (eta): 0.083640\n",
      "Total number of feature updates: 264060\n",
      "Seconds required for this iteration: 0.012\n",
      "\n",
      "***** Epoch #979 *****\n",
      "Loss: 1.488246\n",
      "Improvement ratio: 0.000309\n",
      "Feature L2-norm: 33.522782\n",
      "Learning rate (eta): 0.083626\n",
      "Total number of feature updates: 264330\n",
      "Seconds required for this iteration: 0.010\n",
      "\n",
      "***** Epoch #980 *****\n",
      "Loss: 1.488211\n",
      "Improvement ratio: 0.000283\n",
      "Feature L2-norm: 33.524261\n",
      "Learning rate (eta): 0.083612\n",
      "Total number of feature updates: 264600\n",
      "Seconds required for this iteration: 0.010\n",
      "\n",
      "***** Epoch #981 *****\n",
      "Loss: 1.488169\n",
      "Improvement ratio: 0.000290\n",
      "Feature L2-norm: 33.525736\n",
      "Learning rate (eta): 0.083598\n",
      "Total number of feature updates: 264870\n",
      "Seconds required for this iteration: 0.009\n",
      "\n",
      "***** Epoch #982 *****\n",
      "Loss: 1.488146\n",
      "Improvement ratio: 0.000275\n",
      "Feature L2-norm: 33.527207\n",
      "Learning rate (eta): 0.083584\n",
      "Total number of feature updates: 265140\n",
      "Seconds required for this iteration: 0.010\n",
      "\n",
      "***** Epoch #983 *****\n",
      "Loss: 1.488073\n",
      "Improvement ratio: 0.000298\n",
      "Feature L2-norm: 33.528674\n",
      "Learning rate (eta): 0.083570\n",
      "Total number of feature updates: 265410\n",
      "Seconds required for this iteration: 0.006\n",
      "\n",
      "***** Epoch #984 *****\n",
      "Loss: 1.488040\n",
      "Improvement ratio: 0.000288\n",
      "Feature L2-norm: 33.530138\n",
      "Learning rate (eta): 0.083556\n",
      "Total number of feature updates: 265680\n",
      "Seconds required for this iteration: 0.006\n",
      "\n",
      "***** Epoch #985 *****\n",
      "Loss: 1.488007\n",
      "Improvement ratio: 0.000285\n",
      "Feature L2-norm: 33.531599\n",
      "Learning rate (eta): 0.083542\n",
      "Total number of feature updates: 265950\n",
      "Seconds required for this iteration: 0.011\n",
      "\n",
      "***** Epoch #986 *****\n",
      "Loss: 1.487949\n",
      "Improvement ratio: 0.000287\n",
      "Feature L2-norm: 33.533058\n",
      "Learning rate (eta): 0.083528\n",
      "Total number of feature updates: 266220\n",
      "Seconds required for this iteration: 0.016\n",
      "\n",
      "***** Epoch #987 *****\n",
      "Loss: 1.487927\n",
      "Improvement ratio: 0.000266\n",
      "Feature L2-norm: 33.534514\n",
      "Learning rate (eta): 0.083514\n",
      "Total number of feature updates: 266490\n",
      "Seconds required for this iteration: 0.013\n",
      "\n",
      "***** Epoch #988 *****\n",
      "Loss: 1.487865\n",
      "Improvement ratio: 0.000287\n",
      "Feature L2-norm: 33.535967\n",
      "Learning rate (eta): 0.083500\n",
      "Total number of feature updates: 266760\n",
      "Seconds required for this iteration: 0.020\n",
      "\n",
      "***** Epoch #989 *****\n",
      "Loss: 1.487835\n",
      "Improvement ratio: 0.000276\n",
      "Feature L2-norm: 33.537415\n",
      "Learning rate (eta): 0.083486\n",
      "Total number of feature updates: 267030\n",
      "Seconds required for this iteration: 0.010\n",
      "\n",
      "***** Epoch #990 *****\n",
      "Loss: 1.487798\n",
      "Improvement ratio: 0.000278\n",
      "Feature L2-norm: 33.538862\n",
      "Learning rate (eta): 0.083473\n",
      "Total number of feature updates: 267300\n",
      "Seconds required for this iteration: 0.010\n",
      "\n",
      "***** Epoch #991 *****\n",
      "Loss: 1.487754\n",
      "Improvement ratio: 0.000279\n",
      "Feature L2-norm: 33.540306\n",
      "Learning rate (eta): 0.083459\n",
      "Total number of feature updates: 267570\n",
      "Seconds required for this iteration: 0.010\n",
      "\n",
      "***** Epoch #992 *****\n",
      "Loss: 1.487721\n",
      "Improvement ratio: 0.000286\n",
      "Feature L2-norm: 33.541748\n",
      "Learning rate (eta): 0.083445\n",
      "Total number of feature updates: 267840\n",
      "Seconds required for this iteration: 0.020\n",
      "\n",
      "***** Epoch #993 *****\n",
      "Loss: 1.487667\n",
      "Improvement ratio: 0.000273\n",
      "Feature L2-norm: 33.543186\n",
      "Learning rate (eta): 0.083431\n",
      "Total number of feature updates: 268110\n",
      "Seconds required for this iteration: 0.007\n",
      "\n",
      "***** Epoch #994 *****\n",
      "Loss: 1.487648\n",
      "Improvement ratio: 0.000264\n",
      "Feature L2-norm: 33.544620\n",
      "Learning rate (eta): 0.083417\n",
      "Total number of feature updates: 268380\n",
      "Seconds required for this iteration: 0.009\n",
      "\n",
      "***** Epoch #995 *****\n",
      "Loss: 1.487590\n",
      "Improvement ratio: 0.000280\n",
      "Feature L2-norm: 33.546049\n",
      "Learning rate (eta): 0.083403\n",
      "Total number of feature updates: 268650\n",
      "Seconds required for this iteration: 0.010\n",
      "\n",
      "***** Epoch #996 *****\n",
      "Loss: 1.487550\n",
      "Improvement ratio: 0.000268\n",
      "Feature L2-norm: 33.547478\n",
      "Learning rate (eta): 0.083389\n",
      "Total number of feature updates: 268920\n",
      "Seconds required for this iteration: 0.023\n",
      "\n",
      "***** Epoch #997 *****\n",
      "Loss: 1.487508\n",
      "Improvement ratio: 0.000282\n",
      "Feature L2-norm: 33.548903\n",
      "Learning rate (eta): 0.083375\n",
      "Total number of feature updates: 269190\n",
      "Seconds required for this iteration: 0.020\n",
      "\n",
      "***** Epoch #998 *****\n",
      "Loss: 1.487484\n",
      "Improvement ratio: 0.000256\n",
      "Feature L2-norm: 33.550325\n",
      "Learning rate (eta): 0.083361\n",
      "Total number of feature updates: 269460\n",
      "Seconds required for this iteration: 0.010\n",
      "\n",
      "***** Epoch #999 *****\n",
      "Loss: 1.487443\n",
      "Improvement ratio: 0.000264\n",
      "Feature L2-norm: 33.551746\n",
      "Learning rate (eta): 0.083347\n",
      "Total number of feature updates: 269730\n",
      "Seconds required for this iteration: 0.023\n",
      "\n",
      "***** Epoch #1000 *****\n",
      "Loss: 1.487403\n",
      "Improvement ratio: 0.000266\n",
      "Feature L2-norm: 33.553162\n",
      "Learning rate (eta): 0.083333\n",
      "Total number of feature updates: 270000\n",
      "Seconds required for this iteration: 0.010\n",
      "\n",
      "SGD terminated with the maximum number of iterations\n",
      "Loss: 1.487403\n",
      "Total seconds required for training: 16.444\n",
      "\n",
      "Storing the model\n",
      "Number of active features: 24798 (24798)\n",
      "Number of active attributes: 22470 (22470)\n",
      "Number of active labels: 7 (7)\n",
      "Writing labels\n",
      "Writing attributes\n",
      "Writing feature references for transitions\n",
      "Writing feature references for attributes\n",
      "Seconds required: 0.057\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# NBVAL_IGNORE_OUTPUT\n",
    "trainer.train(text, model_dir='ner_model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to use the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from estnltk.taggers import WordLevelNerTagger"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To predict on the newly trained model, a NerTagger or WordLevelNerTagger object is needed. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For tagging, one option is to use WordLevelNerTagger, which gives a NER-tag for all words in the text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "nertagger = WordLevelNerTagger(model_dir = 'ner_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from estnltk import Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td><div align = \"left\">Tallinna õhusaaste suureneb.</div></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>layer name</th>\n",
       "      <th>attributes</th>\n",
       "      <th>parent</th>\n",
       "      <th>enveloping</th>\n",
       "      <th>ambiguous</th>\n",
       "      <th>span count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>sentences</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>words</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>tokens</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>compound_tokens</td>\n",
       "      <td>type, normalized</td>\n",
       "      <td>None</td>\n",
       "      <td>tokens</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>words</td>\n",
       "      <td>normalized_form</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>morph_analysis</td>\n",
       "      <td>normalized_text, lemma, root, root_tokens, ending, clitic, form, partofspeech</td>\n",
       "      <td>words</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "Text(text='Tallinna õhusaaste suureneb.')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Text it has seen before (first sentence from the trainset)\n",
    "testtext = Text(\"Tallinna õhusaaste suureneb.\")\n",
    "testtext.tag_layer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td><div align = \"left\">Tallinna õhusaaste suureneb.</div></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>layer name</th>\n",
       "      <th>attributes</th>\n",
       "      <th>parent</th>\n",
       "      <th>enveloping</th>\n",
       "      <th>ambiguous</th>\n",
       "      <th>span count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>sentences</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>words</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>tokens</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>compound_tokens</td>\n",
       "      <td>type, normalized</td>\n",
       "      <td>None</td>\n",
       "      <td>tokens</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>words</td>\n",
       "      <td>normalized_form</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>morph_analysis</td>\n",
       "      <td>normalized_text, lemma, root, root_tokens, ending, clitic, form, partofspeech</td>\n",
       "      <td>words</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>wordner</td>\n",
       "      <td>nertag</td>\n",
       "      <td>words</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "Text(text='Tallinna õhusaaste suureneb.')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nertagger.tag(testtext)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h4>Layer</h4>\n",
       "\n",
       "\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>layer name</th>\n",
       "      <th>attributes</th>\n",
       "      <th>parent</th>\n",
       "      <th>enveloping</th>\n",
       "      <th>ambiguous</th>\n",
       "      <th>span count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>wordner</td>\n",
       "      <td>nertag</td>\n",
       "      <td>words</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>text</th>\n",
       "      <th>nertag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>Tallinna</td>\n",
       "      <td>B-LOC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>õhusaaste</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>suureneb</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>.</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "Layer(name='wordner', attributes=('nertag',), spans=SL[Span('Tallinna', [{'nertag': 'B-LOC'}]),\n",
       "Span('õhusaaste', [{'nertag': 'O'}]),\n",
       "Span('suureneb', [{'nertag': 'O'}]),\n",
       "Span('.', [{'nertag': 'O'}])])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testtext.wordner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td><div align = \"left\">Eesti on Euroopas.</div></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>layer name</th>\n",
       "      <th>attributes</th>\n",
       "      <th>parent</th>\n",
       "      <th>enveloping</th>\n",
       "      <th>ambiguous</th>\n",
       "      <th>span count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>sentences</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>words</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>tokens</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>compound_tokens</td>\n",
       "      <td>type, normalized</td>\n",
       "      <td>None</td>\n",
       "      <td>tokens</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>words</td>\n",
       "      <td>normalized_form</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>morph_analysis</td>\n",
       "      <td>normalized_text, lemma, root, root_tokens, ending, clitic, form, partofspeech</td>\n",
       "      <td>words</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "Text(text='Eesti on Euroopas.')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Text it hasn't seen before (new sentence)\n",
    "testtext2 = Text(\"Eesti on Euroopas.\")\n",
    "testtext2.tag_layer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td><div align = \"left\">Eesti on Euroopas.</div></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>layer name</th>\n",
       "      <th>attributes</th>\n",
       "      <th>parent</th>\n",
       "      <th>enveloping</th>\n",
       "      <th>ambiguous</th>\n",
       "      <th>span count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>sentences</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>words</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>tokens</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>compound_tokens</td>\n",
       "      <td>type, normalized</td>\n",
       "      <td>None</td>\n",
       "      <td>tokens</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>words</td>\n",
       "      <td>normalized_form</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>morph_analysis</td>\n",
       "      <td>normalized_text, lemma, root, root_tokens, ending, clitic, form, partofspeech</td>\n",
       "      <td>words</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>wordner</td>\n",
       "      <td>nertag</td>\n",
       "      <td>words</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "Text(text='Eesti on Euroopas.')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nertagger.tag(testtext2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h4>Layer</h4>\n",
       "\n",
       "\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>layer name</th>\n",
       "      <th>attributes</th>\n",
       "      <th>parent</th>\n",
       "      <th>enveloping</th>\n",
       "      <th>ambiguous</th>\n",
       "      <th>span count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>wordner</td>\n",
       "      <td>nertag</td>\n",
       "      <td>words</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>text</th>\n",
       "      <th>nertag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>Eesti</td>\n",
       "      <td>B-LOC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>on</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Euroopas</td>\n",
       "      <td>B-LOC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>.</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "Layer(name='wordner', attributes=('nertag',), spans=SL[Span('Eesti', [{'nertag': 'B-LOC'}]),\n",
       "Span('on', [{'nertag': 'O'}]),\n",
       "Span('Euroopas', [{'nertag': 'B-LOC'}]),\n",
       "Span('.', [{'nertag': 'O'}])])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testtext2.wordner"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another option is to use NerTagger, which will give NER-tags only to the named entities it finds in the given text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from estnltk.taggers import NerTagger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "tagger = NerTagger(model_dir='ner_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td><div align = \"left\">Tallinna õhusaaste suureneb.</div></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>layer name</th>\n",
       "      <th>attributes</th>\n",
       "      <th>parent</th>\n",
       "      <th>enveloping</th>\n",
       "      <th>ambiguous</th>\n",
       "      <th>span count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>sentences</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>words</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>tokens</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>compound_tokens</td>\n",
       "      <td>type, normalized</td>\n",
       "      <td>None</td>\n",
       "      <td>tokens</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>words</td>\n",
       "      <td>normalized_form</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>morph_analysis</td>\n",
       "      <td>normalized_text, lemma, root, root_tokens, ending, clitic, form, partofspeech</td>\n",
       "      <td>words</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>wordner</td>\n",
       "      <td>nertag</td>\n",
       "      <td>words</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>ner</td>\n",
       "      <td>nertag</td>\n",
       "      <td>None</td>\n",
       "      <td>words</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "Text(text='Tallinna õhusaaste suureneb.')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tagger.tag(testtext)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h4>Layer</h4>\n",
       "\n",
       "\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>layer name</th>\n",
       "      <th>attributes</th>\n",
       "      <th>parent</th>\n",
       "      <th>enveloping</th>\n",
       "      <th>ambiguous</th>\n",
       "      <th>span count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>ner</td>\n",
       "      <td>nertag</td>\n",
       "      <td>None</td>\n",
       "      <td>words</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>text</th>\n",
       "      <th>nertag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>['Tallinna']</td>\n",
       "      <td>LOC</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "Layer(name='ner', attributes=('nertag',), spans=SL[EnvelopingSpan(['Tallinna'], [{'nertag': 'LOC'}])])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testtext.ner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td><div align = \"left\">Eesti on Euroopas.</div></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>layer name</th>\n",
       "      <th>attributes</th>\n",
       "      <th>parent</th>\n",
       "      <th>enveloping</th>\n",
       "      <th>ambiguous</th>\n",
       "      <th>span count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>sentences</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>words</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>tokens</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>compound_tokens</td>\n",
       "      <td>type, normalized</td>\n",
       "      <td>None</td>\n",
       "      <td>tokens</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>words</td>\n",
       "      <td>normalized_form</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>morph_analysis</td>\n",
       "      <td>normalized_text, lemma, root, root_tokens, ending, clitic, form, partofspeech</td>\n",
       "      <td>words</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>wordner</td>\n",
       "      <td>nertag</td>\n",
       "      <td>words</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>ner</td>\n",
       "      <td>nertag</td>\n",
       "      <td>None</td>\n",
       "      <td>words</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "Text(text='Eesti on Euroopas.')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tagger.tag(testtext2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h4>Layer</h4>\n",
       "\n",
       "\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>layer name</th>\n",
       "      <th>attributes</th>\n",
       "      <th>parent</th>\n",
       "      <th>enveloping</th>\n",
       "      <th>ambiguous</th>\n",
       "      <th>span count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>ner</td>\n",
       "      <td>nertag</td>\n",
       "      <td>None</td>\n",
       "      <td>words</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>text</th>\n",
       "      <th>nertag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>['Eesti']</td>\n",
       "      <td>LOC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>['Euroopas']</td>\n",
       "      <td>LOC</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "Layer(name='ner', attributes=('nertag',), spans=SL[EnvelopingSpan(['Eesti'], [{'nertag': 'LOC'}]),\n",
       "EnvelopingSpan(['Euroopas'], [{'nertag': 'LOC'}])])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testtext2.ner"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluating on a text with existing labelling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td><div align = \"left\">Riigi kutsekoolidest sai kõige viletsama tulemuse Põltsamaa Kodu - ja Põllumajanduskool , kus kvaliteedistandarditele ei vastanud 33 protsenti kutseõpetajatest ja 27 protsenti üldharidusainete õpetajatest . Kooli direktori asetäitja Tambet Valdma sõnul peetakse nende koolis õpetajatena lugu ka väga headest oma ala spetsialistidest ja praktikutest , kel ei pruugi vastava ainevaldkonna paberit taskus olla . Vajadust kaasata praktikuid kinnitas ka tööandjate keskliidu tööturunõunik Thor-Sten Vertmann . Tema sõnul on kutsekoolides erialasid , mis jääksid kõigilt õpetajatelt erialast kõrgharidust nõudes täielikult ajast maha . Haridusministeeriumi kutse - ja täiskasvanuhariduse osakonna juhataja Andres Pung märkis , et kutsekooliõpetajate hindamise kriteeriume senisest leebemaks muutmine tooks koolidesse rohkem oma ala praktikuid . Kehtiva korra järgi võib praktik küll koolis töötada , kui ta on vähemalt kolm aastat töötanud oma erialal ja jätkab põhitööd ka kooli kõrvalt . Põhikohaga tööd tegevad õpetajad , kel pole pedagoogilist haridus , peavad läbima 320 tunni pikkuse õpetajakoolituse . “ Tundub , et see osa on küll natuke ülepingutatud ning neid mahtusid saaks kindlasti vähendada , ” sõnas Pung . 15-aastase Leedu poisi tapjad on tabatud . Leedu linnas Visaginases võttis politsei kinni kaks noormeest , keda kahtlustatakse 15-aastase koolipoisi tapmises . Kaheksanda klassi õpilase Aleksei Selivanovi läbilõigatud kõri ning rohkete torke - ja lõikehaavadega laip leiti kolmapäeva õhtul . Poiss oli tapetud oma kodu lähedal . Politsei pidas neljapäeval mõrvas kahtlustatutena kinni kaks 17-aastast Visaginase elanikku . Üks neist oli nähtavasti mõrva tellija , teine aga täideviija . Kinnipeetud on oma süü üles tunnistanud . Visaginase politsei otsib taga veel kaht mõrvas osalenut . Esialgsetel andmetel tapeti 15-aastane poiss ühe tüdruku pärast . Pärast kuriteo avastamist on Visaginase linna haaranud paanika . Vanemad kardavad oma lapsi kooli saata . Leedu noores linnas Visaginases , mis ehitati 20 aastat tagasi koos Ignalina aatomielektrijaamaga , oli see esimene alaealise mõrv . Kümned kalamehed jäid taas Peipsil hätta . Peipsil jäid pühapäeval taas hätta kümned kalamehed , kes kaldale saamiseks abi vajasid . Järvejäässe tekkis läänetuulega Peipsi Eesti poolele kümne kuni 200 meetri laiune lõhe , mis jääb 400 meetri kuni kahe kilomeetri kaugusele kaldast . Piirivalveameti pressiesindaja ütles BNS-ile , et ennelõunal tõi piirivalve hõljuk Kauksi alt ära neli kalurit , kuid 12.30 paiku tuli teade suuremast hulgast hädalistest . Pala vallas Ranna asula juures olid teisele poole jääpragu jäänud hinnanguliselt 50-60 kalameest . Kella 16 oli piirivalve ja kohalikud elanikud oma paatidega neist paarkümmend maale toimetanud . Pressiesindaja sõnul ohtlikku olukorda kalameeste jaoks tekkinud ei ole ja päästetööd sujuvad plaanipäraselt . “ Täiesti võimatu oleks kustutada põlevaid kütusemahuteid ning tuleks oodata kuni kütuse täieliku väljapõlemiseni mahutitest . Bensiini ja muude vedelkütuste mahutite plahvatuste juhul ei oleks võimalik päästa terminalide töötajaid ega ka terminalis olevate laevade meeskonnaliikmeid , rääkimata juba kahjustavast mõjust ümbritsevale keskkonnale , Eesti majandusele ja rahvusvahelisele mainele , ” hoiatab turvafirma juhatuse esimees Aleksander Kaspin riigikantseleile saadetud kirjas .</div></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>layer name</th>\n",
       "      <th>attributes</th>\n",
       "      <th>parent</th>\n",
       "      <th>enveloping</th>\n",
       "      <th>ambiguous</th>\n",
       "      <th>span count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>sentences</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>words</td>\n",
       "      <td>False</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>compound_tokens</td>\n",
       "      <td>type, normalized</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>words</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>morph_analysis</td>\n",
       "      <td>normalized_text, lemma, root, root_tokens, ending, clitic, form, partofspeech</td>\n",
       "      <td>words</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>wordner</td>\n",
       "      <td>nertag</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>471</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "Text(text='Riigi kutsekoolidest sai kõige viletsama tulemuse Põltsamaa Kodu - ja Põllumajanduskool , kus kvaliteedistandarditele ei vastanud 33 protsenti kutseõpetajatest ja 27 protsenti üldharidusainete õpetajatest . Kooli direktori asetäitja Tambet Valdma sõnul peetakse nende koolis õpetajatena lugu ka väga headest oma ala spetsialistidest ja praktikutest , kel ei pruugi vastava ainevaldkonna paberit taskus olla . Vajadust kaasata praktikuid kinnitas ka tööandjate keskliidu tööturunõunik Thor-Sten Vertmann . Tema sõnul on kutsekoolides erialasid , mis jääksid kõigilt õpetajatelt erialast kõrgharidust nõudes täielikult ajast maha . Haridusministeeriumi kutse - ja täiskasvanuhariduse osakonna juhataja Andres Pung märkis , et kutsekooliõpetajate hindamise kriteeriume senisest leebemaks muutmine tooks koolidesse rohkem oma ala praktikuid . Kehtiva korra järgi võib praktik küll koolis töötada , kui ta on vähemalt kolm aastat töötanud oma erialal ja jätkab põhitööd ka kooli kõrvalt . Põhikohaga tööd tegevad õpetajad , kel pole pedagoogilist haridus , peavad läbima 320 tunni pikkuse õpetajakoolituse . “ Tundub , et see osa on küll natuke ülepingutatud ning neid mahtusid saaks kindlasti vähendada , ” sõnas Pung . 15-aastase Leedu poisi tapjad on tabatud . Leedu linnas Visaginases võttis politsei kinni kaks noormeest , keda kahtlustatakse 15-aastase koolipoisi tapmises . Kaheksanda klassi õpilase Aleksei Selivanovi läbilõigatud kõri ning rohkete torke - ja lõikehaavadega laip leiti kolmapäeva õhtul . Poiss oli tapetud oma kodu lähedal . Politsei pidas neljapäeval mõrvas kahtlustatutena kinni kaks 17-aastast Visaginase elanikku . Üks neist oli nähtavasti mõrva tellija , teine aga täideviija . Kinnipeetud on oma süü üles tunnistanud . Visaginase politsei otsib taga veel kaht mõrvas osalenut . Esialgsetel andmetel tapeti 15-aastane poiss ühe tüdruku pärast . Pärast kuriteo avastamist on Visaginase linna haaranud paanika . Vanemad kardavad oma lapsi kooli saata . Leedu noores linnas Visaginases , mis ehitati 20 aastat tagasi koos Ignalina aatomielektrijaamaga , oli see esimene alaealise mõrv . Kümned kalamehed jäid taas Peipsil hätta . Peipsil jäid pühapäeval taas hätta kümned kalamehed , kes kaldale saamiseks abi vajasid . Järvejäässe tekkis läänetuulega Peipsi Eesti poolele kümne kuni 200 meetri laiune lõhe , mis jääb 400 meetri kuni kahe kilomeetri kaugusele kaldast . Piirivalveameti pressiesindaja ütles BNS-ile , et ennelõunal tõi piirivalve hõljuk Kauksi alt ära neli kalurit , kuid 12.30 paiku tuli teade suuremast hulgast hädalistest . Pala vallas Ranna asula juures olid teisele poole jääpragu jäänud hinnanguliselt 50-60 kalameest . Kella 16 oli piirivalve ja kohalikud elanikud oma paatidega neist paarkümmend maale toimetanud . Pressiesindaja sõnul ohtlikku olukorda kalameeste jaoks tekkinud ei ole ja päästetööd sujuvad plaanipäraselt . “ Täiesti võimatu oleks kustutada põlevaid kütusemahuteid ning tuleks oodata kuni kütuse täieliku väljapõlemiseni mahutitest . Bensiini ja muude vedelkütuste mahutite plahvatuste juhul ei oleks võimalik päästa terminalide töötajaid ega ka terminalis olevate laevade meeskonnaliikmeid , rääkimata juba kahjustavast mõjust ümbritsevale keskkonnale , Eesti majandusele ja rahvusvahelisele mainele , ” hoiatab turvafirma juhatuse esimees Aleksander Kaspin riigikantseleile saadetud kirjas .')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = conll_to_ner_labelling(\"data/estner_test.cnll\")\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "nerlayer = test.wordner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h4>Layer</h4>\n",
       "\n",
       "\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>layer name</th>\n",
       "      <th>attributes</th>\n",
       "      <th>parent</th>\n",
       "      <th>enveloping</th>\n",
       "      <th>ambiguous</th>\n",
       "      <th>span count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>wordner</td>\n",
       "      <td>nertag</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>471</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>text</th>\n",
       "      <th>nertag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>Riigi</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>kutsekoolidest</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>sai</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>kõige</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>viletsama</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>tulemuse</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Põltsamaa</td>\n",
       "      <td>B-ORG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Kodu</td>\n",
       "      <td>I-ORG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>-</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>ja</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Põllumajanduskool</td>\n",
       "      <td>B-ORG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>,</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>kus</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>kvaliteedistandarditele</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>ei</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>vastanud</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>protsenti</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>kutseõpetajatest</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>ja</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>protsenti</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>üldharidusainete</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>õpetajatest</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>.</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Kooli</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>direktori</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>asetäitja</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Tambet</td>\n",
       "      <td>B-PER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Valdma</td>\n",
       "      <td>I-PER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>sõnul</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>peetakse</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>nende</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>koolis</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>õpetajatena</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>lugu</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>ka</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>väga</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>headest</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>oma</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>ala</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>spetsialistidest</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>ja</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>praktikutest</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>,</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>kel</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>ei</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>pruugi</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>vastava</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>ainevaldkonna</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>paberit</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>taskus</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>olla</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>.</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Vajadust</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>kaasata</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>praktikuid</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>kinnitas</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>ka</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>tööandjate</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>keskliidu</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>tööturunõunik</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Thor-Sten</td>\n",
       "      <td>B-PER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Vertmann</td>\n",
       "      <td>I-PER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>.</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Tema</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>sõnul</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>on</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>kutsekoolides</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>erialasid</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>,</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>mis</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>jääksid</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>kõigilt</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>õpetajatelt</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>erialast</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>kõrgharidust</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>nõudes</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>täielikult</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>ajast</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>maha</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>.</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Haridusministeeriumi</td>\n",
       "      <td>B-ORG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>kutse</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>-</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>ja</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>täiskasvanuhariduse</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>osakonna</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>juhataja</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Andres</td>\n",
       "      <td>B-PER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Pung</td>\n",
       "      <td>I-PER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>märkis</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>,</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>et</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>kutsekooliõpetajate</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>hindamise</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>kriteeriume</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>senisest</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>leebemaks</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>muutmine</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>tooks</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>koolidesse</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>rohkem</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>oma</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>ala</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>praktikuid</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>.</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Kehtiva</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>korra</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>järgi</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>võib</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>praktik</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>küll</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>koolis</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>töötada</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>,</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>kui</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>ta</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>on</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>vähemalt</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>kolm</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>aastat</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>töötanud</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>oma</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>erialal</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>ja</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>jätkab</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>põhitööd</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>ka</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>kooli</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>kõrvalt</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>.</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Põhikohaga</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>tööd</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>tegevad</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>õpetajad</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>,</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>kel</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>pole</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>pedagoogilist</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>haridus</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>,</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>peavad</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>läbima</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>tunni</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>pikkuse</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>õpetajakoolituse</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>.</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>“</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Tundub</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>,</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>et</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>see</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>osa</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>on</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>küll</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>natuke</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>ülepingutatud</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>ning</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>neid</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>mahtusid</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>saaks</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>kindlasti</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>vähendada</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>,</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>”</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>sõnas</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Pung</td>\n",
       "      <td>B-PER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>.</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15-aastase</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Leedu</td>\n",
       "      <td>B-LOC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>poisi</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>tapjad</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>on</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>tabatud</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>.</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Leedu</td>\n",
       "      <td>B-LOC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>linnas</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Visaginases</td>\n",
       "      <td>B-LOC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>võttis</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>politsei</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>kinni</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>kaks</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>noormeest</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>,</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>keda</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>kahtlustatakse</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15-aastase</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>koolipoisi</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>tapmises</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>.</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Kaheksanda</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>klassi</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>õpilase</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Aleksei</td>\n",
       "      <td>B-PER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Selivanovi</td>\n",
       "      <td>I-PER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>läbilõigatud</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>kõri</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>ning</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>rohkete</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>torke</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>-</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>ja</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>lõikehaavadega</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>laip</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>leiti</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>kolmapäeva</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>õhtul</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>.</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Poiss</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>oli</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>tapetud</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>oma</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>kodu</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>lähedal</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>.</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Politsei</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>pidas</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>neljapäeval</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>mõrvas</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>kahtlustatutena</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>kinni</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>kaks</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17-aastast</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Visaginase</td>\n",
       "      <td>B-LOC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>elanikku</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>.</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Üks</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>neist</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>oli</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>nähtavasti</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>mõrva</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>tellija</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>,</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>teine</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>aga</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>täideviija</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>.</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Kinnipeetud</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>on</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>oma</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>süü</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>üles</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>tunnistanud</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>.</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Visaginase</td>\n",
       "      <td>B-ORG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>politsei</td>\n",
       "      <td>I-ORG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>otsib</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>taga</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>veel</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>kaht</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>mõrvas</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>osalenut</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>.</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Esialgsetel</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>andmetel</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>tapeti</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15-aastane</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>poiss</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>ühe</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>tüdruku</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>pärast</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>.</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Pärast</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>kuriteo</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>avastamist</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>on</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Visaginase</td>\n",
       "      <td>B-LOC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>linna</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>haaranud</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>paanika</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>.</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Vanemad</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>kardavad</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>oma</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>lapsi</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>kooli</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>saata</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>.</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Leedu</td>\n",
       "      <td>B-LOC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>noores</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>linnas</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Visaginases</td>\n",
       "      <td>B-LOC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>,</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>mis</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>ehitati</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>aastat</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>tagasi</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>koos</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Ignalina</td>\n",
       "      <td>B-LOC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>aatomielektrijaamaga</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>,</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>oli</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>see</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>esimene</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>alaealise</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>mõrv</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>.</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Kümned</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>kalamehed</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>jäid</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>taas</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Peipsil</td>\n",
       "      <td>B-LOC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>hätta</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>.</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Peipsil</td>\n",
       "      <td>B-LOC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>jäid</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>pühapäeval</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>taas</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>hätta</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>kümned</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>kalamehed</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>,</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>kes</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>kaldale</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>saamiseks</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>abi</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>vajasid</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>.</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Järvejäässe</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>tekkis</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>läänetuulega</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Peipsi</td>\n",
       "      <td>B-LOC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Eesti</td>\n",
       "      <td>I-LOC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>poolele</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>kümne</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>kuni</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>meetri</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>laiune</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>lõhe</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>,</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>mis</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>jääb</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>meetri</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>kuni</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>kahe</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>kilomeetri</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>kaugusele</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>kaldast</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>.</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Piirivalveameti</td>\n",
       "      <td>B-ORG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>pressiesindaja</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>ütles</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>BNS-ile</td>\n",
       "      <td>B-ORG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>,</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>et</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>ennelõunal</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>tõi</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>piirivalve</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>hõljuk</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Kauksi</td>\n",
       "      <td>B-LOC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>alt</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>ära</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>neli</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>kalurit</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>,</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>kuid</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12.30</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>paiku</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>tuli</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>teade</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>suuremast</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>hulgast</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>hädalistest</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>.</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Pala</td>\n",
       "      <td>B-LOC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>vallas</td>\n",
       "      <td>I-LOC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Ranna</td>\n",
       "      <td>B-LOC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>asula</td>\n",
       "      <td>I-LOC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>juures</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>olid</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>teisele</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>poole</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>jääpragu</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>jäänud</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>hinnanguliselt</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50-60</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>kalameest</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>.</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Kella</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>oli</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>piirivalve</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>ja</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>kohalikud</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>elanikud</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>oma</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>paatidega</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>neist</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>paarkümmend</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>maale</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>toimetanud</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>.</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Pressiesindaja</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>sõnul</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>ohtlikku</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>olukorda</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>kalameeste</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>jaoks</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>tekkinud</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>ei</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>ole</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>ja</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>päästetööd</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>sujuvad</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>plaanipäraselt</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>.</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>“</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Täiesti</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>võimatu</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>oleks</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>kustutada</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>põlevaid</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>kütusemahuteid</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>ning</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>tuleks</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>oodata</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>kuni</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>kütuse</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>täieliku</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>väljapõlemiseni</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>mahutitest</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>.</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Bensiini</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>ja</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>muude</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>vedelkütuste</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>mahutite</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>plahvatuste</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>juhul</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>ei</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>oleks</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>võimalik</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>päästa</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>terminalide</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>töötajaid</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>ega</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>ka</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>terminalis</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>olevate</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>laevade</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>meeskonnaliikmeid</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>,</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>rääkimata</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>juba</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>kahjustavast</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>mõjust</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>ümbritsevale</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>keskkonnale</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>,</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Eesti</td>\n",
       "      <td>B-LOC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>majandusele</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>ja</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>rahvusvahelisele</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>mainele</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>,</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>”</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>hoiatab</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>turvafirma</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>juhatuse</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>esimees</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Aleksander</td>\n",
       "      <td>B-PER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Kaspin</td>\n",
       "      <td>I-PER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>riigikantseleile</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>saadetud</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>kirjas</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>.</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "Layer(name='wordner', attributes=('nertag',), spans=SL[Span('Riigi', [{'nertag': 'O'}]),\n",
       "Span('kutsekoolidest', [{'nertag': 'O'}]),\n",
       "Span('sai', [{'nertag': 'O'}]),\n",
       "Span('kõige', [{'nertag': 'O'}]),\n",
       "Span('viletsama', [{'nertag': 'O'}]),\n",
       "Span('tulemuse', [{'nertag': 'O'}]),\n",
       "Span('Põltsamaa', [{'nertag': 'B-ORG'}]),\n",
       "Span('Kodu', [{'nertag': 'I-ORG'}]),\n",
       "Span('-', [{'nertag': 'O'}]),\n",
       "Span('ja', [{'nertag': 'O'}]),\n",
       "Span('Põllumajanduskool', [{'nertag': 'B-ORG'}]),\n",
       "Span(',', [{'nertag': 'O'}]),\n",
       "Span('kus', [{'nertag': 'O'}]),\n",
       "Span('kvaliteedistandarditele', [{'nertag': 'O'}]),\n",
       "Span('ei', [{'nertag': 'O'}]),\n",
       "Span('vastanud', [{'nertag': 'O'}]),\n",
       "Span('33', [{'nertag': 'O'}]),\n",
       "Span('protsenti', [{'nertag': 'O'}]),\n",
       "Span('kutseõpetajatest', [{'nertag': 'O'}]),\n",
       "Span('ja', [{'nertag': 'O'}]),\n",
       "Span('27', [{'nertag': 'O'}]),\n",
       "Span('protsenti', [{'nertag': 'O'}]),\n",
       "Span('üldharidusainete', [{'nertag': 'O'}]),\n",
       "Span('õpetajatest', [{'nertag': 'O'}]),\n",
       "Span('.', [{'nertag': 'O'}]),\n",
       "Span('Kooli', [{'nertag': 'O'}]),\n",
       "Span('direktori', [{'nertag': 'O'}]),\n",
       "Span('asetäitja', [{'nertag': 'O'}]),\n",
       "Span('Tambet', [{'nertag': 'B-PER'}]),\n",
       "Span('Valdma', [{'nertag': 'I-PER'}]),\n",
       "Span('sõnul', [{'nertag': 'O'}]),\n",
       "Span('peetakse', [{'nertag': 'O'}]),\n",
       "Span('nende', [{'nertag': 'O'}]),\n",
       "Span('koolis', [{'nertag': 'O'}]),\n",
       "Span('õpetajatena', [{'nertag': 'O'}]),\n",
       "Span('lugu', [{'nertag': 'O'}]),\n",
       "Span('ka', [{'nertag': 'O'}]),\n",
       "Span('väga', [{'nertag': 'O'}]),\n",
       "Span('headest', [{'nertag': 'O'}]),\n",
       "Span('oma', [{'nertag': 'O'}]),\n",
       "Span('ala', [{'nertag': 'O'}]),\n",
       "Span('spetsialistidest', [{'nertag': 'O'}]),\n",
       "Span('ja', [{'nertag': 'O'}]),\n",
       "Span('praktikutest', [{'nertag': 'O'}]),\n",
       "Span(',', [{'nertag': 'O'}]),\n",
       "Span('kel', [{'nertag': 'O'}]),\n",
       "Span('ei', [{'nertag': 'O'}]),\n",
       "Span('pruugi', [{'nertag': 'O'}]),\n",
       "Span('vastava', [{'nertag': 'O'}]),\n",
       "Span('ainevaldkonna', [{'nertag': 'O'}]),\n",
       "Span('paberit', [{'nertag': 'O'}]),\n",
       "Span('taskus', [{'nertag': 'O'}]),\n",
       "Span('olla', [{'nertag': 'O'}]),\n",
       "Span('.', [{'nertag': 'O'}]),\n",
       "Span('Vajadust', [{'nertag': 'O'}]),\n",
       "Span('kaasata', [{'nertag': 'O'}]),\n",
       "Span('praktikuid', [{'nertag': 'O'}]),\n",
       "Span('kinnitas', [{'nertag': 'O'}]),\n",
       "Span('ka', [{'nertag': 'O'}]),\n",
       "Span('tööandjate', [{'nertag': 'O'}]),\n",
       "Span('keskliidu', [{'nertag': 'O'}]),\n",
       "Span('tööturunõunik', [{'nertag': 'O'}]),\n",
       "Span('Thor-Sten', [{'nertag': 'B-PER'}]),\n",
       "Span('Vertmann', [{'nertag': 'I-PER'}]),\n",
       "Span('.', [{'nertag': 'O'}]),\n",
       "Span('Tema', [{'nertag': 'O'}]),\n",
       "Span('sõnul', [{'nertag': 'O'}]),\n",
       "Span('on', [{'nertag': 'O'}]),\n",
       "Span('kutsekoolides', [{'nertag': 'O'}]),\n",
       "Span('erialasid', [{'nertag': 'O'}]),\n",
       "Span(',', [{'nertag': 'O'}]),\n",
       "Span('mis', [{'nertag': 'O'}]),\n",
       "Span('jääksid', [{'nertag': 'O'}]),\n",
       "Span('kõigilt', [{'nertag': 'O'}]),\n",
       "Span('õpetajatelt', [{'nertag': 'O'}]),\n",
       "Span('erialast', [{'nertag': 'O'}]),\n",
       "Span('kõrgharidust', [{'nertag': 'O'}]),\n",
       "Span('nõudes', [{'nertag': 'O'}]),\n",
       "Span('täielikult', [{'nertag': 'O'}]),\n",
       "Span('ajast', [{'nertag': 'O'}]),\n",
       "Span('maha', [{'nertag': 'O'}]),\n",
       "Span('.', [{'nertag': 'O'}]),\n",
       "Span('Haridusministeeriumi', [{'nertag': 'B-ORG'}]),\n",
       "Span('kutse', [{'nertag': 'O'}]),\n",
       "Span('-', [{'nertag': 'O'}]),\n",
       "Span('ja', [{'nertag': 'O'}]),\n",
       "Span('täiskasvanuhariduse', [{'nertag': 'O'}]),\n",
       "Span('osakonna', [{'nertag': 'O'}]),\n",
       "Span('juhataja', [{'nertag': 'O'}]),\n",
       "Span('Andres', [{'nertag': 'B-PER'}]),\n",
       "Span('Pung', [{'nertag': 'I-PER'}]),\n",
       "Span('märkis', [{'nertag': 'O'}]),\n",
       "Span(',', [{'nertag': 'O'}]),\n",
       "Span('et', [{'nertag': 'O'}]),\n",
       "Span('kutsekooliõpetajate', [{'nertag': 'O'}]),\n",
       "Span('hindamise', [{'nertag': 'O'}]),\n",
       "Span('kriteeriume', [{'nertag': 'O'}]),\n",
       "Span('senisest', [{'nertag': 'O'}]),\n",
       "Span('leebemaks', [{'nertag': 'O'}]),\n",
       "Span('muutmine', [{'nertag': 'O'}]),\n",
       "Span('tooks', [{'nertag': 'O'}]),\n",
       "Span('koolidesse', [{'nertag': 'O'}]),\n",
       "Span('rohkem', [{'nertag': 'O'}]),\n",
       "Span('oma', [{'nertag': 'O'}]),\n",
       "Span('ala', [{'nertag': 'O'}]),\n",
       "Span('praktikuid', [{'nertag': 'O'}]),\n",
       "Span('.', [{'nertag': 'O'}]),\n",
       "Span('Kehtiva', [{'nertag': 'O'}]),\n",
       "Span('korra', [{'nertag': 'O'}]),\n",
       "Span('järgi', [{'nertag': 'O'}]),\n",
       "Span('võib', [{'nertag': 'O'}]),\n",
       "Span('praktik', [{'nertag': 'O'}]),\n",
       "Span('küll', [{'nertag': 'O'}]),\n",
       "Span('koolis', [{'nertag': 'O'}]),\n",
       "Span('töötada', [{'nertag': 'O'}]),\n",
       "Span(',', [{'nertag': 'O'}]),\n",
       "Span('kui', [{'nertag': 'O'}]),\n",
       "Span('ta', [{'nertag': 'O'}]),\n",
       "Span('on', [{'nertag': 'O'}]),\n",
       "Span('vähemalt', [{'nertag': 'O'}]),\n",
       "Span('kolm', [{'nertag': 'O'}]),\n",
       "Span('aastat', [{'nertag': 'O'}]),\n",
       "Span('töötanud', [{'nertag': 'O'}]),\n",
       "Span('oma', [{'nertag': 'O'}]),\n",
       "Span('erialal', [{'nertag': 'O'}]),\n",
       "Span('ja', [{'nertag': 'O'}]),\n",
       "Span('jätkab', [{'nertag': 'O'}]),\n",
       "Span('põhitööd', [{'nertag': 'O'}]),\n",
       "Span('ka', [{'nertag': 'O'}]),\n",
       "Span('kooli', [{'nertag': 'O'}]),\n",
       "Span('kõrvalt', [{'nertag': 'O'}]),\n",
       "Span('.', [{'nertag': 'O'}]),\n",
       "Span('Põhikohaga', [{'nertag': 'O'}]),\n",
       "Span('tööd', [{'nertag': 'O'}]),\n",
       "Span('tegevad', [{'nertag': 'O'}]),\n",
       "Span('õpetajad', [{'nertag': 'O'}]),\n",
       "Span(',', [{'nertag': 'O'}]),\n",
       "Span('kel', [{'nertag': 'O'}]),\n",
       "Span('pole', [{'nertag': 'O'}]),\n",
       "Span('pedagoogilist', [{'nertag': 'O'}]),\n",
       "Span('haridus', [{'nertag': 'O'}]),\n",
       "Span(',', [{'nertag': 'O'}]),\n",
       "Span('peavad', [{'nertag': 'O'}]),\n",
       "Span('läbima', [{'nertag': 'O'}]),\n",
       "Span('320', [{'nertag': 'O'}]),\n",
       "Span('tunni', [{'nertag': 'O'}]),\n",
       "Span('pikkuse', [{'nertag': 'O'}]),\n",
       "Span('õpetajakoolituse', [{'nertag': 'O'}]),\n",
       "Span('.', [{'nertag': 'O'}]),\n",
       "Span('“', [{'nertag': 'O'}]),\n",
       "Span('Tundub', [{'nertag': 'O'}]),\n",
       "Span(',', [{'nertag': 'O'}]),\n",
       "Span('et', [{'nertag': 'O'}]),\n",
       "Span('see', [{'nertag': 'O'}]),\n",
       "Span('osa', [{'nertag': 'O'}]),\n",
       "Span('on', [{'nertag': 'O'}]),\n",
       "Span('küll', [{'nertag': 'O'}]),\n",
       "Span('natuke', [{'nertag': 'O'}]),\n",
       "Span('ülepingutatud', [{'nertag': 'O'}]),\n",
       "Span('ning', [{'nertag': 'O'}]),\n",
       "Span('neid', [{'nertag': 'O'}]),\n",
       "Span('mahtusid', [{'nertag': 'O'}]),\n",
       "Span('saaks', [{'nertag': 'O'}]),\n",
       "Span('kindlasti', [{'nertag': 'O'}]),\n",
       "Span('vähendada', [{'nertag': 'O'}]),\n",
       "Span(',', [{'nertag': 'O'}]),\n",
       "Span('”', [{'nertag': 'O'}]),\n",
       "Span('sõnas', [{'nertag': 'O'}]),\n",
       "Span('Pung', [{'nertag': 'B-PER'}]),\n",
       "Span('.', [{'nertag': 'O'}]),\n",
       "Span('15-aastase', [{'nertag': 'O'}]),\n",
       "Span('Leedu', [{'nertag': 'B-LOC'}]),\n",
       "Span('poisi', [{'nertag': 'O'}]),\n",
       "Span('tapjad', [{'nertag': 'O'}]),\n",
       "Span('on', [{'nertag': 'O'}]),\n",
       "Span('tabatud', [{'nertag': 'O'}]),\n",
       "Span('.', [{'nertag': 'O'}]),\n",
       "Span('Leedu', [{'nertag': 'B-LOC'}]),\n",
       "Span('linnas', [{'nertag': 'O'}]),\n",
       "Span('Visaginases', [{'nertag': 'B-LOC'}]),\n",
       "Span('võttis', [{'nertag': 'O'}]),\n",
       "Span('politsei', [{'nertag': 'O'}]),\n",
       "Span('kinni', [{'nertag': 'O'}]),\n",
       "Span('kaks', [{'nertag': 'O'}]),\n",
       "Span('noormeest', [{'nertag': 'O'}]),\n",
       "Span(',', [{'nertag': 'O'}]),\n",
       "Span('keda', [{'nertag': 'O'}]),\n",
       "Span('kahtlustatakse', [{'nertag': 'O'}]),\n",
       "Span('15-aastase', [{'nertag': 'O'}]),\n",
       "Span('koolipoisi', [{'nertag': 'O'}]),\n",
       "Span('tapmises', [{'nertag': 'O'}]),\n",
       "Span('.', [{'nertag': 'O'}]),\n",
       "Span('Kaheksanda', [{'nertag': 'O'}]),\n",
       "Span('klassi', [{'nertag': 'O'}]),\n",
       "Span('õpilase', [{'nertag': 'O'}]),\n",
       "Span('Aleksei', [{'nertag': 'B-PER'}]),\n",
       "Span('Selivanovi', [{'nertag': 'I-PER'}]),\n",
       "Span('läbilõigatud', [{'nertag': 'O'}]),\n",
       "Span('kõri', [{'nertag': 'O'}]),\n",
       "Span('ning', [{'nertag': 'O'}]),\n",
       "Span('rohkete', [{'nertag': 'O'}]),\n",
       "Span('torke', [{'nertag': 'O'}]),\n",
       "Span('-', [{'nertag': 'O'}]),\n",
       "Span('ja', [{'nertag': 'O'}]),\n",
       "Span('lõikehaavadega', [{'nertag': 'O'}]),\n",
       "Span('laip', [{'nertag': 'O'}]),\n",
       "Span('leiti', [{'nertag': 'O'}]),\n",
       "Span('kolmapäeva', [{'nertag': 'O'}]),\n",
       "Span('õhtul', [{'nertag': 'O'}]),\n",
       "Span('.', [{'nertag': 'O'}]),\n",
       "Span('Poiss', [{'nertag': 'O'}]),\n",
       "Span('oli', [{'nertag': 'O'}]),\n",
       "Span('tapetud', [{'nertag': 'O'}]),\n",
       "Span('oma', [{'nertag': 'O'}]),\n",
       "Span('kodu', [{'nertag': 'O'}]),\n",
       "Span('lähedal', [{'nertag': 'O'}]),\n",
       "Span('.', [{'nertag': 'O'}]),\n",
       "Span('Politsei', [{'nertag': 'O'}]),\n",
       "Span('pidas', [{'nertag': 'O'}]),\n",
       "Span('neljapäeval', [{'nertag': 'O'}]),\n",
       "Span('mõrvas', [{'nertag': 'O'}]),\n",
       "Span('kahtlustatutena', [{'nertag': 'O'}]),\n",
       "Span('kinni', [{'nertag': 'O'}]),\n",
       "Span('kaks', [{'nertag': 'O'}]),\n",
       "Span('17-aastast', [{'nertag': 'O'}]),\n",
       "Span('Visaginase', [{'nertag': 'B-LOC'}]),\n",
       "Span('elanikku', [{'nertag': 'O'}]),\n",
       "Span('.', [{'nertag': 'O'}]),\n",
       "Span('Üks', [{'nertag': 'O'}]),\n",
       "Span('neist', [{'nertag': 'O'}]),\n",
       "Span('oli', [{'nertag': 'O'}]),\n",
       "Span('nähtavasti', [{'nertag': 'O'}]),\n",
       "Span('mõrva', [{'nertag': 'O'}]),\n",
       "Span('tellija', [{'nertag': 'O'}]),\n",
       "Span(',', [{'nertag': 'O'}]),\n",
       "Span('teine', [{'nertag': 'O'}]),\n",
       "Span('aga', [{'nertag': 'O'}]),\n",
       "Span('täideviija', [{'nertag': 'O'}]),\n",
       "Span('.', [{'nertag': 'O'}]),\n",
       "Span('Kinnipeetud', [{'nertag': 'O'}]),\n",
       "Span('on', [{'nertag': 'O'}]),\n",
       "Span('oma', [{'nertag': 'O'}]),\n",
       "Span('süü', [{'nertag': 'O'}]),\n",
       "Span('üles', [{'nertag': 'O'}]),\n",
       "Span('tunnistanud', [{'nertag': 'O'}]),\n",
       "Span('.', [{'nertag': 'O'}]),\n",
       "Span('Visaginase', [{'nertag': 'B-ORG'}]),\n",
       "Span('politsei', [{'nertag': 'I-ORG'}]),\n",
       "Span('otsib', [{'nertag': 'O'}]),\n",
       "Span('taga', [{'nertag': 'O'}]),\n",
       "Span('veel', [{'nertag': 'O'}]),\n",
       "Span('kaht', [{'nertag': 'O'}]),\n",
       "Span('mõrvas', [{'nertag': 'O'}]),\n",
       "Span('osalenut', [{'nertag': 'O'}]),\n",
       "Span('.', [{'nertag': 'O'}]),\n",
       "Span('Esialgsetel', [{'nertag': 'O'}]),\n",
       "Span('andmetel', [{'nertag': 'O'}]),\n",
       "Span('tapeti', [{'nertag': 'O'}]),\n",
       "Span('15-aastane', [{'nertag': 'O'}]),\n",
       "Span('poiss', [{'nertag': 'O'}]),\n",
       "Span('ühe', [{'nertag': 'O'}]),\n",
       "Span('tüdruku', [{'nertag': 'O'}]),\n",
       "Span('pärast', [{'nertag': 'O'}]),\n",
       "Span('.', [{'nertag': 'O'}]),\n",
       "Span('Pärast', [{'nertag': 'O'}]),\n",
       "Span('kuriteo', [{'nertag': 'O'}]),\n",
       "Span('avastamist', [{'nertag': 'O'}]),\n",
       "Span('on', [{'nertag': 'O'}]),\n",
       "Span('Visaginase', [{'nertag': 'B-LOC'}]),\n",
       "Span('linna', [{'nertag': 'O'}]),\n",
       "Span('haaranud', [{'nertag': 'O'}]),\n",
       "Span('paanika', [{'nertag': 'O'}]),\n",
       "Span('.', [{'nertag': 'O'}]),\n",
       "Span('Vanemad', [{'nertag': 'O'}]),\n",
       "Span('kardavad', [{'nertag': 'O'}]),\n",
       "Span('oma', [{'nertag': 'O'}]),\n",
       "Span('lapsi', [{'nertag': 'O'}]),\n",
       "Span('kooli', [{'nertag': 'O'}]),\n",
       "Span('saata', [{'nertag': 'O'}]),\n",
       "Span('.', [{'nertag': 'O'}]),\n",
       "Span('Leedu', [{'nertag': 'B-LOC'}]),\n",
       "Span('noores', [{'nertag': 'O'}]),\n",
       "Span('linnas', [{'nertag': 'O'}]),\n",
       "Span('Visaginases', [{'nertag': 'B-LOC'}]),\n",
       "Span(',', [{'nertag': 'O'}]),\n",
       "Span('mis', [{'nertag': 'O'}]),\n",
       "Span('ehitati', [{'nertag': 'O'}]),\n",
       "Span('20', [{'nertag': 'O'}]),\n",
       "Span('aastat', [{'nertag': 'O'}]),\n",
       "Span('tagasi', [{'nertag': 'O'}]),\n",
       "Span('koos', [{'nertag': 'O'}]),\n",
       "Span('Ignalina', [{'nertag': 'B-LOC'}]),\n",
       "Span('aatomielektrijaamaga', [{'nertag': 'O'}]),\n",
       "Span(',', [{'nertag': 'O'}]),\n",
       "Span('oli', [{'nertag': 'O'}]),\n",
       "Span('see', [{'nertag': 'O'}]),\n",
       "Span('esimene', [{'nertag': 'O'}]),\n",
       "Span('alaealise', [{'nertag': 'O'}]),\n",
       "Span('mõrv', [{'nertag': 'O'}]),\n",
       "Span('.', [{'nertag': 'O'}]),\n",
       "Span('Kümned', [{'nertag': 'O'}]),\n",
       "Span('kalamehed', [{'nertag': 'O'}]),\n",
       "Span('jäid', [{'nertag': 'O'}]),\n",
       "Span('taas', [{'nertag': 'O'}]),\n",
       "Span('Peipsil', [{'nertag': 'B-LOC'}]),\n",
       "Span('hätta', [{'nertag': 'O'}]),\n",
       "Span('.', [{'nertag': 'O'}]),\n",
       "Span('Peipsil', [{'nertag': 'B-LOC'}]),\n",
       "Span('jäid', [{'nertag': 'O'}]),\n",
       "Span('pühapäeval', [{'nertag': 'O'}]),\n",
       "Span('taas', [{'nertag': 'O'}]),\n",
       "Span('hätta', [{'nertag': 'O'}]),\n",
       "Span('kümned', [{'nertag': 'O'}]),\n",
       "Span('kalamehed', [{'nertag': 'O'}]),\n",
       "Span(',', [{'nertag': 'O'}]),\n",
       "Span('kes', [{'nertag': 'O'}]),\n",
       "Span('kaldale', [{'nertag': 'O'}]),\n",
       "Span('saamiseks', [{'nertag': 'O'}]),\n",
       "Span('abi', [{'nertag': 'O'}]),\n",
       "Span('vajasid', [{'nertag': 'O'}]),\n",
       "Span('.', [{'nertag': 'O'}]),\n",
       "Span('Järvejäässe', [{'nertag': 'O'}]),\n",
       "Span('tekkis', [{'nertag': 'O'}]),\n",
       "Span('läänetuulega', [{'nertag': 'O'}]),\n",
       "Span('Peipsi', [{'nertag': 'B-LOC'}]),\n",
       "Span('Eesti', [{'nertag': 'I-LOC'}]),\n",
       "Span('poolele', [{'nertag': 'O'}]),\n",
       "Span('kümne', [{'nertag': 'O'}]),\n",
       "Span('kuni', [{'nertag': 'O'}]),\n",
       "Span('200', [{'nertag': 'O'}]),\n",
       "Span('meetri', [{'nertag': 'O'}]),\n",
       "Span('laiune', [{'nertag': 'O'}]),\n",
       "Span('lõhe', [{'nertag': 'O'}]),\n",
       "Span(',', [{'nertag': 'O'}]),\n",
       "Span('mis', [{'nertag': 'O'}]),\n",
       "Span('jääb', [{'nertag': 'O'}]),\n",
       "Span('400', [{'nertag': 'O'}]),\n",
       "Span('meetri', [{'nertag': 'O'}]),\n",
       "Span('kuni', [{'nertag': 'O'}]),\n",
       "Span('kahe', [{'nertag': 'O'}]),\n",
       "Span('kilomeetri', [{'nertag': 'O'}]),\n",
       "Span('kaugusele', [{'nertag': 'O'}]),\n",
       "Span('kaldast', [{'nertag': 'O'}]),\n",
       "Span('.', [{'nertag': 'O'}]),\n",
       "Span('Piirivalveameti', [{'nertag': 'B-ORG'}]),\n",
       "Span('pressiesindaja', [{'nertag': 'O'}]),\n",
       "Span('ütles', [{'nertag': 'O'}]),\n",
       "Span('BNS-ile', [{'nertag': 'B-ORG'}]),\n",
       "Span(',', [{'nertag': 'O'}]),\n",
       "Span('et', [{'nertag': 'O'}]),\n",
       "Span('ennelõunal', [{'nertag': 'O'}]),\n",
       "Span('tõi', [{'nertag': 'O'}]),\n",
       "Span('piirivalve', [{'nertag': 'O'}]),\n",
       "Span('hõljuk', [{'nertag': 'O'}]),\n",
       "Span('Kauksi', [{'nertag': 'B-LOC'}]),\n",
       "Span('alt', [{'nertag': 'O'}]),\n",
       "Span('ära', [{'nertag': 'O'}]),\n",
       "Span('neli', [{'nertag': 'O'}]),\n",
       "Span('kalurit', [{'nertag': 'O'}]),\n",
       "Span(',', [{'nertag': 'O'}]),\n",
       "Span('kuid', [{'nertag': 'O'}]),\n",
       "Span('12.30', [{'nertag': 'O'}]),\n",
       "Span('paiku', [{'nertag': 'O'}]),\n",
       "Span('tuli', [{'nertag': 'O'}]),\n",
       "Span('teade', [{'nertag': 'O'}]),\n",
       "Span('suuremast', [{'nertag': 'O'}]),\n",
       "Span('hulgast', [{'nertag': 'O'}]),\n",
       "Span('hädalistest', [{'nertag': 'O'}]),\n",
       "Span('.', [{'nertag': 'O'}]),\n",
       "Span('Pala', [{'nertag': 'B-LOC'}]),\n",
       "Span('vallas', [{'nertag': 'I-LOC'}]),\n",
       "Span('Ranna', [{'nertag': 'B-LOC'}]),\n",
       "Span('asula', [{'nertag': 'I-LOC'}]),\n",
       "Span('juures', [{'nertag': 'O'}]),\n",
       "Span('olid', [{'nertag': 'O'}]),\n",
       "Span('teisele', [{'nertag': 'O'}]),\n",
       "Span('poole', [{'nertag': 'O'}]),\n",
       "Span('jääpragu', [{'nertag': 'O'}]),\n",
       "Span('jäänud', [{'nertag': 'O'}]),\n",
       "Span('hinnanguliselt', [{'nertag': 'O'}]),\n",
       "Span('50-60', [{'nertag': 'O'}]),\n",
       "Span('kalameest', [{'nertag': 'O'}]),\n",
       "Span('.', [{'nertag': 'O'}]),\n",
       "Span('Kella', [{'nertag': 'O'}]),\n",
       "Span('16', [{'nertag': 'O'}]),\n",
       "Span('oli', [{'nertag': 'O'}]),\n",
       "Span('piirivalve', [{'nertag': 'O'}]),\n",
       "Span('ja', [{'nertag': 'O'}]),\n",
       "Span('kohalikud', [{'nertag': 'O'}]),\n",
       "Span('elanikud', [{'nertag': 'O'}]),\n",
       "Span('oma', [{'nertag': 'O'}]),\n",
       "Span('paatidega', [{'nertag': 'O'}]),\n",
       "Span('neist', [{'nertag': 'O'}]),\n",
       "Span('paarkümmend', [{'nertag': 'O'}]),\n",
       "Span('maale', [{'nertag': 'O'}]),\n",
       "Span('toimetanud', [{'nertag': 'O'}]),\n",
       "Span('.', [{'nertag': 'O'}]),\n",
       "Span('Pressiesindaja', [{'nertag': 'O'}]),\n",
       "Span('sõnul', [{'nertag': 'O'}]),\n",
       "Span('ohtlikku', [{'nertag': 'O'}]),\n",
       "Span('olukorda', [{'nertag': 'O'}]),\n",
       "Span('kalameeste', [{'nertag': 'O'}]),\n",
       "Span('jaoks', [{'nertag': 'O'}]),\n",
       "Span('tekkinud', [{'nertag': 'O'}]),\n",
       "Span('ei', [{'nertag': 'O'}]),\n",
       "Span('ole', [{'nertag': 'O'}]),\n",
       "Span('ja', [{'nertag': 'O'}]),\n",
       "Span('päästetööd', [{'nertag': 'O'}]),\n",
       "Span('sujuvad', [{'nertag': 'O'}]),\n",
       "Span('plaanipäraselt', [{'nertag': 'O'}]),\n",
       "Span('.', [{'nertag': 'O'}]),\n",
       "Span('“', [{'nertag': 'O'}]),\n",
       "Span('Täiesti', [{'nertag': 'O'}]),\n",
       "Span('võimatu', [{'nertag': 'O'}]),\n",
       "Span('oleks', [{'nertag': 'O'}]),\n",
       "Span('kustutada', [{'nertag': 'O'}]),\n",
       "Span('põlevaid', [{'nertag': 'O'}]),\n",
       "Span('kütusemahuteid', [{'nertag': 'O'}]),\n",
       "Span('ning', [{'nertag': 'O'}]),\n",
       "Span('tuleks', [{'nertag': 'O'}]),\n",
       "Span('oodata', [{'nertag': 'O'}]),\n",
       "Span('kuni', [{'nertag': 'O'}]),\n",
       "Span('kütuse', [{'nertag': 'O'}]),\n",
       "Span('täieliku', [{'nertag': 'O'}]),\n",
       "Span('väljapõlemiseni', [{'nertag': 'O'}]),\n",
       "Span('mahutitest', [{'nertag': 'O'}]),\n",
       "Span('.', [{'nertag': 'O'}]),\n",
       "Span('Bensiini', [{'nertag': 'O'}]),\n",
       "Span('ja', [{'nertag': 'O'}]),\n",
       "Span('muude', [{'nertag': 'O'}]),\n",
       "Span('vedelkütuste', [{'nertag': 'O'}]),\n",
       "Span('mahutite', [{'nertag': 'O'}]),\n",
       "Span('plahvatuste', [{'nertag': 'O'}]),\n",
       "Span('juhul', [{'nertag': 'O'}]),\n",
       "Span('ei', [{'nertag': 'O'}]),\n",
       "Span('oleks', [{'nertag': 'O'}]),\n",
       "Span('võimalik', [{'nertag': 'O'}]),\n",
       "Span('päästa', [{'nertag': 'O'}]),\n",
       "Span('terminalide', [{'nertag': 'O'}]),\n",
       "Span('töötajaid', [{'nertag': 'O'}]),\n",
       "Span('ega', [{'nertag': 'O'}]),\n",
       "Span('ka', [{'nertag': 'O'}]),\n",
       "Span('terminalis', [{'nertag': 'O'}]),\n",
       "Span('olevate', [{'nertag': 'O'}]),\n",
       "Span('laevade', [{'nertag': 'O'}]),\n",
       "Span('meeskonnaliikmeid', [{'nertag': 'O'}]),\n",
       "Span(',', [{'nertag': 'O'}]),\n",
       "Span('rääkimata', [{'nertag': 'O'}]),\n",
       "Span('juba', [{'nertag': 'O'}]),\n",
       "Span('kahjustavast', [{'nertag': 'O'}]),\n",
       "Span('mõjust', [{'nertag': 'O'}]),\n",
       "Span('ümbritsevale', [{'nertag': 'O'}]),\n",
       "Span('keskkonnale', [{'nertag': 'O'}]),\n",
       "Span(',', [{'nertag': 'O'}]),\n",
       "Span('Eesti', [{'nertag': 'B-LOC'}]),\n",
       "Span('majandusele', [{'nertag': 'O'}]),\n",
       "Span('ja', [{'nertag': 'O'}]),\n",
       "Span('rahvusvahelisele', [{'nertag': 'O'}]),\n",
       "Span('mainele', [{'nertag': 'O'}]),\n",
       "Span(',', [{'nertag': 'O'}]),\n",
       "Span('”', [{'nertag': 'O'}]),\n",
       "Span('hoiatab', [{'nertag': 'O'}]),\n",
       "Span('turvafirma', [{'nertag': 'O'}]),\n",
       "Span('juhatuse', [{'nertag': 'O'}]),\n",
       "Span('esimees', [{'nertag': 'O'}]),\n",
       "Span('Aleksander', [{'nertag': 'B-PER'}]),\n",
       "Span('Kaspin', [{'nertag': 'I-PER'}]),\n",
       "Span('riigikantseleile', [{'nertag': 'O'}]),\n",
       "Span('saadetud', [{'nertag': 'O'}]),\n",
       "Span('kirjas', [{'nertag': 'O'}]),\n",
       "Span('.', [{'nertag': 'O'}])])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.pop_layer('wordner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td><div align = \"left\">Riigi kutsekoolidest sai kõige viletsama tulemuse Põltsamaa Kodu - ja Põllumajanduskool , kus kvaliteedistandarditele ei vastanud 33 protsenti kutseõpetajatest ja 27 protsenti üldharidusainete õpetajatest . Kooli direktori asetäitja Tambet Valdma sõnul peetakse nende koolis õpetajatena lugu ka väga headest oma ala spetsialistidest ja praktikutest , kel ei pruugi vastava ainevaldkonna paberit taskus olla . Vajadust kaasata praktikuid kinnitas ka tööandjate keskliidu tööturunõunik Thor-Sten Vertmann . Tema sõnul on kutsekoolides erialasid , mis jääksid kõigilt õpetajatelt erialast kõrgharidust nõudes täielikult ajast maha . Haridusministeeriumi kutse - ja täiskasvanuhariduse osakonna juhataja Andres Pung märkis , et kutsekooliõpetajate hindamise kriteeriume senisest leebemaks muutmine tooks koolidesse rohkem oma ala praktikuid . Kehtiva korra järgi võib praktik küll koolis töötada , kui ta on vähemalt kolm aastat töötanud oma erialal ja jätkab põhitööd ka kooli kõrvalt . Põhikohaga tööd tegevad õpetajad , kel pole pedagoogilist haridus , peavad läbima 320 tunni pikkuse õpetajakoolituse . “ Tundub , et see osa on küll natuke ülepingutatud ning neid mahtusid saaks kindlasti vähendada , ” sõnas Pung . 15-aastase Leedu poisi tapjad on tabatud . Leedu linnas Visaginases võttis politsei kinni kaks noormeest , keda kahtlustatakse 15-aastase koolipoisi tapmises . Kaheksanda klassi õpilase Aleksei Selivanovi läbilõigatud kõri ning rohkete torke - ja lõikehaavadega laip leiti kolmapäeva õhtul . Poiss oli tapetud oma kodu lähedal . Politsei pidas neljapäeval mõrvas kahtlustatutena kinni kaks 17-aastast Visaginase elanikku . Üks neist oli nähtavasti mõrva tellija , teine aga täideviija . Kinnipeetud on oma süü üles tunnistanud . Visaginase politsei otsib taga veel kaht mõrvas osalenut . Esialgsetel andmetel tapeti 15-aastane poiss ühe tüdruku pärast . Pärast kuriteo avastamist on Visaginase linna haaranud paanika . Vanemad kardavad oma lapsi kooli saata . Leedu noores linnas Visaginases , mis ehitati 20 aastat tagasi koos Ignalina aatomielektrijaamaga , oli see esimene alaealise mõrv . Kümned kalamehed jäid taas Peipsil hätta . Peipsil jäid pühapäeval taas hätta kümned kalamehed , kes kaldale saamiseks abi vajasid . Järvejäässe tekkis läänetuulega Peipsi Eesti poolele kümne kuni 200 meetri laiune lõhe , mis jääb 400 meetri kuni kahe kilomeetri kaugusele kaldast . Piirivalveameti pressiesindaja ütles BNS-ile , et ennelõunal tõi piirivalve hõljuk Kauksi alt ära neli kalurit , kuid 12.30 paiku tuli teade suuremast hulgast hädalistest . Pala vallas Ranna asula juures olid teisele poole jääpragu jäänud hinnanguliselt 50-60 kalameest . Kella 16 oli piirivalve ja kohalikud elanikud oma paatidega neist paarkümmend maale toimetanud . Pressiesindaja sõnul ohtlikku olukorda kalameeste jaoks tekkinud ei ole ja päästetööd sujuvad plaanipäraselt . “ Täiesti võimatu oleks kustutada põlevaid kütusemahuteid ning tuleks oodata kuni kütuse täieliku väljapõlemiseni mahutitest . Bensiini ja muude vedelkütuste mahutite plahvatuste juhul ei oleks võimalik päästa terminalide töötajaid ega ka terminalis olevate laevade meeskonnaliikmeid , rääkimata juba kahjustavast mõjust ümbritsevale keskkonnale , Eesti majandusele ja rahvusvahelisele mainele , ” hoiatab turvafirma juhatuse esimees Aleksander Kaspin riigikantseleile saadetud kirjas .</div></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>layer name</th>\n",
       "      <th>attributes</th>\n",
       "      <th>parent</th>\n",
       "      <th>enveloping</th>\n",
       "      <th>ambiguous</th>\n",
       "      <th>span count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>sentences</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>words</td>\n",
       "      <td>False</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>compound_tokens</td>\n",
       "      <td>type, normalized</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>words</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>morph_analysis</td>\n",
       "      <td>normalized_text, lemma, root, root_tokens, ending, clitic, form, partofspeech</td>\n",
       "      <td>words</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>471</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "Text(text='Riigi kutsekoolidest sai kõige viletsama tulemuse Põltsamaa Kodu - ja Põllumajanduskool , kus kvaliteedistandarditele ei vastanud 33 protsenti kutseõpetajatest ja 27 protsenti üldharidusainete õpetajatest . Kooli direktori asetäitja Tambet Valdma sõnul peetakse nende koolis õpetajatena lugu ka väga headest oma ala spetsialistidest ja praktikutest , kel ei pruugi vastava ainevaldkonna paberit taskus olla . Vajadust kaasata praktikuid kinnitas ka tööandjate keskliidu tööturunõunik Thor-Sten Vertmann . Tema sõnul on kutsekoolides erialasid , mis jääksid kõigilt õpetajatelt erialast kõrgharidust nõudes täielikult ajast maha . Haridusministeeriumi kutse - ja täiskasvanuhariduse osakonna juhataja Andres Pung märkis , et kutsekooliõpetajate hindamise kriteeriume senisest leebemaks muutmine tooks koolidesse rohkem oma ala praktikuid . Kehtiva korra järgi võib praktik küll koolis töötada , kui ta on vähemalt kolm aastat töötanud oma erialal ja jätkab põhitööd ka kooli kõrvalt . Põhikohaga tööd tegevad õpetajad , kel pole pedagoogilist haridus , peavad läbima 320 tunni pikkuse õpetajakoolituse . “ Tundub , et see osa on küll natuke ülepingutatud ning neid mahtusid saaks kindlasti vähendada , ” sõnas Pung . 15-aastase Leedu poisi tapjad on tabatud . Leedu linnas Visaginases võttis politsei kinni kaks noormeest , keda kahtlustatakse 15-aastase koolipoisi tapmises . Kaheksanda klassi õpilase Aleksei Selivanovi läbilõigatud kõri ning rohkete torke - ja lõikehaavadega laip leiti kolmapäeva õhtul . Poiss oli tapetud oma kodu lähedal . Politsei pidas neljapäeval mõrvas kahtlustatutena kinni kaks 17-aastast Visaginase elanikku . Üks neist oli nähtavasti mõrva tellija , teine aga täideviija . Kinnipeetud on oma süü üles tunnistanud . Visaginase politsei otsib taga veel kaht mõrvas osalenut . Esialgsetel andmetel tapeti 15-aastane poiss ühe tüdruku pärast . Pärast kuriteo avastamist on Visaginase linna haaranud paanika . Vanemad kardavad oma lapsi kooli saata . Leedu noores linnas Visaginases , mis ehitati 20 aastat tagasi koos Ignalina aatomielektrijaamaga , oli see esimene alaealise mõrv . Kümned kalamehed jäid taas Peipsil hätta . Peipsil jäid pühapäeval taas hätta kümned kalamehed , kes kaldale saamiseks abi vajasid . Järvejäässe tekkis läänetuulega Peipsi Eesti poolele kümne kuni 200 meetri laiune lõhe , mis jääb 400 meetri kuni kahe kilomeetri kaugusele kaldast . Piirivalveameti pressiesindaja ütles BNS-ile , et ennelõunal tõi piirivalve hõljuk Kauksi alt ära neli kalurit , kuid 12.30 paiku tuli teade suuremast hulgast hädalistest . Pala vallas Ranna asula juures olid teisele poole jääpragu jäänud hinnanguliselt 50-60 kalameest . Kella 16 oli piirivalve ja kohalikud elanikud oma paatidega neist paarkümmend maale toimetanud . Pressiesindaja sõnul ohtlikku olukorda kalameeste jaoks tekkinud ei ole ja päästetööd sujuvad plaanipäraselt . “ Täiesti võimatu oleks kustutada põlevaid kütusemahuteid ning tuleks oodata kuni kütuse täieliku väljapõlemiseni mahutitest . Bensiini ja muude vedelkütuste mahutite plahvatuste juhul ei oleks võimalik päästa terminalide töötajaid ega ka terminalis olevate laevade meeskonnaliikmeid , rääkimata juba kahjustavast mõjust ümbritsevale keskkonnale , Eesti majandusele ja rahvusvahelisele mainele , ” hoiatab turvafirma juhatuse esimees Aleksander Kaspin riigikantseleile saadetud kirjas .')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "nertagger = WordLevelNerTagger(model_dir = 'ner_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td><div align = \"left\">Riigi kutsekoolidest sai kõige viletsama tulemuse Põltsamaa Kodu - ja Põllumajanduskool , kus kvaliteedistandarditele ei vastanud 33 protsenti kutseõpetajatest ja 27 protsenti üldharidusainete õpetajatest . Kooli direktori asetäitja Tambet Valdma sõnul peetakse nende koolis õpetajatena lugu ka väga headest oma ala spetsialistidest ja praktikutest , kel ei pruugi vastava ainevaldkonna paberit taskus olla . Vajadust kaasata praktikuid kinnitas ka tööandjate keskliidu tööturunõunik Thor-Sten Vertmann . Tema sõnul on kutsekoolides erialasid , mis jääksid kõigilt õpetajatelt erialast kõrgharidust nõudes täielikult ajast maha . Haridusministeeriumi kutse - ja täiskasvanuhariduse osakonna juhataja Andres Pung märkis , et kutsekooliõpetajate hindamise kriteeriume senisest leebemaks muutmine tooks koolidesse rohkem oma ala praktikuid . Kehtiva korra järgi võib praktik küll koolis töötada , kui ta on vähemalt kolm aastat töötanud oma erialal ja jätkab põhitööd ka kooli kõrvalt . Põhikohaga tööd tegevad õpetajad , kel pole pedagoogilist haridus , peavad läbima 320 tunni pikkuse õpetajakoolituse . “ Tundub , et see osa on küll natuke ülepingutatud ning neid mahtusid saaks kindlasti vähendada , ” sõnas Pung . 15-aastase Leedu poisi tapjad on tabatud . Leedu linnas Visaginases võttis politsei kinni kaks noormeest , keda kahtlustatakse 15-aastase koolipoisi tapmises . Kaheksanda klassi õpilase Aleksei Selivanovi läbilõigatud kõri ning rohkete torke - ja lõikehaavadega laip leiti kolmapäeva õhtul . Poiss oli tapetud oma kodu lähedal . Politsei pidas neljapäeval mõrvas kahtlustatutena kinni kaks 17-aastast Visaginase elanikku . Üks neist oli nähtavasti mõrva tellija , teine aga täideviija . Kinnipeetud on oma süü üles tunnistanud . Visaginase politsei otsib taga veel kaht mõrvas osalenut . Esialgsetel andmetel tapeti 15-aastane poiss ühe tüdruku pärast . Pärast kuriteo avastamist on Visaginase linna haaranud paanika . Vanemad kardavad oma lapsi kooli saata . Leedu noores linnas Visaginases , mis ehitati 20 aastat tagasi koos Ignalina aatomielektrijaamaga , oli see esimene alaealise mõrv . Kümned kalamehed jäid taas Peipsil hätta . Peipsil jäid pühapäeval taas hätta kümned kalamehed , kes kaldale saamiseks abi vajasid . Järvejäässe tekkis läänetuulega Peipsi Eesti poolele kümne kuni 200 meetri laiune lõhe , mis jääb 400 meetri kuni kahe kilomeetri kaugusele kaldast . Piirivalveameti pressiesindaja ütles BNS-ile , et ennelõunal tõi piirivalve hõljuk Kauksi alt ära neli kalurit , kuid 12.30 paiku tuli teade suuremast hulgast hädalistest . Pala vallas Ranna asula juures olid teisele poole jääpragu jäänud hinnanguliselt 50-60 kalameest . Kella 16 oli piirivalve ja kohalikud elanikud oma paatidega neist paarkümmend maale toimetanud . Pressiesindaja sõnul ohtlikku olukorda kalameeste jaoks tekkinud ei ole ja päästetööd sujuvad plaanipäraselt . “ Täiesti võimatu oleks kustutada põlevaid kütusemahuteid ning tuleks oodata kuni kütuse täieliku väljapõlemiseni mahutitest . Bensiini ja muude vedelkütuste mahutite plahvatuste juhul ei oleks võimalik päästa terminalide töötajaid ega ka terminalis olevate laevade meeskonnaliikmeid , rääkimata juba kahjustavast mõjust ümbritsevale keskkonnale , Eesti majandusele ja rahvusvahelisele mainele , ” hoiatab turvafirma juhatuse esimees Aleksander Kaspin riigikantseleile saadetud kirjas .</div></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>layer name</th>\n",
       "      <th>attributes</th>\n",
       "      <th>parent</th>\n",
       "      <th>enveloping</th>\n",
       "      <th>ambiguous</th>\n",
       "      <th>span count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>sentences</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>words</td>\n",
       "      <td>False</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>compound_tokens</td>\n",
       "      <td>type, normalized</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>words</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>morph_analysis</td>\n",
       "      <td>normalized_text, lemma, root, root_tokens, ending, clitic, form, partofspeech</td>\n",
       "      <td>words</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>wordner</td>\n",
       "      <td>nertag</td>\n",
       "      <td>words</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>471</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "Text(text='Riigi kutsekoolidest sai kõige viletsama tulemuse Põltsamaa Kodu - ja Põllumajanduskool , kus kvaliteedistandarditele ei vastanud 33 protsenti kutseõpetajatest ja 27 protsenti üldharidusainete õpetajatest . Kooli direktori asetäitja Tambet Valdma sõnul peetakse nende koolis õpetajatena lugu ka väga headest oma ala spetsialistidest ja praktikutest , kel ei pruugi vastava ainevaldkonna paberit taskus olla . Vajadust kaasata praktikuid kinnitas ka tööandjate keskliidu tööturunõunik Thor-Sten Vertmann . Tema sõnul on kutsekoolides erialasid , mis jääksid kõigilt õpetajatelt erialast kõrgharidust nõudes täielikult ajast maha . Haridusministeeriumi kutse - ja täiskasvanuhariduse osakonna juhataja Andres Pung märkis , et kutsekooliõpetajate hindamise kriteeriume senisest leebemaks muutmine tooks koolidesse rohkem oma ala praktikuid . Kehtiva korra järgi võib praktik küll koolis töötada , kui ta on vähemalt kolm aastat töötanud oma erialal ja jätkab põhitööd ka kooli kõrvalt . Põhikohaga tööd tegevad õpetajad , kel pole pedagoogilist haridus , peavad läbima 320 tunni pikkuse õpetajakoolituse . “ Tundub , et see osa on küll natuke ülepingutatud ning neid mahtusid saaks kindlasti vähendada , ” sõnas Pung . 15-aastase Leedu poisi tapjad on tabatud . Leedu linnas Visaginases võttis politsei kinni kaks noormeest , keda kahtlustatakse 15-aastase koolipoisi tapmises . Kaheksanda klassi õpilase Aleksei Selivanovi läbilõigatud kõri ning rohkete torke - ja lõikehaavadega laip leiti kolmapäeva õhtul . Poiss oli tapetud oma kodu lähedal . Politsei pidas neljapäeval mõrvas kahtlustatutena kinni kaks 17-aastast Visaginase elanikku . Üks neist oli nähtavasti mõrva tellija , teine aga täideviija . Kinnipeetud on oma süü üles tunnistanud . Visaginase politsei otsib taga veel kaht mõrvas osalenut . Esialgsetel andmetel tapeti 15-aastane poiss ühe tüdruku pärast . Pärast kuriteo avastamist on Visaginase linna haaranud paanika . Vanemad kardavad oma lapsi kooli saata . Leedu noores linnas Visaginases , mis ehitati 20 aastat tagasi koos Ignalina aatomielektrijaamaga , oli see esimene alaealise mõrv . Kümned kalamehed jäid taas Peipsil hätta . Peipsil jäid pühapäeval taas hätta kümned kalamehed , kes kaldale saamiseks abi vajasid . Järvejäässe tekkis läänetuulega Peipsi Eesti poolele kümne kuni 200 meetri laiune lõhe , mis jääb 400 meetri kuni kahe kilomeetri kaugusele kaldast . Piirivalveameti pressiesindaja ütles BNS-ile , et ennelõunal tõi piirivalve hõljuk Kauksi alt ära neli kalurit , kuid 12.30 paiku tuli teade suuremast hulgast hädalistest . Pala vallas Ranna asula juures olid teisele poole jääpragu jäänud hinnanguliselt 50-60 kalameest . Kella 16 oli piirivalve ja kohalikud elanikud oma paatidega neist paarkümmend maale toimetanud . Pressiesindaja sõnul ohtlikku olukorda kalameeste jaoks tekkinud ei ole ja päästetööd sujuvad plaanipäraselt . “ Täiesti võimatu oleks kustutada põlevaid kütusemahuteid ning tuleks oodata kuni kütuse täieliku väljapõlemiseni mahutitest . Bensiini ja muude vedelkütuste mahutite plahvatuste juhul ei oleks võimalik päästa terminalide töötajaid ega ka terminalis olevate laevade meeskonnaliikmeid , rääkimata juba kahjustavast mõjust ümbritsevale keskkonnale , Eesti majandusele ja rahvusvahelisele mainele , ” hoiatab turvafirma juhatuse esimees Aleksander Kaspin riigikantseleile saadetud kirjas .')"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nertagger.tag(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct = 0\n",
    "predicted_layer = test.wordner\n",
    "\n",
    "for i, tag in enumerate(nerlayer.nertag):\n",
    "    if tag == predicted_layer[i].nertag:\n",
    "        correct += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 97.45222929936305 %\n"
     ]
    }
   ],
   "source": [
    "# NBVAL_IGNORE_OUTPUT\n",
    "print(\"Accuracy:\", correct/len(nerlayer) * 100, \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparison on non-labelled text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparing the tagger that uses the newly trained model with a tagger that uses the default model that EstNLTK has. For the default model, model_dir doesn't need to be specified."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "nonlabelled = Text('''Eesti Vabariik on riik Põhja-Euroopas.\n",
    "    Eesti piirneb põhjas üle Soome lahe Soome Vabariigiga.\n",
    "    Riigikogu on Eesti Vabariigi parlament. Riigikogule kuulub Eestis seadusandlik võim.\n",
    "    2005. aastal sai peaministriks Andrus Ansip, kes püsis sellel kohal 2014. aastani.\n",
    "    2006. aastal valiti presidendiks Toomas Hendrik Ilves.\n",
    "    ''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td><div align = \"left\">Eesti Vabariik on riik Põhja-Euroopas.</br>    Eesti piirneb põhjas üle Soome lahe Soome Vabariigiga.</br>    Riigikogu on Eesti Vabariigi parlament. Riigikogule kuulub Eestis seadusandlik võim.</br>    2005. aastal sai peaministriks Andrus Ansip, kes püsis sellel kohal 2014. aastani.</br>    2006. aastal valiti presidendiks Toomas Hendrik Ilves.</br>    </div></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>layer name</th>\n",
       "      <th>attributes</th>\n",
       "      <th>parent</th>\n",
       "      <th>enveloping</th>\n",
       "      <th>ambiguous</th>\n",
       "      <th>span count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>sentences</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>words</td>\n",
       "      <td>False</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>tokens</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>compound_tokens</td>\n",
       "      <td>type, normalized</td>\n",
       "      <td>None</td>\n",
       "      <td>tokens</td>\n",
       "      <td>False</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>words</td>\n",
       "      <td>normalized_form</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>morph_analysis</td>\n",
       "      <td>normalized_text, lemma, root, root_tokens, ending, clitic, form, partofspeech</td>\n",
       "      <td>words</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "Text(text='Eesti Vabariik on riik Põhja-Euroopas.\\n    Eesti piirneb põhjas üle Soome lahe Soome Vabariigiga.\\n    Riigikogu on Eesti Vabariigi parlament. Riigikogule kuulub Eestis seadusandlik võim.\\n    2005. aastal sai peaministriks Andrus Ansip, kes püsis sellel kohal 2014. aastani.\\n    2006. aastal valiti presidendiks Toomas Hendrik Ilves.\\n    ')"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nonlabelled.tag_layer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting layer name for both so they could later be easily compared using DiffTagger\n",
    "defaulttagger = WordLevelNerTagger(output_layer='wordner_default')\n",
    "trainedtagger = WordLevelNerTagger(output_layer='wordner_trained', model_dir = 'ner_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td><div align = \"left\">Eesti Vabariik on riik Põhja-Euroopas.</br>    Eesti piirneb põhjas üle Soome lahe Soome Vabariigiga.</br>    Riigikogu on Eesti Vabariigi parlament. Riigikogule kuulub Eestis seadusandlik võim.</br>    2005. aastal sai peaministriks Andrus Ansip, kes püsis sellel kohal 2014. aastani.</br>    2006. aastal valiti presidendiks Toomas Hendrik Ilves.</br>    </div></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>layer name</th>\n",
       "      <th>attributes</th>\n",
       "      <th>parent</th>\n",
       "      <th>enveloping</th>\n",
       "      <th>ambiguous</th>\n",
       "      <th>span count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>sentences</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>words</td>\n",
       "      <td>False</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>tokens</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>compound_tokens</td>\n",
       "      <td>type, normalized</td>\n",
       "      <td>None</td>\n",
       "      <td>tokens</td>\n",
       "      <td>False</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>words</td>\n",
       "      <td>normalized_form</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>morph_analysis</td>\n",
       "      <td>normalized_text, lemma, root, root_tokens, ending, clitic, form, partofspeech</td>\n",
       "      <td>words</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>wordner_default</td>\n",
       "      <td>nertag</td>\n",
       "      <td>words</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "Text(text='Eesti Vabariik on riik Põhja-Euroopas.\\n    Eesti piirneb põhjas üle Soome lahe Soome Vabariigiga.\\n    Riigikogu on Eesti Vabariigi parlament. Riigikogule kuulub Eestis seadusandlik võim.\\n    2005. aastal sai peaministriks Andrus Ansip, kes püsis sellel kohal 2014. aastani.\\n    2006. aastal valiti presidendiks Toomas Hendrik Ilves.\\n    ')"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "defaulttagger.tag(nonlabelled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td><div align = \"left\">Eesti Vabariik on riik Põhja-Euroopas.</br>    Eesti piirneb põhjas üle Soome lahe Soome Vabariigiga.</br>    Riigikogu on Eesti Vabariigi parlament. Riigikogule kuulub Eestis seadusandlik võim.</br>    2005. aastal sai peaministriks Andrus Ansip, kes püsis sellel kohal 2014. aastani.</br>    2006. aastal valiti presidendiks Toomas Hendrik Ilves.</br>    </div></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>layer name</th>\n",
       "      <th>attributes</th>\n",
       "      <th>parent</th>\n",
       "      <th>enveloping</th>\n",
       "      <th>ambiguous</th>\n",
       "      <th>span count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>sentences</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>words</td>\n",
       "      <td>False</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>tokens</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>compound_tokens</td>\n",
       "      <td>type, normalized</td>\n",
       "      <td>None</td>\n",
       "      <td>tokens</td>\n",
       "      <td>False</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>words</td>\n",
       "      <td>normalized_form</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>morph_analysis</td>\n",
       "      <td>normalized_text, lemma, root, root_tokens, ending, clitic, form, partofspeech</td>\n",
       "      <td>words</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>wordner_default</td>\n",
       "      <td>nertag</td>\n",
       "      <td>words</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>wordner_trained</td>\n",
       "      <td>nertag</td>\n",
       "      <td>words</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "Text(text='Eesti Vabariik on riik Põhja-Euroopas.\\n    Eesti piirneb põhjas üle Soome lahe Soome Vabariigiga.\\n    Riigikogu on Eesti Vabariigi parlament. Riigikogule kuulub Eestis seadusandlik võim.\\n    2005. aastal sai peaministriks Andrus Ansip, kes püsis sellel kohal 2014. aastani.\\n    2006. aastal valiti presidendiks Toomas Hendrik Ilves.\\n    ')"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainedtagger.tag(nonlabelled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from estnltk.taggers import DiffTagger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "difftagger = DiffTagger('wordner_default', 'wordner_trained', 'ner_differences', ['nertag'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "difflayer = difftagger.make_layer(nonlabelled, layers={'wordner_default': nonlabelled.wordner_default, 'wordner_trained': nonlabelled.wordner_trained})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h4>Layer</h4>\n",
       "<h4>Metadata</h4>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>conflicts</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>extra_annotations</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>extra_spans</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>missing_annotations</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>missing_spans</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>modified_spans</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>overlapped</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>prolonged</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>shortened</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>unchanged_annotations</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>unchanged_spans</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>layer name</th>\n",
       "      <th>attributes</th>\n",
       "      <th>parent</th>\n",
       "      <th>enveloping</th>\n",
       "      <th>ambiguous</th>\n",
       "      <th>span count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>ner_differences</td>\n",
       "      <td>span_status, input_layer_name, nertag</td>\n",
       "      <td>words</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>text</th>\n",
       "      <th>span_status</th>\n",
       "      <th>input_layer_name</th>\n",
       "      <th>nertag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>lahe</td>\n",
       "      <td>modified</td>\n",
       "      <td>wordner_default</td>\n",
       "      <td>I-LOC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td></td>\n",
       "      <td>modified</td>\n",
       "      <td>wordner_trained</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Vabariigiga</td>\n",
       "      <td>modified</td>\n",
       "      <td>wordner_default</td>\n",
       "      <td>I-LOC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td></td>\n",
       "      <td>modified</td>\n",
       "      <td>wordner_trained</td>\n",
       "      <td>B-LOC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Riigikogu</td>\n",
       "      <td>modified</td>\n",
       "      <td>wordner_default</td>\n",
       "      <td>B-ORG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td></td>\n",
       "      <td>modified</td>\n",
       "      <td>wordner_trained</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Riigikogule</td>\n",
       "      <td>modified</td>\n",
       "      <td>wordner_default</td>\n",
       "      <td>B-ORG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td></td>\n",
       "      <td>modified</td>\n",
       "      <td>wordner_trained</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "Layer(name='ner_differences', attributes=('span_status', 'input_layer_name', 'nertag'), spans=SL[Span('lahe', [{'span_status': 'modified', 'input_layer_name': 'wordner_default', 'nertag': 'I-LOC'}, {'span_status': 'modified', 'input_layer_name': 'wordner_trained', 'nertag': 'O'}]),\n",
       "Span('Vabariigiga', [{'span_status': 'modified', 'input_layer_name': 'wordner_default', 'nertag': 'I-LOC'}, {'span_status': 'modified', 'input_layer_name': 'wordner_trained', 'nertag': 'B-LOC'}]),\n",
       "Span('Riigikogu', [{'span_status': 'modified', 'input_layer_name': 'wordner_default', 'nertag': 'B-ORG'}, {'span_status': 'modified', 'input_layer_name': 'wordner_trained', 'nertag': 'O'}]),\n",
       "Span('Riigikogule', [{'span_status': 'modified', 'input_layer_name': 'wordner_default', 'nertag': 'B-ORG'}, {'span_status': 'modified', 'input_layer_name': 'wordner_trained', 'nertag': 'O'}])])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# NBVAL_IGNORE_OUTPUT\n",
    "difflayer"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
