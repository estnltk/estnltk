{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training CRF-NER model from CNLL-files\n",
    "To train a new model the following steps have to be carried out:\n",
    "* Loading NER-labellings from file\n",
    "* Training a new model\n",
    "* Measuring model performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading NER-labelings from files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from estnltk.converters.conll_ner_importer import conll_to_ner_labelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td><div align = \"left\">Tallinna õhusaaste suureneb . Kuigi möödunud nädala ühel ööl ootamatult kõrgeks tõusnud õhusaaste oli pealinna jaoks haruldane rekord , liigub linnaõhu saastekõver järjekindlalt ülespoole , konkureerides teiste Euroopa pealinnadega . Nagu kirjutab Postimees , registreeriti Taksopargi õhuseirejaamas 11.märtsil Tallinna õhusaastumise rekord . Kuigi kümme aastat tagasi oli pealinna õhk praegusest märksa mustem , ei vabanda see linna keskkonnaspetsialistide sõnul linnaõhu taas halvemaks muutumist . Linna kolmes mõõtejaamas mõõdetakse paar-kolm korda aastas rekordilist õhusaastet , kuid aeglaselt ronib ülespoole ka keskmise saaste näit . Näiteks sisaldub linnaõhus mõõtmiste järgi keskmiselt ööpäevas täpselt sama palju peentolmu , kui näeb ette lubatud piirnorm . Norm , 24 tunni keskmine , on 50 mikrogrammi kuupmeetri kohta ja seda võib ületada 35 päeval aastas , mida seni pole õnneks ette tulnud . Tallinna keskkonnaameti keskkonnahoiu osakonna juhataja Madis Kõrvits ütles , et üksikud kõrged näidud ei muuda Tallinna õhku veel kõlbmatuks , kuid rõõmustada pole samuti millegi üle , sest 2000. aastal pealinnas olnud hea õhk on hakanud autode juurdevoolu tõttu taas saastuma . “ Samas pole paanikaks põhjust , ” sõnas Kõrvits . “ Kui saaste hetkeliselt tõuseb , tasub olla toas , pikaajalist ohtu aga pole. ” Ta tõi näiteks eelmise nädala rekordpäeva , mil tervisele kahjulik saaste oli õhus vaid mõne tunni  — nii vähe aega , et keskkonnaametnikel polnud seadusega ette nähtud inimesi hoiatada . Kui võrrelda Tallinna õhu saastatust naabruses asuvate suurlinnadega , selgub , et tulemused on üsna sarnased ja meie linn on õigusega Euroopa pealinnade seas . Kõrvits ütles , et kui Tallinnas tõuseb peentolmu sisaldus õhus taksopargi ristmikul õhtuti 250 mikrogrammini kuupmeetri kohta , siis Helsingis näitab mõõtur sama taset kesklinnas hommikusel tipptunnil . Stockholmi õhk on Tallinna omast tunduvalt puhtam , kuid Göteborgis kerkib saastenäitur kuni 200 mikrogrammini kuupmeetri kohta . Teiste Eesti linnadega on Tallinna raske võrrelda , näiteks Tartus mõõdetakse õhupuhtust vaid ajutiselt suvel . Nüüd on see paik juba suvest alates vaid jalakäijate päralt . Kõrvits ütles , et ööl vastu 11. märtsi toimunut võib nimetada õigusega ebasoodsate asjaolude kokkulangemiseks . Selle talve kohta üks käredama pakasega ilmu pani linlased ahje kütma , samas tossasid käivitamisel ja soojendamisel kindlasti rohkem ka õhtul koju minejate autod . Suure panuse rekordi sündimisele andsid ka peaaegu olematu tuul ning õhukihtide liikumatus . Kõrvitsa sõnul ongi just talv see aeg , mil õhusaaste linnas tõuseb . “ Kütmine ja autode soojendamine annab siin kindlasti suure osa , ” märkis Kõrvits . Keskkonnaametniku sõnul ei ole ametnikel ega keskkonnakaitsjatel mingit imejõudu pealinna õhu puhastamiseks . Aitab vaid autostumise kasvu piiramine , vähendades liiklust linnasüdames ning suurendades keskkonnasäästliku elektri-ühistranspordi osa linnas . “ Igaühel tasub iga päev mõelda , kas minna äkki tööle jalgratta või ühissõidukiga või hoopis kõndida veidi jala , ” nentis Kõrvits . Politseid vihastab pätiplaani avalikustamine . Politseid pahandab , et justiitsministeerium avalikustas nende asutusesiseseks kasutamiseks mõeldud kuritegevuse avastamise plaanid . Põhja politseiprefektuuris on tegeldud kriminaalasjade etteplaneerimisega , teatas justiitsministeeriumi reedel Delfile . Avalikustamine oli politseile halb üllatus , sest dokumentide sisu kaitseks oli neile löödud tempel “ asutusesiseseks kasutamiseks ” , kirjutab Eesti Päevaleht . “ Politsei lepingute valguses tundub , et meie viga on olnud see , et oleme asju ajanud avalikult ja püüdnud selgitada , ” ütles justiitsministeeriumi endine asekantsler , juhtiv riigiprokurör Margus Kurm . Riigi politseijuhi Robert Antropovi ja Põhja politseiprefekti Raivo Küüdi vahel selleks aastaks sõlmitud tulemusleping märgib , et kui eelmisel aastal avastati 13 grupiviisilist narkokuritegu , siis tänavu tuleb neid rohkem avastada . Põhja politseinikud peavad tänavu taotlema ja kohaldama ka rohkem areste narkokurjategijate jaoks . Sarnased punktid on ka 2004. aasta tulemuslepingus . “ Politsei peab aastas tegelema umbes 55 000 kriminaalasjaga ning me tahame , et meie tegevus muutuks iga aastaga endisest tõhusamaks , ” ütles eesmärkide kohta Antropov . “ Näiteks peab tapmiste avastamine protsentuaalselt kasvama , peab olema kinni peetud senisest rohkem roolijoodikuid , narkosuurdiilereid. ” Siseminister Margus Leivo sõnul pole talle alluva politsei tulemuslepingud ja justiitsminister Ken-Mart Vaherile alluva prokuratuuri mõõdikuteprojekt võrreldavad . “ Need ikka erinevad personaaliani viidud mõõdikutest , ” kaitses Leivo . “ Need erinevad juba suundumustelt ega ole seatud administratiivsete piirkondade kaupa. ” Samas on politseiameti koduleheküljel kirjas , et kõigepealt sõlmib politsei peadirektor tulemuslepingud keskkriminaalpolitsei , julgestuspolitsei ning nelja prefektuuri juhtidega ning seejärel sõlmivad prefektid omakorda tulemuslepingud neile alluvate piirkondlike osakondade juhtidega . Mees ajas ülekäigurajal naise alla . Keskealine naine jäi laupäeval Tallinnas reguleeritud ülekäigurajal auto alla ning sai vigastada . Klenski süüdistab Laari Estonia uputamises . Parvlaeva Estonia uppumise põhjustas tollase peaministri Mart Laari käsul saamatult avatud visiir , et salakaubast lahti saada , kirjutab Dimitri Klenski Kesknädalas . Klenski väidab , et üsna paljugi sellest , millest täna Rootsis kõneldakse , oli meile teada juba 1996. aasta sügisel . “ Pretendeerimata lõpliku tõe väljaütlemisele , tahan püstitada versiooni , millega tutvustas mind Eesti Vabariigi kaitsejõudude leitnant Tiit Uustalu. ” Uustalu väitel veeti parvlaeval salakaubana ühele Rootsi tehasele Venemaalt varastatud strateegilist toorainest . “ Selle tehase omanikuks oli firma , mille aktsiapakist üle poole kuulus Rootsi riigile . Selle tehingu vastu ilmutas oma huvi ka Eesti Kaitseministeerium , mille teisel korrusel “ räägiti üksnes inglise keeles ” . Teadaolevalt täitsid tol ajal meie kaitseasutuse kohalekomandeeritud natolased , ” nendib Klenski . Parvlaeva lossimisel aga afäär laadungiga paljastus , mistõttu laeva randumine Stockholmis ähvardas tekitada ulatusliku skandaali ja võis põhjustada Rootsi riigi prestiiži languse , kirjutab Klenski . Seejärel järgnenud Stockholmist telefonikõne tollasele Eesti peaministrile Mart Laarile . Selleks ajaks oli aga parvlaev juba tormisel merel . „ Leitnant Uustalu kinnitas , et kaitsejõudude staabis on tallel kaks-kolm tundi enne laevahukku tehtud kõnesalvestused peaminister Laari vestlusest Estonia kapteniga , ” kirjutab Klenski . „ Laar nõudis kategooriliselt lasti viskamist merre . Nii otsustatigi toimida . Ent keegi ei osanud arvata , et täiskäigul liikuva laeva avatud visiir rebeneb tormisel merel hirmsa jõuga lahti . Vesi tungis autotekile . Laev hakkas uppuma. ” Parvlaev Estonia hukkus 1994. aastal 28. septmebril tormisel Balti merel teel Tallinnast Stockholmi , viies koos endaga märga hauda 852 inimelu . Vene väed võivad Gruusiast lahkuda . Venemaa võib alustada vägede väljaviimist Gruusiast sel aastal , teatas välisminister Sergei Lavrov ajakirjanikele pärast kohtumist oma Gruusia kolleegiga . Lavrov kinnitas , et kahe riigi välisministri kohtumisel saavutati sisuline edasiminek Vene vägede Gruusiast väljaviimise osas , vahendab ETV Gazeta.ru uudist . Lavrovi kinnitusel jõuti üksmeelele , et vägede lahkumine on järk-järguline ning algab lõpliku kokkuleppe saavutamisel juba sel aastal . Läbirääkimised Vene vägede väljaviimise üle algasid 2001. aastal . Seni on Gruusia pakkunud väljaviimiseks kolmeaastast tähtaega , Venemaa aga ei soovi lahkuda enne kaheksat aastat . Praegu on Gruusias Batumi baasis 2,5 tuhat meest ja 74 tanki , 80 soomukit ja 120 suurtükki , Ahhalkalki baasis 2 tuhat meest , 40 tanki , 130 soomukit ja 50 suurtükki . Lisaks varustatakse Gruusia kaudu Armeenias Gjurmis asuvat 3000-mehelist Vene baasi . Verine kaklus </br></br>&lt;skipping 23482 characters&gt;</br></br>Blair esinedes ärimeestele . Juunis pani Blair veto ettepanekule , millega oleks külmutatud Briti tagasimakse suurus tulevikus . Kutsekoolide õpetajatel napib õiget haridust . Vähemalt veerandi kutsekoolide õpetajatest peaks haridusministeeriumi järelevalve tulemuste kohaselt saatma ümberõppele . Mullu 11 kutsekoolis tehtud järelevalve uuring näitas , et 14 protsenti erialase kutseõppe ja 22 protsenti üldhariduslikke aineid õpetavate pedagoogide teadmised ei vasta nõuetele , kirjutab Postimees . Järelevalvearuandes märgitakse , et probleemi lahendamiseks on äärmiselt oluline kutseõpetajate täiend - ja ümberõpe . Peaprobleem on haridusministeeriumi järelevalvetalituse juhataja Hille Vooremäe sõnul selles , et üldhariduses polnud õpetajatel kõrgharidust õpetatavas valdkonnas ja kutseõpetajatel konkreetse õppekava valdkonnas . “ Tulemuse viis alla ka see , et suur osa oli eraõppeasutusi — eriti mõjutas tulemusi halvemuse suunas üks konkreetne kool — R-Stamp Tallinnas , ” märkis Vooremäe .</div></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>layer name</th>\n",
       "      <th>attributes</th>\n",
       "      <th>parent</th>\n",
       "      <th>enveloping</th>\n",
       "      <th>ambiguous</th>\n",
       "      <th>span count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>sentences</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>words</td>\n",
       "      <td>False</td>\n",
       "      <td>270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>compound_tokens</td>\n",
       "      <td>type, normalized</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>words</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>4723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>morph_analysis</td>\n",
       "      <td>normalized_text, lemma, root, root_tokens, ending, clitic, form, partofspeech</td>\n",
       "      <td>words</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>4723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>wordner</td>\n",
       "      <td>nertag</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>4723</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "Text(text='Tallinna õhusaaste suureneb . Kuigi möödunud nädala ühel ööl ootamatult kõrgeks tõusnud õhusaaste oli pealinna jaoks haruldane rekord , liigub linnaõhu saastekõver järjekindlalt ülespoole , konkureerides teiste Euroopa pealinnadega . Nagu kirjutab Postimees , registreeriti Taksopargi õhuseirejaamas 11.märtsil Tallinna õhusaastumise rekord . Kuigi kümme aastat tagasi oli pealinna õhk praegusest märksa mustem , ei vabanda see linna keskkonnaspetsialistide sõnul linnaõhu taas halvemaks muutumist . Linna kolmes mõõtejaamas mõõdetakse paar-kolm korda aastas rekordilist õhusaastet , kuid aeglaselt ronib ülespoole ka keskmise saaste näit . Näiteks sisaldub linnaõhus mõõtmiste järgi keskmiselt ööpäevas täpselt sama palju peentolmu , kui näeb ette lubatud piirnorm . Norm , 24 tunni keskmine , on 50 mikrogrammi kuupmeetri kohta ja seda võib ületada 35 päeval aastas , mida seni pole õnneks ette tulnud . Tallinna keskkonnaameti keskkonnahoiu osakonna juhataja Madis Kõrvits ütles , et üksikud kõrged näidud ei muuda Tallinna õhku veel kõlbmatuks , kuid rõõmustada pole samuti millegi üle , sest 2000. aastal pealinnas olnud hea õhk on hakanud autode juurdevoolu tõttu taas saastuma . “ Samas pole paanikaks põhjust , ” sõnas Kõrvits . “ Kui saaste hetkeliselt tõuseb , tasub olla toas , pikaajalist ohtu aga pole. ” Ta tõi näiteks eelmise nädala rekordpäeva , mil tervisele kahjulik saaste oli õhus vaid mõne tunni\\xa0 — nii vähe aega , et keskkonnaametnikel polnud seadusega ette nähtud inimesi hoiatada . Kui võrrelda Tallinna õhu saastatust naabruses asuvate suurlinnadega , selgub , et tulemused on üsna sarnased ja meie linn on õigusega Euroopa pealinnade seas . Kõrvits ütles , et kui Tallinnas tõuseb peentolmu sisaldus õhus taksopargi ristmikul õhtuti 250 mikrogrammini kuupmeetri kohta , siis Helsingis näitab mõõtur sama taset kesklinnas hommikusel tipptunnil . Stockholmi õhk on Tallinna omast tunduvalt puhtam , kuid Göteborgis kerkib saastenäitur kuni 200 mikrogrammini kuupmeetri kohta . Teiste Eesti linnadega on Tallinna raske võrrelda , näiteks Tartus mõõdetakse õhupuhtust vaid ajutiselt suvel . Nüüd on see paik juba suvest alates vaid jalakäijate päralt . Kõrvits ütles , et ööl vastu 11. märtsi toimunut võib nimetada õigusega ebasoodsate asjaolude kokkulangemiseks . Selle talve kohta üks käredama pakasega ilmu pani linlased ahje kütma , samas tossasid käivitamisel ja soojendamisel kindlasti rohkem ka õhtul koju minejate autod . Suure panuse rekordi sündimisele andsid ka peaaegu olematu tuul ning õhukihtide liikumatus . Kõrvitsa sõnul ongi just talv see aeg , mil õhusaaste linnas tõuseb . “ Kütmine ja autode soojendamine annab siin kindlasti suure osa , ” märkis Kõrvits . Keskkonnaametniku sõnul ei ole ametnikel ega keskkonnakaitsjatel mingit imejõudu pealinna õhu puhastamiseks . Aitab vaid autostumise kasvu piiramine , vähendades liiklust linnasüdames ning suurendades keskkonnasäästliku elektri-ühistranspordi osa linnas . “ Igaühel tasub iga päev mõelda , kas minna äkki tööle jalgratta või ühissõidukiga või hoopis kõndida veidi jala , ” nentis Kõrvits . Politseid vihastab pätiplaani avalikustamine . Politseid pahandab , et justiitsministeerium avalikustas nende asutusesiseseks kasutamiseks mõeldud kuritegevuse avastamise plaanid . Põhja politseiprefektuuris on tegeldud kriminaalasjade etteplaneerimisega , teatas justiitsministeeriumi reedel Delfile . Avalikustamine oli politseile halb üllatus , sest dokumentide sisu kaitseks oli neile löödud tempel “ asutusesiseseks kasutamiseks ” , kirjutab Eesti Päevaleht . “ Politsei lepingute valguses tundub , et meie viga on olnud see , et oleme asju ajanud avalikult ja püüdnud selgitada , ” ütles justiitsministeeriumi endine asekantsler , juhtiv riigiprokurör Margus Kurm . Riigi politseijuhi Robert Antropovi ja Põhja politseiprefekti Raivo Küüdi vahel selleks aastaks sõlmitud tulemusleping märgib , et kui eelmisel aastal avastati 13 grupiviisilist narkokuritegu , siis tänavu tuleb neid rohkem avastada . Põhja politseinikud peavad tänavu taotlema ja kohaldama ka rohkem areste narkokurjategijate jaoks . Sarnased punktid on ka 2004. aasta tulemuslepingus . “ Politsei peab aastas tegelema umbes 55 000 kriminaalasjaga ning me tahame , et meie tegevus muutuks iga aastaga endisest tõhusamaks , ” ütles eesmärkide kohta Antropov . “ Näiteks peab tapmiste avastamine protsentuaalselt kasvama , peab olema kinni peetud senisest rohkem roolijoodikuid , narkosuurdiilereid. ” Siseminister Margus Leivo sõnul pole talle alluva politsei tulemuslepingud ja justiitsminister Ken-Mart Vaherile alluva prokuratuuri mõõdikuteprojekt võrreldavad . “ Need ikka erinevad personaaliani viidud mõõdikutest , ” kaitses Leivo . “ Need erinevad juba suundumustelt ega ole seatud administratiivsete piirkondade kaupa. ” Samas on politseiameti koduleheküljel kirjas , et kõigepealt sõlmib politsei peadirektor tulemuslepingud keskkriminaalpolitsei , julgestuspolitsei ning nelja prefektuuri juhtidega ning seejärel sõlmivad prefektid omakorda tulemuslepingud neile alluvate piirkondlike osakondade juhtidega . Mees ajas ülekäigurajal naise alla . Keskealine naine jäi laupäeval Tallinnas reguleeritud ülekäigurajal auto alla ning sai vigastada . Klenski süüdistab Laari Estonia uputamises . Parvlaeva Estonia uppumise põhjustas tollase peaministri Mart Laari käsul saamatult avatud visiir , et salakaubast lahti saada , kirjutab Dimitri Klenski Kesknädalas . Klenski väidab , et üsna paljugi sellest , millest täna Rootsis kõneldakse , oli meile teada juba 1996. aasta sügisel . “ Pretendeerimata lõpliku tõe väljaütlemisele , tahan püstitada versiooni , millega tutvustas mind Eesti Vabariigi kaitsejõudude leitnant Tiit Uustalu. ” Uustalu väitel veeti parvlaeval salakaubana ühele Rootsi tehasele Venemaalt varastatud strateegilist toorainest . “ Selle tehase omanikuks oli firma , mille aktsiapakist üle poole kuulus Rootsi riigile . Selle tehingu vastu ilmutas oma huvi ka Eesti Kaitseministeerium , mille teisel korrusel “ räägiti üksnes inglise keeles ” . Teadaolevalt täitsid tol ajal meie kaitseasutuse kohalekomandeeritud natolased , ” nendib Klenski . Parvlaeva lossimisel aga afäär laadungiga paljastus , mistõttu laeva randumine Stockholmis ähvardas tekitada ulatusliku skandaali ja võis põhjustada Rootsi riigi prestiiži languse , kirjutab Klenski . Seejärel järgnenud Stockholmist telefonikõne tollasele Eesti peaministrile Mart Laarile . Selleks ajaks oli aga parvlaev juba tormisel merel . „ Leitnant Uustalu kinnitas , et kaitsejõudude staabis on tallel kaks-kolm tundi enne laevahukku tehtud kõnesalvestused peaminister Laari vestlusest Estonia kapteniga , ” kirjutab Klenski . „ Laar nõudis kategooriliselt lasti viskamist merre . Nii otsustatigi toimida . Ent keegi ei osanud arvata , et täiskäigul liikuva laeva avatud visiir rebeneb tormisel merel hirmsa jõuga lahti . Vesi tungis autotekile . Laev hakkas uppuma. ” Parvlaev Estonia hukkus 1994. aastal 28. septmebril tormisel Balti merel teel Tallinnast Stockholmi , viies koos endaga märga hauda 852 inimelu . Vene väed võivad Gruusiast lahkuda . Venemaa võib alustada vägede väljaviimist Gruusiast sel aastal , teatas välisminister Sergei Lavrov ajakirjanikele pärast kohtumist oma Gruusia kolleegiga . Lavrov kinnitas , et kahe riigi välisministri kohtumisel saavutati sisuline edasiminek Vene vägede Gruusiast väljaviimise osas , vahendab ETV Gazeta.ru uudist . Lavrovi kinnitusel jõuti üksmeelele , et vägede lahkumine on järk-järguline ning algab lõpliku kokkuleppe saavutamisel juba sel aastal . Läbirääkimised Vene vägede väljaviimise üle algasid 2001. aastal . Seni on Gruusia pakkunud väljaviimiseks kolmeaastast tähtaega , Venemaa aga ei soovi lahkuda enne kaheksat aastat . Praegu on Gruusias Batumi baasis 2,5 tuhat meest ja 74 tanki , 80 soomukit ja 120 suurtükki , Ahhalkalki baasis 2 tuhat meest , 40 tanki , 130 soomukit ja 50 suurtükki . Lisaks varustatakse Gruusia kaudu Armeenias Gjurmis asuvat 3000-mehelist Vene baasi . Verine kaklus lõpetas Oksmaa kontserdi . „ See kõik käis nagu action-filmis! ” kirjeldab Arnold Oksmaa SL Õhtulehele baarilöömingut . „ Kes ette jäi , see sai , ” meenutab tema saatebändi laulja Maarika . „ Klaasid lendasid , aken löödi sisse , naised-mehed olid kõik segamini! ” Esmalt viskanud üks nooruk kokakoolapudeli ukse vahelt sisse , tantsupõrandalt aga läkitatud taara sama teed tagasi ja otse ühele ukse taga passinud kaagile pähe — põhjus baar segi lüüa oligi leitud . „ Selle nelja aasta jooksul , mis ma olen artist olnud , pole nii hullu pidu veel olnud , ” leiab Oksmaa . Ta ise pages koos teiste baarikülastajatega kööki . Süldipundi laulja Maarika Jurton sai rüseluses mikrofoniga vastu hambaid . „ Väike tükike tuli hamba küljest , ” ei tee naine ise sellest suurt numbrit . „ Palusime , et jumala eest , ärge meie pille puruks lööge ! Nemad vastu : teid me ei puutu! ” Sissetungijaid kirjeldab ta ehtsate rullnokkadena : „ Laiad teksad , seljakotid , murumütsid . Jõugujuht oli nahktagis ja kiilakas . Tema võis olla 23 või 24 , aga ülejäänud olid ikka nolgid . Rääkisid eesti keelt. ” Isamaaliit taunib 9. mai pidustusi . Tallinna kesklinnas kavandatavad 9. mai üritused ei sobi kokku demokraatlike väärtuste ja eestlaste eneseväärikusega , leiab Isamaaliit . Sõjaveteranide kohtumine Tallinna linnapeaga näitas eredalt , et Pronkssõduri tänane asukoht tiivustab vene šoviniste vahetult ähvardama Eesti Vabariiki , teatas isamaaliit meediale saadetud avalduses . „ Pronksmehe ees peetavad iga-aastased avaliku korra rikkumised ei solva ainult eestlaste eneseväärikust , vaid on omamoodi õigustavaks sümboliks okupantidele , millega seatakse taaskord Eesti õiguslik järjepidevus ning Tartu rahuleping kahtluse alla , ” leiavad isamaaliitlased . Isamaaliit on ka kindlal seisukohal , et 10. mail ei tohi toimuda mingit Eesti riigipiiri muutmise allakirjutamist , eriti tingimustes , kus Venemaa president Putin igatseb tagasi kurjuseimpeeriumi täies ulatuses , tunnustamata Eesti rahva kallal toime pandud genotsiidi . Isamaaliit on seisukohal , et enne kui me saame arutada Venemaaga Eesti riigipiiri muutmise allakirjutamist , peab Venemaa selgelt loobuma oma vaenavast poliitikast . „ Ootame Venemaalt vabandust okupatsioonikahjude eest ning ootame tagasi varasid , mis Venemaa on Eestilt kokku röövinud ning mille tagastamisest on tehtud igikestev farss. ” Pikaro peab abipolitseinik Purjet ohtlikuks . Ekspolitseinik Koit Pikaro leiab , et esmaspäeval poissi jalga tulistanud abipolitseinik Andrus Purje on ühiskonnale ohtlik ning ta oleks tulnud kahtlustatavana kinni pidada . “ Kujutage ette , kui iga abipolitseinik hakkab suukorvita koera patrullides tulistama , ” hüüatab Pikaro , kelle hinnangul puudus Purjel vajadus tulistada , kirjutab Postimees . Pikaro väitel võttis abipolitseinik ka käerauad välja ja ähvardas mehe käed kinni panna . Kui mehega kaasas olnud tütar selle peale nutma hakkas , tegi isa ettepaneku asja peale lapse koju viimist arutada , kuid abipolitseinik võttis püstoli ja tulistas . Purjus juht vedas Läti koolilapsi . Läti koolilapsi Eestisse ekskursioonile sõidutanud bussi roolis istus purjus mees . Kolmapäeva hommikul Ikla-Ainaži piiripunktis sõidukeid kontrollinud piirivalvurile tundus Läti bussi Neoplan juht Aigars Dzjubo ebakaine . Kuigi joovet näitas ka alkomeeter , polnud bussijuht sellega nõus ja ta tuli Pärnusse ekspertiisi toimetada , kirjutab Pärnu Postimees . Kolm tundi hiljem Pärnus antud proov näitas joobeks juba vaid 0,13 promilli . Poola võib saada kaksikutest riigijuhid . Poola võib peagi saada üsna ebaharilikud liidrid , nimelt kandideerivad riigi peaministriks ja presidendiks ühemunakaksikud . Vennad Lech ja Jaroslaw Kaczynskid juhivad pool aastat enne valimisi arvamusküsitlusi , vahendab PM Online BBC uudist . Lech on Varssavi linnapea , Jaroslaw aga juhib Poola suurimat , paremtsentristlikku parteid. 55-aastased vennad on koos käinud kogu elu\\xa0 — lapsepõlves mängisid “ inglinäoga poisikesed ” filmis , kooliajal aga tegid üksteise eest eksameid . Praegu tuntakse mõlemat karmisõnaliste avalduste poolest kuritegevuse ja korruptsiooni aadressil . Segaduse vältimiseks hoiduvad vennad koos avalikkuse ette ilmumast . Teineteise rolle võtta nad enam ei saa , sest Lechil on põse ja nina peal kaks täppi . Vilnius tahab CNN-i ilmateatesse saada . Vilniuse energiline ja ambitsioonikas linnapea , liberaal Arturas Zuokas soovib , et Vilniuse ilmateadet edastataks ka rahvusvahelistes telekanalites . Zuokas ja tema nõunikud peavad praegu läbirääkimisi telekanalitega Cable News Network ( CNN ) ja Independent Television News ( ITN ) , et Euroopa ilmakaardile nende saadetes ilmuks ka Vilnius . Kesk - ja Ida-Euroopa kaartidel , mida need kanalid näitavad on märgitud ainult Minsk , Varssavi ja veel mõned pealinnad . Leedu ajaleht Lietuvos Rytas kirjutab , et ilmateate jooksvas reas tahaks Zuokas näha ka Vilniuse ilmaprognoosi . “ Ma arvan , et ITN-iga on kergem kokku leppida , kuna ma tegin sellele kanalile tööd . Olen ka CNN-i juhtidele meelde tuletanud , et see kanal on kasutanud minu reportaaže , ” ütles Vilniuse linnapea oma intervjuus . Aastail 1990-1993 töötas Zuokas telekanali ITN sõjakorrespondendina Iraagis . Linnapea kavatseb esitada samasuguse palve ka BBC-le ja teistele suurtele telekanalitele . “ Olin hiljuti Pariisis Euroopa pealinnade linnapeade kohtumisel ja konverentsil . Ma olin ebameeldivalt üllatunud , kuuldes , et ainult iga teine neist mäletab , et Vilnius on Leedu pealinn . Samal ajal teavad Riiat ja Tallinna kõik . Tahaksin , et see oleks teisiti , ” ütles Zuokas . Vilniuse linnapea on ka pöördunud lennukompaniide Lufthansa , British Airways ja SAS poole palvega jagada Vilniuse liinidel lendavates lennukites Leedu pealinna tutvustavaid buklette . Kirjad rahvusvahelistele telekanalitele ei ole Zuokase esimene katse populariseerida Vilniust välismaal . Hiljuti saatis ta kirjad ka Austria , Prantsusmaa , Suurbritannia ja USA suurte kasiinode omanikele , kutsudes neid Vilniusse , et anda hinnang olukorrale ning valida sobivaid kohti mängupõrgute ehitamiseks . Zuokase selle sammu taga on asjaolu , et valitsus esitas hiljuti parlamendile kinnitamiseks seaduseelnõu , mis näeb ette hasartmängude lubamise . Zimbabwet võrreldi Kambodža Pol Potiga . Uus-Meremaa välisminister Phil Goff võrdles Robert Mugabe juhitud Zimbabwet Pol Poti Kambodža kommunistliku terrorirežiimiga . Goff tegi oma avalduse teisipäeval , üritades veenda oma riigi kriketimeeskonda loobuma planeeritud tuurist Zimbabwesse , teatab CNN. Uus-Meremaa välisministri sõnul on tänapäeval Zimbabwes „ esimest korda alates Pol Poti päevadest näha inimeste ajamist linnadest maale , kus nad peavad elama lageda taeva all , neilt on ära võetud kõik õigused ja väärikus , mida me nimetame iga iga inimese sünniõiguseks. ” Alates 1981. aastast võimul olnud Mugabe on alustanud oma sõnul kampaaniat kuritegevuse , haiguste ja seadusetuse vastu linnades . Selle käigus hävitatakse vaeste linnaosi ja ajatakse inimesed vägisi küladesse laiali . Punakhmeeride režiimi ajal 1970-ndatel viidi julma vägivalla saatel ellu utoopiat linnadeta maostlikust-budistlikust ühiskonnast , kus kõik inimesed on põlluharijad . Zimbabwe opositsiooni kinnitusel hävitatakse vaeste linnaosi , kuna just seal on rahulolematus valitsusega kõige suurem ning toetus opositsioonile kõige suurem . Politsei on alates 19. maist hävitanud buldooseritega kümneid tuhandeid hütte , putkasid ja linna-aladel olevaid peenraid , mis on toidupuuduses vaevlevatele zimbabvelastele oluline elatisallikas . Hinnanguliselt puudutab kampaania 300 000 kuni 1,5 miljonit inimest , politsei sõnul umbes 120 000 inimest . Mustlased ründavad Mulgimaad . Naine sai Viljandimaal Tarvastu vallas mustlaste käest petta , ostes neilt kuldsõrmuste pähe vaskseid ehteid . Reedel pöördus politseisse Valgamaal elav naine , kes teatas , et paar päeva varem ostis ta Viljandimaal Tarvastu vallas tee ääres olnud mustlaste käest 1000 krooni eest kolm kuldsõrmust , mis hilisemal kontrollimisel osutusid vaskseteks , teatas Delfile Lõuna politsei pressiesindaja . Päev varem mustlaste ohvri politseisse pöördumist võttis politsei Pärnumaal kinni neli mustlast , kes tegelesid analoogse petutööga . Teateid sarnaste juhtumite kohta on tulnud ka Saaremaalt ja Järvamaalt . Allika varjamine viis USA ajakirjaniku vangi . Ühendriikide kohus saatis trellide taha New York Timesi ajakirjaniku Judith Milleri , kes keeldus avaldamast oma infoallika nime . Miller põhjendas oma vaikimist kohtus sellega , et ei saa murda oma allikale antud lubadust , vahendab PM Online New York Timesi uudist . “ Kui allikad ei saa enam ajakirjanikke usaldada , siis ei ole enam vaba ajakirjandust , ” põhjendas ta kohtu ees . Ajakirjanik tegi intervjuusid USA luureagentuuri CIA tegevuse kohta , kuid artiklit sellest materjalist ei ilmunud kunagi . Seetõttu pole ka täpselt teada , mis on kohtuasja tagamaad . CIA süüdistas ajakirjanikku “ koostööst keeldumises ” . New York Timesi hinnangul on tegemist kõige tõsisema vastuoluga võimu ja ajakirjanduse vahel alates 1971. aastast . Kopteriõnnetuses hukkus 14 inimest ( täiend ) Naissaare lähedal kukkus kolmapäeval kella 12.45 ajal merre Copterline’i helikopter 14 inimesega pardal , kõik kopteris olnud hukkusid . Peaminister Andrus Ansipi sõnul pole mingit põhjust arvata , et kopterivrakis on ellujäänuid ning ta avaldas kaastunnet omastele . Pole ka alust arvata , et kopteris oleks säilunud mingi hermeetilisus , ütles ta ajakirjanikele . Ansipi sõnul ei saanud katastroofi põhjuseks olla tuul , sest õnnetuse hetkel puhus see vaid 6m/s . Õnnetuse asjaolude uurimiseks on majandus - ja kommunikatsiooniministeeriumis moodustatud komisjon . Komisjoni esimene koosolek toimub kolmapäeva õhtul . Komisjoni aseesimehe Tõnu Aderi sõnul saab komisjon alustada tööd kohe pärast kopteri leidmist . Copterline’i juhatuse liige Tõnis Lepp ütles , et õnnetuse põhjus pole veel teada . “ Võimalikke põhjuseid on kolm — halb ilm , terror ning tehniline rike , ” vahendab Nelonen Lepa sõnu . Päästeameti peadirektori Mati Raidma sõnul oli päästjate kohale jõudes kopteri tagaosa veest väljas , kuid vajus siis vee alla . “ Me ei leidnud kedagi , ainult tükke , ” ütles ta AP-le . Raidma sõnul otsivad tuukrid inimesi 50-60 meetri sügavuselt . “ Ilmselt oli kokkupõrge veega väga tugev , ” ütles Raidma . Naissaare lähedal umbes 1,8 meremiili kaugusel Viimsi poolsaarest alla kukunud kopteris oli kaheksa soomlast , neli eestlast ning kaks USA reisijat . Kopteri piloodid olid soomlased , üks neist 41 - ning teine 57-aastane . Soomlastest reisijatest oli viis meest ja üks naine . Politsei on kõigi kopteri pardal olnud nelja Eesti kodaniku lähedastega ühendust võtnud . Copterline’i nimekirja kohaselt viibisid kopteri pardal järgmised Eesti kodanikud : Liisa ( s 1983 ) , Carolina ( s 1983 ) , Ruta ( s 1967)ja Kristel ( s 1965 ) . Kanal 2 \" Reporteri \" andmeil olid kopteris Carolina Kremetski , Liisa Suster , ärimees Oliver Kruuda abikaasa Ruta Kruuda ja õde Kristel Soll . Helsingisse teel olnud kopter väljus Tallinnast 12.40 . Lennujuhtimiskeskusel katkes side helikopteriga kell 12.43 , kolm minutit pärast startimist . Lennuteeninduse ASi juhatuse liikme Tanel Rautitsi sõnul nad mingit hädasignaali alla kukkunud kopterist ei saanud . Piirivalveameti pressiesindaja ütles , et kopter on ilmselt vee all , vee peal on tiivik ja õlilaik , aga tiivik on ilma kopterita . ASi Eesti Loots kaks laeva olid esimesed , kes sündmuskohale jõudsid . Lootsilaeva pardal olevad mehed ütlesid , et leiti üks neljameetrine tükk , aga pole täpselt teada , millega on tegemist , vahendab EPL Online . Tõnis Lepp rääkis Eesti Päevalehele , et tehniliste parameetrite poolest ei oleks pidanud kopter uppuma , sest ta oli varustatud pontoonidega ja kere on veekindel , lisaks on reisijatel päästevestid . Päästeameti operatiivkorrapidaja Alo Tammsalu ütles Äripäev Online’ile , et õnnetust juhtus binokliga nägema ka üks eraisik , kes samuti teatas õnnetusest . Naissaarel ametis olev mees ütles Äripäev Online’ile , et sealse piirivalve teatel oli kopter kukkunud otse merre , kuid saarelt seda paista pole . Mehe sõnul kukkus kopter merre Tallinn-2 poi juures , teispool Naissaart . Kopteriõnnetuse asjus algatatakse kriminaalmenetlus , öeldi Delfile riigiprokuratuurist . Menetlus alustati liiklusohutusnõuete ja õhusõiduki käitusnõuete rikkumise paragrahvi alusel . Tõnis Lepp ütles “ Aktuaalsele kaamerale ” , et üldiselt on kopteriõnnetuse puhul reisijate päästmiseks suur šanss , kuid kahjuks pole teada , millises lennu staadiumis kopter alla kukkus . Kuigi Copterline’i tehnilise hooldusega tegeldakse Soomes , mitte Eestis , kinnitas Lepp “ Aktuaalsele kaamerale ” , et võib Soome poole hoolsuse koha pealt käe südamele panna . Eesti Raadio andmetel ei hakanud kopteri päästesüsteemid mingil põhjusel tööle . Soome lennuturvalisusameti hinnangul oli Copterline’i pilootide väljaõppes ja oskustes puudusi , mis võisid seada lennuturvalisuse halva ilma korral ohtu . Helikopterid tohtisid lennata vaid hea ilmaga , vahendab YLE 24 . Copterline’i kinnitusel olid alla kukkunud kopteri piloodid hea väljaõppega ja kogenud lendajad . Informatsiooni kopteris viibinud reisijate kohta saab infotelefonilt 1345 . Tallinna pressiteenistuse teatel avati Tallinnas ka psühholoogilise kriisiabi telefon 6314 300 . Soome kapitalile kuuluv Copterline alustas regulaarlende Tallinna-Helsingi liinil 2000. aasta mais . TV3 Seitsmeste uudiste erisaade Edelaraudtee tahab piletihinda tõsta . Edelaraudtee otsustab sel nädalal , kas tõsta rongipileti hinda kuni viiendiku võrra , mis võib üle jõu käia paljudele vaesematele reisijatele , kes odava hinna tõttu rongi bussile eelistavad . Teede - ja sideministeeriumi pressiesindaja Kuldar Väärsi kinnitusel on olnud juttu kuni 20-protsendilisest hinnatõusust . “ Riigi dotatsioon moodustab 80 protsenti piletihinnast ja seda osa enam suurendada ei saa , ” ütles Väärsi Eesti Päevalehele . Edelaraudtee reisijateenistuse direktor Kalvi Puka lausus , et hinnatõus sõltub eelkõige kütusehinnast . “ Oleme piletihinna tõusu arutanud , kuid pole otsustanud , ” ütles ta . “ Nädala jooksul selgub , kas hinnatõus tuleb. ” Puka möönis , et piletihinna tõstmine viiendiku võrra oleks liiga järsk . “ Lähtudes konkurentsist teiste liiklusvahenditega ei saa me nii palju tõsta , ” tõdes ta . Praegu maksab Tallinna-Tartu rongipilet kiirrongiga 81 krooni ning tavalise rongiga 70 krooni . Pensionäride sooduspilet on aga 40 ja 35 krooni . Õpilaste soodustus on kümme protsenti . Eriti palju kasutavad rongi just sooduspiletiga sõitjad , kelle jaoks bussisõit on liiga kallis . Teede - ja sideminister Toivo Jürgensoni sõnul ootab ministeerium Edelaraudteelt jaanuari lõpuks ettepanekuid rongiliikluse edasiseks korraldamiseks , kuid seda eelarves ette nähtud dotatsioonisumma piires . “ Kokku on see Edelaraudteele 157 miljonit krooni , ” lausus Jürgenson . Esmaspäeval ametist tagandatud Jüri Kuusiku asemel Edelaraudtee tegevjuhiks saanud Henn Ruubeni sõnul tahab firma enamikul liinidest edasi sõita . “ Sel aastal oleme kompromissiga nõus , kui saame valitsusega kokkuleppe , et kunagi on võimalik saavutada ka pikemaajalisem , kaheksa kuni 10-aastane reisijateveo leping , ” lausus Ruuben . Ta pidas loogiliseks , et mõnel pool on otstarbekam rongiliiklus bussidega asendada , kuid mitte nii suures mahus nagu möödunud nädalal ähvardati . Tabati Londoni ründajate dokumendivõltsija . Tai politsei vahistas Alžeeria päritolu mehe , keda kahtlustatakse seotuses 7. augustil Londonis korraldatud pommirünnakuga . Atamnia Yacine ( 33 ) arreteeriti Bangkokis . Talle esitatakse süüdistus 130 Prantsuse ja Hispaania valepassi omamises ja viisatähtaja ületamises , vahendab ETV Online . Meest kahtlustatakse ka Londoni ühistranspordisüsteemis 52 inimese surma põhjustanud pommirünnaku korraldajate varustamises valedokumentidega . Omad kargasid Jürgensonile kõrri . Ehkki opositsiooni katse tagandada ametist teede-ja sideminister Toivo Jürgenson kukkus riigikogus teisipäeval läbi , kritiseeris vastasrinna poliitikute kõrval ministrit ka Reformierakonna fraktsiooni esimees Jürgen Ligi . “ Kui Toivo Jürgenson on teinud vigu , siis on need vead eelkõige seotud avalikkuse mitteinformeerimisega ja sellega , et riigikogule tehakse etteheiteid tema otsuste pärast , ” lausus Ligi Eesti Päevalehe teatel . Tema sõnul ei saa kuidagi nõus olla ministri süüdistustega parlamendi aadressil , kes ei andnud ligi miljardit krooni Edelaraudtee dotatsiooniks . Jürgensoni jätkamist ametis toetas siiski kogu koalitsioon . Tema umbusaldamise poolt hääletas 42 opositsioonisaadikut , kes süüdistasid ministrit peamiselt raudteel reisijateveo väljasuretamises ja Kagu-Eesti inimeste liikumisvõimaluste piiramises . Rünnakuid tõrjunud Jürgenson kinnitas , et 1. märtsiks , kui lõpeb leping Edelaraudteega , peab riik suutma kõik probleemid bussiveoga ära lahendada . Tema sõnul on eelarves piisavalt raha nii uute bussiliinide kui täiendava teede-ehituse ja teehoolduse jaoks . “ Ükski inimene ega ükski küla ei tohi jääda transporditeenuseta , ” lubas ta . Opositsioon pani Jürgensonile süüks ka raudtee põhimõttelagedat erastamist , bussiliikluses monopolide tekitamist ja maksumaksjale kalliks läinud kaadripoliitikat . NATO laskemoonast leiti rikastatud uraani . ÜRO Keskkonnaprogramm ( UNEP ) ütles kolmapäeval , et Šveitsi labor , mis uuris Kosovos kasutatud vaesustatud uraani sisaldavat NATO laskemoona , leidis sellest väikeseid koguseid radioaktiivset rikastatud uraani . UNEP sõnul on uraan 236 lisand nii väike , et laskemoon ei saanud olnud ohtlikum kui ainult vaesustatud uraani sisaldanud laskemoon . Suurem osa uraan 236-st eraldatakse uraanimaagist töötlemise käigus ja seda kasutatakse tuumaelektrijaamades . Järele jääb tunduvalt vähem radioaktiivne uraani isotoop 235 ehk vaesustatud uraan , mida selle suure tiheduse tõttu kasutatakse mürskudes ja kuulides . UNEP-i pressiesindaja Michael Williams ütles , et Ida-Šveitsis asuv Spiezi labor ei otsinud NATO laskemoonast plutooniumit . Selleks tööks valiti üks teine labor viiest Euroopa teaduskeskusest , mis Kosovo lasekemoonanäidiseid analüüsivad . “ Ma võin üksnes kinnitada , et šveitslased leidsid isotoobi U-236 , ” ütles Williams . Ülemaailmse Tervishoiuorganisatsioonil ( WHO ) ja teistel UNEP-iga koostöd tegevatel organisatsioonidel on palutud leiule hinnang anda . UNEP saatis oma missiooni Kosovosse jaanuari alguses , kui teated vähki surnud rahusõduritest vallandasid Euroopas paanika vaesustatud uraanist laskemoona üle . Neliteist eksperti kogusid 340 pinnase - , vee - ja taimkattenäidist , analüüsisid NATO rünnakutes pihta saanud hooneid ja Jugoslaavia armee autosid . Vaesustatud uraanist laskemoona jäänuseid leiti kaheksas kohast üheteiskümnest uuritust . Eestlane osales Inglismaal juveeliröövis . Kolm kurjategijat röövisid Inglismaal juveeliäri , kinni peeti Eestist pärit mees . Röövlid , kolm umbes 20-aastast meest , tegutsesid Yorkis augusti lõpus . Kuriteo toimepanemise järel peeti kinni Eesti kodanik , 21-aastane Oliver , kirjutab SL Õhtuleht . Viimastel aastatel on Eestist pärit pätid rünnanud juveeliärisid üle Euroopa , nii Saksamaal kui ka Austrias , aga ka näiteks Prantsusmaal Pariisis , kus kurjategijate saagiks langes väärisesemeid 10,5 miljoni krooni väärtuses . Pakistanis uus maavärin . Pühapäeval toimus Pakistanis taas tugev maavärin , selle tõuke tugevuseks mõõdeti 6 magnituudi . Esialgu puuduvad teated uue tõuke põhjustatud purustustest ja ohvritest . Laupäeva varahommikul Lõuna-Aasiat tabanud maavärinas on mõningail hinnanguil hukkunud üle 30 000 inimese , vigastatuid on mitu korda enam , teatab ETV Online . Sajad tuhanded inimesed on läheneva talve eel jäänud peavarju , toidu ja arstiabita . Rahvusvahelised abiorganisatsioonid ja paljud riigid on asunud saatma Pakistani ja eriti tugevalt kannatada saanud Kashmiri päästemeeskondi , päästevahendeid ja eluks ning raviks esmatarvilikku varustust . Kesk-Rootsis Karlstadis evakueeriti lennujaamast kõik reisijad ja töötajad , sest lennukompanii SAS töötaja teatas võimalikust enesetapu-pommipanijast lennujaamas . Lennujaama esindaja andmetel otsiti mitte enesetaputerroristi , vaid võimalikku mahajäetud pommi , teatab ETV Online . Põhjalike otsingute järel pommi siiski ei leitud . Värmlandi maakonnas asuv Karlstad jääb pealinnast Stockholmist 200 kilomeetri kaugusele läände . Sealset lennujaama läbib aastas ligikaudu 170 000 reisijat , enamus neist teeb siseriiklikke lende . Sellised me oleme . New Yorgis on avatud näitus inimorganismist , kus on väljas kümned inimkeha mudelid . Näitusekülastajad saavad tutvuda 22 täiesti terve inimkehaga ning lisaks sellele on eraldi väljas 260 haigusest puretut organit . Seejuures saab võrrelda üht ja sama elundit eri haigusestaadiumis . Kukumägi ähvardas Remsul jalad murda . Näitleja Arvo Kukumägi vihjab võimalusele , et ta võib kirjamees Olev Remsu jalaluud ära murda . Nimelt ei istu näitlejale , et kirjamees andis temast kui alkohoolikust aastate eest tehtud filmi „ Uuesti elus ” ETV-le näidata . ” Kui ühel päeval Remsul põlv tagurpidi lüüakse , siis on see organiseeritud , aga võta kinni , kes seda tegi , ” sõnas Kukumägi ajakirjas Teater.Muusika.Kino. viimases numbris . Samas tõmbab ta ähvarduse kraadi võrra mahedamaks ja ütleb , et kuigi ta setu veri ütleb , et peaks natuke verd laskma , ei viitsi ta siiski istuma minna , vahendab SL Õhtuleht . „ See ei olegi film , lihtsalt oksenduse hunnik , ” räägib Kukumägi , miks talle film ei meeldi . Remsu oli talle öelnud , et film tehakse näitamiseks AA jaoks , kuid oli selle siiski „ sitase raha eest ” Eesti Televisioonile maha müünud . Remsu vastab Kukumägi süüdistustele , et mees pole iialgi tema poole isiklikult pöördunud , on ainult selja taga klatšinud . „ Tegemist on ju kriminaalse asjaga , see on ju kriminaalne süüdistus , ” kommenteerib ta Kukumägi ähvardusi . Samas heidab Remsu Kukumägile ette liigset rahahimu . Nimelt oli näitleja dokumentaalfilmis esinemise eest raha küsinud , mis polevat tavaks . Blair valmis loobuma EL tagasimaksest . Briti peaminister Tony Blair on valmis loobuma iga-aastasest tagasimaksest Euroopa Liidu eelarvest , mille tema eelkäija Margaret Thatcher 1984. aastal Brüsselist välja kauples . Tänu tagasimaksele väldib Suurbritannia euroliidu liikmelisusele massilise pealemaksmise . Järeleandmine on tingitud tõsisest survest Blairile ja Briti välisministeeriumile teiste liikmesriikide liidrite poolt . Briti tagasimakse on kujunenud üheks tähtsamaks takistuseks euroliidu eelarve kokku leppimisel ajavahemikuks aastatel 2007 kuni 2013 , teatab The Telegraph . Suurbritannia saab igal aastal Brüsselilt tagasi umbes kolm miljardit naela ( 70 miljardit krooni ) . Opositsiooniline konservatiivne partei süüdistas Blairi „ allaandmises “ , nii konservatiivid kui Blair ise on varem kinnitanud , et tagasimaksest loobumine on mõeldav vaid juhul , kui Prantsusmaa nõustub reformima Pariisile ülikasulikku ühist põllumajanduspoliitikat ( CAP ) . Pariis mingeid järeleandmisi teinud ei ole . Välisminister Jack Straw keeldus andmast parlamendi alamkojas kinnitust sellele , et tagasimakse säilib isegi juhul , kui Prantsusmaa ei tee omapoolseid järeleandmisi põllumajanduspoliitika osas . „ Tagasimaksel on oma põhjus , see on olemas ühise põllumajanduspoliitika maksete ebakõlade tõttu . Kui meil poleks tagasimakset , maksaks me veel rohkem peale euroliidu kassasse , kui me praegu juba maksame , “ ütles Blair esinedes ärimeestele . Juunis pani Blair veto ettepanekule , millega oleks külmutatud Briti tagasimakse suurus tulevikus . Kutsekoolide õpetajatel napib õiget haridust . Vähemalt veerandi kutsekoolide õpetajatest peaks haridusministeeriumi järelevalve tulemuste kohaselt saatma ümberõppele . Mullu 11 kutsekoolis tehtud järelevalve uuring näitas , et 14 protsenti erialase kutseõppe ja 22 protsenti üldhariduslikke aineid õpetavate pedagoogide teadmised ei vasta nõuetele , kirjutab Postimees . Järelevalvearuandes märgitakse , et probleemi lahendamiseks on äärmiselt oluline kutseõpetajate täiend - ja ümberõpe . Peaprobleem on haridusministeeriumi järelevalvetalituse juhataja Hille Vooremäe sõnul selles , et üldhariduses polnud õpetajatel kõrgharidust õpetatavas valdkonnas ja kutseõpetajatel konkreetse õppekava valdkonnas . “ Tulemuse viis alla ka see , et suur osa oli eraõppeasutusi — eriti mõjutas tulemusi halvemuse suunas üks konkreetne kool — R-Stamp Tallinnas , ” märkis Vooremäe .')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = conll_to_ner_labelling(\"data/ner_train.cnll\")\n",
    "text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up model parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from estnltk.taggers.ner.ner_trainer import NerTrainer\n",
    "from estnltk.taggers.ner.model_storage_util import ModelStorageUtil\n",
    "from estnltk.core import DEFAULT_PY3_NER_MODEL_DIR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load CRFsuite model meta parameters. By default parameters are located in ... settings.py file which describes: \n",
    "* label classes (ORG, PER, LOC)\n",
    "* metaparameters for training (CRFSUITE_ALGORITHM, CRFSUITE_C2)\n",
    "* file of known entities (GAZETTEER_FILE)\n",
    "* basic features (TEMPLATES)\n",
    "* feature extractors (FEATURE_EXTRACTORS)\n",
    "\n",
    "For more details, look at CRFsuite documentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dir=DEFAULT_PY3_NER_MODEL_DIR\n",
    "modelUtil = ModelStorageUtil(model_dir)\n",
    "nersettings = modelUtil.load_settings()\n",
    "trainer = NerTrainer(nersettings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training a new model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model takes a long time to train."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature generation\n",
      "type: CRF1d\n",
      "feature.minfreq: 0.000000\n",
      "feature.possible_states: 0\n",
      "feature.possible_transitions: 0\n",
      "0....1....2....3....4....5....6....7....8....9....10\n",
      "Number of features: 24857\n",
      "Seconds required: 0.053\n",
      "\n",
      "Stochastic Gradient Descent (SGD)\n",
      "c2: 0.001000\n",
      "max_iterations: 1000\n",
      "period: 10\n",
      "delta: 0.000001\n",
      "\n",
      "Calibrating the learning rate (eta)\n",
      "calibration.eta: 0.100000\n",
      "calibration.rate: 2.000000\n",
      "calibration.samples: 270\n",
      "calibration.candidates: 10\n",
      "calibration.max_trials: 20\n",
      "Initial loss: 9190.533634\n",
      "Trial #1 (eta = 0.100000): 714.150545\n",
      "Trial #2 (eta = 0.200000): 883.787116\n",
      "Trial #3 (eta = 0.400000): 1692.969284\n",
      "Trial #4 (eta = 0.800000): 3419.601676\n",
      "Trial #5 (eta = 1.600000): 7225.137865\n",
      "Trial #6 (eta = 3.200000): 14022.291626 (worse)\n",
      "Trial #7 (eta = 0.050000): 769.813126\n",
      "Trial #8 (eta = 0.025000): 933.905777\n",
      "Trial #9 (eta = 0.012500): 1189.742954\n",
      "Trial #10 (eta = 0.006250): 1547.141925\n",
      "Trial #11 (eta = 0.003125): 2024.577624\n",
      "Trial #12 (eta = 0.001563): 2653.318095\n",
      "Trial #13 (eta = 0.000781): 3482.269880\n",
      "Trial #14 (eta = 0.000391): 4635.338563\n",
      "Trial #15 (eta = 0.000195): 6132.019304\n",
      "Trial #16 (eta = 0.000098): 7455.363910\n",
      "Best learning rate (eta): 0.100000\n",
      "Seconds required: 0.126\n",
      "\n",
      "***** Epoch #1 *****\n",
      "Loss: 705.382583\n",
      "Feature L2-norm: 11.159689\n",
      "Learning rate (eta): 0.099980\n",
      "Total number of feature updates: 270\n",
      "Seconds required for this iteration: 0.010\n",
      "\n",
      "***** Epoch #2 *****\n",
      "Loss: 194.071554\n",
      "Feature L2-norm: 13.667855\n",
      "Learning rate (eta): 0.099960\n",
      "Total number of feature updates: 540\n",
      "Seconds required for this iteration: 0.007\n",
      "\n",
      "***** Epoch #3 *****\n",
      "Loss: 94.852893\n",
      "Feature L2-norm: 15.165127\n",
      "Learning rate (eta): 0.099940\n",
      "Total number of feature updates: 810\n",
      "Seconds required for this iteration: 0.017\n",
      "\n",
      "***** Epoch #4 *****\n",
      "Loss: 55.792125\n",
      "Feature L2-norm: 16.165673\n",
      "Learning rate (eta): 0.099920\n",
      "Total number of feature updates: 1080\n",
      "Seconds required for this iteration: 0.008\n",
      "\n",
      "***** Epoch #5 *****\n",
      "Loss: 39.468672\n",
      "Feature L2-norm: 16.924678\n",
      "Learning rate (eta): 0.099900\n",
      "Total number of feature updates: 1350\n",
      "Seconds required for this iteration: 0.008\n",
      "\n",
      "***** Epoch #6 *****\n",
      "Loss: 30.877807\n",
      "Feature L2-norm: 17.538035\n",
      "Learning rate (eta): 0.099880\n",
      "Total number of feature updates: 1620\n",
      "Seconds required for this iteration: 0.007\n",
      "\n",
      "***** Epoch #7 *****\n",
      "Loss: 24.768140\n",
      "Feature L2-norm: 18.048483\n",
      "Learning rate (eta): 0.099860\n",
      "Total number of feature updates: 1890\n",
      "Seconds required for this iteration: 0.008\n",
      "\n",
      "***** Epoch #8 *****\n",
      "Loss: 21.460460\n",
      "Feature L2-norm: 18.489530\n",
      "Learning rate (eta): 0.099840\n",
      "Total number of feature updates: 2160\n",
      "Seconds required for this iteration: 0.007\n",
      "\n",
      "***** Epoch #9 *****\n",
      "Loss: 18.692893\n",
      "Feature L2-norm: 18.883845\n",
      "Learning rate (eta): 0.099820\n",
      "Total number of feature updates: 2430\n",
      "Seconds required for this iteration: 0.008\n",
      "\n",
      "***** Epoch #10 *****\n",
      "Loss: 16.798897\n",
      "Feature L2-norm: 19.240007\n",
      "Learning rate (eta): 0.099800\n",
      "Total number of feature updates: 2700\n",
      "Seconds required for this iteration: 0.007\n",
      "\n",
      "***** Epoch #11 *****\n",
      "Loss: 15.057977\n",
      "Improvement ratio: 45.844447\n",
      "Feature L2-norm: 19.558892\n",
      "Learning rate (eta): 0.099781\n",
      "Total number of feature updates: 2970\n",
      "Seconds required for this iteration: 0.008\n",
      "\n",
      "***** Epoch #12 *****\n",
      "Loss: 13.918408\n",
      "Improvement ratio: 12.943516\n",
      "Feature L2-norm: 19.853292\n",
      "Learning rate (eta): 0.099761\n",
      "Total number of feature updates: 3240\n",
      "Seconds required for this iteration: 0.011\n",
      "\n",
      "***** Epoch #13 *****\n",
      "Loss: 12.792350\n",
      "Improvement ratio: 6.414814\n",
      "Feature L2-norm: 20.122490\n",
      "Learning rate (eta): 0.099741\n",
      "Total number of feature updates: 3510\n",
      "Seconds required for this iteration: 0.012\n",
      "\n",
      "***** Epoch #14 *****\n",
      "Loss: 11.957062\n",
      "Improvement ratio: 3.666039\n",
      "Feature L2-norm: 20.374308\n",
      "Learning rate (eta): 0.099721\n",
      "Total number of feature updates: 3780\n",
      "Seconds required for this iteration: 0.012\n",
      "\n",
      "***** Epoch #15 *****\n",
      "Loss: 11.185781\n",
      "Improvement ratio: 2.528468\n",
      "Feature L2-norm: 20.608865\n",
      "Learning rate (eta): 0.099701\n",
      "Total number of feature updates: 4050\n",
      "Seconds required for this iteration: 0.011\n",
      "\n",
      "***** Epoch #16 *****\n",
      "Loss: 10.514858\n",
      "Improvement ratio: 1.936588\n",
      "Feature L2-norm: 20.829381\n",
      "Learning rate (eta): 0.099681\n",
      "Total number of feature updates: 4320\n",
      "Seconds required for this iteration: 0.010\n",
      "\n",
      "***** Epoch #17 *****\n",
      "Loss: 9.990836\n",
      "Improvement ratio: 1.479086\n",
      "Feature L2-norm: 21.037025\n",
      "Learning rate (eta): 0.099661\n",
      "Total number of feature updates: 4590\n",
      "Seconds required for this iteration: 0.010\n",
      "\n",
      "***** Epoch #18 *****\n",
      "Loss: 9.401086\n",
      "Improvement ratio: 1.282764\n",
      "Feature L2-norm: 21.233993\n",
      "Learning rate (eta): 0.099641\n",
      "Total number of feature updates: 4860\n",
      "Seconds required for this iteration: 0.009\n",
      "\n",
      "***** Epoch #19 *****\n",
      "Loss: 8.940833\n",
      "Improvement ratio: 1.090733\n",
      "Feature L2-norm: 21.419770\n",
      "Learning rate (eta): 0.099622\n",
      "Total number of feature updates: 5130\n",
      "Seconds required for this iteration: 0.009\n",
      "\n",
      "***** Epoch #20 *****\n",
      "Loss: 8.573662\n",
      "Improvement ratio: 0.959361\n",
      "Feature L2-norm: 21.597561\n",
      "Learning rate (eta): 0.099602\n",
      "Total number of feature updates: 5400\n",
      "Seconds required for this iteration: 0.008\n",
      "\n",
      "***** Epoch #21 *****\n",
      "Loss: 8.192657\n",
      "Improvement ratio: 0.837984\n",
      "Feature L2-norm: 21.766471\n",
      "Learning rate (eta): 0.099582\n",
      "Total number of feature updates: 5670\n",
      "Seconds required for this iteration: 0.008\n",
      "\n",
      "***** Epoch #22 *****\n",
      "Loss: 7.843801\n",
      "Improvement ratio: 0.774447\n",
      "Feature L2-norm: 21.926773\n",
      "Learning rate (eta): 0.099562\n",
      "Total number of feature updates: 5940\n",
      "Seconds required for this iteration: 0.008\n",
      "\n",
      "***** Epoch #23 *****\n",
      "Loss: 7.561440\n",
      "Improvement ratio: 0.691788\n",
      "Feature L2-norm: 22.081131\n",
      "Learning rate (eta): 0.099542\n",
      "Total number of feature updates: 6210\n",
      "Seconds required for this iteration: 0.008\n",
      "\n",
      "***** Epoch #24 *****\n",
      "Loss: 7.297061\n",
      "Improvement ratio: 0.638614\n",
      "Feature L2-norm: 22.229627\n",
      "Learning rate (eta): 0.099522\n",
      "Total number of feature updates: 6480\n",
      "Seconds required for this iteration: 0.008\n",
      "\n",
      "***** Epoch #25 *****\n",
      "Loss: 7.045138\n",
      "Improvement ratio: 0.587731\n",
      "Feature L2-norm: 22.371685\n",
      "Learning rate (eta): 0.099503\n",
      "Total number of feature updates: 6750\n",
      "Seconds required for this iteration: 0.009\n",
      "\n",
      "***** Epoch #26 *****\n",
      "Loss: 6.763000\n",
      "Improvement ratio: 0.554762\n",
      "Feature L2-norm: 22.508518\n",
      "Learning rate (eta): 0.099483\n",
      "Total number of feature updates: 7020\n",
      "Seconds required for this iteration: 0.008\n",
      "\n",
      "***** Epoch #27 *****\n",
      "Loss: 6.582538\n",
      "Improvement ratio: 0.517779\n",
      "Feature L2-norm: 22.640126\n",
      "Learning rate (eta): 0.099463\n",
      "Total number of feature updates: 7290\n",
      "Seconds required for this iteration: 0.008\n",
      "\n",
      "***** Epoch #28 *****\n",
      "Loss: 6.367462\n",
      "Improvement ratio: 0.476426\n",
      "Feature L2-norm: 22.767169\n",
      "Learning rate (eta): 0.099443\n",
      "Total number of feature updates: 7560\n",
      "Seconds required for this iteration: 0.008\n",
      "\n",
      "***** Epoch #29 *****\n",
      "Loss: 6.187006\n",
      "Improvement ratio: 0.445099\n",
      "Feature L2-norm: 22.889989\n",
      "Learning rate (eta): 0.099423\n",
      "Total number of feature updates: 7830\n",
      "Seconds required for this iteration: 0.008\n",
      "\n",
      "***** Epoch #30 *****\n",
      "Loss: 6.026364\n",
      "Improvement ratio: 0.422692\n",
      "Feature L2-norm: 23.008943\n",
      "Learning rate (eta): 0.099404\n",
      "Total number of feature updates: 8100\n",
      "Seconds required for this iteration: 0.008\n",
      "\n",
      "***** Epoch #31 *****\n",
      "Loss: 5.856631\n",
      "Improvement ratio: 0.398869\n",
      "Feature L2-norm: 23.123779\n",
      "Learning rate (eta): 0.099384\n",
      "Total number of feature updates: 8370\n",
      "Seconds required for this iteration: 0.008\n",
      "\n",
      "***** Epoch #32 *****\n",
      "Loss: 5.697453\n",
      "Improvement ratio: 0.376721\n",
      "Feature L2-norm: 23.235176\n",
      "Learning rate (eta): 0.099364\n",
      "Total number of feature updates: 8640\n",
      "Seconds required for this iteration: 0.008\n",
      "\n",
      "***** Epoch #33 *****\n",
      "Loss: 5.561244\n",
      "Improvement ratio: 0.359667\n",
      "Feature L2-norm: 23.343347\n",
      "Learning rate (eta): 0.099344\n",
      "Total number of feature updates: 8910\n",
      "Seconds required for this iteration: 0.008\n",
      "\n",
      "***** Epoch #34 *****\n",
      "Loss: 5.405855\n",
      "Improvement ratio: 0.349844\n",
      "Feature L2-norm: 23.448199\n",
      "Learning rate (eta): 0.099325\n",
      "Total number of feature updates: 9180\n",
      "Seconds required for this iteration: 0.007\n",
      "\n",
      "***** Epoch #35 *****\n",
      "Loss: 5.302729\n",
      "Improvement ratio: 0.328587\n",
      "Feature L2-norm: 23.550214\n",
      "Learning rate (eta): 0.099305\n",
      "Total number of feature updates: 9450\n",
      "Seconds required for this iteration: 0.007\n",
      "\n",
      "***** Epoch #36 *****\n",
      "Loss: 5.176212\n",
      "Improvement ratio: 0.306554\n",
      "Feature L2-norm: 23.649905\n",
      "Learning rate (eta): 0.099285\n",
      "Total number of feature updates: 9720\n",
      "Seconds required for this iteration: 0.008\n",
      "\n",
      "***** Epoch #37 *****\n",
      "Loss: 5.052407\n",
      "Improvement ratio: 0.302852\n",
      "Feature L2-norm: 23.746135\n",
      "Learning rate (eta): 0.099266\n",
      "Total number of feature updates: 9990\n",
      "Seconds required for this iteration: 0.008\n",
      "\n",
      "***** Epoch #38 *****\n",
      "Loss: 4.960779\n",
      "Improvement ratio: 0.283561\n",
      "Feature L2-norm: 23.840243\n",
      "Learning rate (eta): 0.099246\n",
      "Total number of feature updates: 10260\n",
      "Seconds required for this iteration: 0.008\n",
      "\n",
      "***** Epoch #39 *****\n",
      "Loss: 4.842681\n",
      "Improvement ratio: 0.277599\n",
      "Feature L2-norm: 23.931887\n",
      "Learning rate (eta): 0.099226\n",
      "Total number of feature updates: 10530\n",
      "Seconds required for this iteration: 0.008\n",
      "\n",
      "***** Epoch #40 *****\n",
      "Loss: 4.768618\n",
      "Improvement ratio: 0.263755\n",
      "Feature L2-norm: 24.021565\n",
      "Learning rate (eta): 0.099206\n",
      "Total number of feature updates: 10800\n",
      "Seconds required for this iteration: 0.011\n",
      "\n",
      "***** Epoch #41 *****\n",
      "Loss: 4.663679\n",
      "Improvement ratio: 0.255796\n",
      "Feature L2-norm: 24.108768\n",
      "Learning rate (eta): 0.099187\n",
      "Total number of feature updates: 11070\n",
      "Seconds required for this iteration: 0.009\n",
      "\n",
      "***** Epoch #42 *****\n",
      "Loss: 4.586497\n",
      "Improvement ratio: 0.242223\n",
      "Feature L2-norm: 24.194188\n",
      "Learning rate (eta): 0.099167\n",
      "Total number of feature updates: 11340\n",
      "Seconds required for this iteration: 0.010\n",
      "\n",
      "***** Epoch #43 *****\n",
      "Loss: 4.498171\n",
      "Improvement ratio: 0.236334\n",
      "Feature L2-norm: 24.277534\n",
      "Learning rate (eta): 0.099147\n",
      "Total number of feature updates: 11610\n",
      "Seconds required for this iteration: 0.012\n",
      "\n",
      "***** Epoch #44 *****\n",
      "Loss: 4.421494\n",
      "Improvement ratio: 0.222631\n",
      "Feature L2-norm: 24.358902\n",
      "Learning rate (eta): 0.099128\n",
      "Total number of feature updates: 11880\n",
      "Seconds required for this iteration: 0.009\n",
      "\n",
      "***** Epoch #45 *****\n",
      "Loss: 4.348513\n",
      "Improvement ratio: 0.219435\n",
      "Feature L2-norm: 24.438462\n",
      "Learning rate (eta): 0.099108\n",
      "Total number of feature updates: 12150\n",
      "Seconds required for this iteration: 0.011\n",
      "\n",
      "***** Epoch #46 *****\n",
      "Loss: 4.271978\n",
      "Improvement ratio: 0.211666\n",
      "Feature L2-norm: 24.516310\n",
      "Learning rate (eta): 0.099088\n",
      "Total number of feature updates: 12420\n",
      "Seconds required for this iteration: 0.009\n",
      "\n",
      "***** Epoch #47 *****\n",
      "Loss: 4.205970\n",
      "Improvement ratio: 0.201247\n",
      "Feature L2-norm: 24.592563\n",
      "Learning rate (eta): 0.099069\n",
      "Total number of feature updates: 12690\n",
      "Seconds required for this iteration: 0.010\n",
      "\n",
      "***** Epoch #48 *****\n",
      "Loss: 4.140946\n",
      "Improvement ratio: 0.197982\n",
      "Feature L2-norm: 24.667034\n",
      "Learning rate (eta): 0.099049\n",
      "Total number of feature updates: 12960\n",
      "Seconds required for this iteration: 0.008\n",
      "\n",
      "***** Epoch #49 *****\n",
      "Loss: 4.075630\n",
      "Improvement ratio: 0.188204\n",
      "Feature L2-norm: 24.740124\n",
      "Learning rate (eta): 0.099030\n",
      "Total number of feature updates: 13230\n",
      "Seconds required for this iteration: 0.008\n",
      "\n",
      "***** Epoch #50 *****\n",
      "Loss: 4.012348\n",
      "Improvement ratio: 0.188486\n",
      "Feature L2-norm: 24.811688\n",
      "Learning rate (eta): 0.099010\n",
      "Total number of feature updates: 13500\n",
      "Seconds required for this iteration: 0.009\n",
      "\n",
      "***** Epoch #51 *****\n",
      "Loss: 3.953555\n",
      "Improvement ratio: 0.179617\n",
      "Feature L2-norm: 24.881792\n",
      "Learning rate (eta): 0.098990\n",
      "Total number of feature updates: 13770\n",
      "Seconds required for this iteration: 0.008\n",
      "\n",
      "***** Epoch #52 *****\n",
      "Loss: 3.900371\n",
      "Improvement ratio: 0.175913\n",
      "Feature L2-norm: 24.950671\n",
      "Learning rate (eta): 0.098971\n",
      "Total number of feature updates: 14040\n",
      "Seconds required for this iteration: 0.008\n",
      "\n",
      "***** Epoch #53 *****\n",
      "Loss: 3.844115\n",
      "Improvement ratio: 0.170145\n",
      "Feature L2-norm: 25.018199\n",
      "Learning rate (eta): 0.098951\n",
      "Total number of feature updates: 14310\n",
      "Seconds required for this iteration: 0.007\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** Epoch #54 *****\n",
      "Loss: 3.794627\n",
      "Improvement ratio: 0.165199\n",
      "Feature L2-norm: 25.084452\n",
      "Learning rate (eta): 0.098932\n",
      "Total number of feature updates: 14580\n",
      "Seconds required for this iteration: 0.009\n",
      "\n",
      "***** Epoch #55 *****\n",
      "Loss: 3.743912\n",
      "Improvement ratio: 0.161489\n",
      "Feature L2-norm: 25.149557\n",
      "Learning rate (eta): 0.098912\n",
      "Total number of feature updates: 14850\n",
      "Seconds required for this iteration: 0.008\n",
      "\n",
      "***** Epoch #56 *****\n",
      "Loss: 3.697588\n",
      "Improvement ratio: 0.155342\n",
      "Feature L2-norm: 25.213430\n",
      "Learning rate (eta): 0.098892\n",
      "Total number of feature updates: 15120\n",
      "Seconds required for this iteration: 0.008\n",
      "\n",
      "***** Epoch #57 *****\n",
      "Loss: 3.649177\n",
      "Improvement ratio: 0.152581\n",
      "Feature L2-norm: 25.276222\n",
      "Learning rate (eta): 0.098873\n",
      "Total number of feature updates: 15390\n",
      "Seconds required for this iteration: 0.008\n",
      "\n",
      "***** Epoch #58 *****\n",
      "Loss: 3.604742\n",
      "Improvement ratio: 0.148750\n",
      "Feature L2-norm: 25.337852\n",
      "Learning rate (eta): 0.098853\n",
      "Total number of feature updates: 15660\n",
      "Seconds required for this iteration: 0.008\n",
      "\n",
      "***** Epoch #59 *****\n",
      "Loss: 3.557993\n",
      "Improvement ratio: 0.145486\n",
      "Feature L2-norm: 25.398541\n",
      "Learning rate (eta): 0.098834\n",
      "Total number of feature updates: 15930\n",
      "Seconds required for this iteration: 0.008\n",
      "\n",
      "***** Epoch #60 *****\n",
      "Loss: 3.520864\n",
      "Improvement ratio: 0.139592\n",
      "Feature L2-norm: 25.457966\n",
      "Learning rate (eta): 0.098814\n",
      "Total number of feature updates: 16200\n",
      "Seconds required for this iteration: 0.008\n",
      "\n",
      "***** Epoch #61 *****\n",
      "Loss: 3.478700\n",
      "Improvement ratio: 0.136504\n",
      "Feature L2-norm: 25.516413\n",
      "Learning rate (eta): 0.098795\n",
      "Total number of feature updates: 16470\n",
      "Seconds required for this iteration: 0.008\n",
      "\n",
      "***** Epoch #62 *****\n",
      "Loss: 3.441468\n",
      "Improvement ratio: 0.133345\n",
      "Feature L2-norm: 25.574068\n",
      "Learning rate (eta): 0.098775\n",
      "Total number of feature updates: 16740\n",
      "Seconds required for this iteration: 0.008\n",
      "\n",
      "***** Epoch #63 *****\n",
      "Loss: 3.402625\n",
      "Improvement ratio: 0.129750\n",
      "Feature L2-norm: 25.630767\n",
      "Learning rate (eta): 0.098756\n",
      "Total number of feature updates: 17010\n",
      "Seconds required for this iteration: 0.012\n",
      "\n",
      "***** Epoch #64 *****\n",
      "Loss: 3.366846\n",
      "Improvement ratio: 0.127057\n",
      "Feature L2-norm: 25.686626\n",
      "Learning rate (eta): 0.098736\n",
      "Total number of feature updates: 17280\n",
      "Seconds required for this iteration: 0.009\n",
      "\n",
      "***** Epoch #65 *****\n",
      "Loss: 3.331814\n",
      "Improvement ratio: 0.123686\n",
      "Feature L2-norm: 25.741531\n",
      "Learning rate (eta): 0.098717\n",
      "Total number of feature updates: 17550\n",
      "Seconds required for this iteration: 0.010\n",
      "\n",
      "***** Epoch #66 *****\n",
      "Loss: 3.297154\n",
      "Improvement ratio: 0.121449\n",
      "Feature L2-norm: 25.795659\n",
      "Learning rate (eta): 0.098697\n",
      "Total number of feature updates: 17820\n",
      "Seconds required for this iteration: 0.008\n",
      "\n",
      "***** Epoch #67 *****\n",
      "Loss: 3.262532\n",
      "Improvement ratio: 0.118510\n",
      "Feature L2-norm: 25.848900\n",
      "Learning rate (eta): 0.098678\n",
      "Total number of feature updates: 18090\n",
      "Seconds required for this iteration: 0.008\n",
      "\n",
      "***** Epoch #68 *****\n",
      "Loss: 3.230062\n",
      "Improvement ratio: 0.115998\n",
      "Feature L2-norm: 25.901437\n",
      "Learning rate (eta): 0.098658\n",
      "Total number of feature updates: 18360\n",
      "Seconds required for this iteration: 0.009\n",
      "\n",
      "***** Epoch #69 *****\n",
      "Loss: 3.200826\n",
      "Improvement ratio: 0.111586\n",
      "Feature L2-norm: 25.953146\n",
      "Learning rate (eta): 0.098639\n",
      "Total number of feature updates: 18630\n",
      "Seconds required for this iteration: 0.008\n",
      "\n",
      "***** Epoch #70 *****\n",
      "Loss: 3.170317\n",
      "Improvement ratio: 0.110572\n",
      "Feature L2-norm: 26.003960\n",
      "Learning rate (eta): 0.098619\n",
      "Total number of feature updates: 18900\n",
      "Seconds required for this iteration: 0.008\n",
      "\n",
      "***** Epoch #71 *****\n",
      "Loss: 3.140682\n",
      "Improvement ratio: 0.107626\n",
      "Feature L2-norm: 26.054128\n",
      "Learning rate (eta): 0.098600\n",
      "Total number of feature updates: 19170\n",
      "Seconds required for this iteration: 0.010\n",
      "\n",
      "***** Epoch #72 *****\n",
      "Loss: 3.112583\n",
      "Improvement ratio: 0.105663\n",
      "Feature L2-norm: 26.103532\n",
      "Learning rate (eta): 0.098581\n",
      "Total number of feature updates: 19440\n",
      "Seconds required for this iteration: 0.009\n",
      "\n",
      "***** Epoch #73 *****\n",
      "Loss: 3.084027\n",
      "Improvement ratio: 0.103306\n",
      "Feature L2-norm: 26.152375\n",
      "Learning rate (eta): 0.098561\n",
      "Total number of feature updates: 19710\n",
      "Seconds required for this iteration: 0.008\n",
      "\n",
      "***** Epoch #74 *****\n",
      "Loss: 3.057045\n",
      "Improvement ratio: 0.101340\n",
      "Feature L2-norm: 26.200527\n",
      "Learning rate (eta): 0.098542\n",
      "Total number of feature updates: 19980\n",
      "Seconds required for this iteration: 0.008\n",
      "\n",
      "***** Epoch #75 *****\n",
      "Loss: 3.031888\n",
      "Improvement ratio: 0.098924\n",
      "Feature L2-norm: 26.247985\n",
      "Learning rate (eta): 0.098522\n",
      "Total number of feature updates: 20250\n",
      "Seconds required for this iteration: 0.009\n",
      "\n",
      "***** Epoch #76 *****\n",
      "Loss: 3.005568\n",
      "Improvement ratio: 0.097015\n",
      "Feature L2-norm: 26.294738\n",
      "Learning rate (eta): 0.098503\n",
      "Total number of feature updates: 20520\n",
      "Seconds required for this iteration: 0.008\n",
      "\n",
      "***** Epoch #77 *****\n",
      "Loss: 2.981152\n",
      "Improvement ratio: 0.094386\n",
      "Feature L2-norm: 26.340918\n",
      "Learning rate (eta): 0.098483\n",
      "Total number of feature updates: 20790\n",
      "Seconds required for this iteration: 0.008\n",
      "\n",
      "***** Epoch #78 *****\n",
      "Loss: 2.957058\n",
      "Improvement ratio: 0.092323\n",
      "Feature L2-norm: 26.386463\n",
      "Learning rate (eta): 0.098464\n",
      "Total number of feature updates: 21060\n",
      "Seconds required for this iteration: 0.008\n",
      "\n",
      "***** Epoch #79 *****\n",
      "Loss: 2.933067\n",
      "Improvement ratio: 0.091290\n",
      "Feature L2-norm: 26.431436\n",
      "Learning rate (eta): 0.098445\n",
      "Total number of feature updates: 21330\n",
      "Seconds required for this iteration: 0.008\n",
      "\n",
      "***** Epoch #80 *****\n",
      "Loss: 2.910322\n",
      "Improvement ratio: 0.089335\n",
      "Feature L2-norm: 26.475806\n",
      "Learning rate (eta): 0.098425\n",
      "Total number of feature updates: 21600\n",
      "Seconds required for this iteration: 0.009\n",
      "\n",
      "***** Epoch #81 *****\n",
      "Loss: 2.888037\n",
      "Improvement ratio: 0.087480\n",
      "Feature L2-norm: 26.519597\n",
      "Learning rate (eta): 0.098406\n",
      "Total number of feature updates: 21870\n",
      "Seconds required for this iteration: 0.008\n",
      "\n",
      "***** Epoch #82 *****\n",
      "Loss: 2.864689\n",
      "Improvement ratio: 0.086534\n",
      "Feature L2-norm: 26.562883\n",
      "Learning rate (eta): 0.098387\n",
      "Total number of feature updates: 22140\n",
      "Seconds required for this iteration: 0.008\n",
      "\n",
      "***** Epoch #83 *****\n",
      "Loss: 2.845316\n",
      "Improvement ratio: 0.083896\n",
      "Feature L2-norm: 26.605508\n",
      "Learning rate (eta): 0.098367\n",
      "Total number of feature updates: 22410\n",
      "Seconds required for this iteration: 0.008\n",
      "\n",
      "***** Epoch #84 *****\n",
      "Loss: 2.823602\n",
      "Improvement ratio: 0.082676\n",
      "Feature L2-norm: 26.647649\n",
      "Learning rate (eta): 0.098348\n",
      "Total number of feature updates: 22680\n",
      "Seconds required for this iteration: 0.008\n",
      "\n",
      "***** Epoch #85 *****\n",
      "Loss: 2.802597\n",
      "Improvement ratio: 0.081814\n",
      "Feature L2-norm: 26.689324\n",
      "Learning rate (eta): 0.098328\n",
      "Total number of feature updates: 22950\n",
      "Seconds required for this iteration: 0.008\n",
      "\n",
      "***** Epoch #86 *****\n",
      "Loss: 2.784344\n",
      "Improvement ratio: 0.079453\n",
      "Feature L2-norm: 26.730519\n",
      "Learning rate (eta): 0.098309\n",
      "Total number of feature updates: 23220\n",
      "Seconds required for this iteration: 0.009\n",
      "\n",
      "***** Epoch #87 *****\n",
      "Loss: 2.765391\n",
      "Improvement ratio: 0.078022\n",
      "Feature L2-norm: 26.771131\n",
      "Learning rate (eta): 0.098290\n",
      "Total number of feature updates: 23490\n",
      "Seconds required for this iteration: 0.009\n",
      "\n",
      "***** Epoch #88 *****\n",
      "Loss: 2.746115\n",
      "Improvement ratio: 0.076815\n",
      "Feature L2-norm: 26.811370\n",
      "Learning rate (eta): 0.098271\n",
      "Total number of feature updates: 23760\n",
      "Seconds required for this iteration: 0.010\n",
      "\n",
      "***** Epoch #89 *****\n",
      "Loss: 2.727765\n",
      "Improvement ratio: 0.075264\n",
      "Feature L2-norm: 26.851059\n",
      "Learning rate (eta): 0.098251\n",
      "Total number of feature updates: 24030\n",
      "Seconds required for this iteration: 0.009\n",
      "\n",
      "***** Epoch #90 *****\n",
      "Loss: 2.710525\n",
      "Improvement ratio: 0.073712\n",
      "Feature L2-norm: 26.890276\n",
      "Learning rate (eta): 0.098232\n",
      "Total number of feature updates: 24300\n",
      "Seconds required for this iteration: 0.009\n",
      "\n",
      "***** Epoch #91 *****\n",
      "Loss: 2.691239\n",
      "Improvement ratio: 0.073126\n",
      "Feature L2-norm: 26.929136\n",
      "Learning rate (eta): 0.098213\n",
      "Total number of feature updates: 24570\n",
      "Seconds required for this iteration: 0.008\n",
      "\n",
      "***** Epoch #92 *****\n",
      "Loss: 2.675524\n",
      "Improvement ratio: 0.070702\n",
      "Feature L2-norm: 26.967466\n",
      "Learning rate (eta): 0.098193\n",
      "Total number of feature updates: 24840\n",
      "Seconds required for this iteration: 0.009\n",
      "\n",
      "***** Epoch #93 *****\n",
      "Loss: 2.658651\n",
      "Improvement ratio: 0.070211\n",
      "Feature L2-norm: 27.005384\n",
      "Learning rate (eta): 0.098174\n",
      "Total number of feature updates: 25110\n",
      "Seconds required for this iteration: 0.008\n",
      "\n",
      "***** Epoch #94 *****\n",
      "Loss: 2.642349\n",
      "Improvement ratio: 0.068596\n",
      "Feature L2-norm: 27.042837\n",
      "Learning rate (eta): 0.098155\n",
      "Total number of feature updates: 25380\n",
      "Seconds required for this iteration: 0.008\n",
      "\n",
      "***** Epoch #95 *****\n",
      "Loss: 2.626617\n",
      "Improvement ratio: 0.066999\n",
      "Feature L2-norm: 27.079882\n",
      "Learning rate (eta): 0.098135\n",
      "Total number of feature updates: 25650\n",
      "Seconds required for this iteration: 0.009\n",
      "\n",
      "***** Epoch #96 *****\n",
      "Loss: 2.611068\n",
      "Improvement ratio: 0.066362\n",
      "Feature L2-norm: 27.116543\n",
      "Learning rate (eta): 0.098116\n",
      "Total number of feature updates: 25920\n",
      "Seconds required for this iteration: 0.008\n",
      "\n",
      "***** Epoch #97 *****\n",
      "Loss: 2.595027\n",
      "Improvement ratio: 0.065650\n",
      "Feature L2-norm: 27.152817\n",
      "Learning rate (eta): 0.098097\n",
      "Total number of feature updates: 26190\n",
      "Seconds required for this iteration: 0.009\n",
      "\n",
      "***** Epoch #98 *****\n",
      "Loss: 2.580558\n",
      "Improvement ratio: 0.064156\n",
      "Feature L2-norm: 27.188723\n",
      "Learning rate (eta): 0.098078\n",
      "Total number of feature updates: 26460\n",
      "Seconds required for this iteration: 0.008\n",
      "\n",
      "***** Epoch #99 *****\n",
      "Loss: 2.565906\n",
      "Improvement ratio: 0.063081\n",
      "Feature L2-norm: 27.224248\n",
      "Learning rate (eta): 0.098059\n",
      "Total number of feature updates: 26730\n",
      "Seconds required for this iteration: 0.008\n",
      "\n",
      "***** Epoch #100 *****\n",
      "Loss: 2.551332\n",
      "Improvement ratio: 0.062396\n",
      "Feature L2-norm: 27.259395\n",
      "Learning rate (eta): 0.098039\n",
      "Total number of feature updates: 27000\n",
      "Seconds required for this iteration: 0.009\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** Epoch #101 *****\n",
      "Loss: 2.537824\n",
      "Improvement ratio: 0.060451\n",
      "Feature L2-norm: 27.294118\n",
      "Learning rate (eta): 0.098020\n",
      "Total number of feature updates: 27270\n",
      "Seconds required for this iteration: 0.008\n",
      "\n",
      "***** Epoch #102 *****\n",
      "Loss: 2.523771\n",
      "Improvement ratio: 0.060130\n",
      "Feature L2-norm: 27.328491\n",
      "Learning rate (eta): 0.098001\n",
      "Total number of feature updates: 27540\n",
      "Seconds required for this iteration: 0.008\n",
      "\n",
      "***** Epoch #103 *****\n",
      "Loss: 2.510119\n",
      "Improvement ratio: 0.059173\n",
      "Feature L2-norm: 27.362499\n",
      "Learning rate (eta): 0.097982\n",
      "Total number of feature updates: 27810\n",
      "Seconds required for this iteration: 0.008\n",
      "\n",
      "***** Epoch #104 *****\n",
      "Loss: 2.497678\n",
      "Improvement ratio: 0.057922\n",
      "Feature L2-norm: 27.396197\n",
      "Learning rate (eta): 0.097962\n",
      "Total number of feature updates: 28080\n",
      "Seconds required for this iteration: 0.008\n",
      "\n",
      "***** Epoch #105 *****\n",
      "Loss: 2.484248\n",
      "Improvement ratio: 0.057308\n",
      "Feature L2-norm: 27.429543\n",
      "Learning rate (eta): 0.097943\n",
      "Total number of feature updates: 28350\n",
      "Seconds required for this iteration: 0.007\n",
      "\n",
      "***** Epoch #106 *****\n",
      "Loss: 2.471632\n",
      "Improvement ratio: 0.056414\n",
      "Feature L2-norm: 27.462596\n",
      "Learning rate (eta): 0.097924\n",
      "Total number of feature updates: 28620\n",
      "Seconds required for this iteration: 0.007\n",
      "\n",
      "***** Epoch #107 *****\n",
      "Loss: 2.459037\n",
      "Improvement ratio: 0.055302\n",
      "Feature L2-norm: 27.495293\n",
      "Learning rate (eta): 0.097905\n",
      "Total number of feature updates: 28890\n",
      "Seconds required for this iteration: 0.008\n",
      "\n",
      "***** Epoch #108 *****\n",
      "Loss: 2.447310\n",
      "Improvement ratio: 0.054447\n",
      "Feature L2-norm: 27.527653\n",
      "Learning rate (eta): 0.097886\n",
      "Total number of feature updates: 29160\n",
      "Seconds required for this iteration: 0.008\n",
      "\n",
      "***** Epoch #109 *****\n",
      "Loss: 2.435154\n",
      "Improvement ratio: 0.053693\n",
      "Feature L2-norm: 27.559708\n",
      "Learning rate (eta): 0.097867\n",
      "Total number of feature updates: 29430\n",
      "Seconds required for this iteration: 0.009\n",
      "\n",
      "***** Epoch #110 *****\n",
      "Loss: 2.423660\n",
      "Improvement ratio: 0.052677\n",
      "Feature L2-norm: 27.591452\n",
      "Learning rate (eta): 0.097847\n",
      "Total number of feature updates: 29700\n",
      "Seconds required for this iteration: 0.009\n",
      "\n",
      "***** Epoch #111 *****\n",
      "Loss: 2.411893\n",
      "Improvement ratio: 0.052212\n",
      "Feature L2-norm: 27.622830\n",
      "Learning rate (eta): 0.097828\n",
      "Total number of feature updates: 29970\n",
      "Seconds required for this iteration: 0.009\n",
      "\n",
      "***** Epoch #112 *****\n",
      "Loss: 2.400938\n",
      "Improvement ratio: 0.051160\n",
      "Feature L2-norm: 27.653994\n",
      "Learning rate (eta): 0.097809\n",
      "Total number of feature updates: 30240\n",
      "Seconds required for this iteration: 0.010\n",
      "\n",
      "***** Epoch #113 *****\n",
      "Loss: 2.389001\n",
      "Improvement ratio: 0.050698\n",
      "Feature L2-norm: 27.684836\n",
      "Learning rate (eta): 0.097790\n",
      "Total number of feature updates: 30510\n",
      "Seconds required for this iteration: 0.008\n",
      "\n",
      "***** Epoch #114 *****\n",
      "Loss: 2.378894\n",
      "Improvement ratio: 0.049932\n",
      "Feature L2-norm: 27.715377\n",
      "Learning rate (eta): 0.097771\n",
      "Total number of feature updates: 30780\n",
      "Seconds required for this iteration: 0.008\n",
      "\n",
      "***** Epoch #115 *****\n",
      "Loss: 2.366671\n",
      "Improvement ratio: 0.049681\n",
      "Feature L2-norm: 27.745553\n",
      "Learning rate (eta): 0.097752\n",
      "Total number of feature updates: 31050\n",
      "Seconds required for this iteration: 0.009\n",
      "\n",
      "***** Epoch #116 *****\n",
      "Loss: 2.358092\n",
      "Improvement ratio: 0.048149\n",
      "Feature L2-norm: 27.775536\n",
      "Learning rate (eta): 0.097733\n",
      "Total number of feature updates: 31320\n",
      "Seconds required for this iteration: 0.008\n",
      "\n",
      "***** Epoch #117 *****\n",
      "Loss: 2.346870\n",
      "Improvement ratio: 0.047794\n",
      "Feature L2-norm: 27.805264\n",
      "Learning rate (eta): 0.097714\n",
      "Total number of feature updates: 31590\n",
      "Seconds required for this iteration: 0.009\n",
      "\n",
      "***** Epoch #118 *****\n",
      "Loss: 2.337694\n",
      "Improvement ratio: 0.046891\n",
      "Feature L2-norm: 27.834699\n",
      "Learning rate (eta): 0.097694\n",
      "Total number of feature updates: 31860\n",
      "Seconds required for this iteration: 0.008\n",
      "\n",
      "***** Epoch #119 *****\n",
      "Loss: 2.327542\n",
      "Improvement ratio: 0.046234\n",
      "Feature L2-norm: 27.863854\n",
      "Learning rate (eta): 0.097675\n",
      "Total number of feature updates: 32130\n",
      "Seconds required for this iteration: 0.009\n",
      "\n",
      "***** Epoch #120 *****\n",
      "Loss: 2.318214\n",
      "Improvement ratio: 0.045486\n",
      "Feature L2-norm: 27.892728\n",
      "Learning rate (eta): 0.097656\n",
      "Total number of feature updates: 32400\n",
      "Seconds required for this iteration: 0.008\n",
      "\n",
      "***** Epoch #121 *****\n",
      "Loss: 2.307760\n",
      "Improvement ratio: 0.045123\n",
      "Feature L2-norm: 27.921375\n",
      "Learning rate (eta): 0.097637\n",
      "Total number of feature updates: 32670\n",
      "Seconds required for this iteration: 0.009\n",
      "\n",
      "***** Epoch #122 *****\n",
      "Loss: 2.298883\n",
      "Improvement ratio: 0.044393\n",
      "Feature L2-norm: 27.949729\n",
      "Learning rate (eta): 0.097618\n",
      "Total number of feature updates: 32940\n",
      "Seconds required for this iteration: 0.008\n",
      "\n",
      "***** Epoch #123 *****\n",
      "Loss: 2.290032\n",
      "Improvement ratio: 0.043217\n",
      "Feature L2-norm: 27.977875\n",
      "Learning rate (eta): 0.097599\n",
      "Total number of feature updates: 33210\n",
      "Seconds required for this iteration: 0.009\n",
      "\n",
      "***** Epoch #124 *****\n",
      "Loss: 2.280838\n",
      "Improvement ratio: 0.042991\n",
      "Feature L2-norm: 28.005759\n",
      "Learning rate (eta): 0.097580\n",
      "Total number of feature updates: 33480\n",
      "Seconds required for this iteration: 0.008\n",
      "\n",
      "***** Epoch #125 *****\n",
      "Loss: 2.272000\n",
      "Improvement ratio: 0.041669\n",
      "Feature L2-norm: 28.033409\n",
      "Learning rate (eta): 0.097561\n",
      "Total number of feature updates: 33750\n",
      "Seconds required for this iteration: 0.008\n",
      "\n",
      "***** Epoch #126 *****\n",
      "Loss: 2.262808\n",
      "Improvement ratio: 0.042109\n",
      "Feature L2-norm: 28.060831\n",
      "Learning rate (eta): 0.097542\n",
      "Total number of feature updates: 34020\n",
      "Seconds required for this iteration: 0.009\n",
      "\n",
      "***** Epoch #127 *****\n",
      "Loss: 2.254765\n",
      "Improvement ratio: 0.040849\n",
      "Feature L2-norm: 28.088033\n",
      "Learning rate (eta): 0.097523\n",
      "Total number of feature updates: 34290\n",
      "Seconds required for this iteration: 0.009\n",
      "\n",
      "***** Epoch #128 *****\n",
      "Loss: 2.246094\n",
      "Improvement ratio: 0.040782\n",
      "Feature L2-norm: 28.114986\n",
      "Learning rate (eta): 0.097504\n",
      "Total number of feature updates: 34560\n",
      "Seconds required for this iteration: 0.008\n",
      "\n",
      "***** Epoch #129 *****\n",
      "Loss: 2.238172\n",
      "Improvement ratio: 0.039930\n",
      "Feature L2-norm: 28.141701\n",
      "Learning rate (eta): 0.097485\n",
      "Total number of feature updates: 34830\n",
      "Seconds required for this iteration: 0.008\n",
      "\n",
      "***** Epoch #130 *****\n",
      "Loss: 2.229872\n",
      "Improvement ratio: 0.039618\n",
      "Feature L2-norm: 28.168181\n",
      "Learning rate (eta): 0.097466\n",
      "Total number of feature updates: 35100\n",
      "Seconds required for this iteration: 0.010\n",
      "\n",
      "***** Epoch #131 *****\n",
      "Loss: 2.221704\n",
      "Improvement ratio: 0.038734\n",
      "Feature L2-norm: 28.194413\n",
      "Learning rate (eta): 0.097447\n",
      "Total number of feature updates: 35370\n",
      "Seconds required for this iteration: 0.009\n",
      "\n",
      "***** Epoch #132 *****\n",
      "Loss: 2.213164\n",
      "Improvement ratio: 0.038732\n",
      "Feature L2-norm: 28.220496\n",
      "Learning rate (eta): 0.097428\n",
      "Total number of feature updates: 35640\n",
      "Seconds required for this iteration: 0.008\n",
      "\n",
      "***** Epoch #133 *****\n",
      "Loss: 2.205281\n",
      "Improvement ratio: 0.038431\n",
      "Feature L2-norm: 28.246335\n",
      "Learning rate (eta): 0.097409\n",
      "Total number of feature updates: 35910\n",
      "Seconds required for this iteration: 0.008\n",
      "\n",
      "***** Epoch #134 *****\n",
      "Loss: 2.197890\n",
      "Improvement ratio: 0.037740\n",
      "Feature L2-norm: 28.271925\n",
      "Learning rate (eta): 0.097390\n",
      "Total number of feature updates: 36180\n",
      "Seconds required for this iteration: 0.008\n",
      "\n",
      "***** Epoch #135 *****\n",
      "Loss: 2.190644\n",
      "Improvement ratio: 0.037138\n",
      "Feature L2-norm: 28.297309\n",
      "Learning rate (eta): 0.097371\n",
      "Total number of feature updates: 36450\n",
      "Seconds required for this iteration: 0.010\n",
      "\n",
      "***** Epoch #136 *****\n",
      "Loss: 2.183304\n",
      "Improvement ratio: 0.036414\n",
      "Feature L2-norm: 28.322554\n",
      "Learning rate (eta): 0.097352\n",
      "Total number of feature updates: 36720\n",
      "Seconds required for this iteration: 0.012\n",
      "\n",
      "***** Epoch #137 *****\n",
      "Loss: 2.176252\n",
      "Improvement ratio: 0.036077\n",
      "Feature L2-norm: 28.347582\n",
      "Learning rate (eta): 0.097333\n",
      "Total number of feature updates: 36990\n",
      "Seconds required for this iteration: 0.016\n",
      "\n",
      "***** Epoch #138 *****\n",
      "Loss: 2.168993\n",
      "Improvement ratio: 0.035547\n",
      "Feature L2-norm: 28.372392\n",
      "Learning rate (eta): 0.097314\n",
      "Total number of feature updates: 37260\n",
      "Seconds required for this iteration: 0.011\n",
      "\n",
      "***** Epoch #139 *****\n",
      "Loss: 2.162004\n",
      "Improvement ratio: 0.035230\n",
      "Feature L2-norm: 28.396995\n",
      "Learning rate (eta): 0.097295\n",
      "Total number of feature updates: 37530\n",
      "Seconds required for this iteration: 0.014\n",
      "\n",
      "***** Epoch #140 *****\n",
      "Loss: 2.155094\n",
      "Improvement ratio: 0.034698\n",
      "Feature L2-norm: 28.421419\n",
      "Learning rate (eta): 0.097276\n",
      "Total number of feature updates: 37800\n",
      "Seconds required for this iteration: 0.013\n",
      "\n",
      "***** Epoch #141 *****\n",
      "Loss: 2.148448\n",
      "Improvement ratio: 0.034097\n",
      "Feature L2-norm: 28.445621\n",
      "Learning rate (eta): 0.097257\n",
      "Total number of feature updates: 38070\n",
      "Seconds required for this iteration: 0.012\n",
      "\n",
      "***** Epoch #142 *****\n",
      "Loss: 2.141456\n",
      "Improvement ratio: 0.033485\n",
      "Feature L2-norm: 28.469654\n",
      "Learning rate (eta): 0.097238\n",
      "Total number of feature updates: 38340\n",
      "Seconds required for this iteration: 0.012\n",
      "\n",
      "***** Epoch #143 *****\n",
      "Loss: 2.134803\n",
      "Improvement ratio: 0.033014\n",
      "Feature L2-norm: 28.493544\n",
      "Learning rate (eta): 0.097220\n",
      "Total number of feature updates: 38610\n",
      "Seconds required for this iteration: 0.015\n",
      "\n",
      "***** Epoch #144 *****\n",
      "Loss: 2.127919\n",
      "Improvement ratio: 0.032882\n",
      "Feature L2-norm: 28.517229\n",
      "Learning rate (eta): 0.097201\n",
      "Total number of feature updates: 38880\n",
      "Seconds required for this iteration: 0.014\n",
      "\n",
      "***** Epoch #145 *****\n",
      "Loss: 2.122049\n",
      "Improvement ratio: 0.032325\n",
      "Feature L2-norm: 28.540703\n",
      "Learning rate (eta): 0.097182\n",
      "Total number of feature updates: 39150\n",
      "Seconds required for this iteration: 0.011\n",
      "\n",
      "***** Epoch #146 *****\n",
      "Loss: 2.115366\n",
      "Improvement ratio: 0.032116\n",
      "Feature L2-norm: 28.564013\n",
      "Learning rate (eta): 0.097163\n",
      "Total number of feature updates: 39420\n",
      "Seconds required for this iteration: 0.010\n",
      "\n",
      "***** Epoch #147 *****\n",
      "Loss: 2.109407\n",
      "Improvement ratio: 0.031689\n",
      "Feature L2-norm: 28.587168\n",
      "Learning rate (eta): 0.097144\n",
      "Total number of feature updates: 39690\n",
      "Seconds required for this iteration: 0.010\n",
      "\n",
      "***** Epoch #148 *****\n",
      "Loss: 2.103336\n",
      "Improvement ratio: 0.031216\n",
      "Feature L2-norm: 28.610135\n",
      "Learning rate (eta): 0.097125\n",
      "Total number of feature updates: 39960\n",
      "Seconds required for this iteration: 0.009\n",
      "\n",
      "***** Epoch #149 *****\n",
      "Loss: 2.097128\n",
      "Improvement ratio: 0.030936\n",
      "Feature L2-norm: 28.632932\n",
      "Learning rate (eta): 0.097106\n",
      "Total number of feature updates: 40230\n",
      "Seconds required for this iteration: 0.010\n",
      "\n",
      "***** Epoch #150 *****\n",
      "Loss: 2.091313\n",
      "Improvement ratio: 0.030498\n",
      "Feature L2-norm: 28.655560\n",
      "Learning rate (eta): 0.097087\n",
      "Total number of feature updates: 40500\n",
      "Seconds required for this iteration: 0.009\n",
      "\n",
      "***** Epoch #151 *****\n",
      "Loss: 2.085178\n",
      "Improvement ratio: 0.030343\n",
      "Feature L2-norm: 28.678043\n",
      "Learning rate (eta): 0.097069\n",
      "Total number of feature updates: 40770\n",
      "Seconds required for this iteration: 0.010\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** Epoch #152 *****\n",
      "Loss: 2.079338\n",
      "Improvement ratio: 0.029874\n",
      "Feature L2-norm: 28.700301\n",
      "Learning rate (eta): 0.097050\n",
      "Total number of feature updates: 41040\n",
      "Seconds required for this iteration: 0.012\n",
      "\n",
      "***** Epoch #153 *****\n",
      "Loss: 2.073043\n",
      "Improvement ratio: 0.029792\n",
      "Feature L2-norm: 28.722395\n",
      "Learning rate (eta): 0.097031\n",
      "Total number of feature updates: 41310\n",
      "Seconds required for this iteration: 0.009\n",
      "\n",
      "***** Epoch #154 *****\n",
      "Loss: 2.068311\n",
      "Improvement ratio: 0.028820\n",
      "Feature L2-norm: 28.744390\n",
      "Learning rate (eta): 0.097012\n",
      "Total number of feature updates: 41580\n",
      "Seconds required for this iteration: 0.010\n",
      "\n",
      "***** Epoch #155 *****\n",
      "Loss: 2.062659\n",
      "Improvement ratio: 0.028793\n",
      "Feature L2-norm: 28.766204\n",
      "Learning rate (eta): 0.096993\n",
      "Total number of feature updates: 41850\n",
      "Seconds required for this iteration: 0.009\n",
      "\n",
      "***** Epoch #156 *****\n",
      "Loss: 2.057137\n",
      "Improvement ratio: 0.028306\n",
      "Feature L2-norm: 28.787875\n",
      "Learning rate (eta): 0.096974\n",
      "Total number of feature updates: 42120\n",
      "Seconds required for this iteration: 0.009\n",
      "\n",
      "***** Epoch #157 *****\n",
      "Loss: 2.051813\n",
      "Improvement ratio: 0.028070\n",
      "Feature L2-norm: 28.809370\n",
      "Learning rate (eta): 0.096956\n",
      "Total number of feature updates: 42390\n",
      "Seconds required for this iteration: 0.010\n",
      "\n",
      "***** Epoch #158 *****\n",
      "Loss: 2.046343\n",
      "Improvement ratio: 0.027851\n",
      "Feature L2-norm: 28.830724\n",
      "Learning rate (eta): 0.096937\n",
      "Total number of feature updates: 42660\n",
      "Seconds required for this iteration: 0.012\n",
      "\n",
      "***** Epoch #159 *****\n",
      "Loss: 2.041165\n",
      "Improvement ratio: 0.027417\n",
      "Feature L2-norm: 28.851924\n",
      "Learning rate (eta): 0.096918\n",
      "Total number of feature updates: 42930\n",
      "Seconds required for this iteration: 0.009\n",
      "\n",
      "***** Epoch #160 *****\n",
      "Loss: 2.035997\n",
      "Improvement ratio: 0.027169\n",
      "Feature L2-norm: 28.872974\n",
      "Learning rate (eta): 0.096899\n",
      "Total number of feature updates: 43200\n",
      "Seconds required for this iteration: 0.009\n",
      "\n",
      "***** Epoch #161 *****\n",
      "Loss: 2.030991\n",
      "Improvement ratio: 0.026680\n",
      "Feature L2-norm: 28.893862\n",
      "Learning rate (eta): 0.096881\n",
      "Total number of feature updates: 43470\n",
      "Seconds required for this iteration: 0.010\n",
      "\n",
      "***** Epoch #162 *****\n",
      "Loss: 2.026046\n",
      "Improvement ratio: 0.026303\n",
      "Feature L2-norm: 28.914606\n",
      "Learning rate (eta): 0.096862\n",
      "Total number of feature updates: 43740\n",
      "Seconds required for this iteration: 0.012\n",
      "\n",
      "***** Epoch #163 *****\n",
      "Loss: 2.020877\n",
      "Improvement ratio: 0.025814\n",
      "Feature L2-norm: 28.935212\n",
      "Learning rate (eta): 0.096843\n",
      "Total number of feature updates: 44010\n",
      "Seconds required for this iteration: 0.012\n",
      "\n",
      "***** Epoch #164 *****\n",
      "Loss: 2.015761\n",
      "Improvement ratio: 0.026070\n",
      "Feature L2-norm: 28.955680\n",
      "Learning rate (eta): 0.096824\n",
      "Total number of feature updates: 44280\n",
      "Seconds required for this iteration: 0.010\n",
      "\n",
      "***** Epoch #165 *****\n",
      "Loss: 2.011245\n",
      "Improvement ratio: 0.025563\n",
      "Feature L2-norm: 28.975981\n",
      "Learning rate (eta): 0.096805\n",
      "Total number of feature updates: 44550\n",
      "Seconds required for this iteration: 0.012\n",
      "\n",
      "***** Epoch #166 *****\n",
      "Loss: 2.006131\n",
      "Improvement ratio: 0.025425\n",
      "Feature L2-norm: 28.996156\n",
      "Learning rate (eta): 0.096787\n",
      "Total number of feature updates: 44820\n",
      "Seconds required for this iteration: 0.012\n",
      "\n",
      "***** Epoch #167 *****\n",
      "Loss: 2.001625\n",
      "Improvement ratio: 0.025074\n",
      "Feature L2-norm: 29.016204\n",
      "Learning rate (eta): 0.096768\n",
      "Total number of feature updates: 45090\n",
      "Seconds required for this iteration: 0.014\n",
      "\n",
      "***** Epoch #168 *****\n",
      "Loss: 1.997112\n",
      "Improvement ratio: 0.024651\n",
      "Feature L2-norm: 29.036115\n",
      "Learning rate (eta): 0.096749\n",
      "Total number of feature updates: 45360\n",
      "Seconds required for this iteration: 0.014\n",
      "\n",
      "***** Epoch #169 *****\n",
      "Loss: 1.992500\n",
      "Improvement ratio: 0.024424\n",
      "Feature L2-norm: 29.055909\n",
      "Learning rate (eta): 0.096731\n",
      "Total number of feature updates: 45630\n",
      "Seconds required for this iteration: 0.014\n",
      "\n",
      "***** Epoch #170 *****\n",
      "Loss: 1.987930\n",
      "Improvement ratio: 0.024179\n",
      "Feature L2-norm: 29.075557\n",
      "Learning rate (eta): 0.096712\n",
      "Total number of feature updates: 45900\n",
      "Seconds required for this iteration: 0.014\n",
      "\n",
      "***** Epoch #171 *****\n",
      "Loss: 1.983379\n",
      "Improvement ratio: 0.024006\n",
      "Feature L2-norm: 29.095067\n",
      "Learning rate (eta): 0.096693\n",
      "Total number of feature updates: 46170\n",
      "Seconds required for this iteration: 0.015\n",
      "\n",
      "***** Epoch #172 *****\n",
      "Loss: 1.979146\n",
      "Improvement ratio: 0.023697\n",
      "Feature L2-norm: 29.114474\n",
      "Learning rate (eta): 0.096674\n",
      "Total number of feature updates: 46440\n",
      "Seconds required for this iteration: 0.014\n",
      "\n",
      "***** Epoch #173 *****\n",
      "Loss: 1.974579\n",
      "Improvement ratio: 0.023447\n",
      "Feature L2-norm: 29.133744\n",
      "Learning rate (eta): 0.096656\n",
      "Total number of feature updates: 46710\n",
      "Seconds required for this iteration: 0.015\n",
      "\n",
      "***** Epoch #174 *****\n",
      "Loss: 1.970471\n",
      "Improvement ratio: 0.022984\n",
      "Feature L2-norm: 29.152888\n",
      "Learning rate (eta): 0.096637\n",
      "Total number of feature updates: 46980\n",
      "Seconds required for this iteration: 0.013\n",
      "\n",
      "***** Epoch #175 *****\n",
      "Loss: 1.966300\n",
      "Improvement ratio: 0.022858\n",
      "Feature L2-norm: 29.171892\n",
      "Learning rate (eta): 0.096618\n",
      "Total number of feature updates: 47250\n",
      "Seconds required for this iteration: 0.011\n",
      "\n",
      "***** Epoch #176 *****\n",
      "Loss: 1.961949\n",
      "Improvement ratio: 0.022520\n",
      "Feature L2-norm: 29.190779\n",
      "Learning rate (eta): 0.096600\n",
      "Total number of feature updates: 47520\n",
      "Seconds required for this iteration: 0.013\n",
      "\n",
      "***** Epoch #177 *****\n",
      "Loss: 1.958094\n",
      "Improvement ratio: 0.022231\n",
      "Feature L2-norm: 29.209524\n",
      "Learning rate (eta): 0.096581\n",
      "Total number of feature updates: 47790\n",
      "Seconds required for this iteration: 0.014\n",
      "\n",
      "***** Epoch #178 *****\n",
      "Loss: 1.953861\n",
      "Improvement ratio: 0.022136\n",
      "Feature L2-norm: 29.228167\n",
      "Learning rate (eta): 0.096562\n",
      "Total number of feature updates: 48060\n",
      "Seconds required for this iteration: 0.013\n",
      "\n",
      "***** Epoch #179 *****\n",
      "Loss: 1.949560\n",
      "Improvement ratio: 0.022025\n",
      "Feature L2-norm: 29.246678\n",
      "Learning rate (eta): 0.096544\n",
      "Total number of feature updates: 48330\n",
      "Seconds required for this iteration: 0.012\n",
      "\n",
      "***** Epoch #180 *****\n",
      "Loss: 1.945910\n",
      "Improvement ratio: 0.021594\n",
      "Feature L2-norm: 29.265083\n",
      "Learning rate (eta): 0.096525\n",
      "Total number of feature updates: 48600\n",
      "Seconds required for this iteration: 0.012\n",
      "\n",
      "***** Epoch #181 *****\n",
      "Loss: 1.941946\n",
      "Improvement ratio: 0.021335\n",
      "Feature L2-norm: 29.283378\n",
      "Learning rate (eta): 0.096507\n",
      "Total number of feature updates: 48870\n",
      "Seconds required for this iteration: 0.015\n",
      "\n",
      "***** Epoch #182 *****\n",
      "Loss: 1.938076\n",
      "Improvement ratio: 0.021191\n",
      "Feature L2-norm: 29.301563\n",
      "Learning rate (eta): 0.096488\n",
      "Total number of feature updates: 49140\n",
      "Seconds required for this iteration: 0.013\n",
      "\n",
      "***** Epoch #183 *****\n",
      "Loss: 1.934313\n",
      "Improvement ratio: 0.020817\n",
      "Feature L2-norm: 29.319629\n",
      "Learning rate (eta): 0.096469\n",
      "Total number of feature updates: 49410\n",
      "Seconds required for this iteration: 0.014\n",
      "\n",
      "***** Epoch #184 *****\n",
      "Loss: 1.930284\n",
      "Improvement ratio: 0.020820\n",
      "Feature L2-norm: 29.337564\n",
      "Learning rate (eta): 0.096451\n",
      "Total number of feature updates: 49680\n",
      "Seconds required for this iteration: 0.014\n",
      "\n",
      "***** Epoch #185 *****\n",
      "Loss: 1.926807\n",
      "Improvement ratio: 0.020496\n",
      "Feature L2-norm: 29.355403\n",
      "Learning rate (eta): 0.096432\n",
      "Total number of feature updates: 49950\n",
      "Seconds required for this iteration: 0.012\n",
      "\n",
      "***** Epoch #186 *****\n",
      "Loss: 1.923108\n",
      "Improvement ratio: 0.020197\n",
      "Feature L2-norm: 29.373124\n",
      "Learning rate (eta): 0.096413\n",
      "Total number of feature updates: 50220\n",
      "Seconds required for this iteration: 0.010\n",
      "\n",
      "***** Epoch #187 *****\n",
      "Loss: 1.919022\n",
      "Improvement ratio: 0.020361\n",
      "Feature L2-norm: 29.390753\n",
      "Learning rate (eta): 0.096395\n",
      "Total number of feature updates: 50490\n",
      "Seconds required for this iteration: 0.011\n",
      "\n",
      "***** Epoch #188 *****\n",
      "Loss: 1.915776\n",
      "Improvement ratio: 0.019880\n",
      "Feature L2-norm: 29.408262\n",
      "Learning rate (eta): 0.096376\n",
      "Total number of feature updates: 50760\n",
      "Seconds required for this iteration: 0.010\n",
      "\n",
      "***** Epoch #189 *****\n",
      "Loss: 1.912261\n",
      "Improvement ratio: 0.019505\n",
      "Feature L2-norm: 29.425660\n",
      "Learning rate (eta): 0.096358\n",
      "Total number of feature updates: 51030\n",
      "Seconds required for this iteration: 0.011\n",
      "\n",
      "***** Epoch #190 *****\n",
      "Loss: 1.908700\n",
      "Improvement ratio: 0.019495\n",
      "Feature L2-norm: 29.442955\n",
      "Learning rate (eta): 0.096339\n",
      "Total number of feature updates: 51300\n",
      "Seconds required for this iteration: 0.014\n",
      "\n",
      "***** Epoch #191 *****\n",
      "Loss: 1.905242\n",
      "Improvement ratio: 0.019265\n",
      "Feature L2-norm: 29.460150\n",
      "Learning rate (eta): 0.096321\n",
      "Total number of feature updates: 51570\n",
      "Seconds required for this iteration: 0.011\n",
      "\n",
      "***** Epoch #192 *****\n",
      "Loss: 1.901812\n",
      "Improvement ratio: 0.019068\n",
      "Feature L2-norm: 29.477228\n",
      "Learning rate (eta): 0.096302\n",
      "Total number of feature updates: 51840\n",
      "Seconds required for this iteration: 0.010\n",
      "\n",
      "***** Epoch #193 *****\n",
      "Loss: 1.898337\n",
      "Improvement ratio: 0.018951\n",
      "Feature L2-norm: 29.494194\n",
      "Learning rate (eta): 0.096284\n",
      "Total number of feature updates: 52110\n",
      "Seconds required for this iteration: 0.014\n",
      "\n",
      "***** Epoch #194 *****\n",
      "Loss: 1.895101\n",
      "Improvement ratio: 0.018565\n",
      "Feature L2-norm: 29.511080\n",
      "Learning rate (eta): 0.096265\n",
      "Total number of feature updates: 52380\n",
      "Seconds required for this iteration: 0.015\n",
      "\n",
      "***** Epoch #195 *****\n",
      "Loss: 1.891697\n",
      "Improvement ratio: 0.018560\n",
      "Feature L2-norm: 29.527871\n",
      "Learning rate (eta): 0.096246\n",
      "Total number of feature updates: 52650\n",
      "Seconds required for this iteration: 0.011\n",
      "\n",
      "***** Epoch #196 *****\n",
      "Loss: 1.888338\n",
      "Improvement ratio: 0.018413\n",
      "Feature L2-norm: 29.544546\n",
      "Learning rate (eta): 0.096228\n",
      "Total number of feature updates: 52920\n",
      "Seconds required for this iteration: 0.010\n",
      "\n",
      "***** Epoch #197 *****\n",
      "Loss: 1.885192\n",
      "Improvement ratio: 0.017945\n",
      "Feature L2-norm: 29.561112\n",
      "Learning rate (eta): 0.096209\n",
      "Total number of feature updates: 53190\n",
      "Seconds required for this iteration: 0.011\n",
      "\n",
      "***** Epoch #198 *****\n",
      "Loss: 1.881923\n",
      "Improvement ratio: 0.017989\n",
      "Feature L2-norm: 29.577585\n",
      "Learning rate (eta): 0.096191\n",
      "Total number of feature updates: 53460\n",
      "Seconds required for this iteration: 0.010\n",
      "\n",
      "***** Epoch #199 *****\n",
      "Loss: 1.878834\n",
      "Improvement ratio: 0.017791\n",
      "Feature L2-norm: 29.593963\n",
      "Learning rate (eta): 0.096172\n",
      "Total number of feature updates: 53730\n",
      "Seconds required for this iteration: 0.010\n",
      "\n",
      "***** Epoch #200 *****\n",
      "Loss: 1.875743\n",
      "Improvement ratio: 0.017570\n",
      "Feature L2-norm: 29.610260\n",
      "Learning rate (eta): 0.096154\n",
      "Total number of feature updates: 54000\n",
      "Seconds required for this iteration: 0.013\n",
      "\n",
      "***** Epoch #201 *****\n",
      "Loss: 1.872410\n",
      "Improvement ratio: 0.017534\n",
      "Feature L2-norm: 29.626450\n",
      "Learning rate (eta): 0.096135\n",
      "Total number of feature updates: 54270\n",
      "Seconds required for this iteration: 0.010\n",
      "\n",
      "***** Epoch #202 *****\n",
      "Loss: 1.869478\n",
      "Improvement ratio: 0.017296\n",
      "Feature L2-norm: 29.642545\n",
      "Learning rate (eta): 0.096117\n",
      "Total number of feature updates: 54540\n",
      "Seconds required for this iteration: 0.009\n",
      "\n",
      "***** Epoch #203 *****\n",
      "Loss: 1.866510\n",
      "Improvement ratio: 0.017052\n",
      "Feature L2-norm: 29.658539\n",
      "Learning rate (eta): 0.096098\n",
      "Total number of feature updates: 54810\n",
      "Seconds required for this iteration: 0.010\n",
      "\n",
      "***** Epoch #204 *****\n",
      "Loss: 1.863506\n",
      "Improvement ratio: 0.016955\n",
      "Feature L2-norm: 29.674454\n",
      "Learning rate (eta): 0.096080\n",
      "Total number of feature updates: 55080\n",
      "Seconds required for this iteration: 0.009\n",
      "\n",
      "***** Epoch #205 *****\n",
      "Loss: 1.860581\n",
      "Improvement ratio: 0.016724\n",
      "Feature L2-norm: 29.690272\n",
      "Learning rate (eta): 0.096062\n",
      "Total number of feature updates: 55350\n",
      "Seconds required for this iteration: 0.010\n",
      "\n",
      "***** Epoch #206 *****\n",
      "Loss: 1.857551\n",
      "Improvement ratio: 0.016574\n",
      "Feature L2-norm: 29.706000\n",
      "Learning rate (eta): 0.096043\n",
      "Total number of feature updates: 55620\n",
      "Seconds required for this iteration: 0.010\n",
      "\n",
      "***** Epoch #207 *****\n",
      "Loss: 1.854799\n",
      "Improvement ratio: 0.016386\n",
      "Feature L2-norm: 29.721638\n",
      "Learning rate (eta): 0.096025\n",
      "Total number of feature updates: 55890\n",
      "Seconds required for this iteration: 0.009\n",
      "\n",
      "***** Epoch #208 *****\n",
      "Loss: 1.851867\n",
      "Improvement ratio: 0.016230\n",
      "Feature L2-norm: 29.737192\n",
      "Learning rate (eta): 0.096006\n",
      "Total number of feature updates: 56160\n",
      "Seconds required for this iteration: 0.009\n",
      "\n",
      "***** Epoch #209 *****\n",
      "Loss: 1.849005\n",
      "Improvement ratio: 0.016133\n",
      "Feature L2-norm: 29.752662\n",
      "Learning rate (eta): 0.095988\n",
      "Total number of feature updates: 56430\n",
      "Seconds required for this iteration: 0.009\n",
      "\n",
      "***** Epoch #210 *****\n",
      "Loss: 1.846288\n",
      "Improvement ratio: 0.015954\n",
      "Feature L2-norm: 29.768037\n",
      "Learning rate (eta): 0.095969\n",
      "Total number of feature updates: 56700\n",
      "Seconds required for this iteration: 0.009\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** Epoch #211 *****\n",
      "Loss: 1.843455\n",
      "Improvement ratio: 0.015707\n",
      "Feature L2-norm: 29.783336\n",
      "Learning rate (eta): 0.095951\n",
      "Total number of feature updates: 56970\n",
      "Seconds required for this iteration: 0.009\n",
      "\n",
      "***** Epoch #212 *****\n",
      "Loss: 1.840595\n",
      "Improvement ratio: 0.015692\n",
      "Feature L2-norm: 29.798564\n",
      "Learning rate (eta): 0.095933\n",
      "Total number of feature updates: 57240\n",
      "Seconds required for this iteration: 0.009\n",
      "\n",
      "***** Epoch #213 *****\n",
      "Loss: 1.837889\n",
      "Improvement ratio: 0.015572\n",
      "Feature L2-norm: 29.813668\n",
      "Learning rate (eta): 0.095914\n",
      "Total number of feature updates: 57510\n",
      "Seconds required for this iteration: 0.009\n",
      "\n",
      "***** Epoch #214 *****\n",
      "Loss: 1.835418\n",
      "Improvement ratio: 0.015303\n",
      "Feature L2-norm: 29.828709\n",
      "Learning rate (eta): 0.095896\n",
      "Total number of feature updates: 57780\n",
      "Seconds required for this iteration: 0.010\n",
      "\n",
      "***** Epoch #215 *****\n",
      "Loss: 1.832737\n",
      "Improvement ratio: 0.015192\n",
      "Feature L2-norm: 29.843663\n",
      "Learning rate (eta): 0.095877\n",
      "Total number of feature updates: 58050\n",
      "Seconds required for this iteration: 0.009\n",
      "\n",
      "***** Epoch #216 *****\n",
      "Loss: 1.830121\n",
      "Improvement ratio: 0.014988\n",
      "Feature L2-norm: 29.858531\n",
      "Learning rate (eta): 0.095859\n",
      "Total number of feature updates: 58320\n",
      "Seconds required for this iteration: 0.008\n",
      "\n",
      "***** Epoch #217 *****\n",
      "Loss: 1.827468\n",
      "Improvement ratio: 0.014956\n",
      "Feature L2-norm: 29.873321\n",
      "Learning rate (eta): 0.095841\n",
      "Total number of feature updates: 58590\n",
      "Seconds required for this iteration: 0.009\n",
      "\n",
      "***** Epoch #218 *****\n",
      "Loss: 1.824917\n",
      "Improvement ratio: 0.014768\n",
      "Feature L2-norm: 29.888039\n",
      "Learning rate (eta): 0.095822\n",
      "Total number of feature updates: 58860\n",
      "Seconds required for this iteration: 0.009\n",
      "\n",
      "***** Epoch #219 *****\n",
      "Loss: 1.822433\n",
      "Improvement ratio: 0.014581\n",
      "Feature L2-norm: 29.902665\n",
      "Learning rate (eta): 0.095804\n",
      "Total number of feature updates: 59130\n",
      "Seconds required for this iteration: 0.011\n",
      "\n",
      "***** Epoch #220 *****\n",
      "Loss: 1.819824\n",
      "Improvement ratio: 0.014542\n",
      "Feature L2-norm: 29.917230\n",
      "Learning rate (eta): 0.095786\n",
      "Total number of feature updates: 59400\n",
      "Seconds required for this iteration: 0.010\n",
      "\n",
      "***** Epoch #221 *****\n",
      "Loss: 1.817294\n",
      "Improvement ratio: 0.014396\n",
      "Feature L2-norm: 29.931706\n",
      "Learning rate (eta): 0.095767\n",
      "Total number of feature updates: 59670\n",
      "Seconds required for this iteration: 0.009\n",
      "\n",
      "***** Epoch #222 *****\n",
      "Loss: 1.814941\n",
      "Improvement ratio: 0.014135\n",
      "Feature L2-norm: 29.946094\n",
      "Learning rate (eta): 0.095749\n",
      "Total number of feature updates: 59940\n",
      "Seconds required for this iteration: 0.009\n",
      "\n",
      "***** Epoch #223 *****\n",
      "Loss: 1.812511\n",
      "Improvement ratio: 0.014002\n",
      "Feature L2-norm: 29.960406\n",
      "Learning rate (eta): 0.095730\n",
      "Total number of feature updates: 60210\n",
      "Seconds required for this iteration: 0.009\n",
      "\n",
      "***** Epoch #224 *****\n",
      "Loss: 1.810145\n",
      "Improvement ratio: 0.013962\n",
      "Feature L2-norm: 29.974651\n",
      "Learning rate (eta): 0.095712\n",
      "Total number of feature updates: 60480\n",
      "Seconds required for this iteration: 0.009\n",
      "\n",
      "***** Epoch #225 *****\n",
      "Loss: 1.807707\n",
      "Improvement ratio: 0.013847\n",
      "Feature L2-norm: 29.988818\n",
      "Learning rate (eta): 0.095694\n",
      "Total number of feature updates: 60750\n",
      "Seconds required for this iteration: 0.008\n",
      "\n",
      "***** Epoch #226 *****\n",
      "Loss: 1.805299\n",
      "Improvement ratio: 0.013749\n",
      "Feature L2-norm: 30.002921\n",
      "Learning rate (eta): 0.095676\n",
      "Total number of feature updates: 61020\n",
      "Seconds required for this iteration: 0.009\n",
      "\n",
      "***** Epoch #227 *****\n",
      "Loss: 1.802959\n",
      "Improvement ratio: 0.013593\n",
      "Feature L2-norm: 30.016941\n",
      "Learning rate (eta): 0.095657\n",
      "Total number of feature updates: 61290\n",
      "Seconds required for this iteration: 0.009\n",
      "\n",
      "***** Epoch #228 *****\n",
      "Loss: 1.800662\n",
      "Improvement ratio: 0.013470\n",
      "Feature L2-norm: 30.030876\n",
      "Learning rate (eta): 0.095639\n",
      "Total number of feature updates: 61560\n",
      "Seconds required for this iteration: 0.009\n",
      "\n",
      "***** Epoch #229 *****\n",
      "Loss: 1.798341\n",
      "Improvement ratio: 0.013397\n",
      "Feature L2-norm: 30.044750\n",
      "Learning rate (eta): 0.095621\n",
      "Total number of feature updates: 61830\n",
      "Seconds required for this iteration: 0.009\n",
      "\n",
      "***** Epoch #230 *****\n",
      "Loss: 1.796145\n",
      "Improvement ratio: 0.013183\n",
      "Feature L2-norm: 30.058536\n",
      "Learning rate (eta): 0.095602\n",
      "Total number of feature updates: 62100\n",
      "Seconds required for this iteration: 0.009\n",
      "\n",
      "***** Epoch #231 *****\n",
      "Loss: 1.793940\n",
      "Improvement ratio: 0.013018\n",
      "Feature L2-norm: 30.072257\n",
      "Learning rate (eta): 0.095584\n",
      "Total number of feature updates: 62370\n",
      "Seconds required for this iteration: 0.010\n",
      "\n",
      "***** Epoch #232 *****\n",
      "Loss: 1.791640\n",
      "Improvement ratio: 0.013005\n",
      "Feature L2-norm: 30.085915\n",
      "Learning rate (eta): 0.095566\n",
      "Total number of feature updates: 62640\n",
      "Seconds required for this iteration: 0.010\n",
      "\n",
      "***** Epoch #233 *****\n",
      "Loss: 1.789493\n",
      "Improvement ratio: 0.012863\n",
      "Feature L2-norm: 30.099486\n",
      "Learning rate (eta): 0.095548\n",
      "Total number of feature updates: 62910\n",
      "Seconds required for this iteration: 0.009\n",
      "\n",
      "***** Epoch #234 *****\n",
      "Loss: 1.787292\n",
      "Improvement ratio: 0.012786\n",
      "Feature L2-norm: 30.112995\n",
      "Learning rate (eta): 0.095529\n",
      "Total number of feature updates: 63180\n",
      "Seconds required for this iteration: 0.009\n",
      "\n",
      "***** Epoch #235 *****\n",
      "Loss: 1.785115\n",
      "Improvement ratio: 0.012655\n",
      "Feature L2-norm: 30.126433\n",
      "Learning rate (eta): 0.095511\n",
      "Total number of feature updates: 63450\n",
      "Seconds required for this iteration: 0.009\n",
      "\n",
      "***** Epoch #236 *****\n",
      "Loss: 1.783028\n",
      "Improvement ratio: 0.012491\n",
      "Feature L2-norm: 30.139807\n",
      "Learning rate (eta): 0.095493\n",
      "Total number of feature updates: 63720\n",
      "Seconds required for this iteration: 0.009\n",
      "\n",
      "***** Epoch #237 *****\n",
      "Loss: 1.780958\n",
      "Improvement ratio: 0.012353\n",
      "Feature L2-norm: 30.153119\n",
      "Learning rate (eta): 0.095475\n",
      "Total number of feature updates: 63990\n",
      "Seconds required for this iteration: 0.009\n",
      "\n",
      "***** Epoch #238 *****\n",
      "Loss: 1.778824\n",
      "Improvement ratio: 0.012277\n",
      "Feature L2-norm: 30.166359\n",
      "Learning rate (eta): 0.095456\n",
      "Total number of feature updates: 64260\n",
      "Seconds required for this iteration: 0.009\n",
      "\n",
      "***** Epoch #239 *****\n",
      "Loss: 1.776659\n",
      "Improvement ratio: 0.012204\n",
      "Feature L2-norm: 30.179535\n",
      "Learning rate (eta): 0.095438\n",
      "Total number of feature updates: 64530\n",
      "Seconds required for this iteration: 0.009\n",
      "\n",
      "***** Epoch #240 *****\n",
      "Loss: 1.774635\n",
      "Improvement ratio: 0.012121\n",
      "Feature L2-norm: 30.192635\n",
      "Learning rate (eta): 0.095420\n",
      "Total number of feature updates: 64800\n",
      "Seconds required for this iteration: 0.011\n",
      "\n",
      "***** Epoch #241 *****\n",
      "Loss: 1.772638\n",
      "Improvement ratio: 0.012017\n",
      "Feature L2-norm: 30.205675\n",
      "Learning rate (eta): 0.095402\n",
      "Total number of feature updates: 65070\n",
      "Seconds required for this iteration: 0.009\n",
      "\n",
      "***** Epoch #242 *****\n",
      "Loss: 1.770654\n",
      "Improvement ratio: 0.011852\n",
      "Feature L2-norm: 30.218648\n",
      "Learning rate (eta): 0.095384\n",
      "Total number of feature updates: 65340\n",
      "Seconds required for this iteration: 0.016\n",
      "\n",
      "***** Epoch #243 *****\n",
      "Loss: 1.768633\n",
      "Improvement ratio: 0.011794\n",
      "Feature L2-norm: 30.231557\n",
      "Learning rate (eta): 0.095365\n",
      "Total number of feature updates: 65610\n",
      "Seconds required for this iteration: 0.009\n",
      "\n",
      "***** Epoch #244 *****\n",
      "Loss: 1.766707\n",
      "Improvement ratio: 0.011652\n",
      "Feature L2-norm: 30.244395\n",
      "Learning rate (eta): 0.095347\n",
      "Total number of feature updates: 65880\n",
      "Seconds required for this iteration: 0.010\n",
      "\n",
      "***** Epoch #245 *****\n",
      "Loss: 1.764570\n",
      "Improvement ratio: 0.011643\n",
      "Feature L2-norm: 30.257182\n",
      "Learning rate (eta): 0.095329\n",
      "Total number of feature updates: 66150\n",
      "Seconds required for this iteration: 0.009\n",
      "\n",
      "***** Epoch #246 *****\n",
      "Loss: 1.762703\n",
      "Improvement ratio: 0.011530\n",
      "Feature L2-norm: 30.269903\n",
      "Learning rate (eta): 0.095311\n",
      "Total number of feature updates: 66420\n",
      "Seconds required for this iteration: 0.008\n",
      "\n",
      "***** Epoch #247 *****\n",
      "Loss: 1.760825\n",
      "Improvement ratio: 0.011434\n",
      "Feature L2-norm: 30.282549\n",
      "Learning rate (eta): 0.095293\n",
      "Total number of feature updates: 66690\n",
      "Seconds required for this iteration: 0.008\n",
      "\n",
      "***** Epoch #248 *****\n",
      "Loss: 1.759037\n",
      "Improvement ratio: 0.011249\n",
      "Feature L2-norm: 30.295138\n",
      "Learning rate (eta): 0.095274\n",
      "Total number of feature updates: 66960\n",
      "Seconds required for this iteration: 0.009\n",
      "\n",
      "***** Epoch #249 *****\n",
      "Loss: 1.757128\n",
      "Improvement ratio: 0.011115\n",
      "Feature L2-norm: 30.307660\n",
      "Learning rate (eta): 0.095256\n",
      "Total number of feature updates: 67230\n",
      "Seconds required for this iteration: 0.010\n",
      "\n",
      "***** Epoch #250 *****\n",
      "Loss: 1.755257\n",
      "Improvement ratio: 0.011040\n",
      "Feature L2-norm: 30.320125\n",
      "Learning rate (eta): 0.095238\n",
      "Total number of feature updates: 67500\n",
      "Seconds required for this iteration: 0.009\n",
      "\n",
      "***** Epoch #251 *****\n",
      "Loss: 1.753420\n",
      "Improvement ratio: 0.010961\n",
      "Feature L2-norm: 30.332521\n",
      "Learning rate (eta): 0.095220\n",
      "Total number of feature updates: 67770\n",
      "Seconds required for this iteration: 0.009\n",
      "\n",
      "***** Epoch #252 *****\n",
      "Loss: 1.751547\n",
      "Improvement ratio: 0.010908\n",
      "Feature L2-norm: 30.344872\n",
      "Learning rate (eta): 0.095202\n",
      "Total number of feature updates: 68040\n",
      "Seconds required for this iteration: 0.009\n",
      "\n",
      "***** Epoch #253 *****\n",
      "Loss: 1.749771\n",
      "Improvement ratio: 0.010780\n",
      "Feature L2-norm: 30.357151\n",
      "Learning rate (eta): 0.095184\n",
      "Total number of feature updates: 68310\n",
      "Seconds required for this iteration: 0.009\n",
      "\n",
      "***** Epoch #254 *****\n",
      "Loss: 1.747964\n",
      "Improvement ratio: 0.010723\n",
      "Feature L2-norm: 30.369367\n",
      "Learning rate (eta): 0.095166\n",
      "Total number of feature updates: 68580\n",
      "Seconds required for this iteration: 0.009\n",
      "\n",
      "***** Epoch #255 *****\n",
      "Loss: 1.746136\n",
      "Improvement ratio: 0.010557\n",
      "Feature L2-norm: 30.381528\n",
      "Learning rate (eta): 0.095148\n",
      "Total number of feature updates: 68850\n",
      "Seconds required for this iteration: 0.009\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** Epoch #256 *****\n",
      "Loss: 1.744475\n",
      "Improvement ratio: 0.010449\n",
      "Feature L2-norm: 30.393641\n",
      "Learning rate (eta): 0.095129\n",
      "Total number of feature updates: 69120\n",
      "Seconds required for this iteration: 0.009\n",
      "\n",
      "***** Epoch #257 *****\n",
      "Loss: 1.742714\n",
      "Improvement ratio: 0.010392\n",
      "Feature L2-norm: 30.405689\n",
      "Learning rate (eta): 0.095111\n",
      "Total number of feature updates: 69390\n",
      "Seconds required for this iteration: 0.008\n",
      "\n",
      "***** Epoch #258 *****\n",
      "Loss: 1.740942\n",
      "Improvement ratio: 0.010394\n",
      "Feature L2-norm: 30.417681\n",
      "Learning rate (eta): 0.095093\n",
      "Total number of feature updates: 69660\n",
      "Seconds required for this iteration: 0.009\n",
      "\n",
      "***** Epoch #259 *****\n",
      "Loss: 1.739288\n",
      "Improvement ratio: 0.010257\n",
      "Feature L2-norm: 30.429612\n",
      "Learning rate (eta): 0.095075\n",
      "Total number of feature updates: 69930\n",
      "Seconds required for this iteration: 0.009\n",
      "\n",
      "***** Epoch #260 *****\n",
      "Loss: 1.737514\n",
      "Improvement ratio: 0.010212\n",
      "Feature L2-norm: 30.441496\n",
      "Learning rate (eta): 0.095057\n",
      "Total number of feature updates: 70200\n",
      "Seconds required for this iteration: 0.009\n",
      "\n",
      "***** Epoch #261 *****\n",
      "Loss: 1.735616\n",
      "Improvement ratio: 0.010258\n",
      "Feature L2-norm: 30.453320\n",
      "Learning rate (eta): 0.095039\n",
      "Total number of feature updates: 70470\n",
      "Seconds required for this iteration: 0.011\n",
      "\n",
      "***** Epoch #262 *****\n",
      "Loss: 1.734192\n",
      "Improvement ratio: 0.010008\n",
      "Feature L2-norm: 30.465079\n",
      "Learning rate (eta): 0.095021\n",
      "Total number of feature updates: 70740\n",
      "Seconds required for this iteration: 0.010\n",
      "\n",
      "***** Epoch #263 *****\n",
      "Loss: 1.732606\n",
      "Improvement ratio: 0.009907\n",
      "Feature L2-norm: 30.476786\n",
      "Learning rate (eta): 0.095003\n",
      "Total number of feature updates: 71010\n",
      "Seconds required for this iteration: 0.009\n",
      "\n",
      "***** Epoch #264 *****\n",
      "Loss: 1.730786\n",
      "Improvement ratio: 0.009925\n",
      "Feature L2-norm: 30.488424\n",
      "Learning rate (eta): 0.094985\n",
      "Total number of feature updates: 71280\n",
      "Seconds required for this iteration: 0.008\n",
      "\n",
      "***** Epoch #265 *****\n",
      "Loss: 1.729293\n",
      "Improvement ratio: 0.009740\n",
      "Feature L2-norm: 30.500023\n",
      "Learning rate (eta): 0.094967\n",
      "Total number of feature updates: 71550\n",
      "Seconds required for this iteration: 0.008\n",
      "\n",
      "***** Epoch #266 *****\n",
      "Loss: 1.727699\n",
      "Improvement ratio: 0.009710\n",
      "Feature L2-norm: 30.511563\n",
      "Learning rate (eta): 0.094949\n",
      "Total number of feature updates: 71820\n",
      "Seconds required for this iteration: 0.009\n",
      "\n",
      "***** Epoch #267 *****\n",
      "Loss: 1.726054\n",
      "Improvement ratio: 0.009652\n",
      "Feature L2-norm: 30.523054\n",
      "Learning rate (eta): 0.094931\n",
      "Total number of feature updates: 72090\n",
      "Seconds required for this iteration: 0.009\n",
      "\n",
      "***** Epoch #268 *****\n",
      "Loss: 1.724557\n",
      "Improvement ratio: 0.009501\n",
      "Feature L2-norm: 30.534488\n",
      "Learning rate (eta): 0.094913\n",
      "Total number of feature updates: 72360\n",
      "Seconds required for this iteration: 0.010\n",
      "\n",
      "***** Epoch #269 *****\n",
      "Loss: 1.723002\n",
      "Improvement ratio: 0.009452\n",
      "Feature L2-norm: 30.545877\n",
      "Learning rate (eta): 0.094895\n",
      "Total number of feature updates: 72630\n",
      "Seconds required for this iteration: 0.008\n",
      "\n",
      "***** Epoch #270 *****\n",
      "Loss: 1.721387\n",
      "Improvement ratio: 0.009369\n",
      "Feature L2-norm: 30.557198\n",
      "Learning rate (eta): 0.094877\n",
      "Total number of feature updates: 72900\n",
      "Seconds required for this iteration: 0.009\n",
      "\n",
      "***** Epoch #271 *****\n",
      "Loss: 1.719897\n",
      "Improvement ratio: 0.009139\n",
      "Feature L2-norm: 30.568478\n",
      "Learning rate (eta): 0.094859\n",
      "Total number of feature updates: 73170\n",
      "Seconds required for this iteration: 0.009\n",
      "\n",
      "***** Epoch #272 *****\n",
      "Loss: 1.718369\n",
      "Improvement ratio: 0.009208\n",
      "Feature L2-norm: 30.579711\n",
      "Learning rate (eta): 0.094841\n",
      "Total number of feature updates: 73440\n",
      "Seconds required for this iteration: 0.011\n",
      "\n",
      "***** Epoch #273 *****\n",
      "Loss: 1.716862\n",
      "Improvement ratio: 0.009170\n",
      "Feature L2-norm: 30.590886\n",
      "Learning rate (eta): 0.094823\n",
      "Total number of feature updates: 73710\n",
      "Seconds required for this iteration: 0.009\n",
      "\n",
      "***** Epoch #274 *****\n",
      "Loss: 1.715342\n",
      "Improvement ratio: 0.009004\n",
      "Feature L2-norm: 30.602018\n",
      "Learning rate (eta): 0.094805\n",
      "Total number of feature updates: 73980\n",
      "Seconds required for this iteration: 0.009\n",
      "\n",
      "***** Epoch #275 *****\n",
      "Loss: 1.713939\n",
      "Improvement ratio: 0.008958\n",
      "Feature L2-norm: 30.613092\n",
      "Learning rate (eta): 0.094787\n",
      "Total number of feature updates: 74250\n",
      "Seconds required for this iteration: 0.009\n",
      "\n",
      "***** Epoch #276 *****\n",
      "Loss: 1.712401\n",
      "Improvement ratio: 0.008934\n",
      "Feature L2-norm: 30.624112\n",
      "Learning rate (eta): 0.094769\n",
      "Total number of feature updates: 74520\n",
      "Seconds required for this iteration: 0.009\n",
      "\n",
      "***** Epoch #277 *****\n",
      "Loss: 1.710970\n",
      "Improvement ratio: 0.008817\n",
      "Feature L2-norm: 30.635088\n",
      "Learning rate (eta): 0.094751\n",
      "Total number of feature updates: 74790\n",
      "Seconds required for this iteration: 0.009\n",
      "\n",
      "***** Epoch #278 *****\n",
      "Loss: 1.709500\n",
      "Improvement ratio: 0.008808\n",
      "Feature L2-norm: 30.646010\n",
      "Learning rate (eta): 0.094733\n",
      "Total number of feature updates: 75060\n",
      "Seconds required for this iteration: 0.009\n",
      "\n",
      "***** Epoch #279 *****\n",
      "Loss: 1.708116\n",
      "Improvement ratio: 0.008714\n",
      "Feature L2-norm: 30.656887\n",
      "Learning rate (eta): 0.094715\n",
      "Total number of feature updates: 75330\n",
      "Seconds required for this iteration: 0.009\n",
      "\n",
      "***** Epoch #280 *****\n",
      "Loss: 1.706667\n",
      "Improvement ratio: 0.008625\n",
      "Feature L2-norm: 30.667715\n",
      "Learning rate (eta): 0.094697\n",
      "Total number of feature updates: 75600\n",
      "Seconds required for this iteration: 0.008\n",
      "\n",
      "***** Epoch #281 *****\n",
      "Loss: 1.705295\n",
      "Improvement ratio: 0.008563\n",
      "Feature L2-norm: 30.678492\n",
      "Learning rate (eta): 0.094679\n",
      "Total number of feature updates: 75870\n",
      "Seconds required for this iteration: 0.009\n",
      "\n",
      "***** Epoch #282 *****\n",
      "Loss: 1.703908\n",
      "Improvement ratio: 0.008487\n",
      "Feature L2-norm: 30.689222\n",
      "Learning rate (eta): 0.094661\n",
      "Total number of feature updates: 76140\n",
      "Seconds required for this iteration: 0.009\n",
      "\n",
      "***** Epoch #283 *****\n",
      "Loss: 1.702434\n",
      "Improvement ratio: 0.008475\n",
      "Feature L2-norm: 30.699905\n",
      "Learning rate (eta): 0.094643\n",
      "Total number of feature updates: 76410\n",
      "Seconds required for this iteration: 0.011\n",
      "\n",
      "***** Epoch #284 *****\n",
      "Loss: 1.701100\n",
      "Improvement ratio: 0.008372\n",
      "Feature L2-norm: 30.710541\n",
      "Learning rate (eta): 0.094625\n",
      "Total number of feature updates: 76680\n",
      "Seconds required for this iteration: 0.010\n",
      "\n",
      "***** Epoch #285 *****\n",
      "Loss: 1.699745\n",
      "Improvement ratio: 0.008351\n",
      "Feature L2-norm: 30.721123\n",
      "Learning rate (eta): 0.094607\n",
      "Total number of feature updates: 76950\n",
      "Seconds required for this iteration: 0.014\n",
      "\n",
      "***** Epoch #286 *****\n",
      "Loss: 1.698450\n",
      "Improvement ratio: 0.008214\n",
      "Feature L2-norm: 30.731661\n",
      "Learning rate (eta): 0.094590\n",
      "Total number of feature updates: 77220\n",
      "Seconds required for this iteration: 0.012\n",
      "\n",
      "***** Epoch #287 *****\n",
      "Loss: 1.696989\n",
      "Improvement ratio: 0.008238\n",
      "Feature L2-norm: 30.742155\n",
      "Learning rate (eta): 0.094572\n",
      "Total number of feature updates: 77490\n",
      "Seconds required for this iteration: 0.011\n",
      "\n",
      "***** Epoch #288 *****\n",
      "Loss: 1.695742\n",
      "Improvement ratio: 0.008114\n",
      "Feature L2-norm: 30.752603\n",
      "Learning rate (eta): 0.094554\n",
      "Total number of feature updates: 77760\n",
      "Seconds required for this iteration: 0.009\n",
      "\n",
      "***** Epoch #289 *****\n",
      "Loss: 1.694412\n",
      "Improvement ratio: 0.008088\n",
      "Feature L2-norm: 30.763002\n",
      "Learning rate (eta): 0.094536\n",
      "Total number of feature updates: 78030\n",
      "Seconds required for this iteration: 0.009\n",
      "\n",
      "***** Epoch #290 *****\n",
      "Loss: 1.693089\n",
      "Improvement ratio: 0.008020\n",
      "Feature L2-norm: 30.773349\n",
      "Learning rate (eta): 0.094518\n",
      "Total number of feature updates: 78300\n",
      "Seconds required for this iteration: 0.009\n",
      "\n",
      "***** Epoch #291 *****\n",
      "Loss: 1.691833\n",
      "Improvement ratio: 0.007957\n",
      "Feature L2-norm: 30.783659\n",
      "Learning rate (eta): 0.094500\n",
      "Total number of feature updates: 78570\n",
      "Seconds required for this iteration: 0.009\n",
      "\n",
      "***** Epoch #292 *****\n",
      "Loss: 1.690566\n",
      "Improvement ratio: 0.007892\n",
      "Feature L2-norm: 30.793927\n",
      "Learning rate (eta): 0.094482\n",
      "Total number of feature updates: 78840\n",
      "Seconds required for this iteration: 0.009\n",
      "\n",
      "***** Epoch #293 *****\n",
      "Loss: 1.689276\n",
      "Improvement ratio: 0.007789\n",
      "Feature L2-norm: 30.804151\n",
      "Learning rate (eta): 0.094464\n",
      "Total number of feature updates: 79110\n",
      "Seconds required for this iteration: 0.010\n",
      "\n",
      "***** Epoch #294 *****\n",
      "Loss: 1.688044\n",
      "Improvement ratio: 0.007734\n",
      "Feature L2-norm: 30.814316\n",
      "Learning rate (eta): 0.094447\n",
      "Total number of feature updates: 79380\n",
      "Seconds required for this iteration: 0.009\n",
      "\n",
      "***** Epoch #295 *****\n",
      "Loss: 1.686636\n",
      "Improvement ratio: 0.007772\n",
      "Feature L2-norm: 30.824438\n",
      "Learning rate (eta): 0.094429\n",
      "Total number of feature updates: 79650\n",
      "Seconds required for this iteration: 0.009\n",
      "\n",
      "***** Epoch #296 *****\n",
      "Loss: 1.685558\n",
      "Improvement ratio: 0.007648\n",
      "Feature L2-norm: 30.834527\n",
      "Learning rate (eta): 0.094411\n",
      "Total number of feature updates: 79920\n",
      "Seconds required for this iteration: 0.010\n",
      "\n",
      "***** Epoch #297 *****\n",
      "Loss: 1.684330\n",
      "Improvement ratio: 0.007516\n",
      "Feature L2-norm: 30.844573\n",
      "Learning rate (eta): 0.094393\n",
      "Total number of feature updates: 80190\n",
      "Seconds required for this iteration: 0.009\n",
      "\n",
      "***** Epoch #298 *****\n",
      "Loss: 1.683115\n",
      "Improvement ratio: 0.007502\n",
      "Feature L2-norm: 30.854576\n",
      "Learning rate (eta): 0.094375\n",
      "Total number of feature updates: 80460\n",
      "Seconds required for this iteration: 0.009\n",
      "\n",
      "***** Epoch #299 *****\n",
      "Loss: 1.681863\n",
      "Improvement ratio: 0.007461\n",
      "Feature L2-norm: 30.864538\n",
      "Learning rate (eta): 0.094357\n",
      "Total number of feature updates: 80730\n",
      "Seconds required for this iteration: 0.010\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** Epoch #300 *****\n",
      "Loss: 1.680669\n",
      "Improvement ratio: 0.007390\n",
      "Feature L2-norm: 30.874451\n",
      "Learning rate (eta): 0.094340\n",
      "Total number of feature updates: 81000\n",
      "Seconds required for this iteration: 0.010\n",
      "\n",
      "***** Epoch #301 *****\n",
      "Loss: 1.679470\n",
      "Improvement ratio: 0.007362\n",
      "Feature L2-norm: 30.884315\n",
      "Learning rate (eta): 0.094322\n",
      "Total number of feature updates: 81270\n",
      "Seconds required for this iteration: 0.012\n",
      "\n",
      "***** Epoch #302 *****\n",
      "Loss: 1.678305\n",
      "Improvement ratio: 0.007306\n",
      "Feature L2-norm: 30.894147\n",
      "Learning rate (eta): 0.094304\n",
      "Total number of feature updates: 81540\n",
      "Seconds required for this iteration: 0.009\n",
      "\n",
      "***** Epoch #303 *****\n",
      "Loss: 1.677152\n",
      "Improvement ratio: 0.007229\n",
      "Feature L2-norm: 30.903929\n",
      "Learning rate (eta): 0.094286\n",
      "Total number of feature updates: 81810\n",
      "Seconds required for this iteration: 0.009\n",
      "\n",
      "***** Epoch #304 *****\n",
      "Loss: 1.676017\n",
      "Improvement ratio: 0.007176\n",
      "Feature L2-norm: 30.913675\n",
      "Learning rate (eta): 0.094269\n",
      "Total number of feature updates: 82080\n",
      "Seconds required for this iteration: 0.011\n",
      "\n",
      "***** Epoch #305 *****\n",
      "Loss: 1.674754\n",
      "Improvement ratio: 0.007095\n",
      "Feature L2-norm: 30.923372\n",
      "Learning rate (eta): 0.094251\n",
      "Total number of feature updates: 82350\n",
      "Seconds required for this iteration: 0.010\n",
      "\n",
      "***** Epoch #306 *****\n",
      "Loss: 1.673697\n",
      "Improvement ratio: 0.007087\n",
      "Feature L2-norm: 30.933040\n",
      "Learning rate (eta): 0.094233\n",
      "Total number of feature updates: 82620\n",
      "Seconds required for this iteration: 0.012\n",
      "\n",
      "***** Epoch #307 *****\n",
      "Loss: 1.672543\n",
      "Improvement ratio: 0.007047\n",
      "Feature L2-norm: 30.942666\n",
      "Learning rate (eta): 0.094215\n",
      "Total number of feature updates: 82890\n",
      "Seconds required for this iteration: 0.009\n",
      "\n",
      "***** Epoch #308 *****\n",
      "Loss: 1.671414\n",
      "Improvement ratio: 0.007001\n",
      "Feature L2-norm: 30.952246\n",
      "Learning rate (eta): 0.094198\n",
      "Total number of feature updates: 83160\n",
      "Seconds required for this iteration: 0.010\n",
      "\n",
      "***** Epoch #309 *****\n",
      "Loss: 1.670304\n",
      "Improvement ratio: 0.006920\n",
      "Feature L2-norm: 30.961786\n",
      "Learning rate (eta): 0.094180\n",
      "Total number of feature updates: 83430\n",
      "Seconds required for this iteration: 0.010\n",
      "\n",
      "***** Epoch #310 *****\n",
      "Loss: 1.669194\n",
      "Improvement ratio: 0.006875\n",
      "Feature L2-norm: 30.971293\n",
      "Learning rate (eta): 0.094162\n",
      "Total number of feature updates: 83700\n",
      "Seconds required for this iteration: 0.009\n",
      "\n",
      "***** Epoch #311 *****\n",
      "Loss: 1.668138\n",
      "Improvement ratio: 0.006793\n",
      "Feature L2-norm: 30.980758\n",
      "Learning rate (eta): 0.094144\n",
      "Total number of feature updates: 83970\n",
      "Seconds required for this iteration: 0.009\n",
      "\n",
      "***** Epoch #312 *****\n",
      "Loss: 1.667037\n",
      "Improvement ratio: 0.006759\n",
      "Feature L2-norm: 30.990183\n",
      "Learning rate (eta): 0.094127\n",
      "Total number of feature updates: 84240\n",
      "Seconds required for this iteration: 0.008\n",
      "\n",
      "***** Epoch #313 *****\n",
      "Loss: 1.665896\n",
      "Improvement ratio: 0.006757\n",
      "Feature L2-norm: 30.999574\n",
      "Learning rate (eta): 0.094109\n",
      "Total number of feature updates: 84510\n",
      "Seconds required for this iteration: 0.008\n",
      "\n",
      "***** Epoch #314 *****\n",
      "Loss: 1.664858\n",
      "Improvement ratio: 0.006703\n",
      "Feature L2-norm: 31.008912\n",
      "Learning rate (eta): 0.094091\n",
      "Total number of feature updates: 84780\n",
      "Seconds required for this iteration: 0.009\n",
      "\n",
      "***** Epoch #315 *****\n",
      "Loss: 1.663799\n",
      "Improvement ratio: 0.006585\n",
      "Feature L2-norm: 31.018219\n",
      "Learning rate (eta): 0.094073\n",
      "Total number of feature updates: 85050\n",
      "Seconds required for this iteration: 0.010\n",
      "\n",
      "***** Epoch #316 *****\n",
      "Loss: 1.662718\n",
      "Improvement ratio: 0.006603\n",
      "Feature L2-norm: 31.027485\n",
      "Learning rate (eta): 0.094056\n",
      "Total number of feature updates: 85320\n",
      "Seconds required for this iteration: 0.009\n",
      "\n",
      "***** Epoch #317 *****\n",
      "Loss: 1.661712\n",
      "Improvement ratio: 0.006518\n",
      "Feature L2-norm: 31.036716\n",
      "Learning rate (eta): 0.094038\n",
      "Total number of feature updates: 85590\n",
      "Seconds required for this iteration: 0.010\n",
      "\n",
      "***** Epoch #318 *****\n",
      "Loss: 1.660606\n",
      "Improvement ratio: 0.006508\n",
      "Feature L2-norm: 31.045916\n",
      "Learning rate (eta): 0.094020\n",
      "Total number of feature updates: 85860\n",
      "Seconds required for this iteration: 0.009\n",
      "\n",
      "***** Epoch #319 *****\n",
      "Loss: 1.659645\n",
      "Improvement ratio: 0.006423\n",
      "Feature L2-norm: 31.055074\n",
      "Learning rate (eta): 0.094003\n",
      "Total number of feature updates: 86130\n",
      "Seconds required for this iteration: 0.010\n",
      "\n",
      "***** Epoch #320 *****\n",
      "Loss: 1.658653\n",
      "Improvement ratio: 0.006355\n",
      "Feature L2-norm: 31.064188\n",
      "Learning rate (eta): 0.093985\n",
      "Total number of feature updates: 86400\n",
      "Seconds required for this iteration: 0.009\n",
      "\n",
      "***** Epoch #321 *****\n",
      "Loss: 1.657585\n",
      "Improvement ratio: 0.006366\n",
      "Feature L2-norm: 31.073274\n",
      "Learning rate (eta): 0.093967\n",
      "Total number of feature updates: 86670\n",
      "Seconds required for this iteration: 0.009\n",
      "\n",
      "***** Epoch #322 *****\n",
      "Loss: 1.656540\n",
      "Improvement ratio: 0.006337\n",
      "Feature L2-norm: 31.082322\n",
      "Learning rate (eta): 0.093950\n",
      "Total number of feature updates: 86940\n",
      "Seconds required for this iteration: 0.008\n",
      "\n",
      "***** Epoch #323 *****\n",
      "Loss: 1.655612\n",
      "Improvement ratio: 0.006211\n",
      "Feature L2-norm: 31.091329\n",
      "Learning rate (eta): 0.093932\n",
      "Total number of feature updates: 87210\n",
      "Seconds required for this iteration: 0.010\n",
      "\n",
      "***** Epoch #324 *****\n",
      "Loss: 1.654583\n",
      "Improvement ratio: 0.006210\n",
      "Feature L2-norm: 31.100298\n",
      "Learning rate (eta): 0.093914\n",
      "Total number of feature updates: 87480\n",
      "Seconds required for this iteration: 0.008\n",
      "\n",
      "***** Epoch #325 *****\n",
      "Loss: 1.653584\n",
      "Improvement ratio: 0.006177\n",
      "Feature L2-norm: 31.109237\n",
      "Learning rate (eta): 0.093897\n",
      "Total number of feature updates: 87750\n",
      "Seconds required for this iteration: 0.014\n",
      "\n",
      "***** Epoch #326 *****\n",
      "Loss: 1.652646\n",
      "Improvement ratio: 0.006095\n",
      "Feature L2-norm: 31.118129\n",
      "Learning rate (eta): 0.093879\n",
      "Total number of feature updates: 88020\n",
      "Seconds required for this iteration: 0.008\n",
      "\n",
      "***** Epoch #327 *****\n",
      "Loss: 1.651603\n",
      "Improvement ratio: 0.006120\n",
      "Feature L2-norm: 31.126998\n",
      "Learning rate (eta): 0.093862\n",
      "Total number of feature updates: 88290\n",
      "Seconds required for this iteration: 0.008\n",
      "\n",
      "***** Epoch #328 *****\n",
      "Loss: 1.650698\n",
      "Improvement ratio: 0.006002\n",
      "Feature L2-norm: 31.135826\n",
      "Learning rate (eta): 0.093844\n",
      "Total number of feature updates: 88560\n",
      "Seconds required for this iteration: 0.008\n",
      "\n",
      "***** Epoch #329 *****\n",
      "Loss: 1.649765\n",
      "Improvement ratio: 0.005989\n",
      "Feature L2-norm: 31.144620\n",
      "Learning rate (eta): 0.093826\n",
      "Total number of feature updates: 88830\n",
      "Seconds required for this iteration: 0.009\n",
      "\n",
      "***** Epoch #330 *****\n",
      "Loss: 1.648808\n",
      "Improvement ratio: 0.005971\n",
      "Feature L2-norm: 31.153379\n",
      "Learning rate (eta): 0.093809\n",
      "Total number of feature updates: 89100\n",
      "Seconds required for this iteration: 0.010\n",
      "\n",
      "***** Epoch #331 *****\n",
      "Loss: 1.647884\n",
      "Improvement ratio: 0.005887\n",
      "Feature L2-norm: 31.162103\n",
      "Learning rate (eta): 0.093791\n",
      "Total number of feature updates: 89370\n",
      "Seconds required for this iteration: 0.016\n",
      "\n",
      "***** Epoch #332 *****\n",
      "Loss: 1.646913\n",
      "Improvement ratio: 0.005845\n",
      "Feature L2-norm: 31.170787\n",
      "Learning rate (eta): 0.093774\n",
      "Total number of feature updates: 89640\n",
      "Seconds required for this iteration: 0.009\n",
      "\n",
      "***** Epoch #333 *****\n",
      "Loss: 1.646018\n",
      "Improvement ratio: 0.005829\n",
      "Feature L2-norm: 31.179436\n",
      "Learning rate (eta): 0.093756\n",
      "Total number of feature updates: 89910\n",
      "Seconds required for this iteration: 0.010\n",
      "\n",
      "***** Epoch #334 *****\n",
      "Loss: 1.645096\n",
      "Improvement ratio: 0.005767\n",
      "Feature L2-norm: 31.188053\n",
      "Learning rate (eta): 0.093738\n",
      "Total number of feature updates: 90180\n",
      "Seconds required for this iteration: 0.009\n",
      "\n",
      "***** Epoch #335 *****\n",
      "Loss: 1.644193\n",
      "Improvement ratio: 0.005712\n",
      "Feature L2-norm: 31.196634\n",
      "Learning rate (eta): 0.093721\n",
      "Total number of feature updates: 90450\n",
      "Seconds required for this iteration: 0.008\n",
      "\n",
      "***** Epoch #336 *****\n",
      "Loss: 1.643305\n",
      "Improvement ratio: 0.005684\n",
      "Feature L2-norm: 31.205181\n",
      "Learning rate (eta): 0.093703\n",
      "Total number of feature updates: 90720\n",
      "Seconds required for this iteration: 0.009\n",
      "\n",
      "***** Epoch #337 *****\n",
      "Loss: 1.642400\n",
      "Improvement ratio: 0.005604\n",
      "Feature L2-norm: 31.213692\n",
      "Learning rate (eta): 0.093686\n",
      "Total number of feature updates: 90990\n",
      "Seconds required for this iteration: 0.008\n",
      "\n",
      "***** Epoch #338 *****\n",
      "Loss: 1.641509\n",
      "Improvement ratio: 0.005598\n",
      "Feature L2-norm: 31.222181\n",
      "Learning rate (eta): 0.093668\n",
      "Total number of feature updates: 91260\n",
      "Seconds required for this iteration: 0.009\n",
      "\n",
      "***** Epoch #339 *****\n",
      "Loss: 1.640634\n",
      "Improvement ratio: 0.005565\n",
      "Feature L2-norm: 31.230629\n",
      "Learning rate (eta): 0.093651\n",
      "Total number of feature updates: 91530\n",
      "Seconds required for this iteration: 0.008\n",
      "\n",
      "***** Epoch #340 *****\n",
      "Loss: 1.639701\n",
      "Improvement ratio: 0.005554\n",
      "Feature L2-norm: 31.239048\n",
      "Learning rate (eta): 0.093633\n",
      "Total number of feature updates: 91800\n",
      "Seconds required for this iteration: 0.009\n",
      "\n",
      "***** Epoch #341 *****\n",
      "Loss: 1.638870\n",
      "Improvement ratio: 0.005500\n",
      "Feature L2-norm: 31.247435\n",
      "Learning rate (eta): 0.093615\n",
      "Total number of feature updates: 92070\n",
      "Seconds required for this iteration: 0.008\n",
      "\n",
      "***** Epoch #342 *****\n",
      "Loss: 1.637996\n",
      "Improvement ratio: 0.005444\n",
      "Feature L2-norm: 31.255789\n",
      "Learning rate (eta): 0.093598\n",
      "Total number of feature updates: 92340\n",
      "Seconds required for this iteration: 0.008\n",
      "\n",
      "***** Epoch #343 *****\n",
      "Loss: 1.637105\n",
      "Improvement ratio: 0.005444\n",
      "Feature L2-norm: 31.264114\n",
      "Learning rate (eta): 0.093580\n",
      "Total number of feature updates: 92610\n",
      "Seconds required for this iteration: 0.010\n",
      "\n",
      "***** Epoch #344 *****\n",
      "Loss: 1.636304\n",
      "Improvement ratio: 0.005373\n",
      "Feature L2-norm: 31.272400\n",
      "Learning rate (eta): 0.093563\n",
      "Total number of feature updates: 92880\n",
      "Seconds required for this iteration: 0.009\n",
      "\n",
      "***** Epoch #345 *****\n",
      "Loss: 1.635400\n",
      "Improvement ratio: 0.005377\n",
      "Feature L2-norm: 31.280655\n",
      "Learning rate (eta): 0.093545\n",
      "Total number of feature updates: 93150\n",
      "Seconds required for this iteration: 0.010\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** Epoch #346 *****\n",
      "Loss: 1.634627\n",
      "Improvement ratio: 0.005309\n",
      "Feature L2-norm: 31.288877\n",
      "Learning rate (eta): 0.093528\n",
      "Total number of feature updates: 93420\n",
      "Seconds required for this iteration: 0.011\n",
      "\n",
      "***** Epoch #347 *****\n",
      "Loss: 1.633768\n",
      "Improvement ratio: 0.005283\n",
      "Feature L2-norm: 31.297068\n",
      "Learning rate (eta): 0.093510\n",
      "Total number of feature updates: 93690\n",
      "Seconds required for this iteration: 0.010\n",
      "\n",
      "***** Epoch #348 *****\n",
      "Loss: 1.632938\n",
      "Improvement ratio: 0.005249\n",
      "Feature L2-norm: 31.305222\n",
      "Learning rate (eta): 0.093493\n",
      "Total number of feature updates: 93960\n",
      "Seconds required for this iteration: 0.011\n",
      "\n",
      "***** Epoch #349 *****\n",
      "Loss: 1.632086\n",
      "Improvement ratio: 0.005238\n",
      "Feature L2-norm: 31.313353\n",
      "Learning rate (eta): 0.093475\n",
      "Total number of feature updates: 94230\n",
      "Seconds required for this iteration: 0.009\n",
      "\n",
      "***** Epoch #350 *****\n",
      "Loss: 1.631285\n",
      "Improvement ratio: 0.005159\n",
      "Feature L2-norm: 31.321450\n",
      "Learning rate (eta): 0.093458\n",
      "Total number of feature updates: 94500\n",
      "Seconds required for this iteration: 0.010\n",
      "\n",
      "***** Epoch #351 *****\n",
      "Loss: 1.630498\n",
      "Improvement ratio: 0.005134\n",
      "Feature L2-norm: 31.329515\n",
      "Learning rate (eta): 0.093441\n",
      "Total number of feature updates: 94770\n",
      "Seconds required for this iteration: 0.011\n",
      "\n",
      "***** Epoch #352 *****\n",
      "Loss: 1.629674\n",
      "Improvement ratio: 0.005107\n",
      "Feature L2-norm: 31.337543\n",
      "Learning rate (eta): 0.093423\n",
      "Total number of feature updates: 95040\n",
      "Seconds required for this iteration: 0.010\n",
      "\n",
      "***** Epoch #353 *****\n",
      "Loss: 1.628899\n",
      "Improvement ratio: 0.005038\n",
      "Feature L2-norm: 31.345543\n",
      "Learning rate (eta): 0.093406\n",
      "Total number of feature updates: 95310\n",
      "Seconds required for this iteration: 0.010\n",
      "\n",
      "***** Epoch #354 *****\n",
      "Loss: 1.628067\n",
      "Improvement ratio: 0.005060\n",
      "Feature L2-norm: 31.353522\n",
      "Learning rate (eta): 0.093388\n",
      "Total number of feature updates: 95580\n",
      "Seconds required for this iteration: 0.013\n",
      "\n",
      "***** Epoch #355 *****\n",
      "Loss: 1.627282\n",
      "Improvement ratio: 0.004989\n",
      "Feature L2-norm: 31.361467\n",
      "Learning rate (eta): 0.093371\n",
      "Total number of feature updates: 95850\n",
      "Seconds required for this iteration: 0.016\n",
      "\n",
      "***** Epoch #356 *****\n",
      "Loss: 1.626510\n",
      "Improvement ratio: 0.004990\n",
      "Feature L2-norm: 31.369379\n",
      "Learning rate (eta): 0.093353\n",
      "Total number of feature updates: 96120\n",
      "Seconds required for this iteration: 0.013\n",
      "\n",
      "***** Epoch #357 *****\n",
      "Loss: 1.625716\n",
      "Improvement ratio: 0.004953\n",
      "Feature L2-norm: 31.377266\n",
      "Learning rate (eta): 0.093336\n",
      "Total number of feature updates: 96390\n",
      "Seconds required for this iteration: 0.014\n",
      "\n",
      "***** Epoch #358 *****\n",
      "Loss: 1.624986\n",
      "Improvement ratio: 0.004894\n",
      "Feature L2-norm: 31.385119\n",
      "Learning rate (eta): 0.093318\n",
      "Total number of feature updates: 96660\n",
      "Seconds required for this iteration: 0.012\n",
      "\n",
      "***** Epoch #359 *****\n",
      "Loss: 1.624240\n",
      "Improvement ratio: 0.004831\n",
      "Feature L2-norm: 31.392936\n",
      "Learning rate (eta): 0.093301\n",
      "Total number of feature updates: 96930\n",
      "Seconds required for this iteration: 0.011\n",
      "\n",
      "***** Epoch #360 *****\n",
      "Loss: 1.623494\n",
      "Improvement ratio: 0.004799\n",
      "Feature L2-norm: 31.400729\n",
      "Learning rate (eta): 0.093284\n",
      "Total number of feature updates: 97200\n",
      "Seconds required for this iteration: 0.009\n",
      "\n",
      "***** Epoch #361 *****\n",
      "Loss: 1.622709\n",
      "Improvement ratio: 0.004800\n",
      "Feature L2-norm: 31.408494\n",
      "Learning rate (eta): 0.093266\n",
      "Total number of feature updates: 97470\n",
      "Seconds required for this iteration: 0.011\n",
      "\n",
      "***** Epoch #362 *****\n",
      "Loss: 1.621960\n",
      "Improvement ratio: 0.004756\n",
      "Feature L2-norm: 31.416231\n",
      "Learning rate (eta): 0.093249\n",
      "Total number of feature updates: 97740\n",
      "Seconds required for this iteration: 0.012\n",
      "\n",
      "***** Epoch #363 *****\n",
      "Loss: 1.621202\n",
      "Improvement ratio: 0.004748\n",
      "Feature L2-norm: 31.423945\n",
      "Learning rate (eta): 0.093231\n",
      "Total number of feature updates: 98010\n",
      "Seconds required for this iteration: 0.012\n",
      "\n",
      "***** Epoch #364 *****\n",
      "Loss: 1.620468\n",
      "Improvement ratio: 0.004689\n",
      "Feature L2-norm: 31.431622\n",
      "Learning rate (eta): 0.093214\n",
      "Total number of feature updates: 98280\n",
      "Seconds required for this iteration: 0.010\n",
      "\n",
      "***** Epoch #365 *****\n",
      "Loss: 1.619743\n",
      "Improvement ratio: 0.004655\n",
      "Feature L2-norm: 31.439272\n",
      "Learning rate (eta): 0.093197\n",
      "Total number of feature updates: 98550\n",
      "Seconds required for this iteration: 0.011\n",
      "\n",
      "***** Epoch #366 *****\n",
      "Loss: 1.619009\n",
      "Improvement ratio: 0.004633\n",
      "Feature L2-norm: 31.446897\n",
      "Learning rate (eta): 0.093179\n",
      "Total number of feature updates: 98820\n",
      "Seconds required for this iteration: 0.010\n",
      "\n",
      "***** Epoch #367 *****\n",
      "Loss: 1.618310\n",
      "Improvement ratio: 0.004576\n",
      "Feature L2-norm: 31.454494\n",
      "Learning rate (eta): 0.093162\n",
      "Total number of feature updates: 99090\n",
      "Seconds required for this iteration: 0.009\n",
      "\n",
      "***** Epoch #368 *****\n",
      "Loss: 1.617563\n",
      "Improvement ratio: 0.004589\n",
      "Feature L2-norm: 31.462063\n",
      "Learning rate (eta): 0.093145\n",
      "Total number of feature updates: 99360\n",
      "Seconds required for this iteration: 0.010\n",
      "\n",
      "***** Epoch #369 *****\n",
      "Loss: 1.616865\n",
      "Improvement ratio: 0.004561\n",
      "Feature L2-norm: 31.469600\n",
      "Learning rate (eta): 0.093127\n",
      "Total number of feature updates: 99630\n",
      "Seconds required for this iteration: 0.009\n",
      "\n",
      "***** Epoch #370 *****\n",
      "Loss: 1.616142\n",
      "Improvement ratio: 0.004549\n",
      "Feature L2-norm: 31.477113\n",
      "Learning rate (eta): 0.093110\n",
      "Total number of feature updates: 99900\n",
      "Seconds required for this iteration: 0.008\n",
      "\n",
      "***** Epoch #371 *****\n",
      "Loss: 1.615429\n",
      "Improvement ratio: 0.004507\n",
      "Feature L2-norm: 31.484592\n",
      "Learning rate (eta): 0.093093\n",
      "Total number of feature updates: 100170\n",
      "Seconds required for this iteration: 0.009\n",
      "\n",
      "***** Epoch #372 *****\n",
      "Loss: 1.614683\n",
      "Improvement ratio: 0.004507\n",
      "Feature L2-norm: 31.492048\n",
      "Learning rate (eta): 0.093075\n",
      "Total number of feature updates: 100440\n",
      "Seconds required for this iteration: 0.009\n",
      "\n",
      "***** Epoch #373 *****\n",
      "Loss: 1.614063\n",
      "Improvement ratio: 0.004423\n",
      "Feature L2-norm: 31.499474\n",
      "Learning rate (eta): 0.093058\n",
      "Total number of feature updates: 100710\n",
      "Seconds required for this iteration: 0.011\n",
      "\n",
      "***** Epoch #374 *****\n",
      "Loss: 1.613350\n",
      "Improvement ratio: 0.004412\n",
      "Feature L2-norm: 31.506876\n",
      "Learning rate (eta): 0.093041\n",
      "Total number of feature updates: 100980\n",
      "Seconds required for this iteration: 0.010\n",
      "\n",
      "***** Epoch #375 *****\n",
      "Loss: 1.612670\n",
      "Improvement ratio: 0.004386\n",
      "Feature L2-norm: 31.514249\n",
      "Learning rate (eta): 0.093023\n",
      "Total number of feature updates: 101250\n",
      "Seconds required for this iteration: 0.011\n",
      "\n",
      "***** Epoch #376 *****\n",
      "Loss: 1.611949\n",
      "Improvement ratio: 0.004380\n",
      "Feature L2-norm: 31.521599\n",
      "Learning rate (eta): 0.093006\n",
      "Total number of feature updates: 101520\n",
      "Seconds required for this iteration: 0.009\n",
      "\n",
      "***** Epoch #377 *****\n",
      "Loss: 1.611346\n",
      "Improvement ratio: 0.004322\n",
      "Feature L2-norm: 31.528916\n",
      "Learning rate (eta): 0.092989\n",
      "Total number of feature updates: 101790\n",
      "Seconds required for this iteration: 0.009\n",
      "\n",
      "***** Epoch #378 *****\n",
      "Loss: 1.610666\n",
      "Improvement ratio: 0.004282\n",
      "Feature L2-norm: 31.536204\n",
      "Learning rate (eta): 0.092971\n",
      "Total number of feature updates: 102060\n",
      "Seconds required for this iteration: 0.010\n",
      "\n",
      "***** Epoch #379 *****\n",
      "Loss: 1.610018\n",
      "Improvement ratio: 0.004253\n",
      "Feature L2-norm: 31.543468\n",
      "Learning rate (eta): 0.092954\n",
      "Total number of feature updates: 102330\n",
      "Seconds required for this iteration: 0.009\n",
      "\n",
      "***** Epoch #380 *****\n",
      "Loss: 1.609306\n",
      "Improvement ratio: 0.004248\n",
      "Feature L2-norm: 31.550710\n",
      "Learning rate (eta): 0.092937\n",
      "Total number of feature updates: 102600\n",
      "Seconds required for this iteration: 0.008\n",
      "\n",
      "***** Epoch #381 *****\n",
      "Loss: 1.608638\n",
      "Improvement ratio: 0.004222\n",
      "Feature L2-norm: 31.557919\n",
      "Learning rate (eta): 0.092920\n",
      "Total number of feature updates: 102870\n",
      "Seconds required for this iteration: 0.008\n",
      "\n",
      "***** Epoch #382 *****\n",
      "Loss: 1.607910\n",
      "Improvement ratio: 0.004213\n",
      "Feature L2-norm: 31.565102\n",
      "Learning rate (eta): 0.092902\n",
      "Total number of feature updates: 103140\n",
      "Seconds required for this iteration: 0.009\n",
      "\n",
      "***** Epoch #383 *****\n",
      "Loss: 1.607351\n",
      "Improvement ratio: 0.004176\n",
      "Feature L2-norm: 31.572265\n",
      "Learning rate (eta): 0.092885\n",
      "Total number of feature updates: 103410\n",
      "Seconds required for this iteration: 0.009\n",
      "\n",
      "***** Epoch #384 *****\n",
      "Loss: 1.606760\n",
      "Improvement ratio: 0.004102\n",
      "Feature L2-norm: 31.579399\n",
      "Learning rate (eta): 0.092868\n",
      "Total number of feature updates: 103680\n",
      "Seconds required for this iteration: 0.010\n",
      "\n",
      "***** Epoch #385 *****\n",
      "Loss: 1.606105\n",
      "Improvement ratio: 0.004088\n",
      "Feature L2-norm: 31.586513\n",
      "Learning rate (eta): 0.092851\n",
      "Total number of feature updates: 103950\n",
      "Seconds required for this iteration: 0.008\n",
      "\n",
      "***** Epoch #386 *****\n",
      "Loss: 1.605455\n",
      "Improvement ratio: 0.004045\n",
      "Feature L2-norm: 31.593600\n",
      "Learning rate (eta): 0.092833\n",
      "Total number of feature updates: 104220\n",
      "Seconds required for this iteration: 0.009\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** Epoch #387 *****\n",
      "Loss: 1.604800\n",
      "Improvement ratio: 0.004079\n",
      "Feature L2-norm: 31.600663\n",
      "Learning rate (eta): 0.092816\n",
      "Total number of feature updates: 104490\n",
      "Seconds required for this iteration: 0.009\n",
      "\n",
      "***** Epoch #388 *****\n",
      "Loss: 1.604195\n",
      "Improvement ratio: 0.004034\n",
      "Feature L2-norm: 31.607695\n",
      "Learning rate (eta): 0.092799\n",
      "Total number of feature updates: 104760\n",
      "Seconds required for this iteration: 0.009\n",
      "\n",
      "***** Epoch #389 *****\n",
      "Loss: 1.603560\n",
      "Improvement ratio: 0.004027\n",
      "Feature L2-norm: 31.614707\n",
      "Learning rate (eta): 0.092782\n",
      "Total number of feature updates: 105030\n",
      "Seconds required for this iteration: 0.009\n",
      "\n",
      "***** Epoch #390 *****\n",
      "Loss: 1.602962\n",
      "Improvement ratio: 0.003958\n",
      "Feature L2-norm: 31.621694\n",
      "Learning rate (eta): 0.092764\n",
      "Total number of feature updates: 105300\n",
      "Seconds required for this iteration: 0.008\n",
      "\n",
      "***** Epoch #391 *****\n",
      "Loss: 1.602313\n",
      "Improvement ratio: 0.003947\n",
      "Feature L2-norm: 31.628655\n",
      "Learning rate (eta): 0.092747\n",
      "Total number of feature updates: 105570\n",
      "Seconds required for this iteration: 0.009\n",
      "\n",
      "***** Epoch #392 *****\n",
      "Loss: 1.601672\n",
      "Improvement ratio: 0.003894\n",
      "Feature L2-norm: 31.635591\n",
      "Learning rate (eta): 0.092730\n",
      "Total number of feature updates: 105840\n",
      "Seconds required for this iteration: 0.008\n",
      "\n",
      "***** Epoch #393 *****\n",
      "Loss: 1.601138\n",
      "Improvement ratio: 0.003880\n",
      "Feature L2-norm: 31.642502\n",
      "Learning rate (eta): 0.092713\n",
      "Total number of feature updates: 106110\n",
      "Seconds required for this iteration: 0.008\n",
      "\n",
      "***** Epoch #394 *****\n",
      "Loss: 1.600533\n",
      "Improvement ratio: 0.003890\n",
      "Feature L2-norm: 31.649382\n",
      "Learning rate (eta): 0.092696\n",
      "Total number of feature updates: 106380\n",
      "Seconds required for this iteration: 0.009\n",
      "\n",
      "***** Epoch #395 *****\n",
      "Loss: 1.599931\n",
      "Improvement ratio: 0.003859\n",
      "Feature L2-norm: 31.656243\n",
      "Learning rate (eta): 0.092678\n",
      "Total number of feature updates: 106650\n",
      "Seconds required for this iteration: 0.008\n",
      "\n",
      "***** Epoch #396 *****\n",
      "Loss: 1.599341\n",
      "Improvement ratio: 0.003823\n",
      "Feature L2-norm: 31.663087\n",
      "Learning rate (eta): 0.092661\n",
      "Total number of feature updates: 106920\n",
      "Seconds required for this iteration: 0.010\n",
      "\n",
      "***** Epoch #397 *****\n",
      "Loss: 1.598766\n",
      "Improvement ratio: 0.003774\n",
      "Feature L2-norm: 31.669902\n",
      "Learning rate (eta): 0.092644\n",
      "Total number of feature updates: 107190\n",
      "Seconds required for this iteration: 0.010\n",
      "\n",
      "***** Epoch #398 *****\n",
      "Loss: 1.598158\n",
      "Improvement ratio: 0.003777\n",
      "Feature L2-norm: 31.676694\n",
      "Learning rate (eta): 0.092627\n",
      "Total number of feature updates: 107460\n",
      "Seconds required for this iteration: 0.009\n",
      "\n",
      "***** Epoch #399 *****\n",
      "Loss: 1.597514\n",
      "Improvement ratio: 0.003784\n",
      "Feature L2-norm: 31.683462\n",
      "Learning rate (eta): 0.092610\n",
      "Total number of feature updates: 107730\n",
      "Seconds required for this iteration: 0.011\n",
      "\n",
      "***** Epoch #400 *****\n",
      "Loss: 1.597004\n",
      "Improvement ratio: 0.003730\n",
      "Feature L2-norm: 31.690200\n",
      "Learning rate (eta): 0.092593\n",
      "Total number of feature updates: 108000\n",
      "Seconds required for this iteration: 0.008\n",
      "\n",
      "***** Epoch #401 *****\n",
      "Loss: 1.596410\n",
      "Improvement ratio: 0.003698\n",
      "Feature L2-norm: 31.696919\n",
      "Learning rate (eta): 0.092576\n",
      "Total number of feature updates: 108270\n",
      "Seconds required for this iteration: 0.009\n",
      "\n",
      "***** Epoch #402 *****\n",
      "Loss: 1.595843\n",
      "Improvement ratio: 0.003652\n",
      "Feature L2-norm: 31.703611\n",
      "Learning rate (eta): 0.092558\n",
      "Total number of feature updates: 108540\n",
      "Seconds required for this iteration: 0.009\n",
      "\n",
      "***** Epoch #403 *****\n",
      "Loss: 1.595228\n",
      "Improvement ratio: 0.003705\n",
      "Feature L2-norm: 31.710279\n",
      "Learning rate (eta): 0.092541\n",
      "Total number of feature updates: 108810\n",
      "Seconds required for this iteration: 0.008\n",
      "\n",
      "***** Epoch #404 *****\n",
      "Loss: 1.594742\n",
      "Improvement ratio: 0.003632\n",
      "Feature L2-norm: 31.716925\n",
      "Learning rate (eta): 0.092524\n",
      "Total number of feature updates: 109080\n",
      "Seconds required for this iteration: 0.009\n",
      "\n",
      "***** Epoch #405 *****\n",
      "Loss: 1.594160\n",
      "Improvement ratio: 0.003620\n",
      "Feature L2-norm: 31.723553\n",
      "Learning rate (eta): 0.092507\n",
      "Total number of feature updates: 109350\n",
      "Seconds required for this iteration: 0.008\n",
      "\n",
      "***** Epoch #406 *****\n",
      "Loss: 1.593574\n",
      "Improvement ratio: 0.003619\n",
      "Feature L2-norm: 31.730156\n",
      "Learning rate (eta): 0.092490\n",
      "Total number of feature updates: 109620\n",
      "Seconds required for this iteration: 0.009\n",
      "\n",
      "***** Epoch #407 *****\n",
      "Loss: 1.593025\n",
      "Improvement ratio: 0.003604\n",
      "Feature L2-norm: 31.736739\n",
      "Learning rate (eta): 0.092473\n",
      "Total number of feature updates: 109890\n",
      "Seconds required for this iteration: 0.008\n",
      "\n",
      "***** Epoch #408 *****\n",
      "Loss: 1.592509\n",
      "Improvement ratio: 0.003548\n",
      "Feature L2-norm: 31.743298\n",
      "Learning rate (eta): 0.092456\n",
      "Total number of feature updates: 110160\n",
      "Seconds required for this iteration: 0.008\n",
      "\n",
      "***** Epoch #409 *****\n",
      "Loss: 1.591967\n",
      "Improvement ratio: 0.003484\n",
      "Feature L2-norm: 31.749835\n",
      "Learning rate (eta): 0.092439\n",
      "Total number of feature updates: 110430\n",
      "Seconds required for this iteration: 0.008\n",
      "\n",
      "***** Epoch #410 *****\n",
      "Loss: 1.591405\n",
      "Improvement ratio: 0.003519\n",
      "Feature L2-norm: 31.756346\n",
      "Learning rate (eta): 0.092422\n",
      "Total number of feature updates: 110700\n",
      "Seconds required for this iteration: 0.008\n",
      "\n",
      "***** Epoch #411 *****\n",
      "Loss: 1.590881\n",
      "Improvement ratio: 0.003475\n",
      "Feature L2-norm: 31.762834\n",
      "Learning rate (eta): 0.092404\n",
      "Total number of feature updates: 110970\n",
      "Seconds required for this iteration: 0.008\n",
      "\n",
      "***** Epoch #412 *****\n",
      "Loss: 1.590306\n",
      "Improvement ratio: 0.003482\n",
      "Feature L2-norm: 31.769299\n",
      "Learning rate (eta): 0.092387\n",
      "Total number of feature updates: 111240\n",
      "Seconds required for this iteration: 0.008\n",
      "\n",
      "***** Epoch #413 *****\n",
      "Loss: 1.589810\n",
      "Improvement ratio: 0.003408\n",
      "Feature L2-norm: 31.775742\n",
      "Learning rate (eta): 0.092370\n",
      "Total number of feature updates: 111510\n",
      "Seconds required for this iteration: 0.009\n",
      "\n",
      "***** Epoch #414 *****\n",
      "Loss: 1.589250\n",
      "Improvement ratio: 0.003456\n",
      "Feature L2-norm: 31.782171\n",
      "Learning rate (eta): 0.092353\n",
      "Total number of feature updates: 111780\n",
      "Seconds required for this iteration: 0.008\n",
      "\n",
      "***** Epoch #415 *****\n",
      "Loss: 1.588761\n",
      "Improvement ratio: 0.003398\n",
      "Feature L2-norm: 31.788573\n",
      "Learning rate (eta): 0.092336\n",
      "Total number of feature updates: 112050\n",
      "Seconds required for this iteration: 0.008\n",
      "\n",
      "***** Epoch #416 *****\n",
      "Loss: 1.588265\n",
      "Improvement ratio: 0.003343\n",
      "Feature L2-norm: 31.794950\n",
      "Learning rate (eta): 0.092319\n",
      "Total number of feature updates: 112320\n",
      "Seconds required for this iteration: 0.008\n",
      "\n",
      "***** Epoch #417 *****\n",
      "Loss: 1.587706\n",
      "Improvement ratio: 0.003351\n",
      "Feature L2-norm: 31.801305\n",
      "Learning rate (eta): 0.092302\n",
      "Total number of feature updates: 112590\n",
      "Seconds required for this iteration: 0.008\n",
      "\n",
      "***** Epoch #418 *****\n",
      "Loss: 1.587209\n",
      "Improvement ratio: 0.003339\n",
      "Feature L2-norm: 31.807640\n",
      "Learning rate (eta): 0.092285\n",
      "Total number of feature updates: 112860\n",
      "Seconds required for this iteration: 0.009\n",
      "\n",
      "***** Epoch #419 *****\n",
      "Loss: 1.586676\n",
      "Improvement ratio: 0.003335\n",
      "Feature L2-norm: 31.813958\n",
      "Learning rate (eta): 0.092268\n",
      "Total number of feature updates: 113130\n",
      "Seconds required for this iteration: 0.010\n",
      "\n",
      "***** Epoch #420 *****\n",
      "Loss: 1.586127\n",
      "Improvement ratio: 0.003327\n",
      "Feature L2-norm: 31.820251\n",
      "Learning rate (eta): 0.092251\n",
      "Total number of feature updates: 113400\n",
      "Seconds required for this iteration: 0.009\n",
      "\n",
      "***** Epoch #421 *****\n",
      "Loss: 1.585651\n",
      "Improvement ratio: 0.003299\n",
      "Feature L2-norm: 31.826520\n",
      "Learning rate (eta): 0.092234\n",
      "Total number of feature updates: 113670\n",
      "Seconds required for this iteration: 0.009\n",
      "\n",
      "***** Epoch #422 *****\n",
      "Loss: 1.585158\n",
      "Improvement ratio: 0.003248\n",
      "Feature L2-norm: 31.832772\n",
      "Learning rate (eta): 0.092217\n",
      "Total number of feature updates: 113940\n",
      "Seconds required for this iteration: 0.009\n",
      "\n",
      "***** Epoch #423 *****\n",
      "Loss: 1.584649\n",
      "Improvement ratio: 0.003257\n",
      "Feature L2-norm: 31.839001\n",
      "Learning rate (eta): 0.092200\n",
      "Total number of feature updates: 114210\n",
      "Seconds required for this iteration: 0.008\n",
      "\n",
      "***** Epoch #424 *****\n",
      "Loss: 1.584147\n",
      "Improvement ratio: 0.003221\n",
      "Feature L2-norm: 31.845211\n",
      "Learning rate (eta): 0.092183\n",
      "Total number of feature updates: 114480\n",
      "Seconds required for this iteration: 0.009\n",
      "\n",
      "***** Epoch #425 *****\n",
      "Loss: 1.583662\n",
      "Improvement ratio: 0.003220\n",
      "Feature L2-norm: 31.851397\n",
      "Learning rate (eta): 0.092166\n",
      "Total number of feature updates: 114750\n",
      "Seconds required for this iteration: 0.008\n",
      "\n",
      "***** Epoch #426 *****\n",
      "Loss: 1.583215\n",
      "Improvement ratio: 0.003189\n",
      "Feature L2-norm: 31.857564\n",
      "Learning rate (eta): 0.092149\n",
      "Total number of feature updates: 115020\n",
      "Seconds required for this iteration: 0.008\n",
      "\n",
      "***** Epoch #427 *****\n",
      "Loss: 1.582697\n",
      "Improvement ratio: 0.003165\n",
      "Feature L2-norm: 31.863707\n",
      "Learning rate (eta): 0.092132\n",
      "Total number of feature updates: 115290\n",
      "Seconds required for this iteration: 0.008\n",
      "\n",
      "***** Epoch #428 *****\n",
      "Loss: 1.582209\n",
      "Improvement ratio: 0.003160\n",
      "Feature L2-norm: 31.869837\n",
      "Learning rate (eta): 0.092115\n",
      "Total number of feature updates: 115560\n",
      "Seconds required for this iteration: 0.008\n",
      "\n",
      "***** Epoch #429 *****\n",
      "Loss: 1.581704\n",
      "Improvement ratio: 0.003143\n",
      "Feature L2-norm: 31.875944\n",
      "Learning rate (eta): 0.092098\n",
      "Total number of feature updates: 115830\n",
      "Seconds required for this iteration: 0.008\n",
      "\n",
      "***** Epoch #430 *****\n",
      "Loss: 1.581223\n",
      "Improvement ratio: 0.003101\n",
      "Feature L2-norm: 31.882033\n",
      "Learning rate (eta): 0.092081\n",
      "Total number of feature updates: 116100\n",
      "Seconds required for this iteration: 0.008\n",
      "\n",
      "***** Epoch #431 *****\n",
      "Loss: 1.580748\n",
      "Improvement ratio: 0.003102\n",
      "Feature L2-norm: 31.888100\n",
      "Learning rate (eta): 0.092064\n",
      "Total number of feature updates: 116370\n",
      "Seconds required for this iteration: 0.008\n",
      "\n",
      "***** Epoch #432 *****\n",
      "Loss: 1.580302\n",
      "Improvement ratio: 0.003073\n",
      "Feature L2-norm: 31.894143\n",
      "Learning rate (eta): 0.092047\n",
      "Total number of feature updates: 116640\n",
      "Seconds required for this iteration: 0.008\n",
      "\n",
      "***** Epoch #433 *****\n",
      "Loss: 1.579857\n",
      "Improvement ratio: 0.003033\n",
      "Feature L2-norm: 31.900165\n",
      "Learning rate (eta): 0.092030\n",
      "Total number of feature updates: 116910\n",
      "Seconds required for this iteration: 0.008\n",
      "\n",
      "***** Epoch #434 *****\n",
      "Loss: 1.579372\n",
      "Improvement ratio: 0.003023\n",
      "Feature L2-norm: 31.906171\n",
      "Learning rate (eta): 0.092013\n",
      "Total number of feature updates: 117180\n",
      "Seconds required for this iteration: 0.008\n",
      "\n",
      "***** Epoch #435 *****\n",
      "Loss: 1.578921\n",
      "Improvement ratio: 0.003003\n",
      "Feature L2-norm: 31.912156\n",
      "Learning rate (eta): 0.091996\n",
      "Total number of feature updates: 117450\n",
      "Seconds required for this iteration: 0.008\n",
      "\n",
      "***** Epoch #436 *****\n",
      "Loss: 1.578445\n",
      "Improvement ratio: 0.003022\n",
      "Feature L2-norm: 31.918116\n",
      "Learning rate (eta): 0.091979\n",
      "Total number of feature updates: 117720\n",
      "Seconds required for this iteration: 0.008\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** Epoch #437 *****\n",
      "Loss: 1.578004\n",
      "Improvement ratio: 0.002974\n",
      "Feature L2-norm: 31.924059\n",
      "Learning rate (eta): 0.091963\n",
      "Total number of feature updates: 117990\n",
      "Seconds required for this iteration: 0.008\n",
      "\n",
      "***** Epoch #438 *****\n",
      "Loss: 1.577544\n",
      "Improvement ratio: 0.002957\n",
      "Feature L2-norm: 31.929983\n",
      "Learning rate (eta): 0.091946\n",
      "Total number of feature updates: 118260\n",
      "Seconds required for this iteration: 0.008\n",
      "\n",
      "***** Epoch #439 *****\n",
      "Loss: 1.577075\n",
      "Improvement ratio: 0.002936\n",
      "Feature L2-norm: 31.935889\n",
      "Learning rate (eta): 0.091929\n",
      "Total number of feature updates: 118530\n",
      "Seconds required for this iteration: 0.008\n",
      "\n",
      "***** Epoch #440 *****\n",
      "Loss: 1.576586\n",
      "Improvement ratio: 0.002941\n",
      "Feature L2-norm: 31.941771\n",
      "Learning rate (eta): 0.091912\n",
      "Total number of feature updates: 118800\n",
      "Seconds required for this iteration: 0.007\n",
      "\n",
      "***** Epoch #441 *****\n",
      "Loss: 1.576177\n",
      "Improvement ratio: 0.002900\n",
      "Feature L2-norm: 31.947639\n",
      "Learning rate (eta): 0.091895\n",
      "Total number of feature updates: 119070\n",
      "Seconds required for this iteration: 0.008\n",
      "\n",
      "***** Epoch #442 *****\n",
      "Loss: 1.575765\n",
      "Improvement ratio: 0.002879\n",
      "Feature L2-norm: 31.953485\n",
      "Learning rate (eta): 0.091878\n",
      "Total number of feature updates: 119340\n",
      "Seconds required for this iteration: 0.008\n",
      "\n",
      "***** Epoch #443 *****\n",
      "Loss: 1.575299\n",
      "Improvement ratio: 0.002893\n",
      "Feature L2-norm: 31.959314\n",
      "Learning rate (eta): 0.091861\n",
      "Total number of feature updates: 119610\n",
      "Seconds required for this iteration: 0.008\n",
      "\n",
      "***** Epoch #444 *****\n",
      "Loss: 1.574835\n",
      "Improvement ratio: 0.002881\n",
      "Feature L2-norm: 31.965126\n",
      "Learning rate (eta): 0.091844\n",
      "Total number of feature updates: 119880\n",
      "Seconds required for this iteration: 0.007\n",
      "\n",
      "***** Epoch #445 *****\n",
      "Loss: 1.574409\n",
      "Improvement ratio: 0.002865\n",
      "Feature L2-norm: 31.970914\n",
      "Learning rate (eta): 0.091827\n",
      "Total number of feature updates: 120150\n",
      "Seconds required for this iteration: 0.008\n",
      "\n",
      "***** Epoch #446 *****\n",
      "Loss: 1.573958\n",
      "Improvement ratio: 0.002851\n",
      "Feature L2-norm: 31.976686\n",
      "Learning rate (eta): 0.091811\n",
      "Total number of feature updates: 120420\n",
      "Seconds required for this iteration: 0.008\n",
      "\n",
      "***** Epoch #447 *****\n",
      "Loss: 1.573562\n",
      "Improvement ratio: 0.002823\n",
      "Feature L2-norm: 31.982438\n",
      "Learning rate (eta): 0.091794\n",
      "Total number of feature updates: 120690\n",
      "Seconds required for this iteration: 0.008\n",
      "\n",
      "***** Epoch #448 *****\n",
      "Loss: 1.573141\n",
      "Improvement ratio: 0.002799\n",
      "Feature L2-norm: 31.988171\n",
      "Learning rate (eta): 0.091777\n",
      "Total number of feature updates: 120960\n",
      "Seconds required for this iteration: 0.009\n",
      "\n",
      "***** Epoch #449 *****\n",
      "Loss: 1.572690\n",
      "Improvement ratio: 0.002788\n",
      "Feature L2-norm: 31.993891\n",
      "Learning rate (eta): 0.091760\n",
      "Total number of feature updates: 121230\n",
      "Seconds required for this iteration: 0.008\n",
      "\n",
      "***** Epoch #450 *****\n",
      "Loss: 1.572265\n",
      "Improvement ratio: 0.002748\n",
      "Feature L2-norm: 31.999588\n",
      "Learning rate (eta): 0.091743\n",
      "Total number of feature updates: 121500\n",
      "Seconds required for this iteration: 0.008\n",
      "\n",
      "***** Epoch #451 *****\n",
      "Loss: 1.571892\n",
      "Improvement ratio: 0.002726\n",
      "Feature L2-norm: 32.005268\n",
      "Learning rate (eta): 0.091726\n",
      "Total number of feature updates: 121770\n",
      "Seconds required for this iteration: 0.008\n",
      "\n",
      "***** Epoch #452 *****\n",
      "Loss: 1.571437\n",
      "Improvement ratio: 0.002754\n",
      "Feature L2-norm: 32.010924\n",
      "Learning rate (eta): 0.091710\n",
      "Total number of feature updates: 122040\n",
      "Seconds required for this iteration: 0.008\n",
      "\n",
      "***** Epoch #453 *****\n",
      "Loss: 1.571036\n",
      "Improvement ratio: 0.002713\n",
      "Feature L2-norm: 32.016569\n",
      "Learning rate (eta): 0.091693\n",
      "Total number of feature updates: 122310\n",
      "Seconds required for this iteration: 0.007\n",
      "\n",
      "***** Epoch #454 *****\n",
      "Loss: 1.570611\n",
      "Improvement ratio: 0.002689\n",
      "Feature L2-norm: 32.022191\n",
      "Learning rate (eta): 0.091676\n",
      "Total number of feature updates: 122580\n",
      "Seconds required for this iteration: 0.008\n",
      "\n",
      "***** Epoch #455 *****\n",
      "Loss: 1.570199\n",
      "Improvement ratio: 0.002681\n",
      "Feature L2-norm: 32.027801\n",
      "Learning rate (eta): 0.091659\n",
      "Total number of feature updates: 122850\n",
      "Seconds required for this iteration: 0.008\n",
      "\n",
      "***** Epoch #456 *****\n",
      "Loss: 1.569800\n",
      "Improvement ratio: 0.002649\n",
      "Feature L2-norm: 32.033388\n",
      "Learning rate (eta): 0.091642\n",
      "Total number of feature updates: 123120\n",
      "Seconds required for this iteration: 0.008\n",
      "\n",
      "***** Epoch #457 *****\n",
      "Loss: 1.569392\n",
      "Improvement ratio: 0.002657\n",
      "Feature L2-norm: 32.038959\n",
      "Learning rate (eta): 0.091625\n",
      "Total number of feature updates: 123390\n",
      "Seconds required for this iteration: 0.008\n",
      "\n",
      "***** Epoch #458 *****\n",
      "Loss: 1.568981\n",
      "Improvement ratio: 0.002651\n",
      "Feature L2-norm: 32.044511\n",
      "Learning rate (eta): 0.091609\n",
      "Total number of feature updates: 123660\n",
      "Seconds required for this iteration: 0.008\n",
      "\n",
      "***** Epoch #459 *****\n",
      "Loss: 1.568574\n",
      "Improvement ratio: 0.002624\n",
      "Feature L2-norm: 32.050043\n",
      "Learning rate (eta): 0.091592\n",
      "Total number of feature updates: 123930\n",
      "Seconds required for this iteration: 0.011\n",
      "\n",
      "***** Epoch #460 *****\n",
      "Loss: 1.568157\n",
      "Improvement ratio: 0.002620\n",
      "Feature L2-norm: 32.055564\n",
      "Learning rate (eta): 0.091575\n",
      "Total number of feature updates: 124200\n",
      "Seconds required for this iteration: 0.011\n",
      "\n",
      "***** Epoch #461 *****\n",
      "Loss: 1.567788\n",
      "Improvement ratio: 0.002617\n",
      "Feature L2-norm: 32.061063\n",
      "Learning rate (eta): 0.091558\n",
      "Total number of feature updates: 124470\n",
      "Seconds required for this iteration: 0.009\n",
      "\n",
      "***** Epoch #462 *****\n",
      "Loss: 1.567394\n",
      "Improvement ratio: 0.002580\n",
      "Feature L2-norm: 32.066544\n",
      "Learning rate (eta): 0.091542\n",
      "Total number of feature updates: 124740\n",
      "Seconds required for this iteration: 0.008\n",
      "\n",
      "***** Epoch #463 *****\n",
      "Loss: 1.566996\n",
      "Improvement ratio: 0.002578\n",
      "Feature L2-norm: 32.072009\n",
      "Learning rate (eta): 0.091525\n",
      "Total number of feature updates: 125010\n",
      "Seconds required for this iteration: 0.008\n",
      "\n",
      "***** Epoch #464 *****\n",
      "Loss: 1.566605\n",
      "Improvement ratio: 0.002557\n",
      "Feature L2-norm: 32.077459\n",
      "Learning rate (eta): 0.091508\n",
      "Total number of feature updates: 125280\n",
      "Seconds required for this iteration: 0.007\n",
      "\n",
      "***** Epoch #465 *****\n",
      "Loss: 1.566261\n",
      "Improvement ratio: 0.002514\n",
      "Feature L2-norm: 32.082889\n",
      "Learning rate (eta): 0.091491\n",
      "Total number of feature updates: 125550\n",
      "Seconds required for this iteration: 0.009\n",
      "\n",
      "***** Epoch #466 *****\n",
      "Loss: 1.565835\n",
      "Improvement ratio: 0.002532\n",
      "Feature L2-norm: 32.088300\n",
      "Learning rate (eta): 0.091475\n",
      "Total number of feature updates: 125820\n",
      "Seconds required for this iteration: 0.009\n",
      "\n",
      "***** Epoch #467 *****\n",
      "Loss: 1.565471\n",
      "Improvement ratio: 0.002505\n",
      "Feature L2-norm: 32.093696\n",
      "Learning rate (eta): 0.091458\n",
      "Total number of feature updates: 126090\n",
      "Seconds required for this iteration: 0.008\n",
      "\n",
      "***** Epoch #468 *****\n",
      "Loss: 1.565034\n",
      "Improvement ratio: 0.002522\n",
      "Feature L2-norm: 32.099071\n",
      "Learning rate (eta): 0.091441\n",
      "Total number of feature updates: 126360\n",
      "Seconds required for this iteration: 0.008\n",
      "\n",
      "***** Epoch #469 *****\n",
      "Loss: 1.564700\n",
      "Improvement ratio: 0.002476\n",
      "Feature L2-norm: 32.104431\n",
      "Learning rate (eta): 0.091424\n",
      "Total number of feature updates: 126630\n",
      "Seconds required for this iteration: 0.009\n",
      "\n",
      "***** Epoch #470 *****\n",
      "Loss: 1.564326\n",
      "Improvement ratio: 0.002449\n",
      "Feature L2-norm: 32.109774\n",
      "Learning rate (eta): 0.091408\n",
      "Total number of feature updates: 126900\n",
      "Seconds required for this iteration: 0.008\n",
      "\n",
      "***** Epoch #471 *****\n",
      "Loss: 1.563946\n",
      "Improvement ratio: 0.002457\n",
      "Feature L2-norm: 32.115105\n",
      "Learning rate (eta): 0.091391\n",
      "Total number of feature updates: 127170\n",
      "Seconds required for this iteration: 0.008\n",
      "\n",
      "***** Epoch #472 *****\n",
      "Loss: 1.563548\n",
      "Improvement ratio: 0.002460\n",
      "Feature L2-norm: 32.120418\n",
      "Learning rate (eta): 0.091374\n",
      "Total number of feature updates: 127440\n",
      "Seconds required for this iteration: 0.009\n",
      "\n",
      "***** Epoch #473 *****\n",
      "Loss: 1.563214\n",
      "Improvement ratio: 0.002419\n",
      "Feature L2-norm: 32.125715\n",
      "Learning rate (eta): 0.091358\n",
      "Total number of feature updates: 127710\n",
      "Seconds required for this iteration: 0.009\n",
      "\n",
      "***** Epoch #474 *****\n",
      "Loss: 1.562839\n",
      "Improvement ratio: 0.002409\n",
      "Feature L2-norm: 32.130994\n",
      "Learning rate (eta): 0.091341\n",
      "Total number of feature updates: 127980\n",
      "Seconds required for this iteration: 0.008\n",
      "\n",
      "***** Epoch #475 *****\n",
      "Loss: 1.562470\n",
      "Improvement ratio: 0.002426\n",
      "Feature L2-norm: 32.136256\n",
      "Learning rate (eta): 0.091324\n",
      "Total number of feature updates: 128250\n",
      "Seconds required for this iteration: 0.008\n",
      "\n",
      "***** Epoch #476 *****\n",
      "Loss: 1.562052\n",
      "Improvement ratio: 0.002421\n",
      "Feature L2-norm: 32.141503\n",
      "Learning rate (eta): 0.091308\n",
      "Total number of feature updates: 128520\n",
      "Seconds required for this iteration: 0.008\n",
      "\n",
      "***** Epoch #477 *****\n",
      "Loss: 1.561719\n",
      "Improvement ratio: 0.002403\n",
      "Feature L2-norm: 32.146731\n",
      "Learning rate (eta): 0.091291\n",
      "Total number of feature updates: 128790\n",
      "Seconds required for this iteration: 0.009\n",
      "\n",
      "***** Epoch #478 *****\n",
      "Loss: 1.561363\n",
      "Improvement ratio: 0.002351\n",
      "Feature L2-norm: 32.151945\n",
      "Learning rate (eta): 0.091274\n",
      "Total number of feature updates: 129060\n",
      "Seconds required for this iteration: 0.009\n",
      "\n",
      "***** Epoch #479 *****\n",
      "Loss: 1.561030\n",
      "Improvement ratio: 0.002351\n",
      "Feature L2-norm: 32.157140\n",
      "Learning rate (eta): 0.091258\n",
      "Total number of feature updates: 129330\n",
      "Seconds required for this iteration: 0.008\n",
      "\n",
      "***** Epoch #480 *****\n",
      "Loss: 1.560684\n",
      "Improvement ratio: 0.002333\n",
      "Feature L2-norm: 32.162320\n",
      "Learning rate (eta): 0.091241\n",
      "Total number of feature updates: 129600\n",
      "Seconds required for this iteration: 0.011\n",
      "\n",
      "***** Epoch #481 *****\n",
      "Loss: 1.560322\n",
      "Improvement ratio: 0.002323\n",
      "Feature L2-norm: 32.167484\n",
      "Learning rate (eta): 0.091224\n",
      "Total number of feature updates: 129870\n",
      "Seconds required for this iteration: 0.010\n",
      "\n",
      "***** Epoch #482 *****\n",
      "Loss: 1.559938\n",
      "Improvement ratio: 0.002314\n",
      "Feature L2-norm: 32.172629\n",
      "Learning rate (eta): 0.091208\n",
      "Total number of feature updates: 130140\n",
      "Seconds required for this iteration: 0.008\n",
      "\n",
      "***** Epoch #483 *****\n",
      "Loss: 1.559581\n",
      "Improvement ratio: 0.002329\n",
      "Feature L2-norm: 32.177756\n",
      "Learning rate (eta): 0.091191\n",
      "Total number of feature updates: 130410\n",
      "Seconds required for this iteration: 0.008\n",
      "\n",
      "***** Epoch #484 *****\n",
      "Loss: 1.559269\n",
      "Improvement ratio: 0.002290\n",
      "Feature L2-norm: 32.182870\n",
      "Learning rate (eta): 0.091174\n",
      "Total number of feature updates: 130680\n",
      "Seconds required for this iteration: 0.008\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** Epoch #485 *****\n",
      "Loss: 1.558913\n",
      "Improvement ratio: 0.002282\n",
      "Feature L2-norm: 32.187970\n",
      "Learning rate (eta): 0.091158\n",
      "Total number of feature updates: 130950\n",
      "Seconds required for this iteration: 0.007\n",
      "\n",
      "***** Epoch #486 *****\n",
      "Loss: 1.558581\n",
      "Improvement ratio: 0.002227\n",
      "Feature L2-norm: 32.193057\n",
      "Learning rate (eta): 0.091141\n",
      "Total number of feature updates: 131220\n",
      "Seconds required for this iteration: 0.008\n",
      "\n",
      "***** Epoch #487 *****\n",
      "Loss: 1.558248\n",
      "Improvement ratio: 0.002227\n",
      "Feature L2-norm: 32.198124\n",
      "Learning rate (eta): 0.091125\n",
      "Total number of feature updates: 131490\n",
      "Seconds required for this iteration: 0.007\n",
      "\n",
      "***** Epoch #488 *****\n",
      "Loss: 1.557867\n",
      "Improvement ratio: 0.002244\n",
      "Feature L2-norm: 32.203180\n",
      "Learning rate (eta): 0.091108\n",
      "Total number of feature updates: 131760\n",
      "Seconds required for this iteration: 0.007\n",
      "\n",
      "***** Epoch #489 *****\n",
      "Loss: 1.557515\n",
      "Improvement ratio: 0.002257\n",
      "Feature L2-norm: 32.208217\n",
      "Learning rate (eta): 0.091091\n",
      "Total number of feature updates: 132030\n",
      "Seconds required for this iteration: 0.008\n",
      "\n",
      "***** Epoch #490 *****\n",
      "Loss: 1.557234\n",
      "Improvement ratio: 0.002216\n",
      "Feature L2-norm: 32.213241\n",
      "Learning rate (eta): 0.091075\n",
      "Total number of feature updates: 132300\n",
      "Seconds required for this iteration: 0.007\n",
      "\n",
      "***** Epoch #491 *****\n",
      "Loss: 1.556901\n",
      "Improvement ratio: 0.002197\n",
      "Feature L2-norm: 32.218245\n",
      "Learning rate (eta): 0.091058\n",
      "Total number of feature updates: 132570\n",
      "Seconds required for this iteration: 0.007\n",
      "\n",
      "***** Epoch #492 *****\n",
      "Loss: 1.556543\n",
      "Improvement ratio: 0.002181\n",
      "Feature L2-norm: 32.223235\n",
      "Learning rate (eta): 0.091042\n",
      "Total number of feature updates: 132840\n",
      "Seconds required for this iteration: 0.008\n",
      "\n",
      "***** Epoch #493 *****\n",
      "Loss: 1.556222\n",
      "Improvement ratio: 0.002159\n",
      "Feature L2-norm: 32.228206\n",
      "Learning rate (eta): 0.091025\n",
      "Total number of feature updates: 133110\n",
      "Seconds required for this iteration: 0.015\n",
      "\n",
      "***** Epoch #494 *****\n",
      "Loss: 1.555917\n",
      "Improvement ratio: 0.002154\n",
      "Feature L2-norm: 32.233168\n",
      "Learning rate (eta): 0.091008\n",
      "Total number of feature updates: 133380\n",
      "Seconds required for this iteration: 0.010\n",
      "\n",
      "***** Epoch #495 *****\n",
      "Loss: 1.555547\n",
      "Improvement ratio: 0.002164\n",
      "Feature L2-norm: 32.238114\n",
      "Learning rate (eta): 0.090992\n",
      "Total number of feature updates: 133650\n",
      "Seconds required for this iteration: 0.011\n",
      "\n",
      "***** Epoch #496 *****\n",
      "Loss: 1.555253\n",
      "Improvement ratio: 0.002140\n",
      "Feature L2-norm: 32.243044\n",
      "Learning rate (eta): 0.090975\n",
      "Total number of feature updates: 133920\n",
      "Seconds required for this iteration: 0.012\n",
      "\n",
      "***** Epoch #497 *****\n",
      "Loss: 1.554912\n",
      "Improvement ratio: 0.002146\n",
      "Feature L2-norm: 32.247958\n",
      "Learning rate (eta): 0.090959\n",
      "Total number of feature updates: 134190\n",
      "Seconds required for this iteration: 0.011\n",
      "\n",
      "***** Epoch #498 *****\n",
      "Loss: 1.554617\n",
      "Improvement ratio: 0.002091\n",
      "Feature L2-norm: 32.252859\n",
      "Learning rate (eta): 0.090942\n",
      "Total number of feature updates: 134460\n",
      "Seconds required for this iteration: 0.011\n",
      "\n",
      "***** Epoch #499 *****\n",
      "Loss: 1.554270\n",
      "Improvement ratio: 0.002088\n",
      "Feature L2-norm: 32.257747\n",
      "Learning rate (eta): 0.090926\n",
      "Total number of feature updates: 134730\n",
      "Seconds required for this iteration: 0.011\n",
      "\n",
      "***** Epoch #500 *****\n",
      "Loss: 1.553981\n",
      "Improvement ratio: 0.002093\n",
      "Feature L2-norm: 32.262618\n",
      "Learning rate (eta): 0.090909\n",
      "Total number of feature updates: 135000\n",
      "Seconds required for this iteration: 0.010\n",
      "\n",
      "***** Epoch #501 *****\n",
      "Loss: 1.553617\n",
      "Improvement ratio: 0.002114\n",
      "Feature L2-norm: 32.267471\n",
      "Learning rate (eta): 0.090893\n",
      "Total number of feature updates: 135270\n",
      "Seconds required for this iteration: 0.015\n",
      "\n",
      "***** Epoch #502 *****\n",
      "Loss: 1.553346\n",
      "Improvement ratio: 0.002058\n",
      "Feature L2-norm: 32.272315\n",
      "Learning rate (eta): 0.090876\n",
      "Total number of feature updates: 135540\n",
      "Seconds required for this iteration: 0.010\n",
      "\n",
      "***** Epoch #503 *****\n",
      "Loss: 1.553044\n",
      "Improvement ratio: 0.002046\n",
      "Feature L2-norm: 32.277139\n",
      "Learning rate (eta): 0.090860\n",
      "Total number of feature updates: 135810\n",
      "Seconds required for this iteration: 0.009\n",
      "\n",
      "***** Epoch #504 *****\n",
      "Loss: 1.552746\n",
      "Improvement ratio: 0.002042\n",
      "Feature L2-norm: 32.281953\n",
      "Learning rate (eta): 0.090843\n",
      "Total number of feature updates: 136080\n",
      "Seconds required for this iteration: 0.009\n",
      "\n",
      "***** Epoch #505 *****\n",
      "Loss: 1.552411\n",
      "Improvement ratio: 0.002020\n",
      "Feature L2-norm: 32.286752\n",
      "Learning rate (eta): 0.090827\n",
      "Total number of feature updates: 136350\n",
      "Seconds required for this iteration: 0.009\n",
      "\n",
      "***** Epoch #506 *****\n",
      "Loss: 1.552096\n",
      "Improvement ratio: 0.002034\n",
      "Feature L2-norm: 32.291533\n",
      "Learning rate (eta): 0.090810\n",
      "Total number of feature updates: 136620\n",
      "Seconds required for this iteration: 0.009\n",
      "\n",
      "***** Epoch #507 *****\n",
      "Loss: 1.551774\n",
      "Improvement ratio: 0.002022\n",
      "Feature L2-norm: 32.296303\n",
      "Learning rate (eta): 0.090794\n",
      "Total number of feature updates: 136890\n",
      "Seconds required for this iteration: 0.008\n",
      "\n",
      "***** Epoch #508 *****\n",
      "Loss: 1.551481\n",
      "Improvement ratio: 0.002021\n",
      "Feature L2-norm: 32.301058\n",
      "Learning rate (eta): 0.090777\n",
      "Total number of feature updates: 137160\n",
      "Seconds required for this iteration: 0.009\n",
      "\n",
      "***** Epoch #509 *****\n",
      "Loss: 1.551188\n",
      "Improvement ratio: 0.001987\n",
      "Feature L2-norm: 32.305800\n",
      "Learning rate (eta): 0.090761\n",
      "Total number of feature updates: 137430\n",
      "Seconds required for this iteration: 0.008\n",
      "\n",
      "***** Epoch #510 *****\n",
      "Loss: 1.550896\n",
      "Improvement ratio: 0.001989\n",
      "Feature L2-norm: 32.310526\n",
      "Learning rate (eta): 0.090744\n",
      "Total number of feature updates: 137700\n",
      "Seconds required for this iteration: 0.008\n",
      "\n",
      "***** Epoch #511 *****\n",
      "Loss: 1.550607\n",
      "Improvement ratio: 0.001941\n",
      "Feature L2-norm: 32.315237\n",
      "Learning rate (eta): 0.090728\n",
      "Total number of feature updates: 137970\n",
      "Seconds required for this iteration: 0.008\n",
      "\n",
      "***** Epoch #512 *****\n",
      "Loss: 1.550287\n",
      "Improvement ratio: 0.001974\n",
      "Feature L2-norm: 32.319937\n",
      "Learning rate (eta): 0.090711\n",
      "Total number of feature updates: 138240\n",
      "Seconds required for this iteration: 0.008\n",
      "\n",
      "***** Epoch #513 *****\n",
      "Loss: 1.550014\n",
      "Improvement ratio: 0.001955\n",
      "Feature L2-norm: 32.324618\n",
      "Learning rate (eta): 0.090695\n",
      "Total number of feature updates: 138510\n",
      "Seconds required for this iteration: 0.008\n",
      "\n",
      "***** Epoch #514 *****\n",
      "Loss: 1.549693\n",
      "Improvement ratio: 0.001970\n",
      "Feature L2-norm: 32.329285\n",
      "Learning rate (eta): 0.090678\n",
      "Total number of feature updates: 138780\n",
      "Seconds required for this iteration: 0.008\n",
      "\n",
      "***** Epoch #515 *****\n",
      "Loss: 1.549400\n",
      "Improvement ratio: 0.001944\n",
      "Feature L2-norm: 32.333940\n",
      "Learning rate (eta): 0.090662\n",
      "Total number of feature updates: 139050\n",
      "Seconds required for this iteration: 0.010\n",
      "\n",
      "***** Epoch #516 *****\n",
      "Loss: 1.549118\n",
      "Improvement ratio: 0.001922\n",
      "Feature L2-norm: 32.338583\n",
      "Learning rate (eta): 0.090645\n",
      "Total number of feature updates: 139320\n",
      "Seconds required for this iteration: 0.010\n",
      "\n",
      "***** Epoch #517 *****\n",
      "Loss: 1.548813\n",
      "Improvement ratio: 0.001912\n",
      "Feature L2-norm: 32.343209\n",
      "Learning rate (eta): 0.090629\n",
      "Total number of feature updates: 139590\n",
      "Seconds required for this iteration: 0.009\n",
      "\n",
      "***** Epoch #518 *****\n",
      "Loss: 1.548538\n",
      "Improvement ratio: 0.001901\n",
      "Feature L2-norm: 32.347825\n",
      "Learning rate (eta): 0.090613\n",
      "Total number of feature updates: 139860\n",
      "Seconds required for this iteration: 0.008\n",
      "\n",
      "***** Epoch #519 *****\n",
      "Loss: 1.548243\n",
      "Improvement ratio: 0.001902\n",
      "Feature L2-norm: 32.352424\n",
      "Learning rate (eta): 0.090596\n",
      "Total number of feature updates: 140130\n",
      "Seconds required for this iteration: 0.008\n",
      "\n",
      "***** Epoch #520 *****\n",
      "Loss: 1.547970\n",
      "Improvement ratio: 0.001890\n",
      "Feature L2-norm: 32.357010\n",
      "Learning rate (eta): 0.090580\n",
      "Total number of feature updates: 140400\n",
      "Seconds required for this iteration: 0.009\n",
      "\n",
      "***** Epoch #521 *****\n",
      "Loss: 1.547680\n",
      "Improvement ratio: 0.001891\n",
      "Feature L2-norm: 32.361584\n",
      "Learning rate (eta): 0.090563\n",
      "Total number of feature updates: 140670\n",
      "Seconds required for this iteration: 0.009\n",
      "\n",
      "***** Epoch #522 *****\n",
      "Loss: 1.547407\n",
      "Improvement ratio: 0.001861\n",
      "Feature L2-norm: 32.366147\n",
      "Learning rate (eta): 0.090547\n",
      "Total number of feature updates: 140940\n",
      "Seconds required for this iteration: 0.008\n",
      "\n",
      "***** Epoch #523 *****\n",
      "Loss: 1.547137\n",
      "Improvement ratio: 0.001859\n",
      "Feature L2-norm: 32.370692\n",
      "Learning rate (eta): 0.090531\n",
      "Total number of feature updates: 141210\n",
      "Seconds required for this iteration: 0.009\n",
      "\n",
      "***** Epoch #524 *****\n",
      "Loss: 1.546834\n",
      "Improvement ratio: 0.001849\n",
      "Feature L2-norm: 32.375226\n",
      "Learning rate (eta): 0.090514\n",
      "Total number of feature updates: 141480\n",
      "Seconds required for this iteration: 0.008\n",
      "\n",
      "***** Epoch #525 *****\n",
      "Loss: 1.546569\n",
      "Improvement ratio: 0.001830\n",
      "Feature L2-norm: 32.379745\n",
      "Learning rate (eta): 0.090498\n",
      "Total number of feature updates: 141750\n",
      "Seconds required for this iteration: 0.008\n",
      "\n",
      "***** Epoch #526 *****\n",
      "Loss: 1.546285\n",
      "Improvement ratio: 0.001833\n",
      "Feature L2-norm: 32.384251\n",
      "Learning rate (eta): 0.090481\n",
      "Total number of feature updates: 142020\n",
      "Seconds required for this iteration: 0.008\n",
      "\n",
      "***** Epoch #527 *****\n",
      "Loss: 1.546028\n",
      "Improvement ratio: 0.001801\n",
      "Feature L2-norm: 32.388743\n",
      "Learning rate (eta): 0.090465\n",
      "Total number of feature updates: 142290\n",
      "Seconds required for this iteration: 0.008\n",
      "\n",
      "***** Epoch #528 *****\n",
      "Loss: 1.545740\n",
      "Improvement ratio: 0.001810\n",
      "Feature L2-norm: 32.393225\n",
      "Learning rate (eta): 0.090449\n",
      "Total number of feature updates: 142560\n",
      "Seconds required for this iteration: 0.009\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** Epoch #529 *****\n",
      "Loss: 1.545467\n",
      "Improvement ratio: 0.001796\n",
      "Feature L2-norm: 32.397693\n",
      "Learning rate (eta): 0.090432\n",
      "Total number of feature updates: 142830\n",
      "Seconds required for this iteration: 0.008\n",
      "\n",
      "***** Epoch #530 *****\n",
      "Loss: 1.545186\n",
      "Improvement ratio: 0.001802\n",
      "Feature L2-norm: 32.402148\n",
      "Learning rate (eta): 0.090416\n",
      "Total number of feature updates: 143100\n",
      "Seconds required for this iteration: 0.008\n",
      "\n",
      "***** Epoch #531 *****\n",
      "Loss: 1.544912\n",
      "Improvement ratio: 0.001792\n",
      "Feature L2-norm: 32.406587\n",
      "Learning rate (eta): 0.090400\n",
      "Total number of feature updates: 143370\n",
      "Seconds required for this iteration: 0.008\n",
      "\n",
      "***** Epoch #532 *****\n",
      "Loss: 1.544682\n",
      "Improvement ratio: 0.001764\n",
      "Feature L2-norm: 32.411016\n",
      "Learning rate (eta): 0.090383\n",
      "Total number of feature updates: 143640\n",
      "Seconds required for this iteration: 0.008\n",
      "\n",
      "***** Epoch #533 *****\n",
      "Loss: 1.544409\n",
      "Improvement ratio: 0.001767\n",
      "Feature L2-norm: 32.415433\n",
      "Learning rate (eta): 0.090367\n",
      "Total number of feature updates: 143910\n",
      "Seconds required for this iteration: 0.008\n",
      "\n",
      "***** Epoch #534 *****\n",
      "Loss: 1.544150\n",
      "Improvement ratio: 0.001738\n",
      "Feature L2-norm: 32.419833\n",
      "Learning rate (eta): 0.090351\n",
      "Total number of feature updates: 144180\n",
      "Seconds required for this iteration: 0.008\n",
      "\n",
      "***** Epoch #535 *****\n",
      "Loss: 1.543876\n",
      "Improvement ratio: 0.001744\n",
      "Feature L2-norm: 32.424224\n",
      "Learning rate (eta): 0.090334\n",
      "Total number of feature updates: 144450\n",
      "Seconds required for this iteration: 0.009\n",
      "\n",
      "***** Epoch #536 *****\n",
      "Loss: 1.543614\n",
      "Improvement ratio: 0.001730\n",
      "Feature L2-norm: 32.428602\n",
      "Learning rate (eta): 0.090318\n",
      "Total number of feature updates: 144720\n",
      "Seconds required for this iteration: 0.009\n",
      "\n",
      "***** Epoch #537 *****\n",
      "Loss: 1.543327\n",
      "Improvement ratio: 0.001750\n",
      "Feature L2-norm: 32.432968\n",
      "Learning rate (eta): 0.090302\n",
      "Total number of feature updates: 144990\n",
      "Seconds required for this iteration: 0.010\n",
      "\n",
      "***** Epoch #538 *****\n",
      "Loss: 1.543096\n",
      "Improvement ratio: 0.001713\n",
      "Feature L2-norm: 32.437320\n",
      "Learning rate (eta): 0.090285\n",
      "Total number of feature updates: 145260\n",
      "Seconds required for this iteration: 0.010\n",
      "\n",
      "***** Epoch #539 *****\n",
      "Loss: 1.542838\n",
      "Improvement ratio: 0.001704\n",
      "Feature L2-norm: 32.441662\n",
      "Learning rate (eta): 0.090269\n",
      "Total number of feature updates: 145530\n",
      "Seconds required for this iteration: 0.009\n",
      "\n",
      "***** Epoch #540 *****\n",
      "Loss: 1.542550\n",
      "Improvement ratio: 0.001709\n",
      "Feature L2-norm: 32.445989\n",
      "Learning rate (eta): 0.090253\n",
      "Total number of feature updates: 145800\n",
      "Seconds required for this iteration: 0.008\n",
      "\n",
      "***** Epoch #541 *****\n",
      "Loss: 1.542319\n",
      "Improvement ratio: 0.001682\n",
      "Feature L2-norm: 32.450301\n",
      "Learning rate (eta): 0.090236\n",
      "Total number of feature updates: 146070\n",
      "Seconds required for this iteration: 0.009\n",
      "\n",
      "***** Epoch #542 *****\n",
      "Loss: 1.542065\n",
      "Improvement ratio: 0.001697\n",
      "Feature L2-norm: 32.454600\n",
      "Learning rate (eta): 0.090220\n",
      "Total number of feature updates: 146340\n",
      "Seconds required for this iteration: 0.008\n",
      "\n",
      "***** Epoch #543 *****\n",
      "Loss: 1.541829\n",
      "Improvement ratio: 0.001673\n",
      "Feature L2-norm: 32.458891\n",
      "Learning rate (eta): 0.090204\n",
      "Total number of feature updates: 146610\n",
      "Seconds required for this iteration: 0.008\n",
      "\n",
      "***** Epoch #544 *****\n",
      "Loss: 1.541563\n",
      "Improvement ratio: 0.001678\n",
      "Feature L2-norm: 32.463169\n",
      "Learning rate (eta): 0.090188\n",
      "Total number of feature updates: 146880\n",
      "Seconds required for this iteration: 0.008\n",
      "\n",
      "***** Epoch #545 *****\n",
      "Loss: 1.541301\n",
      "Improvement ratio: 0.001671\n",
      "Feature L2-norm: 32.467434\n",
      "Learning rate (eta): 0.090171\n",
      "Total number of feature updates: 147150\n",
      "Seconds required for this iteration: 0.008\n",
      "\n",
      "***** Epoch #546 *****\n",
      "Loss: 1.541043\n",
      "Improvement ratio: 0.001668\n",
      "Feature L2-norm: 32.471688\n",
      "Learning rate (eta): 0.090155\n",
      "Total number of feature updates: 147420\n",
      "Seconds required for this iteration: 0.009\n",
      "\n",
      "***** Epoch #547 *****\n",
      "Loss: 1.540788\n",
      "Improvement ratio: 0.001648\n",
      "Feature L2-norm: 32.475928\n",
      "Learning rate (eta): 0.090139\n",
      "Total number of feature updates: 147690\n",
      "Seconds required for this iteration: 0.009\n",
      "\n",
      "***** Epoch #548 *****\n",
      "Loss: 1.540572\n",
      "Improvement ratio: 0.001638\n",
      "Feature L2-norm: 32.480156\n",
      "Learning rate (eta): 0.090123\n",
      "Total number of feature updates: 147960\n",
      "Seconds required for this iteration: 0.008\n",
      "\n",
      "***** Epoch #549 *****\n",
      "Loss: 1.540330\n",
      "Improvement ratio: 0.001628\n",
      "Feature L2-norm: 32.484371\n",
      "Learning rate (eta): 0.090106\n",
      "Total number of feature updates: 148230\n",
      "Seconds required for this iteration: 0.008\n",
      "\n",
      "***** Epoch #550 *****\n",
      "Loss: 1.540069\n",
      "Improvement ratio: 0.001611\n",
      "Feature L2-norm: 32.488574\n",
      "Learning rate (eta): 0.090090\n",
      "Total number of feature updates: 148500\n",
      "Seconds required for this iteration: 0.008\n",
      "\n",
      "***** Epoch #551 *****\n",
      "Loss: 1.539822\n",
      "Improvement ratio: 0.001621\n",
      "Feature L2-norm: 32.492767\n",
      "Learning rate (eta): 0.090074\n",
      "Total number of feature updates: 148770\n",
      "Seconds required for this iteration: 0.008\n",
      "\n",
      "***** Epoch #552 *****\n",
      "Loss: 1.539606\n",
      "Improvement ratio: 0.001598\n",
      "Feature L2-norm: 32.496946\n",
      "Learning rate (eta): 0.090058\n",
      "Total number of feature updates: 149040\n",
      "Seconds required for this iteration: 0.008\n",
      "\n",
      "***** Epoch #553 *****\n",
      "Loss: 1.539368\n",
      "Improvement ratio: 0.001599\n",
      "Feature L2-norm: 32.501112\n",
      "Learning rate (eta): 0.090041\n",
      "Total number of feature updates: 149310\n",
      "Seconds required for this iteration: 0.008\n",
      "\n",
      "***** Epoch #554 *****\n",
      "Loss: 1.539101\n",
      "Improvement ratio: 0.001600\n",
      "Feature L2-norm: 32.505266\n",
      "Learning rate (eta): 0.090025\n",
      "Total number of feature updates: 149580\n",
      "Seconds required for this iteration: 0.008\n",
      "\n",
      "***** Epoch #555 *****\n",
      "Loss: 1.538897\n",
      "Improvement ratio: 0.001562\n",
      "Feature L2-norm: 32.509407\n",
      "Learning rate (eta): 0.090009\n",
      "Total number of feature updates: 149850\n",
      "Seconds required for this iteration: 0.008\n",
      "\n",
      "***** Epoch #556 *****\n",
      "Loss: 1.538650\n",
      "Improvement ratio: 0.001555\n",
      "Feature L2-norm: 32.513538\n",
      "Learning rate (eta): 0.089993\n",
      "Total number of feature updates: 150120\n",
      "Seconds required for this iteration: 0.008\n",
      "\n",
      "***** Epoch #557 *****\n",
      "Loss: 1.538402\n",
      "Improvement ratio: 0.001551\n",
      "Feature L2-norm: 32.517658\n",
      "Learning rate (eta): 0.089977\n",
      "Total number of feature updates: 150390\n",
      "Seconds required for this iteration: 0.008\n",
      "\n",
      "***** Epoch #558 *****\n",
      "Loss: 1.538185\n",
      "Improvement ratio: 0.001552\n",
      "Feature L2-norm: 32.521765\n",
      "Learning rate (eta): 0.089960\n",
      "Total number of feature updates: 150660\n",
      "Seconds required for this iteration: 0.007\n",
      "\n",
      "***** Epoch #559 *****\n",
      "Loss: 1.537953\n",
      "Improvement ratio: 0.001545\n",
      "Feature L2-norm: 32.525864\n",
      "Learning rate (eta): 0.089944\n",
      "Total number of feature updates: 150930\n",
      "Seconds required for this iteration: 0.008\n",
      "\n",
      "***** Epoch #560 *****\n",
      "Loss: 1.537702\n",
      "Improvement ratio: 0.001539\n",
      "Feature L2-norm: 32.529946\n",
      "Learning rate (eta): 0.089928\n",
      "Total number of feature updates: 151200\n",
      "Seconds required for this iteration: 0.009\n",
      "\n",
      "***** Epoch #561 *****\n",
      "Loss: 1.537490\n",
      "Improvement ratio: 0.001517\n",
      "Feature L2-norm: 32.534020\n",
      "Learning rate (eta): 0.089912\n",
      "Total number of feature updates: 151470\n",
      "Seconds required for this iteration: 0.010\n",
      "\n",
      "***** Epoch #562 *****\n",
      "Loss: 1.537264\n",
      "Improvement ratio: 0.001523\n",
      "Feature L2-norm: 32.538083\n",
      "Learning rate (eta): 0.089896\n",
      "Total number of feature updates: 151740\n",
      "Seconds required for this iteration: 0.008\n",
      "\n",
      "***** Epoch #563 *****\n",
      "Loss: 1.537055\n",
      "Improvement ratio: 0.001505\n",
      "Feature L2-norm: 32.542133\n",
      "Learning rate (eta): 0.089880\n",
      "Total number of feature updates: 152010\n",
      "Seconds required for this iteration: 0.008\n",
      "\n",
      "***** Epoch #564 *****\n",
      "Loss: 1.536806\n",
      "Improvement ratio: 0.001493\n",
      "Feature L2-norm: 32.546172\n",
      "Learning rate (eta): 0.089863\n",
      "Total number of feature updates: 152280\n",
      "Seconds required for this iteration: 0.008\n",
      "\n",
      "***** Epoch #565 *****\n",
      "Loss: 1.536576\n",
      "Improvement ratio: 0.001511\n",
      "Feature L2-norm: 32.550202\n",
      "Learning rate (eta): 0.089847\n",
      "Total number of feature updates: 152550\n",
      "Seconds required for this iteration: 0.008\n",
      "\n",
      "***** Epoch #566 *****\n",
      "Loss: 1.536366\n",
      "Improvement ratio: 0.001487\n",
      "Feature L2-norm: 32.554219\n",
      "Learning rate (eta): 0.089831\n",
      "Total number of feature updates: 152820\n",
      "Seconds required for this iteration: 0.008\n",
      "\n",
      "***** Epoch #567 *****\n",
      "Loss: 1.536136\n",
      "Improvement ratio: 0.001475\n",
      "Feature L2-norm: 32.558223\n",
      "Learning rate (eta): 0.089815\n",
      "Total number of feature updates: 153090\n",
      "Seconds required for this iteration: 0.008\n",
      "\n",
      "***** Epoch #568 *****\n",
      "Loss: 1.535921\n",
      "Improvement ratio: 0.001474\n",
      "Feature L2-norm: 32.562219\n",
      "Learning rate (eta): 0.089799\n",
      "Total number of feature updates: 153360\n",
      "Seconds required for this iteration: 0.008\n",
      "\n",
      "***** Epoch #569 *****\n",
      "Loss: 1.535678\n",
      "Improvement ratio: 0.001482\n",
      "Feature L2-norm: 32.566200\n",
      "Learning rate (eta): 0.089783\n",
      "Total number of feature updates: 153630\n",
      "Seconds required for this iteration: 0.008\n",
      "\n",
      "***** Epoch #570 *****\n",
      "Loss: 1.535473\n",
      "Improvement ratio: 0.001452\n",
      "Feature L2-norm: 32.570172\n",
      "Learning rate (eta): 0.089767\n",
      "Total number of feature updates: 153900\n",
      "Seconds required for this iteration: 0.008\n",
      "\n",
      "***** Epoch #571 *****\n",
      "Loss: 1.535223\n",
      "Improvement ratio: 0.001477\n",
      "Feature L2-norm: 32.574134\n",
      "Learning rate (eta): 0.089751\n",
      "Total number of feature updates: 154170\n",
      "Seconds required for this iteration: 0.008\n",
      "\n",
      "***** Epoch #572 *****\n",
      "Loss: 1.535036\n",
      "Improvement ratio: 0.001451\n",
      "Feature L2-norm: 32.578082\n",
      "Learning rate (eta): 0.089734\n",
      "Total number of feature updates: 154440\n",
      "Seconds required for this iteration: 0.008\n",
      "\n",
      "***** Epoch #573 *****\n",
      "Loss: 1.534796\n",
      "Improvement ratio: 0.001472\n",
      "Feature L2-norm: 32.582021\n",
      "Learning rate (eta): 0.089718\n",
      "Total number of feature updates: 154710\n",
      "Seconds required for this iteration: 0.008\n",
      "\n",
      "***** Epoch #574 *****\n",
      "Loss: 1.534585\n",
      "Improvement ratio: 0.001448\n",
      "Feature L2-norm: 32.585950\n",
      "Learning rate (eta): 0.089702\n",
      "Total number of feature updates: 154980\n",
      "Seconds required for this iteration: 0.008\n",
      "\n",
      "***** Epoch #575 *****\n",
      "Loss: 1.534389\n",
      "Improvement ratio: 0.001425\n",
      "Feature L2-norm: 32.589867\n",
      "Learning rate (eta): 0.089686\n",
      "Total number of feature updates: 155250\n",
      "Seconds required for this iteration: 0.008\n",
      "\n",
      "***** Epoch #576 *****\n",
      "Loss: 1.534150\n",
      "Improvement ratio: 0.001445\n",
      "Feature L2-norm: 32.593772\n",
      "Learning rate (eta): 0.089670\n",
      "Total number of feature updates: 155520\n",
      "Seconds required for this iteration: 0.008\n",
      "\n",
      "***** Epoch #577 *****\n",
      "Loss: 1.533952\n",
      "Improvement ratio: 0.001423\n",
      "Feature L2-norm: 32.597668\n",
      "Learning rate (eta): 0.089654\n",
      "Total number of feature updates: 155790\n",
      "Seconds required for this iteration: 0.008\n",
      "\n",
      "***** Epoch #578 *****\n",
      "Loss: 1.533742\n",
      "Improvement ratio: 0.001421\n",
      "Feature L2-norm: 32.601551\n",
      "Learning rate (eta): 0.089638\n",
      "Total number of feature updates: 156060\n",
      "Seconds required for this iteration: 0.008\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** Epoch #579 *****\n",
      "Loss: 1.533556\n",
      "Improvement ratio: 0.001384\n",
      "Feature L2-norm: 32.605425\n",
      "Learning rate (eta): 0.089622\n",
      "Total number of feature updates: 156330\n",
      "Seconds required for this iteration: 0.009\n",
      "\n",
      "***** Epoch #580 *****\n",
      "Loss: 1.533329\n",
      "Improvement ratio: 0.001398\n",
      "Feature L2-norm: 32.609286\n",
      "Learning rate (eta): 0.089606\n",
      "Total number of feature updates: 156600\n",
      "Seconds required for this iteration: 0.008\n",
      "\n",
      "***** Epoch #581 *****\n",
      "Loss: 1.533117\n",
      "Improvement ratio: 0.001374\n",
      "Feature L2-norm: 32.613135\n",
      "Learning rate (eta): 0.089590\n",
      "Total number of feature updates: 156870\n",
      "Seconds required for this iteration: 0.009\n",
      "\n",
      "***** Epoch #582 *****\n",
      "Loss: 1.532890\n",
      "Improvement ratio: 0.001400\n",
      "Feature L2-norm: 32.616978\n",
      "Learning rate (eta): 0.089574\n",
      "Total number of feature updates: 157140\n",
      "Seconds required for this iteration: 0.007\n",
      "\n",
      "***** Epoch #583 *****\n",
      "Loss: 1.532697\n",
      "Improvement ratio: 0.001370\n",
      "Feature L2-norm: 32.620811\n",
      "Learning rate (eta): 0.089558\n",
      "Total number of feature updates: 157410\n",
      "Seconds required for this iteration: 0.009\n",
      "\n",
      "***** Epoch #584 *****\n",
      "Loss: 1.532479\n",
      "Improvement ratio: 0.001374\n",
      "Feature L2-norm: 32.624633\n",
      "Learning rate (eta): 0.089542\n",
      "Total number of feature updates: 157680\n",
      "Seconds required for this iteration: 0.009\n",
      "\n",
      "***** Epoch #585 *****\n",
      "Loss: 1.532308\n",
      "Improvement ratio: 0.001358\n",
      "Feature L2-norm: 32.628442\n",
      "Learning rate (eta): 0.089526\n",
      "Total number of feature updates: 157950\n",
      "Seconds required for this iteration: 0.010\n",
      "\n",
      "***** Epoch #586 *****\n",
      "Loss: 1.532073\n",
      "Improvement ratio: 0.001355\n",
      "Feature L2-norm: 32.632240\n",
      "Learning rate (eta): 0.089510\n",
      "Total number of feature updates: 158220\n",
      "Seconds required for this iteration: 0.010\n",
      "\n",
      "***** Epoch #587 *****\n",
      "Loss: 1.531887\n",
      "Improvement ratio: 0.001348\n",
      "Feature L2-norm: 32.636028\n",
      "Learning rate (eta): 0.089494\n",
      "Total number of feature updates: 158490\n",
      "Seconds required for this iteration: 0.009\n",
      "\n",
      "***** Epoch #588 *****\n",
      "Loss: 1.531685\n",
      "Improvement ratio: 0.001343\n",
      "Feature L2-norm: 32.639808\n",
      "Learning rate (eta): 0.089478\n",
      "Total number of feature updates: 158760\n",
      "Seconds required for this iteration: 0.012\n",
      "\n",
      "***** Epoch #589 *****\n",
      "Loss: 1.531491\n",
      "Improvement ratio: 0.001348\n",
      "Feature L2-norm: 32.643572\n",
      "Learning rate (eta): 0.089462\n",
      "Total number of feature updates: 159030\n",
      "Seconds required for this iteration: 0.010\n",
      "\n",
      "***** Epoch #590 *****\n",
      "Loss: 1.531272\n",
      "Improvement ratio: 0.001343\n",
      "Feature L2-norm: 32.647327\n",
      "Learning rate (eta): 0.089445\n",
      "Total number of feature updates: 159300\n",
      "Seconds required for this iteration: 0.011\n",
      "\n",
      "***** Epoch #591 *****\n",
      "Loss: 1.531098\n",
      "Improvement ratio: 0.001319\n",
      "Feature L2-norm: 32.651075\n",
      "Learning rate (eta): 0.089429\n",
      "Total number of feature updates: 159570\n",
      "Seconds required for this iteration: 0.012\n",
      "\n",
      "***** Epoch #592 *****\n",
      "Loss: 1.530864\n",
      "Improvement ratio: 0.001324\n",
      "Feature L2-norm: 32.654813\n",
      "Learning rate (eta): 0.089414\n",
      "Total number of feature updates: 159840\n",
      "Seconds required for this iteration: 0.008\n",
      "\n",
      "***** Epoch #593 *****\n",
      "Loss: 1.530697\n",
      "Improvement ratio: 0.001306\n",
      "Feature L2-norm: 32.658537\n",
      "Learning rate (eta): 0.089398\n",
      "Total number of feature updates: 160110\n",
      "Seconds required for this iteration: 0.009\n",
      "\n",
      "***** Epoch #594 *****\n",
      "Loss: 1.530505\n",
      "Improvement ratio: 0.001290\n",
      "Feature L2-norm: 32.662253\n",
      "Learning rate (eta): 0.089382\n",
      "Total number of feature updates: 160380\n",
      "Seconds required for this iteration: 0.008\n",
      "\n",
      "***** Epoch #595 *****\n",
      "Loss: 1.530326\n",
      "Improvement ratio: 0.001295\n",
      "Feature L2-norm: 32.665958\n",
      "Learning rate (eta): 0.089366\n",
      "Total number of feature updates: 160650\n",
      "Seconds required for this iteration: 0.008\n",
      "\n",
      "***** Epoch #596 *****\n",
      "Loss: 1.530108\n",
      "Improvement ratio: 0.001285\n",
      "Feature L2-norm: 32.669653\n",
      "Learning rate (eta): 0.089350\n",
      "Total number of feature updates: 160920\n",
      "Seconds required for this iteration: 0.009\n",
      "\n",
      "***** Epoch #597 *****\n",
      "Loss: 1.529919\n",
      "Improvement ratio: 0.001286\n",
      "Feature L2-norm: 32.673336\n",
      "Learning rate (eta): 0.089334\n",
      "Total number of feature updates: 161190\n",
      "Seconds required for this iteration: 0.008\n",
      "\n",
      "***** Epoch #598 *****\n",
      "Loss: 1.529754\n",
      "Improvement ratio: 0.001262\n",
      "Feature L2-norm: 32.677011\n",
      "Learning rate (eta): 0.089318\n",
      "Total number of feature updates: 161460\n",
      "Seconds required for this iteration: 0.008\n",
      "\n",
      "***** Epoch #599 *****\n",
      "Loss: 1.529560\n",
      "Improvement ratio: 0.001262\n",
      "Feature L2-norm: 32.680675\n",
      "Learning rate (eta): 0.089302\n",
      "Total number of feature updates: 161730\n",
      "Seconds required for this iteration: 0.008\n",
      "\n",
      "***** Epoch #600 *****\n",
      "Loss: 1.529348\n",
      "Improvement ratio: 0.001258\n",
      "Feature L2-norm: 32.684333\n",
      "Learning rate (eta): 0.089286\n",
      "Total number of feature updates: 162000\n",
      "Seconds required for this iteration: 0.008\n",
      "\n",
      "***** Epoch #601 *****\n",
      "Loss: 1.529142\n",
      "Improvement ratio: 0.001279\n",
      "Feature L2-norm: 32.687979\n",
      "Learning rate (eta): 0.089270\n",
      "Total number of feature updates: 162270\n",
      "Seconds required for this iteration: 0.008\n",
      "\n",
      "***** Epoch #602 *****\n",
      "Loss: 1.528958\n",
      "Improvement ratio: 0.001246\n",
      "Feature L2-norm: 32.691617\n",
      "Learning rate (eta): 0.089254\n",
      "Total number of feature updates: 162540\n",
      "Seconds required for this iteration: 0.008\n",
      "\n",
      "***** Epoch #603 *****\n",
      "Loss: 1.528811\n",
      "Improvement ratio: 0.001233\n",
      "Feature L2-norm: 32.695243\n",
      "Learning rate (eta): 0.089238\n",
      "Total number of feature updates: 162810\n",
      "Seconds required for this iteration: 0.008\n",
      "\n",
      "***** Epoch #604 *****\n",
      "Loss: 1.528590\n",
      "Improvement ratio: 0.001253\n",
      "Feature L2-norm: 32.698862\n",
      "Learning rate (eta): 0.089222\n",
      "Total number of feature updates: 163080\n",
      "Seconds required for this iteration: 0.008\n",
      "\n",
      "***** Epoch #605 *****\n",
      "Loss: 1.528397\n",
      "Improvement ratio: 0.001262\n",
      "Feature L2-norm: 32.702468\n",
      "Learning rate (eta): 0.089206\n",
      "Total number of feature updates: 163350\n",
      "Seconds required for this iteration: 0.008\n",
      "\n",
      "***** Epoch #606 *****\n",
      "Loss: 1.528215\n",
      "Improvement ratio: 0.001239\n",
      "Feature L2-norm: 32.706064\n",
      "Learning rate (eta): 0.089190\n",
      "Total number of feature updates: 163620\n",
      "Seconds required for this iteration: 0.008\n",
      "\n",
      "***** Epoch #607 *****\n",
      "Loss: 1.528050\n",
      "Improvement ratio: 0.001223\n",
      "Feature L2-norm: 32.709651\n",
      "Learning rate (eta): 0.089174\n",
      "Total number of feature updates: 163890\n",
      "Seconds required for this iteration: 0.008\n",
      "\n",
      "***** Epoch #608 *****\n",
      "Loss: 1.527867\n",
      "Improvement ratio: 0.001235\n",
      "Feature L2-norm: 32.713228\n",
      "Learning rate (eta): 0.089158\n",
      "Total number of feature updates: 164160\n",
      "Seconds required for this iteration: 0.008\n",
      "\n",
      "***** Epoch #609 *****\n",
      "Loss: 1.527704\n",
      "Improvement ratio: 0.001215\n",
      "Feature L2-norm: 32.716795\n",
      "Learning rate (eta): 0.089143\n",
      "Total number of feature updates: 164430\n",
      "Seconds required for this iteration: 0.008\n",
      "\n",
      "***** Epoch #610 *****\n",
      "Loss: 1.527522\n",
      "Improvement ratio: 0.001196\n",
      "Feature L2-norm: 32.720352\n",
      "Learning rate (eta): 0.089127\n",
      "Total number of feature updates: 164700\n",
      "Seconds required for this iteration: 0.008\n",
      "\n",
      "***** Epoch #611 *****\n",
      "Loss: 1.527312\n",
      "Improvement ratio: 0.001198\n",
      "Feature L2-norm: 32.723899\n",
      "Learning rate (eta): 0.089111\n",
      "Total number of feature updates: 164970\n",
      "Seconds required for this iteration: 0.009\n",
      "\n",
      "***** Epoch #612 *****\n",
      "Loss: 1.527121\n",
      "Improvement ratio: 0.001203\n",
      "Feature L2-norm: 32.727434\n",
      "Learning rate (eta): 0.089095\n",
      "Total number of feature updates: 165240\n",
      "Seconds required for this iteration: 0.011\n",
      "\n",
      "***** Epoch #613 *****\n",
      "Loss: 1.526958\n",
      "Improvement ratio: 0.001214\n",
      "Feature L2-norm: 32.730963\n",
      "Learning rate (eta): 0.089079\n",
      "Total number of feature updates: 165510\n",
      "Seconds required for this iteration: 0.008\n",
      "\n",
      "***** Epoch #614 *****\n",
      "Loss: 1.526764\n",
      "Improvement ratio: 0.001196\n",
      "Feature L2-norm: 32.734485\n",
      "Learning rate (eta): 0.089063\n",
      "Total number of feature updates: 165780\n",
      "Seconds required for this iteration: 0.010\n",
      "\n",
      "***** Epoch #615 *****\n",
      "Loss: 1.526611\n",
      "Improvement ratio: 0.001170\n",
      "Feature L2-norm: 32.737995\n",
      "Learning rate (eta): 0.089047\n",
      "Total number of feature updates: 166050\n",
      "Seconds required for this iteration: 0.008\n",
      "\n",
      "***** Epoch #616 *****\n",
      "Loss: 1.526417\n",
      "Improvement ratio: 0.001178\n",
      "Feature L2-norm: 32.741499\n",
      "Learning rate (eta): 0.089031\n",
      "Total number of feature updates: 166320\n",
      "Seconds required for this iteration: 0.009\n",
      "\n",
      "***** Epoch #617 *****\n",
      "Loss: 1.526249\n",
      "Improvement ratio: 0.001180\n",
      "Feature L2-norm: 32.744989\n",
      "Learning rate (eta): 0.089016\n",
      "Total number of feature updates: 166590\n",
      "Seconds required for this iteration: 0.008\n",
      "\n",
      "***** Epoch #618 *****\n",
      "Loss: 1.526074\n",
      "Improvement ratio: 0.001175\n",
      "Feature L2-norm: 32.748471\n",
      "Learning rate (eta): 0.089000\n",
      "Total number of feature updates: 166860\n",
      "Seconds required for this iteration: 0.009\n",
      "\n",
      "***** Epoch #619 *****\n",
      "Loss: 1.525922\n",
      "Improvement ratio: 0.001168\n",
      "Feature L2-norm: 32.751943\n",
      "Learning rate (eta): 0.088984\n",
      "Total number of feature updates: 167130\n",
      "Seconds required for this iteration: 0.008\n",
      "\n",
      "***** Epoch #620 *****\n",
      "Loss: 1.525745\n",
      "Improvement ratio: 0.001165\n",
      "Feature L2-norm: 32.755407\n",
      "Learning rate (eta): 0.088968\n",
      "Total number of feature updates: 167400\n",
      "Seconds required for this iteration: 0.009\n",
      "\n",
      "***** Epoch #621 *****\n",
      "Loss: 1.525575\n",
      "Improvement ratio: 0.001138\n",
      "Feature L2-norm: 32.758861\n",
      "Learning rate (eta): 0.088952\n",
      "Total number of feature updates: 167670\n",
      "Seconds required for this iteration: 0.008\n",
      "\n",
      "***** Epoch #622 *****\n",
      "Loss: 1.525386\n",
      "Improvement ratio: 0.001137\n",
      "Feature L2-norm: 32.762305\n",
      "Learning rate (eta): 0.088936\n",
      "Total number of feature updates: 167940\n",
      "Seconds required for this iteration: 0.008\n",
      "\n",
      "***** Epoch #623 *****\n",
      "Loss: 1.525242\n",
      "Improvement ratio: 0.001125\n",
      "Feature L2-norm: 32.765740\n",
      "Learning rate (eta): 0.088921\n",
      "Total number of feature updates: 168210\n",
      "Seconds required for this iteration: 0.008\n",
      "\n",
      "***** Epoch #624 *****\n",
      "Loss: 1.525072\n",
      "Improvement ratio: 0.001109\n",
      "Feature L2-norm: 32.769166\n",
      "Learning rate (eta): 0.088905\n",
      "Total number of feature updates: 168480\n",
      "Seconds required for this iteration: 0.008\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** Epoch #625 *****\n",
      "Loss: 1.524885\n",
      "Improvement ratio: 0.001132\n",
      "Feature L2-norm: 32.772581\n",
      "Learning rate (eta): 0.088889\n",
      "Total number of feature updates: 168750\n",
      "Seconds required for this iteration: 0.008\n",
      "\n",
      "***** Epoch #626 *****\n",
      "Loss: 1.524707\n",
      "Improvement ratio: 0.001122\n",
      "Feature L2-norm: 32.775987\n",
      "Learning rate (eta): 0.088873\n",
      "Total number of feature updates: 169020\n",
      "Seconds required for this iteration: 0.008\n",
      "\n",
      "***** Epoch #627 *****\n",
      "Loss: 1.524575\n",
      "Improvement ratio: 0.001098\n",
      "Feature L2-norm: 32.779386\n",
      "Learning rate (eta): 0.088857\n",
      "Total number of feature updates: 169290\n",
      "Seconds required for this iteration: 0.008\n",
      "\n",
      "***** Epoch #628 *****\n",
      "Loss: 1.524387\n",
      "Improvement ratio: 0.001107\n",
      "Feature L2-norm: 32.782778\n",
      "Learning rate (eta): 0.088842\n",
      "Total number of feature updates: 169560\n",
      "Seconds required for this iteration: 0.008\n",
      "\n",
      "***** Epoch #629 *****\n",
      "Loss: 1.524217\n",
      "Improvement ratio: 0.001118\n",
      "Feature L2-norm: 32.786160\n",
      "Learning rate (eta): 0.088826\n",
      "Total number of feature updates: 169830\n",
      "Seconds required for this iteration: 0.007\n",
      "\n",
      "***** Epoch #630 *****\n",
      "Loss: 1.524055\n",
      "Improvement ratio: 0.001109\n",
      "Feature L2-norm: 32.789531\n",
      "Learning rate (eta): 0.088810\n",
      "Total number of feature updates: 170100\n",
      "Seconds required for this iteration: 0.008\n",
      "\n",
      "***** Epoch #631 *****\n",
      "Loss: 1.523886\n",
      "Improvement ratio: 0.001108\n",
      "Feature L2-norm: 32.792894\n",
      "Learning rate (eta): 0.088794\n",
      "Total number of feature updates: 170370\n",
      "Seconds required for this iteration: 0.008\n",
      "\n",
      "***** Epoch #632 *****\n",
      "Loss: 1.523756\n",
      "Improvement ratio: 0.001070\n",
      "Feature L2-norm: 32.796248\n",
      "Learning rate (eta): 0.088778\n",
      "Total number of feature updates: 170640\n",
      "Seconds required for this iteration: 0.009\n",
      "\n",
      "***** Epoch #633 *****\n",
      "Loss: 1.523569\n",
      "Improvement ratio: 0.001098\n",
      "Feature L2-norm: 32.799591\n",
      "Learning rate (eta): 0.088763\n",
      "Total number of feature updates: 170910\n",
      "Seconds required for this iteration: 0.009\n",
      "\n",
      "***** Epoch #634 *****\n",
      "Loss: 1.523402\n",
      "Improvement ratio: 0.001097\n",
      "Feature L2-norm: 32.802928\n",
      "Learning rate (eta): 0.088747\n",
      "Total number of feature updates: 171180\n",
      "Seconds required for this iteration: 0.010\n",
      "\n",
      "***** Epoch #635 *****\n",
      "Loss: 1.523230\n",
      "Improvement ratio: 0.001087\n",
      "Feature L2-norm: 32.806258\n",
      "Learning rate (eta): 0.088731\n",
      "Total number of feature updates: 171450\n",
      "Seconds required for this iteration: 0.008\n",
      "\n",
      "***** Epoch #636 *****\n",
      "Loss: 1.523096\n",
      "Improvement ratio: 0.001058\n",
      "Feature L2-norm: 32.809579\n",
      "Learning rate (eta): 0.088715\n",
      "Total number of feature updates: 171720\n",
      "Seconds required for this iteration: 0.009\n",
      "\n",
      "***** Epoch #637 *****\n",
      "Loss: 1.522926\n",
      "Improvement ratio: 0.001083\n",
      "Feature L2-norm: 32.812890\n",
      "Learning rate (eta): 0.088700\n",
      "Total number of feature updates: 171990\n",
      "Seconds required for this iteration: 0.008\n",
      "\n",
      "***** Epoch #638 *****\n",
      "Loss: 1.522763\n",
      "Improvement ratio: 0.001066\n",
      "Feature L2-norm: 32.816191\n",
      "Learning rate (eta): 0.088684\n",
      "Total number of feature updates: 172260\n",
      "Seconds required for this iteration: 0.008\n",
      "\n",
      "***** Epoch #639 *****\n",
      "Loss: 1.522612\n",
      "Improvement ratio: 0.001054\n",
      "Feature L2-norm: 32.819484\n",
      "Learning rate (eta): 0.088668\n",
      "Total number of feature updates: 172530\n",
      "Seconds required for this iteration: 0.008\n",
      "\n",
      "***** Epoch #640 *****\n",
      "Loss: 1.522417\n",
      "Improvement ratio: 0.001076\n",
      "Feature L2-norm: 32.822770\n",
      "Learning rate (eta): 0.088653\n",
      "Total number of feature updates: 172800\n",
      "Seconds required for this iteration: 0.008\n",
      "\n",
      "***** Epoch #641 *****\n",
      "Loss: 1.522270\n",
      "Improvement ratio: 0.001061\n",
      "Feature L2-norm: 32.826048\n",
      "Learning rate (eta): 0.088637\n",
      "Total number of feature updates: 173070\n",
      "Seconds required for this iteration: 0.008\n",
      "\n",
      "***** Epoch #642 *****\n",
      "Loss: 1.522136\n",
      "Improvement ratio: 0.001064\n",
      "Feature L2-norm: 32.829314\n",
      "Learning rate (eta): 0.088621\n",
      "Total number of feature updates: 173340\n",
      "Seconds required for this iteration: 0.008\n",
      "\n",
      "***** Epoch #643 *****\n",
      "Loss: 1.521984\n",
      "Improvement ratio: 0.001042\n",
      "Feature L2-norm: 32.832573\n",
      "Learning rate (eta): 0.088605\n",
      "Total number of feature updates: 173610\n",
      "Seconds required for this iteration: 0.008\n",
      "\n",
      "***** Epoch #644 *****\n",
      "Loss: 1.521856\n",
      "Improvement ratio: 0.001016\n",
      "Feature L2-norm: 32.835821\n",
      "Learning rate (eta): 0.088590\n",
      "Total number of feature updates: 173880\n",
      "Seconds required for this iteration: 0.008\n",
      "\n",
      "***** Epoch #645 *****\n",
      "Loss: 1.521678\n",
      "Improvement ratio: 0.001020\n",
      "Feature L2-norm: 32.839061\n",
      "Learning rate (eta): 0.088574\n",
      "Total number of feature updates: 174150\n",
      "Seconds required for this iteration: 0.008\n",
      "\n",
      "***** Epoch #646 *****\n",
      "Loss: 1.521523\n",
      "Improvement ratio: 0.001034\n",
      "Feature L2-norm: 32.842293\n",
      "Learning rate (eta): 0.088558\n",
      "Total number of feature updates: 174420\n",
      "Seconds required for this iteration: 0.007\n",
      "\n",
      "***** Epoch #647 *****\n",
      "Loss: 1.521389\n",
      "Improvement ratio: 0.001010\n",
      "Feature L2-norm: 32.845519\n",
      "Learning rate (eta): 0.088543\n",
      "Total number of feature updates: 174690\n",
      "Seconds required for this iteration: 0.007\n",
      "\n",
      "***** Epoch #648 *****\n",
      "Loss: 1.521227\n",
      "Improvement ratio: 0.001010\n",
      "Feature L2-norm: 32.848736\n",
      "Learning rate (eta): 0.088527\n",
      "Total number of feature updates: 174960\n",
      "Seconds required for this iteration: 0.008\n",
      "\n",
      "***** Epoch #649 *****\n",
      "Loss: 1.521056\n",
      "Improvement ratio: 0.001023\n",
      "Feature L2-norm: 32.851945\n",
      "Learning rate (eta): 0.088511\n",
      "Total number of feature updates: 175230\n",
      "Seconds required for this iteration: 0.008\n",
      "\n",
      "***** Epoch #650 *****\n",
      "Loss: 1.520929\n",
      "Improvement ratio: 0.000978\n",
      "Feature L2-norm: 32.855145\n",
      "Learning rate (eta): 0.088496\n",
      "Total number of feature updates: 175500\n",
      "Seconds required for this iteration: 0.009\n",
      "\n",
      "***** Epoch #651 *****\n",
      "Loss: 1.520747\n",
      "Improvement ratio: 0.001001\n",
      "Feature L2-norm: 32.858339\n",
      "Learning rate (eta): 0.088480\n",
      "Total number of feature updates: 175770\n",
      "Seconds required for this iteration: 0.010\n",
      "\n",
      "***** Epoch #652 *****\n",
      "Loss: 1.520632\n",
      "Improvement ratio: 0.000989\n",
      "Feature L2-norm: 32.861521\n",
      "Learning rate (eta): 0.088464\n",
      "Total number of feature updates: 176040\n",
      "Seconds required for this iteration: 0.008\n",
      "\n",
      "***** Epoch #653 *****\n",
      "Loss: 1.520475\n",
      "Improvement ratio: 0.000992\n",
      "Feature L2-norm: 32.864694\n",
      "Learning rate (eta): 0.088449\n",
      "Total number of feature updates: 176310\n",
      "Seconds required for this iteration: 0.008\n",
      "\n",
      "***** Epoch #654 *****\n",
      "Loss: 1.520325\n",
      "Improvement ratio: 0.001007\n",
      "Feature L2-norm: 32.867860\n",
      "Learning rate (eta): 0.088433\n",
      "Total number of feature updates: 176580\n",
      "Seconds required for this iteration: 0.008\n",
      "\n",
      "***** Epoch #655 *****\n",
      "Loss: 1.520174\n",
      "Improvement ratio: 0.000989\n",
      "Feature L2-norm: 32.871017\n",
      "Learning rate (eta): 0.088417\n",
      "Total number of feature updates: 176850\n",
      "Seconds required for this iteration: 0.008\n",
      "\n",
      "***** Epoch #656 *****\n",
      "Loss: 1.520030\n",
      "Improvement ratio: 0.000982\n",
      "Feature L2-norm: 32.874165\n",
      "Learning rate (eta): 0.088402\n",
      "Total number of feature updates: 177120\n",
      "Seconds required for this iteration: 0.008\n",
      "\n",
      "***** Epoch #657 *****\n",
      "Loss: 1.519880\n",
      "Improvement ratio: 0.000992\n",
      "Feature L2-norm: 32.877307\n",
      "Learning rate (eta): 0.088386\n",
      "Total number of feature updates: 177390\n",
      "Seconds required for this iteration: 0.013\n",
      "\n",
      "***** Epoch #658 *****\n",
      "Loss: 1.519762\n",
      "Improvement ratio: 0.000964\n",
      "Feature L2-norm: 32.880441\n",
      "Learning rate (eta): 0.088371\n",
      "Total number of feature updates: 177660\n",
      "Seconds required for this iteration: 0.011\n",
      "\n",
      "***** Epoch #659 *****\n",
      "Loss: 1.519603\n",
      "Improvement ratio: 0.000956\n",
      "Feature L2-norm: 32.883566\n",
      "Learning rate (eta): 0.088355\n",
      "Total number of feature updates: 177930\n",
      "Seconds required for this iteration: 0.009\n",
      "\n",
      "***** Epoch #660 *****\n",
      "Loss: 1.519448\n",
      "Improvement ratio: 0.000975\n",
      "Feature L2-norm: 32.886684\n",
      "Learning rate (eta): 0.088339\n",
      "Total number of feature updates: 178200\n",
      "Seconds required for this iteration: 0.008\n",
      "\n",
      "***** Epoch #661 *****\n",
      "Loss: 1.519311\n",
      "Improvement ratio: 0.000945\n",
      "Feature L2-norm: 32.889794\n",
      "Learning rate (eta): 0.088324\n",
      "Total number of feature updates: 178470\n",
      "Seconds required for this iteration: 0.009\n",
      "\n",
      "***** Epoch #662 *****\n",
      "Loss: 1.519165\n",
      "Improvement ratio: 0.000966\n",
      "Feature L2-norm: 32.892897\n",
      "Learning rate (eta): 0.088308\n",
      "Total number of feature updates: 178740\n",
      "Seconds required for this iteration: 0.009\n",
      "\n",
      "***** Epoch #663 *****\n",
      "Loss: 1.519015\n",
      "Improvement ratio: 0.000961\n",
      "Feature L2-norm: 32.895988\n",
      "Learning rate (eta): 0.088292\n",
      "Total number of feature updates: 179010\n",
      "Seconds required for this iteration: 0.009\n",
      "\n",
      "***** Epoch #664 *****\n",
      "Loss: 1.518894\n",
      "Improvement ratio: 0.000942\n",
      "Feature L2-norm: 32.899074\n",
      "Learning rate (eta): 0.088277\n",
      "Total number of feature updates: 179280\n",
      "Seconds required for this iteration: 0.010\n",
      "\n",
      "***** Epoch #665 *****\n",
      "Loss: 1.518747\n",
      "Improvement ratio: 0.000940\n",
      "Feature L2-norm: 32.902154\n",
      "Learning rate (eta): 0.088261\n",
      "Total number of feature updates: 179550\n",
      "Seconds required for this iteration: 0.009\n",
      "\n",
      "***** Epoch #666 *****\n",
      "Loss: 1.518601\n",
      "Improvement ratio: 0.000941\n",
      "Feature L2-norm: 32.905223\n",
      "Learning rate (eta): 0.088246\n",
      "Total number of feature updates: 179820\n",
      "Seconds required for this iteration: 0.008\n",
      "\n",
      "***** Epoch #667 *****\n",
      "Loss: 1.518461\n",
      "Improvement ratio: 0.000934\n",
      "Feature L2-norm: 32.908284\n",
      "Learning rate (eta): 0.088230\n",
      "Total number of feature updates: 180090\n",
      "Seconds required for this iteration: 0.008\n",
      "\n",
      "***** Epoch #668 *****\n",
      "Loss: 1.518307\n",
      "Improvement ratio: 0.000958\n",
      "Feature L2-norm: 32.911335\n",
      "Learning rate (eta): 0.088215\n",
      "Total number of feature updates: 180360\n",
      "Seconds required for this iteration: 0.009\n",
      "\n",
      "***** Epoch #669 *****\n",
      "Loss: 1.518193\n",
      "Improvement ratio: 0.000928\n",
      "Feature L2-norm: 32.914378\n",
      "Learning rate (eta): 0.088199\n",
      "Total number of feature updates: 180630\n",
      "Seconds required for this iteration: 0.009\n",
      "\n",
      "***** Epoch #670 *****\n",
      "Loss: 1.518049\n",
      "Improvement ratio: 0.000922\n",
      "Feature L2-norm: 32.917419\n",
      "Learning rate (eta): 0.088183\n",
      "Total number of feature updates: 180900\n",
      "Seconds required for this iteration: 0.009\n",
      "\n",
      "***** Epoch #671 *****\n",
      "Loss: 1.517910\n",
      "Improvement ratio: 0.000923\n",
      "Feature L2-norm: 32.920450\n",
      "Learning rate (eta): 0.088168\n",
      "Total number of feature updates: 181170\n",
      "Seconds required for this iteration: 0.009\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** Epoch #672 *****\n",
      "Loss: 1.517748\n",
      "Improvement ratio: 0.000933\n",
      "Feature L2-norm: 32.923471\n",
      "Learning rate (eta): 0.088152\n",
      "Total number of feature updates: 181440\n",
      "Seconds required for this iteration: 0.009\n",
      "\n",
      "***** Epoch #673 *****\n",
      "Loss: 1.517642\n",
      "Improvement ratio: 0.000905\n",
      "Feature L2-norm: 32.926488\n",
      "Learning rate (eta): 0.088137\n",
      "Total number of feature updates: 181710\n",
      "Seconds required for this iteration: 0.009\n",
      "\n",
      "***** Epoch #674 *****\n",
      "Loss: 1.517529\n",
      "Improvement ratio: 0.000900\n",
      "Feature L2-norm: 32.929495\n",
      "Learning rate (eta): 0.088121\n",
      "Total number of feature updates: 181980\n",
      "Seconds required for this iteration: 0.008\n",
      "\n",
      "***** Epoch #675 *****\n",
      "Loss: 1.517361\n",
      "Improvement ratio: 0.000913\n",
      "Feature L2-norm: 32.932493\n",
      "Learning rate (eta): 0.088106\n",
      "Total number of feature updates: 182250\n",
      "Seconds required for this iteration: 0.010\n",
      "\n",
      "***** Epoch #676 *****\n",
      "Loss: 1.517223\n",
      "Improvement ratio: 0.000908\n",
      "Feature L2-norm: 32.935484\n",
      "Learning rate (eta): 0.088090\n",
      "Total number of feature updates: 182520\n",
      "Seconds required for this iteration: 0.010\n",
      "\n",
      "***** Epoch #677 *****\n",
      "Loss: 1.517105\n",
      "Improvement ratio: 0.000894\n",
      "Feature L2-norm: 32.938469\n",
      "Learning rate (eta): 0.088075\n",
      "Total number of feature updates: 182790\n",
      "Seconds required for this iteration: 0.011\n",
      "\n",
      "***** Epoch #678 *****\n",
      "Loss: 1.516958\n",
      "Improvement ratio: 0.000889\n",
      "Feature L2-norm: 32.941446\n",
      "Learning rate (eta): 0.088059\n",
      "Total number of feature updates: 183060\n",
      "Seconds required for this iteration: 0.008\n",
      "\n",
      "***** Epoch #679 *****\n",
      "Loss: 1.516861\n",
      "Improvement ratio: 0.000879\n",
      "Feature L2-norm: 32.944417\n",
      "Learning rate (eta): 0.088044\n",
      "Total number of feature updates: 183330\n",
      "Seconds required for this iteration: 0.009\n",
      "\n",
      "***** Epoch #680 *****\n",
      "Loss: 1.516719\n",
      "Improvement ratio: 0.000877\n",
      "Feature L2-norm: 32.947379\n",
      "Learning rate (eta): 0.088028\n",
      "Total number of feature updates: 183600\n",
      "Seconds required for this iteration: 0.009\n",
      "\n",
      "***** Epoch #681 *****\n",
      "Loss: 1.516591\n",
      "Improvement ratio: 0.000870\n",
      "Feature L2-norm: 32.950333\n",
      "Learning rate (eta): 0.088013\n",
      "Total number of feature updates: 183870\n",
      "Seconds required for this iteration: 0.010\n",
      "\n",
      "***** Epoch #682 *****\n",
      "Loss: 1.516461\n",
      "Improvement ratio: 0.000849\n",
      "Feature L2-norm: 32.953282\n",
      "Learning rate (eta): 0.087997\n",
      "Total number of feature updates: 184140\n",
      "Seconds required for this iteration: 0.009\n",
      "\n",
      "***** Epoch #683 *****\n",
      "Loss: 1.516310\n",
      "Improvement ratio: 0.000879\n",
      "Feature L2-norm: 32.956221\n",
      "Learning rate (eta): 0.087982\n",
      "Total number of feature updates: 184410\n",
      "Seconds required for this iteration: 0.010\n",
      "\n",
      "***** Epoch #684 *****\n",
      "Loss: 1.516193\n",
      "Improvement ratio: 0.000881\n",
      "Feature L2-norm: 32.959152\n",
      "Learning rate (eta): 0.087966\n",
      "Total number of feature updates: 184680\n",
      "Seconds required for this iteration: 0.009\n",
      "\n",
      "***** Epoch #685 *****\n",
      "Loss: 1.516059\n",
      "Improvement ratio: 0.000858\n",
      "Feature L2-norm: 32.962076\n",
      "Learning rate (eta): 0.087951\n",
      "Total number of feature updates: 184950\n",
      "Seconds required for this iteration: 0.009\n",
      "\n",
      "***** Epoch #686 *****\n",
      "Loss: 1.515911\n",
      "Improvement ratio: 0.000865\n",
      "Feature L2-norm: 32.964993\n",
      "Learning rate (eta): 0.087935\n",
      "Total number of feature updates: 185220\n",
      "Seconds required for this iteration: 0.009\n",
      "\n",
      "***** Epoch #687 *****\n",
      "Loss: 1.515805\n",
      "Improvement ratio: 0.000857\n",
      "Feature L2-norm: 32.967902\n",
      "Learning rate (eta): 0.087920\n",
      "Total number of feature updates: 185490\n",
      "Seconds required for this iteration: 0.009\n",
      "\n",
      "***** Epoch #688 *****\n",
      "Loss: 1.515676\n",
      "Improvement ratio: 0.000846\n",
      "Feature L2-norm: 32.970805\n",
      "Learning rate (eta): 0.087904\n",
      "Total number of feature updates: 185760\n",
      "Seconds required for this iteration: 0.009\n",
      "\n",
      "***** Epoch #689 *****\n",
      "Loss: 1.515547\n",
      "Improvement ratio: 0.000867\n",
      "Feature L2-norm: 32.973698\n",
      "Learning rate (eta): 0.087889\n",
      "Total number of feature updates: 186030\n",
      "Seconds required for this iteration: 0.009\n",
      "\n",
      "***** Epoch #690 *****\n",
      "Loss: 1.515440\n",
      "Improvement ratio: 0.000844\n",
      "Feature L2-norm: 32.976588\n",
      "Learning rate (eta): 0.087874\n",
      "Total number of feature updates: 186300\n",
      "Seconds required for this iteration: 0.009\n",
      "\n",
      "***** Epoch #691 *****\n",
      "Loss: 1.515309\n",
      "Improvement ratio: 0.000846\n",
      "Feature L2-norm: 32.979469\n",
      "Learning rate (eta): 0.087858\n",
      "Total number of feature updates: 186570\n",
      "Seconds required for this iteration: 0.009\n",
      "\n",
      "***** Epoch #692 *****\n",
      "Loss: 1.515175\n",
      "Improvement ratio: 0.000849\n",
      "Feature L2-norm: 32.982342\n",
      "Learning rate (eta): 0.087843\n",
      "Total number of feature updates: 186840\n",
      "Seconds required for this iteration: 0.010\n",
      "\n",
      "***** Epoch #693 *****\n",
      "Loss: 1.515035\n",
      "Improvement ratio: 0.000841\n",
      "Feature L2-norm: 32.985206\n",
      "Learning rate (eta): 0.087827\n",
      "Total number of feature updates: 187110\n",
      "Seconds required for this iteration: 0.009\n",
      "\n",
      "***** Epoch #694 *****\n",
      "Loss: 1.514915\n",
      "Improvement ratio: 0.000844\n",
      "Feature L2-norm: 32.988065\n",
      "Learning rate (eta): 0.087812\n",
      "Total number of feature updates: 187380\n",
      "Seconds required for this iteration: 0.009\n",
      "\n",
      "***** Epoch #695 *****\n",
      "Loss: 1.514803\n",
      "Improvement ratio: 0.000830\n",
      "Feature L2-norm: 32.990917\n",
      "Learning rate (eta): 0.087796\n",
      "Total number of feature updates: 187650\n",
      "Seconds required for this iteration: 0.009\n",
      "\n",
      "***** Epoch #696 *****\n",
      "Loss: 1.514681\n",
      "Improvement ratio: 0.000812\n",
      "Feature L2-norm: 32.993762\n",
      "Learning rate (eta): 0.087781\n",
      "Total number of feature updates: 187920\n",
      "Seconds required for this iteration: 0.009\n",
      "\n",
      "***** Epoch #697 *****\n",
      "Loss: 1.514539\n",
      "Improvement ratio: 0.000836\n",
      "Feature L2-norm: 32.996600\n",
      "Learning rate (eta): 0.087766\n",
      "Total number of feature updates: 188190\n",
      "Seconds required for this iteration: 0.015\n",
      "\n",
      "***** Epoch #698 *****\n",
      "Loss: 1.514456\n",
      "Improvement ratio: 0.000806\n",
      "Feature L2-norm: 32.999431\n",
      "Learning rate (eta): 0.087750\n",
      "Total number of feature updates: 188460\n",
      "Seconds required for this iteration: 0.009\n",
      "\n",
      "***** Epoch #699 *****\n",
      "Loss: 1.514300\n",
      "Improvement ratio: 0.000824\n",
      "Feature L2-norm: 33.002254\n",
      "Learning rate (eta): 0.087735\n",
      "Total number of feature updates: 188730\n",
      "Seconds required for this iteration: 0.008\n",
      "\n",
      "***** Epoch #700 *****\n",
      "Loss: 1.514178\n",
      "Improvement ratio: 0.000834\n",
      "Feature L2-norm: 33.005066\n",
      "Learning rate (eta): 0.087719\n",
      "Total number of feature updates: 189000\n",
      "Seconds required for this iteration: 0.009\n",
      "\n",
      "***** Epoch #701 *****\n",
      "Loss: 1.514085\n",
      "Improvement ratio: 0.000809\n",
      "Feature L2-norm: 33.007876\n",
      "Learning rate (eta): 0.087704\n",
      "Total number of feature updates: 189270\n",
      "Seconds required for this iteration: 0.008\n",
      "\n",
      "***** Epoch #702 *****\n",
      "Loss: 1.513966\n",
      "Improvement ratio: 0.000798\n",
      "Feature L2-norm: 33.010678\n",
      "Learning rate (eta): 0.087689\n",
      "Total number of feature updates: 189540\n",
      "Seconds required for this iteration: 0.011\n",
      "\n",
      "***** Epoch #703 *****\n",
      "Loss: 1.513844\n",
      "Improvement ratio: 0.000787\n",
      "Feature L2-norm: 33.013474\n",
      "Learning rate (eta): 0.087673\n",
      "Total number of feature updates: 189810\n",
      "Seconds required for this iteration: 0.008\n",
      "\n",
      "***** Epoch #704 *****\n",
      "Loss: 1.513706\n",
      "Improvement ratio: 0.000799\n",
      "Feature L2-norm: 33.016263\n",
      "Learning rate (eta): 0.087658\n",
      "Total number of feature updates: 190080\n",
      "Seconds required for this iteration: 0.009\n",
      "\n",
      "***** Epoch #705 *****\n",
      "Loss: 1.513585\n",
      "Improvement ratio: 0.000804\n",
      "Feature L2-norm: 33.019043\n",
      "Learning rate (eta): 0.087642\n",
      "Total number of feature updates: 190350\n",
      "Seconds required for this iteration: 0.010\n",
      "\n",
      "***** Epoch #706 *****\n",
      "Loss: 1.513488\n",
      "Improvement ratio: 0.000788\n",
      "Feature L2-norm: 33.021815\n",
      "Learning rate (eta): 0.087627\n",
      "Total number of feature updates: 190620\n",
      "Seconds required for this iteration: 0.008\n",
      "\n",
      "***** Epoch #707 *****\n",
      "Loss: 1.513367\n",
      "Improvement ratio: 0.000775\n",
      "Feature L2-norm: 33.024582\n",
      "Learning rate (eta): 0.087612\n",
      "Total number of feature updates: 190890\n",
      "Seconds required for this iteration: 0.010\n",
      "\n",
      "***** Epoch #708 *****\n",
      "Loss: 1.513248\n",
      "Improvement ratio: 0.000798\n",
      "Feature L2-norm: 33.027341\n",
      "Learning rate (eta): 0.087596\n",
      "Total number of feature updates: 191160\n",
      "Seconds required for this iteration: 0.008\n",
      "\n",
      "***** Epoch #709 *****\n",
      "Loss: 1.513115\n",
      "Improvement ratio: 0.000783\n",
      "Feature L2-norm: 33.030095\n",
      "Learning rate (eta): 0.087581\n",
      "Total number of feature updates: 191430\n",
      "Seconds required for this iteration: 0.010\n",
      "\n",
      "***** Epoch #710 *****\n",
      "Loss: 1.513004\n",
      "Improvement ratio: 0.000776\n",
      "Feature L2-norm: 33.032839\n",
      "Learning rate (eta): 0.087566\n",
      "Total number of feature updates: 191700\n",
      "Seconds required for this iteration: 0.009\n",
      "\n",
      "***** Epoch #711 *****\n",
      "Loss: 1.512890\n",
      "Improvement ratio: 0.000790\n",
      "Feature L2-norm: 33.035579\n",
      "Learning rate (eta): 0.087550\n",
      "Total number of feature updates: 191970\n",
      "Seconds required for this iteration: 0.009\n",
      "\n",
      "***** Epoch #712 *****\n",
      "Loss: 1.512782\n",
      "Improvement ratio: 0.000783\n",
      "Feature L2-norm: 33.038312\n",
      "Learning rate (eta): 0.087535\n",
      "Total number of feature updates: 192240\n",
      "Seconds required for this iteration: 0.008\n",
      "\n",
      "***** Epoch #713 *****\n",
      "Loss: 1.512668\n",
      "Improvement ratio: 0.000778\n",
      "Feature L2-norm: 33.041038\n",
      "Learning rate (eta): 0.087520\n",
      "Total number of feature updates: 192510\n",
      "Seconds required for this iteration: 0.008\n",
      "\n",
      "***** Epoch #714 *****\n",
      "Loss: 1.512546\n",
      "Improvement ratio: 0.000767\n",
      "Feature L2-norm: 33.043758\n",
      "Learning rate (eta): 0.087504\n",
      "Total number of feature updates: 192780\n",
      "Seconds required for this iteration: 0.008\n",
      "\n",
      "***** Epoch #715 *****\n",
      "Loss: 1.512440\n",
      "Improvement ratio: 0.000757\n",
      "Feature L2-norm: 33.046469\n",
      "Learning rate (eta): 0.087489\n",
      "Total number of feature updates: 193050\n",
      "Seconds required for this iteration: 0.009\n",
      "\n",
      "***** Epoch #716 *****\n",
      "Loss: 1.512329\n",
      "Improvement ratio: 0.000767\n",
      "Feature L2-norm: 33.049176\n",
      "Learning rate (eta): 0.087474\n",
      "Total number of feature updates: 193320\n",
      "Seconds required for this iteration: 0.008\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** Epoch #717 *****\n",
      "Loss: 1.512203\n",
      "Improvement ratio: 0.000770\n",
      "Feature L2-norm: 33.051874\n",
      "Learning rate (eta): 0.087459\n",
      "Total number of feature updates: 193590\n",
      "Seconds required for this iteration: 0.008\n",
      "\n",
      "***** Epoch #718 *****\n",
      "Loss: 1.512106\n",
      "Improvement ratio: 0.000755\n",
      "Feature L2-norm: 33.054567\n",
      "Learning rate (eta): 0.087443\n",
      "Total number of feature updates: 193860\n",
      "Seconds required for this iteration: 0.009\n",
      "\n",
      "***** Epoch #719 *****\n",
      "Loss: 1.512008\n",
      "Improvement ratio: 0.000732\n",
      "Feature L2-norm: 33.057252\n",
      "Learning rate (eta): 0.087428\n",
      "Total number of feature updates: 194130\n",
      "Seconds required for this iteration: 0.008\n",
      "\n",
      "***** Epoch #720 *****\n",
      "Loss: 1.511860\n",
      "Improvement ratio: 0.000756\n",
      "Feature L2-norm: 33.059932\n",
      "Learning rate (eta): 0.087413\n",
      "Total number of feature updates: 194400\n",
      "Seconds required for this iteration: 0.008\n",
      "\n",
      "***** Epoch #721 *****\n",
      "Loss: 1.511766\n",
      "Improvement ratio: 0.000744\n",
      "Feature L2-norm: 33.062606\n",
      "Learning rate (eta): 0.087397\n",
      "Total number of feature updates: 194670\n",
      "Seconds required for this iteration: 0.008\n",
      "\n",
      "***** Epoch #722 *****\n",
      "Loss: 1.511686\n",
      "Improvement ratio: 0.000725\n",
      "Feature L2-norm: 33.065270\n",
      "Learning rate (eta): 0.087382\n",
      "Total number of feature updates: 194940\n",
      "Seconds required for this iteration: 0.009\n",
      "\n",
      "***** Epoch #723 *****\n",
      "Loss: 1.511566\n",
      "Improvement ratio: 0.000729\n",
      "Feature L2-norm: 33.067928\n",
      "Learning rate (eta): 0.087367\n",
      "Total number of feature updates: 195210\n",
      "Seconds required for this iteration: 0.010\n",
      "\n",
      "***** Epoch #724 *****\n",
      "Loss: 1.511469\n",
      "Improvement ratio: 0.000712\n",
      "Feature L2-norm: 33.070580\n",
      "Learning rate (eta): 0.087352\n",
      "Total number of feature updates: 195480\n",
      "Seconds required for this iteration: 0.009\n",
      "\n",
      "***** Epoch #725 *****\n",
      "Loss: 1.511358\n",
      "Improvement ratio: 0.000716\n",
      "Feature L2-norm: 33.073226\n",
      "Learning rate (eta): 0.087336\n",
      "Total number of feature updates: 195750\n",
      "Seconds required for this iteration: 0.008\n",
      "\n",
      "***** Epoch #726 *****\n",
      "Loss: 1.511253\n",
      "Improvement ratio: 0.000712\n",
      "Feature L2-norm: 33.075864\n",
      "Learning rate (eta): 0.087321\n",
      "Total number of feature updates: 196020\n",
      "Seconds required for this iteration: 0.009\n",
      "\n",
      "***** Epoch #727 *****\n",
      "Loss: 1.511141\n",
      "Improvement ratio: 0.000703\n",
      "Feature L2-norm: 33.078498\n",
      "Learning rate (eta): 0.087306\n",
      "Total number of feature updates: 196290\n",
      "Seconds required for this iteration: 0.008\n",
      "\n",
      "***** Epoch #728 *****\n",
      "Loss: 1.511022\n",
      "Improvement ratio: 0.000717\n",
      "Feature L2-norm: 33.081126\n",
      "Learning rate (eta): 0.087291\n",
      "Total number of feature updates: 196560\n",
      "Seconds required for this iteration: 0.008\n",
      "\n",
      "***** Epoch #729 *****\n",
      "Loss: 1.510912\n",
      "Improvement ratio: 0.000726\n",
      "Feature L2-norm: 33.083744\n",
      "Learning rate (eta): 0.087275\n",
      "Total number of feature updates: 196830\n",
      "Seconds required for this iteration: 0.009\n",
      "\n",
      "***** Epoch #730 *****\n",
      "Loss: 1.510808\n",
      "Improvement ratio: 0.000697\n",
      "Feature L2-norm: 33.086359\n",
      "Learning rate (eta): 0.087260\n",
      "Total number of feature updates: 197100\n",
      "Seconds required for this iteration: 0.008\n",
      "\n",
      "***** Epoch #731 *****\n",
      "Loss: 1.510705\n",
      "Improvement ratio: 0.000702\n",
      "Feature L2-norm: 33.088967\n",
      "Learning rate (eta): 0.087245\n",
      "Total number of feature updates: 197370\n",
      "Seconds required for this iteration: 0.008\n",
      "\n",
      "***** Epoch #732 *****\n",
      "Loss: 1.510590\n",
      "Improvement ratio: 0.000725\n",
      "Feature L2-norm: 33.091568\n",
      "Learning rate (eta): 0.087230\n",
      "Total number of feature updates: 197640\n",
      "Seconds required for this iteration: 0.008\n",
      "\n",
      "***** Epoch #733 *****\n",
      "Loss: 1.510488\n",
      "Improvement ratio: 0.000713\n",
      "Feature L2-norm: 33.094165\n",
      "Learning rate (eta): 0.087214\n",
      "Total number of feature updates: 197910\n",
      "Seconds required for this iteration: 0.008\n",
      "\n",
      "***** Epoch #734 *****\n",
      "Loss: 1.510367\n",
      "Improvement ratio: 0.000730\n",
      "Feature L2-norm: 33.096754\n",
      "Learning rate (eta): 0.087199\n",
      "Total number of feature updates: 198180\n",
      "Seconds required for this iteration: 0.008\n",
      "\n",
      "***** Epoch #735 *****\n",
      "Loss: 1.510256\n",
      "Improvement ratio: 0.000730\n",
      "Feature L2-norm: 33.099335\n",
      "Learning rate (eta): 0.087184\n",
      "Total number of feature updates: 198450\n",
      "Seconds required for this iteration: 0.011\n",
      "\n",
      "***** Epoch #736 *****\n",
      "Loss: 1.510173\n",
      "Improvement ratio: 0.000715\n",
      "Feature L2-norm: 33.101912\n",
      "Learning rate (eta): 0.087169\n",
      "Total number of feature updates: 198720\n",
      "Seconds required for this iteration: 0.008\n",
      "\n",
      "***** Epoch #737 *****\n",
      "Loss: 1.510065\n",
      "Improvement ratio: 0.000713\n",
      "Feature L2-norm: 33.104480\n",
      "Learning rate (eta): 0.087154\n",
      "Total number of feature updates: 198990\n",
      "Seconds required for this iteration: 0.008\n",
      "\n",
      "***** Epoch #738 *****\n",
      "Loss: 1.509987\n",
      "Improvement ratio: 0.000685\n",
      "Feature L2-norm: 33.107046\n",
      "Learning rate (eta): 0.087138\n",
      "Total number of feature updates: 199260\n",
      "Seconds required for this iteration: 0.008\n",
      "\n",
      "***** Epoch #739 *****\n",
      "Loss: 1.509858\n",
      "Improvement ratio: 0.000698\n",
      "Feature L2-norm: 33.109605\n",
      "Learning rate (eta): 0.087123\n",
      "Total number of feature updates: 199530\n",
      "Seconds required for this iteration: 0.008\n",
      "\n",
      "***** Epoch #740 *****\n",
      "Loss: 1.509764\n",
      "Improvement ratio: 0.000691\n",
      "Feature L2-norm: 33.112155\n",
      "Learning rate (eta): 0.087108\n",
      "Total number of feature updates: 199800\n",
      "Seconds required for this iteration: 0.008\n",
      "\n",
      "***** Epoch #741 *****\n",
      "Loss: 1.509663\n",
      "Improvement ratio: 0.000690\n",
      "Feature L2-norm: 33.114699\n",
      "Learning rate (eta): 0.087093\n",
      "Total number of feature updates: 200070\n",
      "Seconds required for this iteration: 0.008\n",
      "\n",
      "***** Epoch #742 *****\n",
      "Loss: 1.509575\n",
      "Improvement ratio: 0.000672\n",
      "Feature L2-norm: 33.117237\n",
      "Learning rate (eta): 0.087078\n",
      "Total number of feature updates: 200340\n",
      "Seconds required for this iteration: 0.008\n",
      "\n",
      "***** Epoch #743 *****\n",
      "Loss: 1.509474\n",
      "Improvement ratio: 0.000672\n",
      "Feature L2-norm: 33.119769\n",
      "Learning rate (eta): 0.087063\n",
      "Total number of feature updates: 200610\n",
      "Seconds required for this iteration: 0.008\n",
      "\n",
      "***** Epoch #744 *****\n",
      "Loss: 1.509351\n",
      "Improvement ratio: 0.000673\n",
      "Feature L2-norm: 33.122294\n",
      "Learning rate (eta): 0.087047\n",
      "Total number of feature updates: 200880\n",
      "Seconds required for this iteration: 0.008\n",
      "\n",
      "***** Epoch #745 *****\n",
      "Loss: 1.509265\n",
      "Improvement ratio: 0.000657\n",
      "Feature L2-norm: 33.124814\n",
      "Learning rate (eta): 0.087032\n",
      "Total number of feature updates: 201150\n",
      "Seconds required for this iteration: 0.008\n",
      "\n",
      "***** Epoch #746 *****\n",
      "Loss: 1.509163\n",
      "Improvement ratio: 0.000670\n",
      "Feature L2-norm: 33.127329\n",
      "Learning rate (eta): 0.087017\n",
      "Total number of feature updates: 201420\n",
      "Seconds required for this iteration: 0.007\n",
      "\n",
      "***** Epoch #747 *****\n",
      "Loss: 1.509068\n",
      "Improvement ratio: 0.000660\n",
      "Feature L2-norm: 33.129837\n",
      "Learning rate (eta): 0.087002\n",
      "Total number of feature updates: 201690\n",
      "Seconds required for this iteration: 0.008\n",
      "\n",
      "***** Epoch #748 *****\n",
      "Loss: 1.508969\n",
      "Improvement ratio: 0.000674\n",
      "Feature L2-norm: 33.132339\n",
      "Learning rate (eta): 0.086987\n",
      "Total number of feature updates: 201960\n",
      "Seconds required for this iteration: 0.008\n",
      "\n",
      "***** Epoch #749 *****\n",
      "Loss: 1.508868\n",
      "Improvement ratio: 0.000656\n",
      "Feature L2-norm: 33.134834\n",
      "Learning rate (eta): 0.086972\n",
      "Total number of feature updates: 202230\n",
      "Seconds required for this iteration: 0.012\n",
      "\n",
      "***** Epoch #750 *****\n",
      "Loss: 1.508758\n",
      "Improvement ratio: 0.000667\n",
      "Feature L2-norm: 33.137324\n",
      "Learning rate (eta): 0.086957\n",
      "Total number of feature updates: 202500\n",
      "Seconds required for this iteration: 0.010\n",
      "\n",
      "***** Epoch #751 *****\n",
      "Loss: 1.508670\n",
      "Improvement ratio: 0.000658\n",
      "Feature L2-norm: 33.139807\n",
      "Learning rate (eta): 0.086941\n",
      "Total number of feature updates: 202770\n",
      "Seconds required for this iteration: 0.008\n",
      "\n",
      "***** Epoch #752 *****\n",
      "Loss: 1.508562\n",
      "Improvement ratio: 0.000672\n",
      "Feature L2-norm: 33.142285\n",
      "Learning rate (eta): 0.086926\n",
      "Total number of feature updates: 203040\n",
      "Seconds required for this iteration: 0.009\n",
      "\n",
      "***** Epoch #753 *****\n",
      "Loss: 1.508463\n",
      "Improvement ratio: 0.000670\n",
      "Feature L2-norm: 33.144755\n",
      "Learning rate (eta): 0.086911\n",
      "Total number of feature updates: 203310\n",
      "Seconds required for this iteration: 0.008\n",
      "\n",
      "***** Epoch #754 *****\n",
      "Loss: 1.508362\n",
      "Improvement ratio: 0.000656\n",
      "Feature L2-norm: 33.147223\n",
      "Learning rate (eta): 0.086896\n",
      "Total number of feature updates: 203580\n",
      "Seconds required for this iteration: 0.008\n",
      "\n",
      "***** Epoch #755 *****\n",
      "Loss: 1.508280\n",
      "Improvement ratio: 0.000653\n",
      "Feature L2-norm: 33.149683\n",
      "Learning rate (eta): 0.086881\n",
      "Total number of feature updates: 203850\n",
      "Seconds required for this iteration: 0.009\n",
      "\n",
      "***** Epoch #756 *****\n",
      "Loss: 1.508169\n",
      "Improvement ratio: 0.000658\n",
      "Feature L2-norm: 33.152136\n",
      "Learning rate (eta): 0.086866\n",
      "Total number of feature updates: 204120\n",
      "Seconds required for this iteration: 0.008\n",
      "\n",
      "***** Epoch #757 *****\n",
      "Loss: 1.508093\n",
      "Improvement ratio: 0.000646\n",
      "Feature L2-norm: 33.154585\n",
      "Learning rate (eta): 0.086851\n",
      "Total number of feature updates: 204390\n",
      "Seconds required for this iteration: 0.007\n",
      "\n",
      "***** Epoch #758 *****\n",
      "Loss: 1.507994\n",
      "Improvement ratio: 0.000647\n",
      "Feature L2-norm: 33.157025\n",
      "Learning rate (eta): 0.086836\n",
      "Total number of feature updates: 204660\n",
      "Seconds required for this iteration: 0.007\n",
      "\n",
      "***** Epoch #759 *****\n",
      "Loss: 1.507884\n",
      "Improvement ratio: 0.000653\n",
      "Feature L2-norm: 33.159460\n",
      "Learning rate (eta): 0.086821\n",
      "Total number of feature updates: 204930\n",
      "Seconds required for this iteration: 0.007\n",
      "\n",
      "***** Epoch #760 *****\n",
      "Loss: 1.507769\n",
      "Improvement ratio: 0.000656\n",
      "Feature L2-norm: 33.161889\n",
      "Learning rate (eta): 0.086806\n",
      "Total number of feature updates: 205200\n",
      "Seconds required for this iteration: 0.008\n",
      "\n",
      "***** Epoch #761 *****\n",
      "Loss: 1.507705\n",
      "Improvement ratio: 0.000640\n",
      "Feature L2-norm: 33.164316\n",
      "Learning rate (eta): 0.086791\n",
      "Total number of feature updates: 205470\n",
      "Seconds required for this iteration: 0.008\n",
      "\n",
      "***** Epoch #762 *****\n",
      "Loss: 1.507625\n",
      "Improvement ratio: 0.000622\n",
      "Feature L2-norm: 33.166736\n",
      "Learning rate (eta): 0.086775\n",
      "Total number of feature updates: 205740\n",
      "Seconds required for this iteration: 0.008\n",
      "\n",
      "***** Epoch #763 *****\n",
      "Loss: 1.507526\n",
      "Improvement ratio: 0.000621\n",
      "Feature L2-norm: 33.169149\n",
      "Learning rate (eta): 0.086760\n",
      "Total number of feature updates: 206010\n",
      "Seconds required for this iteration: 0.008\n",
      "\n",
      "***** Epoch #764 *****\n",
      "Loss: 1.507448\n",
      "Improvement ratio: 0.000606\n",
      "Feature L2-norm: 33.171557\n",
      "Learning rate (eta): 0.086745\n",
      "Total number of feature updates: 206280\n",
      "Seconds required for this iteration: 0.008\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** Epoch #765 *****\n",
      "Loss: 1.507330\n",
      "Improvement ratio: 0.000630\n",
      "Feature L2-norm: 33.173959\n",
      "Learning rate (eta): 0.086730\n",
      "Total number of feature updates: 206550\n",
      "Seconds required for this iteration: 0.008\n",
      "\n",
      "***** Epoch #766 *****\n",
      "Loss: 1.507243\n",
      "Improvement ratio: 0.000614\n",
      "Feature L2-norm: 33.176356\n",
      "Learning rate (eta): 0.086715\n",
      "Total number of feature updates: 206820\n",
      "Seconds required for this iteration: 0.008\n",
      "\n",
      "***** Epoch #767 *****\n",
      "Loss: 1.507163\n",
      "Improvement ratio: 0.000618\n",
      "Feature L2-norm: 33.178745\n",
      "Learning rate (eta): 0.086700\n",
      "Total number of feature updates: 207090\n",
      "Seconds required for this iteration: 0.008\n",
      "\n",
      "***** Epoch #768 *****\n",
      "Loss: 1.507088\n",
      "Improvement ratio: 0.000601\n",
      "Feature L2-norm: 33.181129\n",
      "Learning rate (eta): 0.086685\n",
      "Total number of feature updates: 207360\n",
      "Seconds required for this iteration: 0.007\n",
      "\n",
      "***** Epoch #769 *****\n",
      "Loss: 1.506968\n",
      "Improvement ratio: 0.000607\n",
      "Feature L2-norm: 33.183507\n",
      "Learning rate (eta): 0.086670\n",
      "Total number of feature updates: 207630\n",
      "Seconds required for this iteration: 0.008\n",
      "\n",
      "***** Epoch #770 *****\n",
      "Loss: 1.506878\n",
      "Improvement ratio: 0.000591\n",
      "Feature L2-norm: 33.185881\n",
      "Learning rate (eta): 0.086655\n",
      "Total number of feature updates: 207900\n",
      "Seconds required for this iteration: 0.007\n",
      "\n",
      "***** Epoch #771 *****\n",
      "Loss: 1.506786\n",
      "Improvement ratio: 0.000610\n",
      "Feature L2-norm: 33.188248\n",
      "Learning rate (eta): 0.086640\n",
      "Total number of feature updates: 208170\n",
      "Seconds required for this iteration: 0.008\n",
      "\n",
      "***** Epoch #772 *****\n",
      "Loss: 1.506703\n",
      "Improvement ratio: 0.000612\n",
      "Feature L2-norm: 33.190610\n",
      "Learning rate (eta): 0.086625\n",
      "Total number of feature updates: 208440\n",
      "Seconds required for this iteration: 0.007\n",
      "\n",
      "***** Epoch #773 *****\n",
      "Loss: 1.506614\n",
      "Improvement ratio: 0.000605\n",
      "Feature L2-norm: 33.192967\n",
      "Learning rate (eta): 0.086610\n",
      "Total number of feature updates: 208710\n",
      "Seconds required for this iteration: 0.008\n",
      "\n",
      "***** Epoch #774 *****\n",
      "Loss: 1.506526\n",
      "Improvement ratio: 0.000611\n",
      "Feature L2-norm: 33.195318\n",
      "Learning rate (eta): 0.086595\n",
      "Total number of feature updates: 208980\n",
      "Seconds required for this iteration: 0.009\n",
      "\n",
      "***** Epoch #775 *****\n",
      "Loss: 1.506436\n",
      "Improvement ratio: 0.000593\n",
      "Feature L2-norm: 33.197663\n",
      "Learning rate (eta): 0.086580\n",
      "Total number of feature updates: 209250\n",
      "Seconds required for this iteration: 0.009\n",
      "\n",
      "***** Epoch #776 *****\n",
      "Loss: 1.506370\n",
      "Improvement ratio: 0.000580\n",
      "Feature L2-norm: 33.200001\n",
      "Learning rate (eta): 0.086565\n",
      "Total number of feature updates: 209520\n",
      "Seconds required for this iteration: 0.008\n",
      "\n",
      "***** Epoch #777 *****\n",
      "Loss: 1.506261\n",
      "Improvement ratio: 0.000599\n",
      "Feature L2-norm: 33.202336\n",
      "Learning rate (eta): 0.086550\n",
      "Total number of feature updates: 209790\n",
      "Seconds required for this iteration: 0.008\n",
      "\n",
      "***** Epoch #778 *****\n",
      "Loss: 1.506190\n",
      "Improvement ratio: 0.000596\n",
      "Feature L2-norm: 33.204664\n",
      "Learning rate (eta): 0.086535\n",
      "Total number of feature updates: 210060\n",
      "Seconds required for this iteration: 0.009\n",
      "\n",
      "***** Epoch #779 *****\n",
      "Loss: 1.506089\n",
      "Improvement ratio: 0.000584\n",
      "Feature L2-norm: 33.206985\n",
      "Learning rate (eta): 0.086520\n",
      "Total number of feature updates: 210330\n",
      "Seconds required for this iteration: 0.008\n",
      "\n",
      "***** Epoch #780 *****\n",
      "Loss: 1.506009\n",
      "Improvement ratio: 0.000577\n",
      "Feature L2-norm: 33.209301\n",
      "Learning rate (eta): 0.086505\n",
      "Total number of feature updates: 210600\n",
      "Seconds required for this iteration: 0.008\n",
      "\n",
      "***** Epoch #781 *****\n",
      "Loss: 1.505892\n",
      "Improvement ratio: 0.000594\n",
      "Feature L2-norm: 33.211609\n",
      "Learning rate (eta): 0.086490\n",
      "Total number of feature updates: 210870\n",
      "Seconds required for this iteration: 0.008\n",
      "\n",
      "***** Epoch #782 *****\n",
      "Loss: 1.505821\n",
      "Improvement ratio: 0.000586\n",
      "Feature L2-norm: 33.213915\n",
      "Learning rate (eta): 0.086475\n",
      "Total number of feature updates: 211140\n",
      "Seconds required for this iteration: 0.007\n",
      "\n",
      "***** Epoch #783 *****\n",
      "Loss: 1.505752\n",
      "Improvement ratio: 0.000573\n",
      "Feature L2-norm: 33.216217\n",
      "Learning rate (eta): 0.086460\n",
      "Total number of feature updates: 211410\n",
      "Seconds required for this iteration: 0.008\n",
      "\n",
      "***** Epoch #784 *****\n",
      "Loss: 1.505674\n",
      "Improvement ratio: 0.000566\n",
      "Feature L2-norm: 33.218512\n",
      "Learning rate (eta): 0.086445\n",
      "Total number of feature updates: 211680\n",
      "Seconds required for this iteration: 0.008\n",
      "\n",
      "***** Epoch #785 *****\n",
      "Loss: 1.505560\n",
      "Improvement ratio: 0.000582\n",
      "Feature L2-norm: 33.220800\n",
      "Learning rate (eta): 0.086430\n",
      "Total number of feature updates: 211950\n",
      "Seconds required for this iteration: 0.008\n",
      "\n",
      "***** Epoch #786 *****\n",
      "Loss: 1.505491\n",
      "Improvement ratio: 0.000584\n",
      "Feature L2-norm: 33.223085\n",
      "Learning rate (eta): 0.086416\n",
      "Total number of feature updates: 212220\n",
      "Seconds required for this iteration: 0.008\n",
      "\n",
      "***** Epoch #787 *****\n",
      "Loss: 1.505398\n",
      "Improvement ratio: 0.000573\n",
      "Feature L2-norm: 33.225365\n",
      "Learning rate (eta): 0.086401\n",
      "Total number of feature updates: 212490\n",
      "Seconds required for this iteration: 0.007\n",
      "\n",
      "***** Epoch #788 *****\n",
      "Loss: 1.505310\n",
      "Improvement ratio: 0.000584\n",
      "Feature L2-norm: 33.227638\n",
      "Learning rate (eta): 0.086386\n",
      "Total number of feature updates: 212760\n",
      "Seconds required for this iteration: 0.007\n",
      "\n",
      "***** Epoch #789 *****\n",
      "Loss: 1.505233\n",
      "Improvement ratio: 0.000569\n",
      "Feature L2-norm: 33.229907\n",
      "Learning rate (eta): 0.086371\n",
      "Total number of feature updates: 213030\n",
      "Seconds required for this iteration: 0.008\n",
      "\n",
      "***** Epoch #790 *****\n",
      "Loss: 1.505142\n",
      "Improvement ratio: 0.000576\n",
      "Feature L2-norm: 33.232170\n",
      "Learning rate (eta): 0.086356\n",
      "Total number of feature updates: 213300\n",
      "Seconds required for this iteration: 0.007\n",
      "\n",
      "***** Epoch #791 *****\n",
      "Loss: 1.505059\n",
      "Improvement ratio: 0.000554\n",
      "Feature L2-norm: 33.234429\n",
      "Learning rate (eta): 0.086341\n",
      "Total number of feature updates: 213570\n",
      "Seconds required for this iteration: 0.007\n",
      "\n",
      "***** Epoch #792 *****\n",
      "Loss: 1.504978\n",
      "Improvement ratio: 0.000560\n",
      "Feature L2-norm: 33.236681\n",
      "Learning rate (eta): 0.086326\n",
      "Total number of feature updates: 213840\n",
      "Seconds required for this iteration: 0.008\n",
      "\n",
      "***** Epoch #793 *****\n",
      "Loss: 1.504911\n",
      "Improvement ratio: 0.000559\n",
      "Feature L2-norm: 33.238926\n",
      "Learning rate (eta): 0.086311\n",
      "Total number of feature updates: 214110\n",
      "Seconds required for this iteration: 0.008\n",
      "\n",
      "***** Epoch #794 *****\n",
      "Loss: 1.504837\n",
      "Improvement ratio: 0.000556\n",
      "Feature L2-norm: 33.241168\n",
      "Learning rate (eta): 0.086296\n",
      "Total number of feature updates: 214380\n",
      "Seconds required for this iteration: 0.008\n",
      "\n",
      "***** Epoch #795 *****\n",
      "Loss: 1.504750\n",
      "Improvement ratio: 0.000538\n",
      "Feature L2-norm: 33.243403\n",
      "Learning rate (eta): 0.086281\n",
      "Total number of feature updates: 214650\n",
      "Seconds required for this iteration: 0.007\n",
      "\n",
      "***** Epoch #796 *****\n",
      "Loss: 1.504643\n",
      "Improvement ratio: 0.000563\n",
      "Feature L2-norm: 33.245635\n",
      "Learning rate (eta): 0.086266\n",
      "Total number of feature updates: 214920\n",
      "Seconds required for this iteration: 0.007\n",
      "\n",
      "***** Epoch #797 *****\n",
      "Loss: 1.504587\n",
      "Improvement ratio: 0.000539\n",
      "Feature L2-norm: 33.247862\n",
      "Learning rate (eta): 0.086252\n",
      "Total number of feature updates: 215190\n",
      "Seconds required for this iteration: 0.008\n",
      "\n",
      "***** Epoch #798 *****\n",
      "Loss: 1.504491\n",
      "Improvement ratio: 0.000544\n",
      "Feature L2-norm: 33.250082\n",
      "Learning rate (eta): 0.086237\n",
      "Total number of feature updates: 215460\n",
      "Seconds required for this iteration: 0.008\n",
      "\n",
      "***** Epoch #799 *****\n",
      "Loss: 1.504410\n",
      "Improvement ratio: 0.000547\n",
      "Feature L2-norm: 33.252298\n",
      "Learning rate (eta): 0.086222\n",
      "Total number of feature updates: 215730\n",
      "Seconds required for this iteration: 0.007\n",
      "\n",
      "***** Epoch #800 *****\n",
      "Loss: 1.504353\n",
      "Improvement ratio: 0.000524\n",
      "Feature L2-norm: 33.254509\n",
      "Learning rate (eta): 0.086207\n",
      "Total number of feature updates: 216000\n",
      "Seconds required for this iteration: 0.008\n",
      "\n",
      "***** Epoch #801 *****\n",
      "Loss: 1.504236\n",
      "Improvement ratio: 0.000547\n",
      "Feature L2-norm: 33.256716\n",
      "Learning rate (eta): 0.086192\n",
      "Total number of feature updates: 216270\n",
      "Seconds required for this iteration: 0.009\n",
      "\n",
      "***** Epoch #802 *****\n",
      "Loss: 1.504168\n",
      "Improvement ratio: 0.000538\n",
      "Feature L2-norm: 33.258918\n",
      "Learning rate (eta): 0.086177\n",
      "Total number of feature updates: 216540\n",
      "Seconds required for this iteration: 0.009\n",
      "\n",
      "***** Epoch #803 *****\n",
      "Loss: 1.504075\n",
      "Improvement ratio: 0.000556\n",
      "Feature L2-norm: 33.261113\n",
      "Learning rate (eta): 0.086162\n",
      "Total number of feature updates: 216810\n",
      "Seconds required for this iteration: 0.010\n",
      "\n",
      "***** Epoch #804 *****\n",
      "Loss: 1.504005\n",
      "Improvement ratio: 0.000553\n",
      "Feature L2-norm: 33.263304\n",
      "Learning rate (eta): 0.086148\n",
      "Total number of feature updates: 217080\n",
      "Seconds required for this iteration: 0.007\n",
      "\n",
      "***** Epoch #805 *****\n",
      "Loss: 1.503940\n",
      "Improvement ratio: 0.000539\n",
      "Feature L2-norm: 33.265488\n",
      "Learning rate (eta): 0.086133\n",
      "Total number of feature updates: 217350\n",
      "Seconds required for this iteration: 0.008\n",
      "\n",
      "***** Epoch #806 *****\n",
      "Loss: 1.503854\n",
      "Improvement ratio: 0.000525\n",
      "Feature L2-norm: 33.267668\n",
      "Learning rate (eta): 0.086118\n",
      "Total number of feature updates: 217620\n",
      "Seconds required for this iteration: 0.008\n",
      "\n",
      "***** Epoch #807 *****\n",
      "Loss: 1.503790\n",
      "Improvement ratio: 0.000530\n",
      "Feature L2-norm: 33.269843\n",
      "Learning rate (eta): 0.086103\n",
      "Total number of feature updates: 217890\n",
      "Seconds required for this iteration: 0.008\n",
      "\n",
      "***** Epoch #808 *****\n",
      "Loss: 1.503709\n",
      "Improvement ratio: 0.000520\n",
      "Feature L2-norm: 33.272011\n",
      "Learning rate (eta): 0.086088\n",
      "Total number of feature updates: 218160\n",
      "Seconds required for this iteration: 0.008\n",
      "\n",
      "***** Epoch #809 *****\n",
      "Loss: 1.503645\n",
      "Improvement ratio: 0.000509\n",
      "Feature L2-norm: 33.274176\n",
      "Learning rate (eta): 0.086073\n",
      "Total number of feature updates: 218430\n",
      "Seconds required for this iteration: 0.008\n",
      "\n",
      "***** Epoch #810 *****\n",
      "Loss: 1.503544\n",
      "Improvement ratio: 0.000538\n",
      "Feature L2-norm: 33.276334\n",
      "Learning rate (eta): 0.086059\n",
      "Total number of feature updates: 218700\n",
      "Seconds required for this iteration: 0.008\n",
      "\n",
      "***** Epoch #811 *****\n",
      "Loss: 1.503461\n",
      "Improvement ratio: 0.000516\n",
      "Feature L2-norm: 33.278486\n",
      "Learning rate (eta): 0.086044\n",
      "Total number of feature updates: 218970\n",
      "Seconds required for this iteration: 0.008\n",
      "\n",
      "***** Epoch #812 *****\n",
      "Loss: 1.503389\n",
      "Improvement ratio: 0.000518\n",
      "Feature L2-norm: 33.280634\n",
      "Learning rate (eta): 0.086029\n",
      "Total number of feature updates: 219240\n",
      "Seconds required for this iteration: 0.008\n",
      "\n",
      "***** Epoch #813 *****\n",
      "Loss: 1.503325\n",
      "Improvement ratio: 0.000499\n",
      "Feature L2-norm: 33.282779\n",
      "Learning rate (eta): 0.086014\n",
      "Total number of feature updates: 219510\n",
      "Seconds required for this iteration: 0.009\n",
      "\n",
      "***** Epoch #814 *****\n",
      "Loss: 1.503242\n",
      "Improvement ratio: 0.000508\n",
      "Feature L2-norm: 33.284918\n",
      "Learning rate (eta): 0.085999\n",
      "Total number of feature updates: 219780\n",
      "Seconds required for this iteration: 0.008\n",
      "\n",
      "***** Epoch #815 *****\n",
      "Loss: 1.503166\n",
      "Improvement ratio: 0.000515\n",
      "Feature L2-norm: 33.287055\n",
      "Learning rate (eta): 0.085985\n",
      "Total number of feature updates: 220050\n",
      "Seconds required for this iteration: 0.008\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** Epoch #816 *****\n",
      "Loss: 1.503086\n",
      "Improvement ratio: 0.000511\n",
      "Feature L2-norm: 33.289187\n",
      "Learning rate (eta): 0.085970\n",
      "Total number of feature updates: 220320\n",
      "Seconds required for this iteration: 0.008\n",
      "\n",
      "***** Epoch #817 *****\n",
      "Loss: 1.503020\n",
      "Improvement ratio: 0.000512\n",
      "Feature L2-norm: 33.291311\n",
      "Learning rate (eta): 0.085955\n",
      "Total number of feature updates: 220590\n",
      "Seconds required for this iteration: 0.008\n",
      "\n",
      "***** Epoch #818 *****\n",
      "Loss: 1.502922\n",
      "Improvement ratio: 0.000523\n",
      "Feature L2-norm: 33.293430\n",
      "Learning rate (eta): 0.085940\n",
      "Total number of feature updates: 220860\n",
      "Seconds required for this iteration: 0.008\n",
      "\n",
      "***** Epoch #819 *****\n",
      "Loss: 1.502844\n",
      "Improvement ratio: 0.000533\n",
      "Feature L2-norm: 33.295545\n",
      "Learning rate (eta): 0.085925\n",
      "Total number of feature updates: 221130\n",
      "Seconds required for this iteration: 0.008\n",
      "\n",
      "***** Epoch #820 *****\n",
      "Loss: 1.502782\n",
      "Improvement ratio: 0.000507\n",
      "Feature L2-norm: 33.297655\n",
      "Learning rate (eta): 0.085911\n",
      "Total number of feature updates: 221400\n",
      "Seconds required for this iteration: 0.008\n",
      "\n",
      "***** Epoch #821 *****\n",
      "Loss: 1.502718\n",
      "Improvement ratio: 0.000494\n",
      "Feature L2-norm: 33.299760\n",
      "Learning rate (eta): 0.085896\n",
      "Total number of feature updates: 221670\n",
      "Seconds required for this iteration: 0.007\n",
      "\n",
      "***** Epoch #822 *****\n",
      "Loss: 1.502635\n",
      "Improvement ratio: 0.000502\n",
      "Feature L2-norm: 33.301860\n",
      "Learning rate (eta): 0.085881\n",
      "Total number of feature updates: 221940\n",
      "Seconds required for this iteration: 0.009\n",
      "\n",
      "***** Epoch #823 *****\n",
      "Loss: 1.502569\n",
      "Improvement ratio: 0.000503\n",
      "Feature L2-norm: 33.303956\n",
      "Learning rate (eta): 0.085866\n",
      "Total number of feature updates: 222210\n",
      "Seconds required for this iteration: 0.008\n",
      "\n",
      "***** Epoch #824 *****\n",
      "Loss: 1.502485\n",
      "Improvement ratio: 0.000504\n",
      "Feature L2-norm: 33.306047\n",
      "Learning rate (eta): 0.085852\n",
      "Total number of feature updates: 222480\n",
      "Seconds required for this iteration: 0.010\n",
      "\n",
      "***** Epoch #825 *****\n",
      "Loss: 1.502419\n",
      "Improvement ratio: 0.000497\n",
      "Feature L2-norm: 33.308133\n",
      "Learning rate (eta): 0.085837\n",
      "Total number of feature updates: 222750\n",
      "Seconds required for this iteration: 0.009\n",
      "\n",
      "***** Epoch #826 *****\n",
      "Loss: 1.502350\n",
      "Improvement ratio: 0.000490\n",
      "Feature L2-norm: 33.310213\n",
      "Learning rate (eta): 0.085822\n",
      "Total number of feature updates: 223020\n",
      "Seconds required for this iteration: 0.009\n",
      "\n",
      "***** Epoch #827 *****\n",
      "Loss: 1.502284\n",
      "Improvement ratio: 0.000490\n",
      "Feature L2-norm: 33.312288\n",
      "Learning rate (eta): 0.085808\n",
      "Total number of feature updates: 223290\n",
      "Seconds required for this iteration: 0.009\n",
      "\n",
      "***** Epoch #828 *****\n",
      "Loss: 1.502200\n",
      "Improvement ratio: 0.000481\n",
      "Feature L2-norm: 33.314359\n",
      "Learning rate (eta): 0.085793\n",
      "Total number of feature updates: 223560\n",
      "Seconds required for this iteration: 0.008\n",
      "\n",
      "***** Epoch #829 *****\n",
      "Loss: 1.502136\n",
      "Improvement ratio: 0.000471\n",
      "Feature L2-norm: 33.316427\n",
      "Learning rate (eta): 0.085778\n",
      "Total number of feature updates: 223830\n",
      "Seconds required for this iteration: 0.008\n",
      "\n",
      "***** Epoch #830 *****\n",
      "Loss: 1.502052\n",
      "Improvement ratio: 0.000486\n",
      "Feature L2-norm: 33.318491\n",
      "Learning rate (eta): 0.085763\n",
      "Total number of feature updates: 224100\n",
      "Seconds required for this iteration: 0.009\n",
      "\n",
      "***** Epoch #831 *****\n",
      "Loss: 1.501984\n",
      "Improvement ratio: 0.000489\n",
      "Feature L2-norm: 33.320548\n",
      "Learning rate (eta): 0.085749\n",
      "Total number of feature updates: 224370\n",
      "Seconds required for this iteration: 0.008\n",
      "\n",
      "***** Epoch #832 *****\n",
      "Loss: 1.501923\n",
      "Improvement ratio: 0.000474\n",
      "Feature L2-norm: 33.322600\n",
      "Learning rate (eta): 0.085734\n",
      "Total number of feature updates: 224640\n",
      "Seconds required for this iteration: 0.008\n",
      "\n",
      "***** Epoch #833 *****\n",
      "Loss: 1.501855\n",
      "Improvement ratio: 0.000476\n",
      "Feature L2-norm: 33.324648\n",
      "Learning rate (eta): 0.085719\n",
      "Total number of feature updates: 224910\n",
      "Seconds required for this iteration: 0.008\n",
      "\n",
      "***** Epoch #834 *****\n",
      "Loss: 1.501772\n",
      "Improvement ratio: 0.000474\n",
      "Feature L2-norm: 33.326690\n",
      "Learning rate (eta): 0.085705\n",
      "Total number of feature updates: 225180\n",
      "Seconds required for this iteration: 0.008\n",
      "\n",
      "***** Epoch #835 *****\n",
      "Loss: 1.501704\n",
      "Improvement ratio: 0.000476\n",
      "Feature L2-norm: 33.328729\n",
      "Learning rate (eta): 0.085690\n",
      "Total number of feature updates: 225450\n",
      "Seconds required for this iteration: 0.007\n",
      "\n",
      "***** Epoch #836 *****\n",
      "Loss: 1.501636\n",
      "Improvement ratio: 0.000475\n",
      "Feature L2-norm: 33.330764\n",
      "Learning rate (eta): 0.085675\n",
      "Total number of feature updates: 225720\n",
      "Seconds required for this iteration: 0.008\n",
      "\n",
      "***** Epoch #837 *****\n",
      "Loss: 1.501536\n",
      "Improvement ratio: 0.000498\n",
      "Feature L2-norm: 33.332793\n",
      "Learning rate (eta): 0.085660\n",
      "Total number of feature updates: 225990\n",
      "Seconds required for this iteration: 0.008\n",
      "\n",
      "***** Epoch #838 *****\n",
      "Loss: 1.501483\n",
      "Improvement ratio: 0.000478\n",
      "Feature L2-norm: 33.334817\n",
      "Learning rate (eta): 0.085646\n",
      "Total number of feature updates: 226260\n",
      "Seconds required for this iteration: 0.008\n",
      "\n",
      "***** Epoch #839 *****\n",
      "Loss: 1.501412\n",
      "Improvement ratio: 0.000482\n",
      "Feature L2-norm: 33.336838\n",
      "Learning rate (eta): 0.085631\n",
      "Total number of feature updates: 226530\n",
      "Seconds required for this iteration: 0.010\n",
      "\n",
      "***** Epoch #840 *****\n",
      "Loss: 1.501356\n",
      "Improvement ratio: 0.000463\n",
      "Feature L2-norm: 33.338853\n",
      "Learning rate (eta): 0.085616\n",
      "Total number of feature updates: 226800\n",
      "Seconds required for this iteration: 0.009\n",
      "\n",
      "***** Epoch #841 *****\n",
      "Loss: 1.501264\n",
      "Improvement ratio: 0.000479\n",
      "Feature L2-norm: 33.340864\n",
      "Learning rate (eta): 0.085602\n",
      "Total number of feature updates: 227070\n",
      "Seconds required for this iteration: 0.009\n",
      "\n",
      "***** Epoch #842 *****\n",
      "Loss: 1.501209\n",
      "Improvement ratio: 0.000475\n",
      "Feature L2-norm: 33.342868\n",
      "Learning rate (eta): 0.085587\n",
      "Total number of feature updates: 227340\n",
      "Seconds required for this iteration: 0.009\n",
      "\n",
      "***** Epoch #843 *****\n",
      "Loss: 1.501138\n",
      "Improvement ratio: 0.000478\n",
      "Feature L2-norm: 33.344870\n",
      "Learning rate (eta): 0.085573\n",
      "Total number of feature updates: 227610\n",
      "Seconds required for this iteration: 0.009\n",
      "\n",
      "***** Epoch #844 *****\n",
      "Loss: 1.501077\n",
      "Improvement ratio: 0.000463\n",
      "Feature L2-norm: 33.346868\n",
      "Learning rate (eta): 0.085558\n",
      "Total number of feature updates: 227880\n",
      "Seconds required for this iteration: 0.008\n",
      "\n",
      "***** Epoch #845 *****\n",
      "Loss: 1.500989\n",
      "Improvement ratio: 0.000476\n",
      "Feature L2-norm: 33.348862\n",
      "Learning rate (eta): 0.085543\n",
      "Total number of feature updates: 228150\n",
      "Seconds required for this iteration: 0.008\n",
      "\n",
      "***** Epoch #846 *****\n",
      "Loss: 1.500936\n",
      "Improvement ratio: 0.000467\n",
      "Feature L2-norm: 33.350849\n",
      "Learning rate (eta): 0.085529\n",
      "Total number of feature updates: 228420\n",
      "Seconds required for this iteration: 0.008\n",
      "\n",
      "***** Epoch #847 *****\n",
      "Loss: 1.500859\n",
      "Improvement ratio: 0.000451\n",
      "Feature L2-norm: 33.352831\n",
      "Learning rate (eta): 0.085514\n",
      "Total number of feature updates: 228690\n",
      "Seconds required for this iteration: 0.007\n",
      "\n",
      "***** Epoch #848 *****\n",
      "Loss: 1.500812\n",
      "Improvement ratio: 0.000447\n",
      "Feature L2-norm: 33.354808\n",
      "Learning rate (eta): 0.085499\n",
      "Total number of feature updates: 228960\n",
      "Seconds required for this iteration: 0.011\n",
      "\n",
      "***** Epoch #849 *****\n",
      "Loss: 1.500735\n",
      "Improvement ratio: 0.000451\n",
      "Feature L2-norm: 33.356782\n",
      "Learning rate (eta): 0.085485\n",
      "Total number of feature updates: 229230\n",
      "Seconds required for this iteration: 0.010\n",
      "\n",
      "***** Epoch #850 *****\n",
      "Loss: 1.500684\n",
      "Improvement ratio: 0.000448\n",
      "Feature L2-norm: 33.358754\n",
      "Learning rate (eta): 0.085470\n",
      "Total number of feature updates: 229500\n",
      "Seconds required for this iteration: 0.010\n",
      "\n",
      "***** Epoch #851 *****\n",
      "Loss: 1.500592\n",
      "Improvement ratio: 0.000448\n",
      "Feature L2-norm: 33.360720\n",
      "Learning rate (eta): 0.085456\n",
      "Total number of feature updates: 229770\n",
      "Seconds required for this iteration: 0.008\n",
      "\n",
      "***** Epoch #852 *****\n",
      "Loss: 1.500548\n",
      "Improvement ratio: 0.000440\n",
      "Feature L2-norm: 33.362680\n",
      "Learning rate (eta): 0.085441\n",
      "Total number of feature updates: 230040\n",
      "Seconds required for this iteration: 0.009\n",
      "\n",
      "***** Epoch #853 *****\n",
      "Loss: 1.500487\n",
      "Improvement ratio: 0.000434\n",
      "Feature L2-norm: 33.364636\n",
      "Learning rate (eta): 0.085426\n",
      "Total number of feature updates: 230310\n",
      "Seconds required for this iteration: 0.008\n",
      "\n",
      "***** Epoch #854 *****\n",
      "Loss: 1.500419\n",
      "Improvement ratio: 0.000439\n",
      "Feature L2-norm: 33.366589\n",
      "Learning rate (eta): 0.085412\n",
      "Total number of feature updates: 230580\n",
      "Seconds required for this iteration: 0.008\n",
      "\n",
      "***** Epoch #855 *****\n",
      "Loss: 1.500337\n",
      "Improvement ratio: 0.000434\n",
      "Feature L2-norm: 33.368536\n",
      "Learning rate (eta): 0.085397\n",
      "Total number of feature updates: 230850\n",
      "Seconds required for this iteration: 0.008\n",
      "\n",
      "***** Epoch #856 *****\n",
      "Loss: 1.500292\n",
      "Improvement ratio: 0.000429\n",
      "Feature L2-norm: 33.370479\n",
      "Learning rate (eta): 0.085383\n",
      "Total number of feature updates: 231120\n",
      "Seconds required for this iteration: 0.009\n",
      "\n",
      "***** Epoch #857 *****\n",
      "Loss: 1.500211\n",
      "Improvement ratio: 0.000432\n",
      "Feature L2-norm: 33.372416\n",
      "Learning rate (eta): 0.085368\n",
      "Total number of feature updates: 231390\n",
      "Seconds required for this iteration: 0.009\n",
      "\n",
      "***** Epoch #858 *****\n",
      "Loss: 1.500152\n",
      "Improvement ratio: 0.000440\n",
      "Feature L2-norm: 33.374350\n",
      "Learning rate (eta): 0.085353\n",
      "Total number of feature updates: 231660\n",
      "Seconds required for this iteration: 0.008\n",
      "\n",
      "***** Epoch #859 *****\n",
      "Loss: 1.500085\n",
      "Improvement ratio: 0.000433\n",
      "Feature L2-norm: 33.376280\n",
      "Learning rate (eta): 0.085339\n",
      "Total number of feature updates: 231930\n",
      "Seconds required for this iteration: 0.008\n",
      "\n",
      "***** Epoch #860 *****\n",
      "Loss: 1.500017\n",
      "Improvement ratio: 0.000444\n",
      "Feature L2-norm: 33.378204\n",
      "Learning rate (eta): 0.085324\n",
      "Total number of feature updates: 232200\n",
      "Seconds required for this iteration: 0.008\n",
      "\n",
      "***** Epoch #861 *****\n",
      "Loss: 1.499950\n",
      "Improvement ratio: 0.000428\n",
      "Feature L2-norm: 33.380126\n",
      "Learning rate (eta): 0.085310\n",
      "Total number of feature updates: 232470\n",
      "Seconds required for this iteration: 0.008\n",
      "\n",
      "***** Epoch #862 *****\n",
      "Loss: 1.499880\n",
      "Improvement ratio: 0.000446\n",
      "Feature L2-norm: 33.382043\n",
      "Learning rate (eta): 0.085295\n",
      "Total number of feature updates: 232740\n",
      "Seconds required for this iteration: 0.008\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** Epoch #863 *****\n",
      "Loss: 1.499827\n",
      "Improvement ratio: 0.000440\n",
      "Feature L2-norm: 33.383956\n",
      "Learning rate (eta): 0.085281\n",
      "Total number of feature updates: 233010\n",
      "Seconds required for this iteration: 0.008\n",
      "\n",
      "***** Epoch #864 *****\n",
      "Loss: 1.499752\n",
      "Improvement ratio: 0.000444\n",
      "Feature L2-norm: 33.385864\n",
      "Learning rate (eta): 0.085266\n",
      "Total number of feature updates: 233280\n",
      "Seconds required for this iteration: 0.008\n",
      "\n",
      "***** Epoch #865 *****\n",
      "Loss: 1.499692\n",
      "Improvement ratio: 0.000430\n",
      "Feature L2-norm: 33.387767\n",
      "Learning rate (eta): 0.085252\n",
      "Total number of feature updates: 233550\n",
      "Seconds required for this iteration: 0.008\n",
      "\n",
      "***** Epoch #866 *****\n",
      "Loss: 1.499630\n",
      "Improvement ratio: 0.000442\n",
      "Feature L2-norm: 33.389666\n",
      "Learning rate (eta): 0.085237\n",
      "Total number of feature updates: 233820\n",
      "Seconds required for this iteration: 0.008\n",
      "\n",
      "***** Epoch #867 *****\n",
      "Loss: 1.499560\n",
      "Improvement ratio: 0.000434\n",
      "Feature L2-norm: 33.391561\n",
      "Learning rate (eta): 0.085222\n",
      "Total number of feature updates: 234090\n",
      "Seconds required for this iteration: 0.009\n",
      "\n",
      "***** Epoch #868 *****\n",
      "Loss: 1.499525\n",
      "Improvement ratio: 0.000418\n",
      "Feature L2-norm: 33.393452\n",
      "Learning rate (eta): 0.085208\n",
      "Total number of feature updates: 234360\n",
      "Seconds required for this iteration: 0.009\n",
      "\n",
      "***** Epoch #869 *****\n",
      "Loss: 1.499451\n",
      "Improvement ratio: 0.000423\n",
      "Feature L2-norm: 33.395340\n",
      "Learning rate (eta): 0.085193\n",
      "Total number of feature updates: 234630\n",
      "Seconds required for this iteration: 0.009\n",
      "\n",
      "***** Epoch #870 *****\n",
      "Loss: 1.499385\n",
      "Improvement ratio: 0.000421\n",
      "Feature L2-norm: 33.397223\n",
      "Learning rate (eta): 0.085179\n",
      "Total number of feature updates: 234900\n",
      "Seconds required for this iteration: 0.009\n",
      "\n",
      "***** Epoch #871 *****\n",
      "Loss: 1.499325\n",
      "Improvement ratio: 0.000417\n",
      "Feature L2-norm: 33.399102\n",
      "Learning rate (eta): 0.085164\n",
      "Total number of feature updates: 235170\n",
      "Seconds required for this iteration: 0.008\n",
      "\n",
      "***** Epoch #872 *****\n",
      "Loss: 1.499268\n",
      "Improvement ratio: 0.000408\n",
      "Feature L2-norm: 33.400975\n",
      "Learning rate (eta): 0.085150\n",
      "Total number of feature updates: 235440\n",
      "Seconds required for this iteration: 0.008\n",
      "\n",
      "***** Epoch #873 *****\n",
      "Loss: 1.499188\n",
      "Improvement ratio: 0.000426\n",
      "Feature L2-norm: 33.402843\n",
      "Learning rate (eta): 0.085135\n",
      "Total number of feature updates: 235710\n",
      "Seconds required for this iteration: 0.008\n",
      "\n",
      "***** Epoch #874 *****\n",
      "Loss: 1.499142\n",
      "Improvement ratio: 0.000407\n",
      "Feature L2-norm: 33.404708\n",
      "Learning rate (eta): 0.085121\n",
      "Total number of feature updates: 235980\n",
      "Seconds required for this iteration: 0.008\n",
      "\n",
      "***** Epoch #875 *****\n",
      "Loss: 1.499067\n",
      "Improvement ratio: 0.000417\n",
      "Feature L2-norm: 33.406570\n",
      "Learning rate (eta): 0.085106\n",
      "Total number of feature updates: 236250\n",
      "Seconds required for this iteration: 0.008\n",
      "\n",
      "***** Epoch #876 *****\n",
      "Loss: 1.499004\n",
      "Improvement ratio: 0.000417\n",
      "Feature L2-norm: 33.408429\n",
      "Learning rate (eta): 0.085092\n",
      "Total number of feature updates: 236520\n",
      "Seconds required for this iteration: 0.008\n",
      "\n",
      "***** Epoch #877 *****\n",
      "Loss: 1.498955\n",
      "Improvement ratio: 0.000404\n",
      "Feature L2-norm: 33.410283\n",
      "Learning rate (eta): 0.085077\n",
      "Total number of feature updates: 236790\n",
      "Seconds required for this iteration: 0.008\n",
      "\n",
      "***** Epoch #878 *****\n",
      "Loss: 1.498903\n",
      "Improvement ratio: 0.000415\n",
      "Feature L2-norm: 33.412131\n",
      "Learning rate (eta): 0.085063\n",
      "Total number of feature updates: 237060\n",
      "Seconds required for this iteration: 0.008\n",
      "\n",
      "***** Epoch #879 *****\n",
      "Loss: 1.498836\n",
      "Improvement ratio: 0.000410\n",
      "Feature L2-norm: 33.413976\n",
      "Learning rate (eta): 0.085049\n",
      "Total number of feature updates: 237330\n",
      "Seconds required for this iteration: 0.008\n",
      "\n",
      "***** Epoch #880 *****\n",
      "Loss: 1.498796\n",
      "Improvement ratio: 0.000393\n",
      "Feature L2-norm: 33.415817\n",
      "Learning rate (eta): 0.085034\n",
      "Total number of feature updates: 237600\n",
      "Seconds required for this iteration: 0.007\n",
      "\n",
      "***** Epoch #881 *****\n",
      "Loss: 1.498717\n",
      "Improvement ratio: 0.000406\n",
      "Feature L2-norm: 33.417654\n",
      "Learning rate (eta): 0.085020\n",
      "Total number of feature updates: 237870\n",
      "Seconds required for this iteration: 0.008\n",
      "\n",
      "***** Epoch #882 *****\n",
      "Loss: 1.498658\n",
      "Improvement ratio: 0.000407\n",
      "Feature L2-norm: 33.419487\n",
      "Learning rate (eta): 0.085005\n",
      "Total number of feature updates: 238140\n",
      "Seconds required for this iteration: 0.008\n",
      "\n",
      "***** Epoch #883 *****\n",
      "Loss: 1.498585\n",
      "Improvement ratio: 0.000402\n",
      "Feature L2-norm: 33.421315\n",
      "Learning rate (eta): 0.084991\n",
      "Total number of feature updates: 238410\n",
      "Seconds required for this iteration: 0.008\n",
      "\n",
      "***** Epoch #884 *****\n",
      "Loss: 1.498530\n",
      "Improvement ratio: 0.000409\n",
      "Feature L2-norm: 33.423140\n",
      "Learning rate (eta): 0.084976\n",
      "Total number of feature updates: 238680\n",
      "Seconds required for this iteration: 0.008\n",
      "\n",
      "***** Epoch #885 *****\n",
      "Loss: 1.498469\n",
      "Improvement ratio: 0.000399\n",
      "Feature L2-norm: 33.424961\n",
      "Learning rate (eta): 0.084962\n",
      "Total number of feature updates: 238950\n",
      "Seconds required for this iteration: 0.008\n",
      "\n",
      "***** Epoch #886 *****\n",
      "Loss: 1.498422\n",
      "Improvement ratio: 0.000388\n",
      "Feature L2-norm: 33.426777\n",
      "Learning rate (eta): 0.084947\n",
      "Total number of feature updates: 239220\n",
      "Seconds required for this iteration: 0.008\n",
      "\n",
      "***** Epoch #887 *****\n",
      "Loss: 1.498367\n",
      "Improvement ratio: 0.000393\n",
      "Feature L2-norm: 33.428589\n",
      "Learning rate (eta): 0.084933\n",
      "Total number of feature updates: 239490\n",
      "Seconds required for this iteration: 0.008\n",
      "\n",
      "***** Epoch #888 *****\n",
      "Loss: 1.498301\n",
      "Improvement ratio: 0.000401\n",
      "Feature L2-norm: 33.430396\n",
      "Learning rate (eta): 0.084919\n",
      "Total number of feature updates: 239760\n",
      "Seconds required for this iteration: 0.008\n",
      "\n",
      "***** Epoch #889 *****\n",
      "Loss: 1.498259\n",
      "Improvement ratio: 0.000385\n",
      "Feature L2-norm: 33.432201\n",
      "Learning rate (eta): 0.084904\n",
      "Total number of feature updates: 240030\n",
      "Seconds required for this iteration: 0.008\n",
      "\n",
      "***** Epoch #890 *****\n",
      "Loss: 1.498198\n",
      "Improvement ratio: 0.000399\n",
      "Feature L2-norm: 33.434001\n",
      "Learning rate (eta): 0.084890\n",
      "Total number of feature updates: 240300\n",
      "Seconds required for this iteration: 0.008\n",
      "\n",
      "***** Epoch #891 *****\n",
      "Loss: 1.498126\n",
      "Improvement ratio: 0.000394\n",
      "Feature L2-norm: 33.435796\n",
      "Learning rate (eta): 0.084875\n",
      "Total number of feature updates: 240570\n",
      "Seconds required for this iteration: 0.007\n",
      "\n",
      "***** Epoch #892 *****\n",
      "Loss: 1.498077\n",
      "Improvement ratio: 0.000387\n",
      "Feature L2-norm: 33.437589\n",
      "Learning rate (eta): 0.084861\n",
      "Total number of feature updates: 240840\n",
      "Seconds required for this iteration: 0.007\n",
      "\n",
      "***** Epoch #893 *****\n",
      "Loss: 1.498022\n",
      "Improvement ratio: 0.000376\n",
      "Feature L2-norm: 33.439376\n",
      "Learning rate (eta): 0.084846\n",
      "Total number of feature updates: 241110\n",
      "Seconds required for this iteration: 0.008\n",
      "\n",
      "***** Epoch #894 *****\n",
      "Loss: 1.497961\n",
      "Improvement ratio: 0.000380\n",
      "Feature L2-norm: 33.441160\n",
      "Learning rate (eta): 0.084832\n",
      "Total number of feature updates: 241380\n",
      "Seconds required for this iteration: 0.008\n",
      "\n",
      "***** Epoch #895 *****\n",
      "Loss: 1.497890\n",
      "Improvement ratio: 0.000387\n",
      "Feature L2-norm: 33.442941\n",
      "Learning rate (eta): 0.084818\n",
      "Total number of feature updates: 241650\n",
      "Seconds required for this iteration: 0.007\n",
      "\n",
      "***** Epoch #896 *****\n",
      "Loss: 1.497834\n",
      "Improvement ratio: 0.000393\n",
      "Feature L2-norm: 33.444717\n",
      "Learning rate (eta): 0.084803\n",
      "Total number of feature updates: 241920\n",
      "Seconds required for this iteration: 0.008\n",
      "\n",
      "***** Epoch #897 *****\n",
      "Loss: 1.497802\n",
      "Improvement ratio: 0.000377\n",
      "Feature L2-norm: 33.446490\n",
      "Learning rate (eta): 0.084789\n",
      "Total number of feature updates: 242190\n",
      "Seconds required for this iteration: 0.007\n",
      "\n",
      "***** Epoch #898 *****\n",
      "Loss: 1.497738\n",
      "Improvement ratio: 0.000376\n",
      "Feature L2-norm: 33.448257\n",
      "Learning rate (eta): 0.084775\n",
      "Total number of feature updates: 242460\n",
      "Seconds required for this iteration: 0.015\n",
      "\n",
      "***** Epoch #899 *****\n",
      "Loss: 1.497678\n",
      "Improvement ratio: 0.000388\n",
      "Feature L2-norm: 33.450022\n",
      "Learning rate (eta): 0.084760\n",
      "Total number of feature updates: 242730\n",
      "Seconds required for this iteration: 0.009\n",
      "\n",
      "***** Epoch #900 *****\n",
      "Loss: 1.497612\n",
      "Improvement ratio: 0.000392\n",
      "Feature L2-norm: 33.451780\n",
      "Learning rate (eta): 0.084746\n",
      "Total number of feature updates: 243000\n",
      "Seconds required for this iteration: 0.008\n",
      "\n",
      "***** Epoch #901 *****\n",
      "Loss: 1.497554\n",
      "Improvement ratio: 0.000382\n",
      "Feature L2-norm: 33.453538\n",
      "Learning rate (eta): 0.084731\n",
      "Total number of feature updates: 243270\n",
      "Seconds required for this iteration: 0.009\n",
      "\n",
      "***** Epoch #902 *****\n",
      "Loss: 1.497505\n",
      "Improvement ratio: 0.000382\n",
      "Feature L2-norm: 33.455290\n",
      "Learning rate (eta): 0.084717\n",
      "Total number of feature updates: 243540\n",
      "Seconds required for this iteration: 0.008\n",
      "\n",
      "***** Epoch #903 *****\n",
      "Loss: 1.497456\n",
      "Improvement ratio: 0.000378\n",
      "Feature L2-norm: 33.457040\n",
      "Learning rate (eta): 0.084703\n",
      "Total number of feature updates: 243810\n",
      "Seconds required for this iteration: 0.008\n",
      "\n",
      "***** Epoch #904 *****\n",
      "Loss: 1.497407\n",
      "Improvement ratio: 0.000370\n",
      "Feature L2-norm: 33.458784\n",
      "Learning rate (eta): 0.084688\n",
      "Total number of feature updates: 244080\n",
      "Seconds required for this iteration: 0.007\n",
      "\n",
      "***** Epoch #905 *****\n",
      "Loss: 1.497337\n",
      "Improvement ratio: 0.000369\n",
      "Feature L2-norm: 33.460526\n",
      "Learning rate (eta): 0.084674\n",
      "Total number of feature updates: 244350\n",
      "Seconds required for this iteration: 0.007\n",
      "\n",
      "***** Epoch #906 *****\n",
      "Loss: 1.497288\n",
      "Improvement ratio: 0.000364\n",
      "Feature L2-norm: 33.462265\n",
      "Learning rate (eta): 0.084660\n",
      "Total number of feature updates: 244620\n",
      "Seconds required for this iteration: 0.008\n",
      "\n",
      "***** Epoch #907 *****\n",
      "Loss: 1.497221\n",
      "Improvement ratio: 0.000388\n",
      "Feature L2-norm: 33.463998\n",
      "Learning rate (eta): 0.084645\n",
      "Total number of feature updates: 244890\n",
      "Seconds required for this iteration: 0.008\n",
      "\n",
      "***** Epoch #908 *****\n",
      "Loss: 1.497180\n",
      "Improvement ratio: 0.000372\n",
      "Feature L2-norm: 33.465729\n",
      "Learning rate (eta): 0.084631\n",
      "Total number of feature updates: 245160\n",
      "Seconds required for this iteration: 0.008\n",
      "\n",
      "***** Epoch #909 *****\n",
      "Loss: 1.497124\n",
      "Improvement ratio: 0.000370\n",
      "Feature L2-norm: 33.467455\n",
      "Learning rate (eta): 0.084617\n",
      "Total number of feature updates: 245430\n",
      "Seconds required for this iteration: 0.008\n",
      "\n",
      "***** Epoch #910 *****\n",
      "Loss: 1.497089\n",
      "Improvement ratio: 0.000349\n",
      "Feature L2-norm: 33.469177\n",
      "Learning rate (eta): 0.084602\n",
      "Total number of feature updates: 245700\n",
      "Seconds required for this iteration: 0.008\n",
      "\n",
      "***** Epoch #911 *****\n",
      "Loss: 1.497012\n",
      "Improvement ratio: 0.000362\n",
      "Feature L2-norm: 33.470893\n",
      "Learning rate (eta): 0.084588\n",
      "Total number of feature updates: 245970\n",
      "Seconds required for this iteration: 0.008\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** Epoch #912 *****\n",
      "Loss: 1.496982\n",
      "Improvement ratio: 0.000350\n",
      "Feature L2-norm: 33.472608\n",
      "Learning rate (eta): 0.084574\n",
      "Total number of feature updates: 246240\n",
      "Seconds required for this iteration: 0.007\n",
      "\n",
      "***** Epoch #913 *****\n",
      "Loss: 1.496911\n",
      "Improvement ratio: 0.000364\n",
      "Feature L2-norm: 33.474319\n",
      "Learning rate (eta): 0.084559\n",
      "Total number of feature updates: 246510\n",
      "Seconds required for this iteration: 0.008\n",
      "\n",
      "***** Epoch #914 *****\n",
      "Loss: 1.496862\n",
      "Improvement ratio: 0.000364\n",
      "Feature L2-norm: 33.476026\n",
      "Learning rate (eta): 0.084545\n",
      "Total number of feature updates: 246780\n",
      "Seconds required for this iteration: 0.007\n",
      "\n",
      "***** Epoch #915 *****\n",
      "Loss: 1.496812\n",
      "Improvement ratio: 0.000351\n",
      "Feature L2-norm: 33.477729\n",
      "Learning rate (eta): 0.084531\n",
      "Total number of feature updates: 247050\n",
      "Seconds required for this iteration: 0.008\n",
      "\n",
      "***** Epoch #916 *****\n",
      "Loss: 1.496744\n",
      "Improvement ratio: 0.000363\n",
      "Feature L2-norm: 33.479429\n",
      "Learning rate (eta): 0.084517\n",
      "Total number of feature updates: 247320\n",
      "Seconds required for this iteration: 0.008\n",
      "\n",
      "***** Epoch #917 *****\n",
      "Loss: 1.496719\n",
      "Improvement ratio: 0.000336\n",
      "Feature L2-norm: 33.481126\n",
      "Learning rate (eta): 0.084502\n",
      "Total number of feature updates: 247590\n",
      "Seconds required for this iteration: 0.007\n",
      "\n",
      "***** Epoch #918 *****\n",
      "Loss: 1.496654\n",
      "Improvement ratio: 0.000352\n",
      "Feature L2-norm: 33.482817\n",
      "Learning rate (eta): 0.084488\n",
      "Total number of feature updates: 247860\n",
      "Seconds required for this iteration: 0.007\n",
      "\n",
      "***** Epoch #919 *****\n",
      "Loss: 1.496594\n",
      "Improvement ratio: 0.000354\n",
      "Feature L2-norm: 33.484507\n",
      "Learning rate (eta): 0.084474\n",
      "Total number of feature updates: 248130\n",
      "Seconds required for this iteration: 0.007\n",
      "\n",
      "***** Epoch #920 *****\n",
      "Loss: 1.496540\n",
      "Improvement ratio: 0.000366\n",
      "Feature L2-norm: 33.486191\n",
      "Learning rate (eta): 0.084460\n",
      "Total number of feature updates: 248400\n",
      "Seconds required for this iteration: 0.007\n",
      "\n",
      "***** Epoch #921 *****\n",
      "Loss: 1.496486\n",
      "Improvement ratio: 0.000351\n",
      "Feature L2-norm: 33.487873\n",
      "Learning rate (eta): 0.084445\n",
      "Total number of feature updates: 248670\n",
      "Seconds required for this iteration: 0.008\n",
      "\n",
      "***** Epoch #922 *****\n",
      "Loss: 1.496439\n",
      "Improvement ratio: 0.000363\n",
      "Feature L2-norm: 33.489551\n",
      "Learning rate (eta): 0.084431\n",
      "Total number of feature updates: 248940\n",
      "Seconds required for this iteration: 0.012\n",
      "\n",
      "***** Epoch #923 *****\n",
      "Loss: 1.496376\n",
      "Improvement ratio: 0.000357\n",
      "Feature L2-norm: 33.491224\n",
      "Learning rate (eta): 0.084417\n",
      "Total number of feature updates: 249210\n",
      "Seconds required for this iteration: 0.009\n",
      "\n",
      "***** Epoch #924 *****\n",
      "Loss: 1.496355\n",
      "Improvement ratio: 0.000339\n",
      "Feature L2-norm: 33.492893\n",
      "Learning rate (eta): 0.084402\n",
      "Total number of feature updates: 249480\n",
      "Seconds required for this iteration: 0.009\n",
      "\n",
      "***** Epoch #925 *****\n",
      "Loss: 1.496280\n",
      "Improvement ratio: 0.000356\n",
      "Feature L2-norm: 33.494560\n",
      "Learning rate (eta): 0.084388\n",
      "Total number of feature updates: 249750\n",
      "Seconds required for this iteration: 0.009\n",
      "\n",
      "***** Epoch #926 *****\n",
      "Loss: 1.496238\n",
      "Improvement ratio: 0.000339\n",
      "Feature L2-norm: 33.496221\n",
      "Learning rate (eta): 0.084374\n",
      "Total number of feature updates: 250020\n",
      "Seconds required for this iteration: 0.008\n",
      "\n",
      "***** Epoch #927 *****\n",
      "Loss: 1.496185\n",
      "Improvement ratio: 0.000357\n",
      "Feature L2-norm: 33.497879\n",
      "Learning rate (eta): 0.084360\n",
      "Total number of feature updates: 250290\n",
      "Seconds required for this iteration: 0.008\n",
      "\n",
      "***** Epoch #928 *****\n",
      "Loss: 1.496120\n",
      "Improvement ratio: 0.000357\n",
      "Feature L2-norm: 33.499532\n",
      "Learning rate (eta): 0.084346\n",
      "Total number of feature updates: 250560\n",
      "Seconds required for this iteration: 0.008\n",
      "\n",
      "***** Epoch #929 *****\n",
      "Loss: 1.496073\n",
      "Improvement ratio: 0.000348\n",
      "Feature L2-norm: 33.501183\n",
      "Learning rate (eta): 0.084331\n",
      "Total number of feature updates: 250830\n",
      "Seconds required for this iteration: 0.008\n",
      "\n",
      "***** Epoch #930 *****\n",
      "Loss: 1.496039\n",
      "Improvement ratio: 0.000335\n",
      "Feature L2-norm: 33.502832\n",
      "Learning rate (eta): 0.084317\n",
      "Total number of feature updates: 251100\n",
      "Seconds required for this iteration: 0.008\n",
      "\n",
      "***** Epoch #931 *****\n",
      "Loss: 1.495966\n",
      "Improvement ratio: 0.000348\n",
      "Feature L2-norm: 33.504475\n",
      "Learning rate (eta): 0.084303\n",
      "Total number of feature updates: 251370\n",
      "Seconds required for this iteration: 0.008\n",
      "\n",
      "***** Epoch #932 *****\n",
      "Loss: 1.495929\n",
      "Improvement ratio: 0.000340\n",
      "Feature L2-norm: 33.506116\n",
      "Learning rate (eta): 0.084289\n",
      "Total number of feature updates: 251640\n",
      "Seconds required for this iteration: 0.008\n",
      "\n",
      "***** Epoch #933 *****\n",
      "Loss: 1.495881\n",
      "Improvement ratio: 0.000331\n",
      "Feature L2-norm: 33.507753\n",
      "Learning rate (eta): 0.084274\n",
      "Total number of feature updates: 251910\n",
      "Seconds required for this iteration: 0.008\n",
      "\n",
      "***** Epoch #934 *****\n",
      "Loss: 1.495829\n",
      "Improvement ratio: 0.000352\n",
      "Feature L2-norm: 33.509386\n",
      "Learning rate (eta): 0.084260\n",
      "Total number of feature updates: 252180\n",
      "Seconds required for this iteration: 0.007\n",
      "\n",
      "***** Epoch #935 *****\n",
      "Loss: 1.495792\n",
      "Improvement ratio: 0.000326\n",
      "Feature L2-norm: 33.511016\n",
      "Learning rate (eta): 0.084246\n",
      "Total number of feature updates: 252450\n",
      "Seconds required for this iteration: 0.008\n",
      "\n",
      "***** Epoch #936 *****\n",
      "Loss: 1.495739\n",
      "Improvement ratio: 0.000333\n",
      "Feature L2-norm: 33.512643\n",
      "Learning rate (eta): 0.084232\n",
      "Total number of feature updates: 252720\n",
      "Seconds required for this iteration: 0.008\n",
      "\n",
      "***** Epoch #937 *****\n",
      "Loss: 1.495680\n",
      "Improvement ratio: 0.000337\n",
      "Feature L2-norm: 33.514267\n",
      "Learning rate (eta): 0.084218\n",
      "Total number of feature updates: 252990\n",
      "Seconds required for this iteration: 0.008\n",
      "\n",
      "***** Epoch #938 *****\n",
      "Loss: 1.495633\n",
      "Improvement ratio: 0.000326\n",
      "Feature L2-norm: 33.515886\n",
      "Learning rate (eta): 0.084203\n",
      "Total number of feature updates: 253260\n",
      "Seconds required for this iteration: 0.008\n",
      "\n",
      "***** Epoch #939 *****\n",
      "Loss: 1.495580\n",
      "Improvement ratio: 0.000330\n",
      "Feature L2-norm: 33.517504\n",
      "Learning rate (eta): 0.084189\n",
      "Total number of feature updates: 253530\n",
      "Seconds required for this iteration: 0.007\n",
      "\n",
      "***** Epoch #940 *****\n",
      "Loss: 1.495531\n",
      "Improvement ratio: 0.000340\n",
      "Feature L2-norm: 33.519116\n",
      "Learning rate (eta): 0.084175\n",
      "Total number of feature updates: 253800\n",
      "Seconds required for this iteration: 0.008\n",
      "\n",
      "***** Epoch #941 *****\n",
      "Loss: 1.495494\n",
      "Improvement ratio: 0.000316\n",
      "Feature L2-norm: 33.520726\n",
      "Learning rate (eta): 0.084161\n",
      "Total number of feature updates: 254070\n",
      "Seconds required for this iteration: 0.007\n",
      "\n",
      "***** Epoch #942 *****\n",
      "Loss: 1.495437\n",
      "Improvement ratio: 0.000330\n",
      "Feature L2-norm: 33.522332\n",
      "Learning rate (eta): 0.084147\n",
      "Total number of feature updates: 254340\n",
      "Seconds required for this iteration: 0.010\n",
      "\n",
      "***** Epoch #943 *****\n",
      "Loss: 1.495392\n",
      "Improvement ratio: 0.000327\n",
      "Feature L2-norm: 33.523934\n",
      "Learning rate (eta): 0.084133\n",
      "Total number of feature updates: 254610\n",
      "Seconds required for this iteration: 0.007\n",
      "\n",
      "***** Epoch #944 *****\n",
      "Loss: 1.495332\n",
      "Improvement ratio: 0.000332\n",
      "Feature L2-norm: 33.525533\n",
      "Learning rate (eta): 0.084118\n",
      "Total number of feature updates: 254880\n",
      "Seconds required for this iteration: 0.010\n",
      "\n",
      "***** Epoch #945 *****\n",
      "Loss: 1.495284\n",
      "Improvement ratio: 0.000340\n",
      "Feature L2-norm: 33.527127\n",
      "Learning rate (eta): 0.084104\n",
      "Total number of feature updates: 255150\n",
      "Seconds required for this iteration: 0.009\n",
      "\n",
      "***** Epoch #946 *****\n",
      "Loss: 1.495243\n",
      "Improvement ratio: 0.000332\n",
      "Feature L2-norm: 33.528718\n",
      "Learning rate (eta): 0.084090\n",
      "Total number of feature updates: 255420\n",
      "Seconds required for this iteration: 0.009\n",
      "\n",
      "***** Epoch #947 *****\n",
      "Loss: 1.495191\n",
      "Improvement ratio: 0.000327\n",
      "Feature L2-norm: 33.530306\n",
      "Learning rate (eta): 0.084076\n",
      "Total number of feature updates: 255690\n",
      "Seconds required for this iteration: 0.007\n",
      "\n",
      "***** Epoch #948 *****\n",
      "Loss: 1.495161\n",
      "Improvement ratio: 0.000316\n",
      "Feature L2-norm: 33.531891\n",
      "Learning rate (eta): 0.084062\n",
      "Total number of feature updates: 255960\n",
      "Seconds required for this iteration: 0.009\n",
      "\n",
      "***** Epoch #949 *****\n",
      "Loss: 1.495098\n",
      "Improvement ratio: 0.000322\n",
      "Feature L2-norm: 33.533472\n",
      "Learning rate (eta): 0.084048\n",
      "Total number of feature updates: 256230\n",
      "Seconds required for this iteration: 0.008\n",
      "\n",
      "***** Epoch #950 *****\n",
      "Loss: 1.495045\n",
      "Improvement ratio: 0.000325\n",
      "Feature L2-norm: 33.535050\n",
      "Learning rate (eta): 0.084034\n",
      "Total number of feature updates: 256500\n",
      "Seconds required for this iteration: 0.008\n",
      "\n",
      "***** Epoch #951 *****\n",
      "Loss: 1.495007\n",
      "Improvement ratio: 0.000326\n",
      "Feature L2-norm: 33.536626\n",
      "Learning rate (eta): 0.084020\n",
      "Total number of feature updates: 256770\n",
      "Seconds required for this iteration: 0.007\n",
      "\n",
      "***** Epoch #952 *****\n",
      "Loss: 1.494957\n",
      "Improvement ratio: 0.000321\n",
      "Feature L2-norm: 33.538198\n",
      "Learning rate (eta): 0.084005\n",
      "Total number of feature updates: 257040\n",
      "Seconds required for this iteration: 0.008\n",
      "\n",
      "***** Epoch #953 *****\n",
      "Loss: 1.494912\n",
      "Improvement ratio: 0.000321\n",
      "Feature L2-norm: 33.539766\n",
      "Learning rate (eta): 0.083991\n",
      "Total number of feature updates: 257310\n",
      "Seconds required for this iteration: 0.008\n",
      "\n",
      "***** Epoch #954 *****\n",
      "Loss: 1.494863\n",
      "Improvement ratio: 0.000313\n",
      "Feature L2-norm: 33.541331\n",
      "Learning rate (eta): 0.083977\n",
      "Total number of feature updates: 257580\n",
      "Seconds required for this iteration: 0.008\n",
      "\n",
      "***** Epoch #955 *****\n",
      "Loss: 1.494819\n",
      "Improvement ratio: 0.000311\n",
      "Feature L2-norm: 33.542892\n",
      "Learning rate (eta): 0.083963\n",
      "Total number of feature updates: 257850\n",
      "Seconds required for this iteration: 0.007\n",
      "\n",
      "***** Epoch #956 *****\n",
      "Loss: 1.494774\n",
      "Improvement ratio: 0.000314\n",
      "Feature L2-norm: 33.544449\n",
      "Learning rate (eta): 0.083949\n",
      "Total number of feature updates: 258120\n",
      "Seconds required for this iteration: 0.008\n",
      "\n",
      "***** Epoch #957 *****\n",
      "Loss: 1.494730\n",
      "Improvement ratio: 0.000308\n",
      "Feature L2-norm: 33.546003\n",
      "Learning rate (eta): 0.083935\n",
      "Total number of feature updates: 258390\n",
      "Seconds required for this iteration: 0.008\n",
      "\n",
      "***** Epoch #958 *****\n",
      "Loss: 1.494673\n",
      "Improvement ratio: 0.000326\n",
      "Feature L2-norm: 33.547552\n",
      "Learning rate (eta): 0.083921\n",
      "Total number of feature updates: 258660\n",
      "Seconds required for this iteration: 0.007\n",
      "\n",
      "***** Epoch #959 *****\n",
      "Loss: 1.494640\n",
      "Improvement ratio: 0.000307\n",
      "Feature L2-norm: 33.549099\n",
      "Learning rate (eta): 0.083907\n",
      "Total number of feature updates: 258930\n",
      "Seconds required for this iteration: 0.008\n",
      "\n",
      "***** Epoch #960 *****\n",
      "Loss: 1.494584\n",
      "Improvement ratio: 0.000308\n",
      "Feature L2-norm: 33.550642\n",
      "Learning rate (eta): 0.083893\n",
      "Total number of feature updates: 259200\n",
      "Seconds required for this iteration: 0.008\n",
      "\n",
      "***** Epoch #961 *****\n",
      "Loss: 1.494544\n",
      "Improvement ratio: 0.000310\n",
      "Feature L2-norm: 33.552184\n",
      "Learning rate (eta): 0.083879\n",
      "Total number of feature updates: 259470\n",
      "Seconds required for this iteration: 0.008\n",
      "\n",
      "***** Epoch #962 *****\n",
      "Loss: 1.494517\n",
      "Improvement ratio: 0.000294\n",
      "Feature L2-norm: 33.553721\n",
      "Learning rate (eta): 0.083865\n",
      "Total number of feature updates: 259740\n",
      "Seconds required for this iteration: 0.008\n",
      "\n",
      "***** Epoch #963 *****\n",
      "Loss: 1.494457\n",
      "Improvement ratio: 0.000305\n",
      "Feature L2-norm: 33.555257\n",
      "Learning rate (eta): 0.083850\n",
      "Total number of feature updates: 260010\n",
      "Seconds required for this iteration: 0.008\n",
      "\n",
      "***** Epoch #964 *****\n",
      "Loss: 1.494411\n",
      "Improvement ratio: 0.000302\n",
      "Feature L2-norm: 33.556788\n",
      "Learning rate (eta): 0.083836\n",
      "Total number of feature updates: 260280\n",
      "Seconds required for this iteration: 0.008\n",
      "\n",
      "***** Epoch #965 *****\n",
      "Loss: 1.494366\n",
      "Improvement ratio: 0.000303\n",
      "Feature L2-norm: 33.558315\n",
      "Learning rate (eta): 0.083822\n",
      "Total number of feature updates: 260550\n",
      "Seconds required for this iteration: 0.008\n",
      "\n",
      "***** Epoch #966 *****\n",
      "Loss: 1.494328\n",
      "Improvement ratio: 0.000299\n",
      "Feature L2-norm: 33.559840\n",
      "Learning rate (eta): 0.083808\n",
      "Total number of feature updates: 260820\n",
      "Seconds required for this iteration: 0.008\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** Epoch #967 *****\n",
      "Loss: 1.494285\n",
      "Improvement ratio: 0.000298\n",
      "Feature L2-norm: 33.561361\n",
      "Learning rate (eta): 0.083794\n",
      "Total number of feature updates: 261090\n",
      "Seconds required for this iteration: 0.008\n",
      "\n",
      "***** Epoch #968 *****\n",
      "Loss: 1.494220\n",
      "Improvement ratio: 0.000304\n",
      "Feature L2-norm: 33.562879\n",
      "Learning rate (eta): 0.083780\n",
      "Total number of feature updates: 261360\n",
      "Seconds required for this iteration: 0.007\n",
      "\n",
      "***** Epoch #969 *****\n",
      "Loss: 1.494178\n",
      "Improvement ratio: 0.000309\n",
      "Feature L2-norm: 33.564394\n",
      "Learning rate (eta): 0.083766\n",
      "Total number of feature updates: 261630\n",
      "Seconds required for this iteration: 0.008\n",
      "\n",
      "***** Epoch #970 *****\n",
      "Loss: 1.494147\n",
      "Improvement ratio: 0.000292\n",
      "Feature L2-norm: 33.565906\n",
      "Learning rate (eta): 0.083752\n",
      "Total number of feature updates: 261900\n",
      "Seconds required for this iteration: 0.008\n",
      "\n",
      "***** Epoch #971 *****\n",
      "Loss: 1.494106\n",
      "Improvement ratio: 0.000293\n",
      "Feature L2-norm: 33.567414\n",
      "Learning rate (eta): 0.083738\n",
      "Total number of feature updates: 262170\n",
      "Seconds required for this iteration: 0.007\n",
      "\n",
      "***** Epoch #972 *****\n",
      "Loss: 1.494055\n",
      "Improvement ratio: 0.000309\n",
      "Feature L2-norm: 33.568920\n",
      "Learning rate (eta): 0.083724\n",
      "Total number of feature updates: 262440\n",
      "Seconds required for this iteration: 0.007\n",
      "\n",
      "***** Epoch #973 *****\n",
      "Loss: 1.494017\n",
      "Improvement ratio: 0.000294\n",
      "Feature L2-norm: 33.570421\n",
      "Learning rate (eta): 0.083710\n",
      "Total number of feature updates: 262710\n",
      "Seconds required for this iteration: 0.007\n",
      "\n",
      "***** Epoch #974 *****\n",
      "Loss: 1.493975\n",
      "Improvement ratio: 0.000292\n",
      "Feature L2-norm: 33.571918\n",
      "Learning rate (eta): 0.083696\n",
      "Total number of feature updates: 262980\n",
      "Seconds required for this iteration: 0.007\n",
      "\n",
      "***** Epoch #975 *****\n",
      "Loss: 1.493927\n",
      "Improvement ratio: 0.000294\n",
      "Feature L2-norm: 33.573415\n",
      "Learning rate (eta): 0.083682\n",
      "Total number of feature updates: 263250\n",
      "Seconds required for this iteration: 0.007\n",
      "\n",
      "***** Epoch #976 *****\n",
      "Loss: 1.493863\n",
      "Improvement ratio: 0.000311\n",
      "Feature L2-norm: 33.574907\n",
      "Learning rate (eta): 0.083668\n",
      "Total number of feature updates: 263520\n",
      "Seconds required for this iteration: 0.008\n",
      "\n",
      "***** Epoch #977 *****\n",
      "Loss: 1.493833\n",
      "Improvement ratio: 0.000302\n",
      "Feature L2-norm: 33.576396\n",
      "Learning rate (eta): 0.083654\n",
      "Total number of feature updates: 263790\n",
      "Seconds required for this iteration: 0.008\n",
      "\n",
      "***** Epoch #978 *****\n",
      "Loss: 1.493799\n",
      "Improvement ratio: 0.000282\n",
      "Feature L2-norm: 33.577882\n",
      "Learning rate (eta): 0.083640\n",
      "Total number of feature updates: 264060\n",
      "Seconds required for this iteration: 0.009\n",
      "\n",
      "***** Epoch #979 *****\n",
      "Loss: 1.493752\n",
      "Improvement ratio: 0.000285\n",
      "Feature L2-norm: 33.579365\n",
      "Learning rate (eta): 0.083626\n",
      "Total number of feature updates: 264330\n",
      "Seconds required for this iteration: 0.009\n",
      "\n",
      "***** Epoch #980 *****\n",
      "Loss: 1.493716\n",
      "Improvement ratio: 0.000289\n",
      "Feature L2-norm: 33.580844\n",
      "Learning rate (eta): 0.083612\n",
      "Total number of feature updates: 264600\n",
      "Seconds required for this iteration: 0.008\n",
      "\n",
      "***** Epoch #981 *****\n",
      "Loss: 1.493668\n",
      "Improvement ratio: 0.000293\n",
      "Feature L2-norm: 33.582320\n",
      "Learning rate (eta): 0.083598\n",
      "Total number of feature updates: 264870\n",
      "Seconds required for this iteration: 0.008\n",
      "\n",
      "***** Epoch #982 *****\n",
      "Loss: 1.493623\n",
      "Improvement ratio: 0.000289\n",
      "Feature L2-norm: 33.583793\n",
      "Learning rate (eta): 0.083584\n",
      "Total number of feature updates: 265140\n",
      "Seconds required for this iteration: 0.008\n",
      "\n",
      "***** Epoch #983 *****\n",
      "Loss: 1.493581\n",
      "Improvement ratio: 0.000292\n",
      "Feature L2-norm: 33.585264\n",
      "Learning rate (eta): 0.083570\n",
      "Total number of feature updates: 265410\n",
      "Seconds required for this iteration: 0.008\n",
      "\n",
      "***** Epoch #984 *****\n",
      "Loss: 1.493540\n",
      "Improvement ratio: 0.000291\n",
      "Feature L2-norm: 33.586728\n",
      "Learning rate (eta): 0.083556\n",
      "Total number of feature updates: 265680\n",
      "Seconds required for this iteration: 0.007\n",
      "\n",
      "***** Epoch #985 *****\n",
      "Loss: 1.493487\n",
      "Improvement ratio: 0.000294\n",
      "Feature L2-norm: 33.588193\n",
      "Learning rate (eta): 0.083542\n",
      "Total number of feature updates: 265950\n",
      "Seconds required for this iteration: 0.007\n",
      "\n",
      "***** Epoch #986 *****\n",
      "Loss: 1.493464\n",
      "Improvement ratio: 0.000267\n",
      "Feature L2-norm: 33.589652\n",
      "Learning rate (eta): 0.083528\n",
      "Total number of feature updates: 266220\n",
      "Seconds required for this iteration: 0.008\n",
      "\n",
      "***** Epoch #987 *****\n",
      "Loss: 1.493412\n",
      "Improvement ratio: 0.000282\n",
      "Feature L2-norm: 33.591111\n",
      "Learning rate (eta): 0.083514\n",
      "Total number of feature updates: 266490\n",
      "Seconds required for this iteration: 0.007\n",
      "\n",
      "***** Epoch #988 *****\n",
      "Loss: 1.493378\n",
      "Improvement ratio: 0.000282\n",
      "Feature L2-norm: 33.592566\n",
      "Learning rate (eta): 0.083500\n",
      "Total number of feature updates: 266760\n",
      "Seconds required for this iteration: 0.008\n",
      "\n",
      "***** Epoch #989 *****\n",
      "Loss: 1.493324\n",
      "Improvement ratio: 0.000287\n",
      "Feature L2-norm: 33.594019\n",
      "Learning rate (eta): 0.083486\n",
      "Total number of feature updates: 267030\n",
      "Seconds required for this iteration: 0.008\n",
      "\n",
      "***** Epoch #990 *****\n",
      "Loss: 1.493264\n",
      "Improvement ratio: 0.000303\n",
      "Feature L2-norm: 33.595468\n",
      "Learning rate (eta): 0.083473\n",
      "Total number of feature updates: 267300\n",
      "Seconds required for this iteration: 0.007\n",
      "\n",
      "***** Epoch #991 *****\n",
      "Loss: 1.493229\n",
      "Improvement ratio: 0.000294\n",
      "Feature L2-norm: 33.596913\n",
      "Learning rate (eta): 0.083459\n",
      "Total number of feature updates: 267570\n",
      "Seconds required for this iteration: 0.008\n",
      "\n",
      "***** Epoch #992 *****\n",
      "Loss: 1.493215\n",
      "Improvement ratio: 0.000274\n",
      "Feature L2-norm: 33.598355\n",
      "Learning rate (eta): 0.083445\n",
      "Total number of feature updates: 267840\n",
      "Seconds required for this iteration: 0.007\n",
      "\n",
      "***** Epoch #993 *****\n",
      "Loss: 1.493171\n",
      "Improvement ratio: 0.000274\n",
      "Feature L2-norm: 33.599794\n",
      "Learning rate (eta): 0.083431\n",
      "Total number of feature updates: 268110\n",
      "Seconds required for this iteration: 0.008\n",
      "\n",
      "***** Epoch #994 *****\n",
      "Loss: 1.493120\n",
      "Improvement ratio: 0.000282\n",
      "Feature L2-norm: 33.601230\n",
      "Learning rate (eta): 0.083417\n",
      "Total number of feature updates: 268380\n",
      "Seconds required for this iteration: 0.007\n",
      "\n",
      "***** Epoch #995 *****\n",
      "Loss: 1.493087\n",
      "Improvement ratio: 0.000268\n",
      "Feature L2-norm: 33.602665\n",
      "Learning rate (eta): 0.083403\n",
      "Total number of feature updates: 268650\n",
      "Seconds required for this iteration: 0.008\n",
      "\n",
      "***** Epoch #996 *****\n",
      "Loss: 1.493048\n",
      "Improvement ratio: 0.000279\n",
      "Feature L2-norm: 33.604096\n",
      "Learning rate (eta): 0.083389\n",
      "Total number of feature updates: 268920\n",
      "Seconds required for this iteration: 0.007\n",
      "\n",
      "***** Epoch #997 *****\n",
      "Loss: 1.493015\n",
      "Improvement ratio: 0.000266\n",
      "Feature L2-norm: 33.605523\n",
      "Learning rate (eta): 0.083375\n",
      "Total number of feature updates: 269190\n",
      "Seconds required for this iteration: 0.007\n",
      "\n",
      "***** Epoch #998 *****\n",
      "Loss: 1.492954\n",
      "Improvement ratio: 0.000284\n",
      "Feature L2-norm: 33.606947\n",
      "Learning rate (eta): 0.083361\n",
      "Total number of feature updates: 269460\n",
      "Seconds required for this iteration: 0.007\n",
      "\n",
      "***** Epoch #999 *****\n",
      "Loss: 1.492903\n",
      "Improvement ratio: 0.000282\n",
      "Feature L2-norm: 33.608369\n",
      "Learning rate (eta): 0.083347\n",
      "Total number of feature updates: 269730\n",
      "Seconds required for this iteration: 0.008\n",
      "\n",
      "***** Epoch #1000 *****\n",
      "Loss: 1.492885\n",
      "Improvement ratio: 0.000254\n",
      "Feature L2-norm: 33.609786\n",
      "Learning rate (eta): 0.083333\n",
      "Total number of feature updates: 270000\n",
      "Seconds required for this iteration: 0.007\n",
      "\n",
      "SGD terminated with the maximum number of iterations\n",
      "Loss: 1.492885\n",
      "Total seconds required for training: 9.131\n",
      "\n",
      "Storing the model\n",
      "Number of active features: 24857 (24857)\n",
      "Number of active attributes: 22526 (22526)\n",
      "Number of active labels: 7 (7)\n",
      "Writing labels\n",
      "Writing attributes\n",
      "Writing feature references for transitions\n",
      "Writing feature references for attributes\n",
      "Seconds required: 0.073\n",
      "\n"
     ]
    }
   ],
   "source": [
    "trainer.train(text, model_dir='ner_model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to use the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from estnltk.taggers import WordLevelNerTagger"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To predict on the newly trained model, a NerTagger or WordLevelNerTagger object is needed. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For tagging, one option is to use WordLevelNerTagger, which gives a NER-tag for all words in the text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "nertagger = WordLevelNerTagger(model_dir = 'ner_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from estnltk import Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td><div align = \"left\">Tallinna õhusaaste suureneb.</div></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>layer name</th>\n",
       "      <th>attributes</th>\n",
       "      <th>parent</th>\n",
       "      <th>enveloping</th>\n",
       "      <th>ambiguous</th>\n",
       "      <th>span count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>sentences</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>words</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>tokens</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>compound_tokens</td>\n",
       "      <td>type, normalized</td>\n",
       "      <td>None</td>\n",
       "      <td>tokens</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>words</td>\n",
       "      <td>normalized_form</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>morph_analysis</td>\n",
       "      <td>normalized_text, lemma, root, root_tokens, ending, clitic, form, partofspeech</td>\n",
       "      <td>words</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "Text(text='Tallinna õhusaaste suureneb.')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Text it has seen before (first sentence from the trainset)\n",
    "testtext = Text(\"Tallinna õhusaaste suureneb.\")\n",
    "testtext.tag_layer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td><div align = \"left\">Tallinna õhusaaste suureneb.</div></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>layer name</th>\n",
       "      <th>attributes</th>\n",
       "      <th>parent</th>\n",
       "      <th>enveloping</th>\n",
       "      <th>ambiguous</th>\n",
       "      <th>span count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>sentences</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>words</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>tokens</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>compound_tokens</td>\n",
       "      <td>type, normalized</td>\n",
       "      <td>None</td>\n",
       "      <td>tokens</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>words</td>\n",
       "      <td>normalized_form</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>morph_analysis</td>\n",
       "      <td>normalized_text, lemma, root, root_tokens, ending, clitic, form, partofspeech</td>\n",
       "      <td>words</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>wordner</td>\n",
       "      <td>nertag</td>\n",
       "      <td>None</td>\n",
       "      <td>words</td>\n",
       "      <td>False</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "Text(text='Tallinna õhusaaste suureneb.')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nertagger.tag(testtext)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h4>Layer</h4>\n",
       "\n",
       "\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>layer name</th>\n",
       "      <th>attributes</th>\n",
       "      <th>parent</th>\n",
       "      <th>enveloping</th>\n",
       "      <th>ambiguous</th>\n",
       "      <th>span count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>wordner</td>\n",
       "      <td>nertag</td>\n",
       "      <td>None</td>\n",
       "      <td>words</td>\n",
       "      <td>False</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>text</th>\n",
       "      <th>nertag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>Tallinna</td>\n",
       "      <td>B-LOC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>õhusaaste</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>suureneb</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>.</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "Layer(name='wordner', attributes=('nertag',), spans=SL[EnvelopingSpan('Tallinna', [{'nertag': 'B-LOC'}]),\n",
       "EnvelopingSpan('õhusaaste', [{'nertag': 'O'}]),\n",
       "EnvelopingSpan('suureneb', [{'nertag': 'O'}]),\n",
       "EnvelopingSpan('.', [{'nertag': 'O'}])])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testtext.wordner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td><div align = \"left\">Eesti on Euroopas.</div></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>layer name</th>\n",
       "      <th>attributes</th>\n",
       "      <th>parent</th>\n",
       "      <th>enveloping</th>\n",
       "      <th>ambiguous</th>\n",
       "      <th>span count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>sentences</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>words</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>tokens</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>compound_tokens</td>\n",
       "      <td>type, normalized</td>\n",
       "      <td>None</td>\n",
       "      <td>tokens</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>words</td>\n",
       "      <td>normalized_form</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>morph_analysis</td>\n",
       "      <td>normalized_text, lemma, root, root_tokens, ending, clitic, form, partofspeech</td>\n",
       "      <td>words</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "Text(text='Eesti on Euroopas.')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Text it hasn't seen before (new sentence)\n",
    "testtext2 = Text(\"Eesti on Euroopas.\")\n",
    "testtext2.tag_layer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td><div align = \"left\">Eesti on Euroopas.</div></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>layer name</th>\n",
       "      <th>attributes</th>\n",
       "      <th>parent</th>\n",
       "      <th>enveloping</th>\n",
       "      <th>ambiguous</th>\n",
       "      <th>span count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>sentences</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>words</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>tokens</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>compound_tokens</td>\n",
       "      <td>type, normalized</td>\n",
       "      <td>None</td>\n",
       "      <td>tokens</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>words</td>\n",
       "      <td>normalized_form</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>morph_analysis</td>\n",
       "      <td>normalized_text, lemma, root, root_tokens, ending, clitic, form, partofspeech</td>\n",
       "      <td>words</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>wordner</td>\n",
       "      <td>nertag</td>\n",
       "      <td>None</td>\n",
       "      <td>words</td>\n",
       "      <td>False</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "Text(text='Eesti on Euroopas.')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nertagger.tag(testtext2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h4>Layer</h4>\n",
       "\n",
       "\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>layer name</th>\n",
       "      <th>attributes</th>\n",
       "      <th>parent</th>\n",
       "      <th>enveloping</th>\n",
       "      <th>ambiguous</th>\n",
       "      <th>span count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>wordner</td>\n",
       "      <td>nertag</td>\n",
       "      <td>None</td>\n",
       "      <td>words</td>\n",
       "      <td>False</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>text</th>\n",
       "      <th>nertag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>Eesti</td>\n",
       "      <td>B-LOC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>on</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Euroopas</td>\n",
       "      <td>B-LOC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>.</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "Layer(name='wordner', attributes=('nertag',), spans=SL[EnvelopingSpan('Eesti', [{'nertag': 'B-LOC'}]),\n",
       "EnvelopingSpan('on', [{'nertag': 'O'}]),\n",
       "EnvelopingSpan('Euroopas', [{'nertag': 'B-LOC'}]),\n",
       "EnvelopingSpan('.', [{'nertag': 'O'}])])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testtext2.wordner"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another option is to use NerTagger, which will give NER-tags only to the named entities it finds in the given text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from estnltk.taggers import NerTagger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "tagger = NerTagger(model_dir='ner_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td><div align = \"left\">Tallinna õhusaaste suureneb.</div></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>layer name</th>\n",
       "      <th>attributes</th>\n",
       "      <th>parent</th>\n",
       "      <th>enveloping</th>\n",
       "      <th>ambiguous</th>\n",
       "      <th>span count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>sentences</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>words</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>tokens</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>compound_tokens</td>\n",
       "      <td>type, normalized</td>\n",
       "      <td>None</td>\n",
       "      <td>tokens</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>words</td>\n",
       "      <td>normalized_form</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>morph_analysis</td>\n",
       "      <td>normalized_text, lemma, root, root_tokens, ending, clitic, form, partofspeech</td>\n",
       "      <td>words</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>ner</td>\n",
       "      <td>nertag</td>\n",
       "      <td>None</td>\n",
       "      <td>words</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>wordner</td>\n",
       "      <td>nertag</td>\n",
       "      <td>None</td>\n",
       "      <td>words</td>\n",
       "      <td>False</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "Text(text='Tallinna õhusaaste suureneb.')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tagger.tag(testtext)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h4>Layer</h4>\n",
       "\n",
       "\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>layer name</th>\n",
       "      <th>attributes</th>\n",
       "      <th>parent</th>\n",
       "      <th>enveloping</th>\n",
       "      <th>ambiguous</th>\n",
       "      <th>span count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>ner</td>\n",
       "      <td>nertag</td>\n",
       "      <td>None</td>\n",
       "      <td>words</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>text</th>\n",
       "      <th>nertag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>['Tallinna']</td>\n",
       "      <td>LOC</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "Layer(name='ner', attributes=('nertag',), spans=SL[EnvelopingSpan(['Tallinna'], [{'nertag': 'LOC'}])])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testtext.ner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td><div align = \"left\">Eesti on Euroopas.</div></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>layer name</th>\n",
       "      <th>attributes</th>\n",
       "      <th>parent</th>\n",
       "      <th>enveloping</th>\n",
       "      <th>ambiguous</th>\n",
       "      <th>span count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>sentences</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>words</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>tokens</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>compound_tokens</td>\n",
       "      <td>type, normalized</td>\n",
       "      <td>None</td>\n",
       "      <td>tokens</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>words</td>\n",
       "      <td>normalized_form</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>morph_analysis</td>\n",
       "      <td>normalized_text, lemma, root, root_tokens, ending, clitic, form, partofspeech</td>\n",
       "      <td>words</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>ner</td>\n",
       "      <td>nertag</td>\n",
       "      <td>None</td>\n",
       "      <td>words</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>wordner</td>\n",
       "      <td>nertag</td>\n",
       "      <td>None</td>\n",
       "      <td>words</td>\n",
       "      <td>False</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "Text(text='Eesti on Euroopas.')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tagger.tag(testtext2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h4>Layer</h4>\n",
       "\n",
       "\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>layer name</th>\n",
       "      <th>attributes</th>\n",
       "      <th>parent</th>\n",
       "      <th>enveloping</th>\n",
       "      <th>ambiguous</th>\n",
       "      <th>span count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>ner</td>\n",
       "      <td>nertag</td>\n",
       "      <td>None</td>\n",
       "      <td>words</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>text</th>\n",
       "      <th>nertag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>['Eesti']</td>\n",
       "      <td>LOC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>['Euroopas']</td>\n",
       "      <td>LOC</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "Layer(name='ner', attributes=('nertag',), spans=SL[EnvelopingSpan(['Eesti'], [{'nertag': 'LOC'}]),\n",
       "EnvelopingSpan(['Euroopas'], [{'nertag': 'LOC'}])])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testtext2.ner"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluating on a text with existing labelling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td><div align = \"left\">Riigi kutsekoolidest sai kõige viletsama tulemuse Põltsamaa Kodu - ja Põllumajanduskool , kus kvaliteedistandarditele ei vastanud 33 protsenti kutseõpetajatest ja 27 protsenti üldharidusainete õpetajatest . Kooli direktori asetäitja Tambet Valdma sõnul peetakse nende koolis õpetajatena lugu ka väga headest oma ala spetsialistidest ja praktikutest , kel ei pruugi vastava ainevaldkonna paberit taskus olla . Vajadust kaasata praktikuid kinnitas ka tööandjate keskliidu tööturunõunik Thor-Sten Vertmann . Tema sõnul on kutsekoolides erialasid , mis jääksid kõigilt õpetajatelt erialast kõrgharidust nõudes täielikult ajast maha . Haridusministeeriumi kutse - ja täiskasvanuhariduse osakonna juhataja Andres Pung märkis , et kutsekooliõpetajate hindamise kriteeriume senisest leebemaks muutmine tooks koolidesse rohkem oma ala praktikuid . Kehtiva korra järgi võib praktik küll koolis töötada , kui ta on vähemalt kolm aastat töötanud oma erialal ja jätkab põhitööd ka kooli kõrvalt . Põhikohaga tööd tegevad õpetajad , kel pole pedagoogilist haridus , peavad läbima 320 tunni pikkuse õpetajakoolituse . “ Tundub , et see osa on küll natuke ülepingutatud ning neid mahtusid saaks kindlasti vähendada , ” sõnas Pung . 15-aastase Leedu poisi tapjad on tabatud . Leedu linnas Visaginases võttis politsei kinni kaks noormeest , keda kahtlustatakse 15-aastase koolipoisi tapmises . Kaheksanda klassi õpilase Aleksei Selivanovi läbilõigatud kõri ning rohkete torke - ja lõikehaavadega laip leiti kolmapäeva õhtul . Poiss oli tapetud oma kodu lähedal . Politsei pidas neljapäeval mõrvas kahtlustatutena kinni kaks 17-aastast Visaginase elanikku . Üks neist oli nähtavasti mõrva tellija , teine aga täideviija . Kinnipeetud on oma süü üles tunnistanud . Visaginase politsei otsib taga veel kaht mõrvas osalenut . Esialgsetel andmetel tapeti 15-aastane poiss ühe tüdruku pärast . Pärast kuriteo avastamist on Visaginase linna haaranud paanika . Vanemad kardavad oma lapsi kooli saata . Leedu noores linnas Visaginases , mis ehitati 20 aastat tagasi koos Ignalina aatomielektrijaamaga , oli see esimene alaealise mõrv . Kümned kalamehed jäid taas Peipsil hätta . Peipsil jäid pühapäeval taas hätta kümned kalamehed , kes kaldale saamiseks abi vajasid . Järvejäässe tekkis läänetuulega Peipsi Eesti poolele kümne kuni 200 meetri laiune lõhe , mis jääb 400 meetri kuni kahe kilomeetri kaugusele kaldast . Piirivalveameti pressiesindaja ütles BNS-ile , et ennelõunal tõi piirivalve hõljuk Kauksi alt ära neli kalurit , kuid 12.30 paiku tuli teade suuremast hulgast hädalistest . Pala vallas Ranna asula juures olid teisele poole jääpragu jäänud hinnanguliselt 50-60 kalameest . Kella 16 oli piirivalve ja kohalikud elanikud oma paatidega neist paarkümmend maale toimetanud . Pressiesindaja sõnul ohtlikku olukorda kalameeste jaoks tekkinud ei ole ja päästetööd sujuvad plaanipäraselt . “ Täiesti võimatu oleks kustutada põlevaid kütusemahuteid ning tuleks oodata kuni kütuse täieliku väljapõlemiseni mahutitest . Bensiini ja muude vedelkütuste mahutite plahvatuste juhul ei oleks võimalik päästa terminalide töötajaid ega ka terminalis olevate laevade meeskonnaliikmeid , rääkimata juba kahjustavast mõjust ümbritsevale keskkonnale , Eesti majandusele ja rahvusvahelisele mainele , ” hoiatab turvafirma juhatuse esimees Aleksander Kaspin riigikantseleile saadetud kirjas .</div></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>layer name</th>\n",
       "      <th>attributes</th>\n",
       "      <th>parent</th>\n",
       "      <th>enveloping</th>\n",
       "      <th>ambiguous</th>\n",
       "      <th>span count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>sentences</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>words</td>\n",
       "      <td>False</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>compound_tokens</td>\n",
       "      <td>type, normalized</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>words</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>morph_analysis</td>\n",
       "      <td>normalized_text, lemma, root, root_tokens, ending, clitic, form, partofspeech</td>\n",
       "      <td>words</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>wordner</td>\n",
       "      <td>nertag</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>471</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "Text(text='Riigi kutsekoolidest sai kõige viletsama tulemuse Põltsamaa Kodu - ja Põllumajanduskool , kus kvaliteedistandarditele ei vastanud 33 protsenti kutseõpetajatest ja 27 protsenti üldharidusainete õpetajatest . Kooli direktori asetäitja Tambet Valdma sõnul peetakse nende koolis õpetajatena lugu ka väga headest oma ala spetsialistidest ja praktikutest , kel ei pruugi vastava ainevaldkonna paberit taskus olla . Vajadust kaasata praktikuid kinnitas ka tööandjate keskliidu tööturunõunik Thor-Sten Vertmann . Tema sõnul on kutsekoolides erialasid , mis jääksid kõigilt õpetajatelt erialast kõrgharidust nõudes täielikult ajast maha . Haridusministeeriumi kutse - ja täiskasvanuhariduse osakonna juhataja Andres Pung märkis , et kutsekooliõpetajate hindamise kriteeriume senisest leebemaks muutmine tooks koolidesse rohkem oma ala praktikuid . Kehtiva korra järgi võib praktik küll koolis töötada , kui ta on vähemalt kolm aastat töötanud oma erialal ja jätkab põhitööd ka kooli kõrvalt . Põhikohaga tööd tegevad õpetajad , kel pole pedagoogilist haridus , peavad läbima 320 tunni pikkuse õpetajakoolituse . “ Tundub , et see osa on küll natuke ülepingutatud ning neid mahtusid saaks kindlasti vähendada , ” sõnas Pung . 15-aastase Leedu poisi tapjad on tabatud . Leedu linnas Visaginases võttis politsei kinni kaks noormeest , keda kahtlustatakse 15-aastase koolipoisi tapmises . Kaheksanda klassi õpilase Aleksei Selivanovi läbilõigatud kõri ning rohkete torke - ja lõikehaavadega laip leiti kolmapäeva õhtul . Poiss oli tapetud oma kodu lähedal . Politsei pidas neljapäeval mõrvas kahtlustatutena kinni kaks 17-aastast Visaginase elanikku . Üks neist oli nähtavasti mõrva tellija , teine aga täideviija . Kinnipeetud on oma süü üles tunnistanud . Visaginase politsei otsib taga veel kaht mõrvas osalenut . Esialgsetel andmetel tapeti 15-aastane poiss ühe tüdruku pärast . Pärast kuriteo avastamist on Visaginase linna haaranud paanika . Vanemad kardavad oma lapsi kooli saata . Leedu noores linnas Visaginases , mis ehitati 20 aastat tagasi koos Ignalina aatomielektrijaamaga , oli see esimene alaealise mõrv . Kümned kalamehed jäid taas Peipsil hätta . Peipsil jäid pühapäeval taas hätta kümned kalamehed , kes kaldale saamiseks abi vajasid . Järvejäässe tekkis läänetuulega Peipsi Eesti poolele kümne kuni 200 meetri laiune lõhe , mis jääb 400 meetri kuni kahe kilomeetri kaugusele kaldast . Piirivalveameti pressiesindaja ütles BNS-ile , et ennelõunal tõi piirivalve hõljuk Kauksi alt ära neli kalurit , kuid 12.30 paiku tuli teade suuremast hulgast hädalistest . Pala vallas Ranna asula juures olid teisele poole jääpragu jäänud hinnanguliselt 50-60 kalameest . Kella 16 oli piirivalve ja kohalikud elanikud oma paatidega neist paarkümmend maale toimetanud . Pressiesindaja sõnul ohtlikku olukorda kalameeste jaoks tekkinud ei ole ja päästetööd sujuvad plaanipäraselt . “ Täiesti võimatu oleks kustutada põlevaid kütusemahuteid ning tuleks oodata kuni kütuse täieliku väljapõlemiseni mahutitest . Bensiini ja muude vedelkütuste mahutite plahvatuste juhul ei oleks võimalik päästa terminalide töötajaid ega ka terminalis olevate laevade meeskonnaliikmeid , rääkimata juba kahjustavast mõjust ümbritsevale keskkonnale , Eesti majandusele ja rahvusvahelisele mainele , ” hoiatab turvafirma juhatuse esimees Aleksander Kaspin riigikantseleile saadetud kirjas .')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = conll_to_ner_labelling(\"data/ner_test.cnll\")\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "nerlayer = test.wordner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h4>Layer</h4>\n",
       "\n",
       "\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>layer name</th>\n",
       "      <th>attributes</th>\n",
       "      <th>parent</th>\n",
       "      <th>enveloping</th>\n",
       "      <th>ambiguous</th>\n",
       "      <th>span count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>wordner</td>\n",
       "      <td>nertag</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>471</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>text</th>\n",
       "      <th>nertag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>Riigi</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>kutsekoolidest</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>sai</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>kõige</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>viletsama</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>tulemuse</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Põltsamaa</td>\n",
       "      <td>B-ORG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Kodu</td>\n",
       "      <td>I-ORG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>-</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>ja</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Põllumajanduskool</td>\n",
       "      <td>B-ORG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>,</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>kus</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>kvaliteedistandarditele</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>ei</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>vastanud</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>protsenti</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>kutseõpetajatest</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>ja</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>protsenti</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>üldharidusainete</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>õpetajatest</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>.</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Kooli</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>direktori</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>asetäitja</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Tambet</td>\n",
       "      <td>B-PER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Valdma</td>\n",
       "      <td>I-PER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>sõnul</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>peetakse</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>nende</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>koolis</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>õpetajatena</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>lugu</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>ka</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>väga</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>headest</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>oma</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>ala</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>spetsialistidest</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>ja</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>praktikutest</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>,</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>kel</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>ei</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>pruugi</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>vastava</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>ainevaldkonna</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>paberit</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>taskus</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>olla</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>.</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Vajadust</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>kaasata</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>praktikuid</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>kinnitas</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>ka</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>tööandjate</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>keskliidu</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>tööturunõunik</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Thor-Sten</td>\n",
       "      <td>B-PER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Vertmann</td>\n",
       "      <td>I-PER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>.</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Tema</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>sõnul</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>on</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>kutsekoolides</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>erialasid</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>,</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>mis</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>jääksid</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>kõigilt</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>õpetajatelt</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>erialast</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>kõrgharidust</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>nõudes</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>täielikult</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>ajast</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>maha</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>.</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Haridusministeeriumi</td>\n",
       "      <td>B-ORG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>kutse</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>-</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>ja</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>täiskasvanuhariduse</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>osakonna</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>juhataja</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Andres</td>\n",
       "      <td>B-PER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Pung</td>\n",
       "      <td>I-PER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>märkis</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>,</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>et</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>kutsekooliõpetajate</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>hindamise</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>kriteeriume</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>senisest</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>leebemaks</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>muutmine</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>tooks</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>koolidesse</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>rohkem</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>oma</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>ala</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>praktikuid</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>.</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Kehtiva</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>korra</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>järgi</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>võib</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>praktik</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>küll</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>koolis</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>töötada</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>,</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>kui</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>ta</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>on</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>vähemalt</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>kolm</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>aastat</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>töötanud</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>oma</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>erialal</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>ja</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>jätkab</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>põhitööd</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>ka</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>kooli</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>kõrvalt</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>.</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Põhikohaga</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>tööd</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>tegevad</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>õpetajad</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>,</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>kel</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>pole</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>pedagoogilist</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>haridus</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>,</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>peavad</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>läbima</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>tunni</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>pikkuse</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>õpetajakoolituse</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>.</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>“</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Tundub</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>,</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>et</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>see</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>osa</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>on</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>küll</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>natuke</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>ülepingutatud</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>ning</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>neid</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>mahtusid</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>saaks</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>kindlasti</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>vähendada</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>,</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>”</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>sõnas</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Pung</td>\n",
       "      <td>B-PER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>.</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15-aastase</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Leedu</td>\n",
       "      <td>B-LOC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>poisi</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>tapjad</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>on</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>tabatud</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>.</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Leedu</td>\n",
       "      <td>B-LOC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>linnas</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Visaginases</td>\n",
       "      <td>B-LOC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>võttis</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>politsei</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>kinni</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>kaks</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>noormeest</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>,</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>keda</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>kahtlustatakse</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15-aastase</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>koolipoisi</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>tapmises</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>.</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Kaheksanda</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>klassi</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>õpilase</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Aleksei</td>\n",
       "      <td>B-PER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Selivanovi</td>\n",
       "      <td>I-PER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>läbilõigatud</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>kõri</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>ning</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>rohkete</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>torke</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>-</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>ja</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>lõikehaavadega</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>laip</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>leiti</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>kolmapäeva</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>õhtul</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>.</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Poiss</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>oli</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>tapetud</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>oma</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>kodu</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>lähedal</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>.</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Politsei</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>pidas</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>neljapäeval</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>mõrvas</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>kahtlustatutena</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>kinni</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>kaks</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17-aastast</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Visaginase</td>\n",
       "      <td>B-LOC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>elanikku</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>.</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Üks</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>neist</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>oli</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>nähtavasti</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>mõrva</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>tellija</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>,</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>teine</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>aga</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>täideviija</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>.</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Kinnipeetud</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>on</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>oma</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>süü</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>üles</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>tunnistanud</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>.</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Visaginase</td>\n",
       "      <td>B-ORG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>politsei</td>\n",
       "      <td>I-ORG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>otsib</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>taga</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>veel</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>kaht</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>mõrvas</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>osalenut</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>.</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Esialgsetel</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>andmetel</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>tapeti</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15-aastane</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>poiss</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>ühe</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>tüdruku</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>pärast</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>.</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Pärast</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>kuriteo</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>avastamist</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>on</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Visaginase</td>\n",
       "      <td>B-LOC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>linna</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>haaranud</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>paanika</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>.</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Vanemad</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>kardavad</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>oma</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>lapsi</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>kooli</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>saata</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>.</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Leedu</td>\n",
       "      <td>B-LOC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>noores</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>linnas</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Visaginases</td>\n",
       "      <td>B-LOC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>,</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>mis</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>ehitati</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>aastat</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>tagasi</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>koos</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Ignalina</td>\n",
       "      <td>B-LOC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>aatomielektrijaamaga</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>,</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>oli</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>see</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>esimene</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>alaealise</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>mõrv</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>.</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Kümned</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>kalamehed</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>jäid</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>taas</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Peipsil</td>\n",
       "      <td>B-LOC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>hätta</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>.</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Peipsil</td>\n",
       "      <td>B-LOC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>jäid</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>pühapäeval</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>taas</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>hätta</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>kümned</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>kalamehed</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>,</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>kes</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>kaldale</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>saamiseks</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>abi</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>vajasid</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>.</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Järvejäässe</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>tekkis</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>läänetuulega</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Peipsi</td>\n",
       "      <td>B-LOC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Eesti</td>\n",
       "      <td>I-LOC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>poolele</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>kümne</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>kuni</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>meetri</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>laiune</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>lõhe</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>,</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>mis</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>jääb</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>meetri</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>kuni</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>kahe</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>kilomeetri</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>kaugusele</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>kaldast</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>.</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Piirivalveameti</td>\n",
       "      <td>B-ORG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>pressiesindaja</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>ütles</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>BNS-ile</td>\n",
       "      <td>B-ORG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>,</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>et</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>ennelõunal</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>tõi</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>piirivalve</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>hõljuk</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Kauksi</td>\n",
       "      <td>B-LOC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>alt</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>ära</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>neli</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>kalurit</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>,</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>kuid</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12.30</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>paiku</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>tuli</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>teade</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>suuremast</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>hulgast</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>hädalistest</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>.</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Pala</td>\n",
       "      <td>B-LOC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>vallas</td>\n",
       "      <td>I-LOC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Ranna</td>\n",
       "      <td>B-LOC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>asula</td>\n",
       "      <td>I-LOC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>juures</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>olid</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>teisele</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>poole</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>jääpragu</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>jäänud</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>hinnanguliselt</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50-60</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>kalameest</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>.</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Kella</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>oli</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>piirivalve</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>ja</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>kohalikud</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>elanikud</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>oma</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>paatidega</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>neist</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>paarkümmend</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>maale</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>toimetanud</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>.</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Pressiesindaja</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>sõnul</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>ohtlikku</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>olukorda</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>kalameeste</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>jaoks</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>tekkinud</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>ei</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>ole</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>ja</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>päästetööd</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>sujuvad</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>plaanipäraselt</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>.</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>“</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Täiesti</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>võimatu</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>oleks</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>kustutada</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>põlevaid</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>kütusemahuteid</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>ning</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>tuleks</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>oodata</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>kuni</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>kütuse</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>täieliku</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>väljapõlemiseni</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>mahutitest</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>.</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Bensiini</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>ja</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>muude</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>vedelkütuste</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>mahutite</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>plahvatuste</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>juhul</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>ei</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>oleks</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>võimalik</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>päästa</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>terminalide</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>töötajaid</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>ega</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>ka</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>terminalis</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>olevate</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>laevade</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>meeskonnaliikmeid</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>,</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>rääkimata</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>juba</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>kahjustavast</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>mõjust</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>ümbritsevale</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>keskkonnale</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>,</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Eesti</td>\n",
       "      <td>B-LOC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>majandusele</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>ja</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>rahvusvahelisele</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>mainele</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>,</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>”</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>hoiatab</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>turvafirma</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>juhatuse</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>esimees</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Aleksander</td>\n",
       "      <td>B-PER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Kaspin</td>\n",
       "      <td>I-PER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>riigikantseleile</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>saadetud</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>kirjas</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>.</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "Layer(name='wordner', attributes=('nertag',), spans=SL[Span('Riigi', [{'nertag': 'O'}]),\n",
       "Span('kutsekoolidest', [{'nertag': 'O'}]),\n",
       "Span('sai', [{'nertag': 'O'}]),\n",
       "Span('kõige', [{'nertag': 'O'}]),\n",
       "Span('viletsama', [{'nertag': 'O'}]),\n",
       "Span('tulemuse', [{'nertag': 'O'}]),\n",
       "Span('Põltsamaa', [{'nertag': 'B-ORG'}]),\n",
       "Span('Kodu', [{'nertag': 'I-ORG'}]),\n",
       "Span('-', [{'nertag': 'O'}]),\n",
       "Span('ja', [{'nertag': 'O'}]),\n",
       "Span('Põllumajanduskool', [{'nertag': 'B-ORG'}]),\n",
       "Span(',', [{'nertag': 'O'}]),\n",
       "Span('kus', [{'nertag': 'O'}]),\n",
       "Span('kvaliteedistandarditele', [{'nertag': 'O'}]),\n",
       "Span('ei', [{'nertag': 'O'}]),\n",
       "Span('vastanud', [{'nertag': 'O'}]),\n",
       "Span('33', [{'nertag': 'O'}]),\n",
       "Span('protsenti', [{'nertag': 'O'}]),\n",
       "Span('kutseõpetajatest', [{'nertag': 'O'}]),\n",
       "Span('ja', [{'nertag': 'O'}]),\n",
       "Span('27', [{'nertag': 'O'}]),\n",
       "Span('protsenti', [{'nertag': 'O'}]),\n",
       "Span('üldharidusainete', [{'nertag': 'O'}]),\n",
       "Span('õpetajatest', [{'nertag': 'O'}]),\n",
       "Span('.', [{'nertag': 'O'}]),\n",
       "Span('Kooli', [{'nertag': 'O'}]),\n",
       "Span('direktori', [{'nertag': 'O'}]),\n",
       "Span('asetäitja', [{'nertag': 'O'}]),\n",
       "Span('Tambet', [{'nertag': 'B-PER'}]),\n",
       "Span('Valdma', [{'nertag': 'I-PER'}]),\n",
       "Span('sõnul', [{'nertag': 'O'}]),\n",
       "Span('peetakse', [{'nertag': 'O'}]),\n",
       "Span('nende', [{'nertag': 'O'}]),\n",
       "Span('koolis', [{'nertag': 'O'}]),\n",
       "Span('õpetajatena', [{'nertag': 'O'}]),\n",
       "Span('lugu', [{'nertag': 'O'}]),\n",
       "Span('ka', [{'nertag': 'O'}]),\n",
       "Span('väga', [{'nertag': 'O'}]),\n",
       "Span('headest', [{'nertag': 'O'}]),\n",
       "Span('oma', [{'nertag': 'O'}]),\n",
       "Span('ala', [{'nertag': 'O'}]),\n",
       "Span('spetsialistidest', [{'nertag': 'O'}]),\n",
       "Span('ja', [{'nertag': 'O'}]),\n",
       "Span('praktikutest', [{'nertag': 'O'}]),\n",
       "Span(',', [{'nertag': 'O'}]),\n",
       "Span('kel', [{'nertag': 'O'}]),\n",
       "Span('ei', [{'nertag': 'O'}]),\n",
       "Span('pruugi', [{'nertag': 'O'}]),\n",
       "Span('vastava', [{'nertag': 'O'}]),\n",
       "Span('ainevaldkonna', [{'nertag': 'O'}]),\n",
       "Span('paberit', [{'nertag': 'O'}]),\n",
       "Span('taskus', [{'nertag': 'O'}]),\n",
       "Span('olla', [{'nertag': 'O'}]),\n",
       "Span('.', [{'nertag': 'O'}]),\n",
       "Span('Vajadust', [{'nertag': 'O'}]),\n",
       "Span('kaasata', [{'nertag': 'O'}]),\n",
       "Span('praktikuid', [{'nertag': 'O'}]),\n",
       "Span('kinnitas', [{'nertag': 'O'}]),\n",
       "Span('ka', [{'nertag': 'O'}]),\n",
       "Span('tööandjate', [{'nertag': 'O'}]),\n",
       "Span('keskliidu', [{'nertag': 'O'}]),\n",
       "Span('tööturunõunik', [{'nertag': 'O'}]),\n",
       "Span('Thor-Sten', [{'nertag': 'B-PER'}]),\n",
       "Span('Vertmann', [{'nertag': 'I-PER'}]),\n",
       "Span('.', [{'nertag': 'O'}]),\n",
       "Span('Tema', [{'nertag': 'O'}]),\n",
       "Span('sõnul', [{'nertag': 'O'}]),\n",
       "Span('on', [{'nertag': 'O'}]),\n",
       "Span('kutsekoolides', [{'nertag': 'O'}]),\n",
       "Span('erialasid', [{'nertag': 'O'}]),\n",
       "Span(',', [{'nertag': 'O'}]),\n",
       "Span('mis', [{'nertag': 'O'}]),\n",
       "Span('jääksid', [{'nertag': 'O'}]),\n",
       "Span('kõigilt', [{'nertag': 'O'}]),\n",
       "Span('õpetajatelt', [{'nertag': 'O'}]),\n",
       "Span('erialast', [{'nertag': 'O'}]),\n",
       "Span('kõrgharidust', [{'nertag': 'O'}]),\n",
       "Span('nõudes', [{'nertag': 'O'}]),\n",
       "Span('täielikult', [{'nertag': 'O'}]),\n",
       "Span('ajast', [{'nertag': 'O'}]),\n",
       "Span('maha', [{'nertag': 'O'}]),\n",
       "Span('.', [{'nertag': 'O'}]),\n",
       "Span('Haridusministeeriumi', [{'nertag': 'B-ORG'}]),\n",
       "Span('kutse', [{'nertag': 'O'}]),\n",
       "Span('-', [{'nertag': 'O'}]),\n",
       "Span('ja', [{'nertag': 'O'}]),\n",
       "Span('täiskasvanuhariduse', [{'nertag': 'O'}]),\n",
       "Span('osakonna', [{'nertag': 'O'}]),\n",
       "Span('juhataja', [{'nertag': 'O'}]),\n",
       "Span('Andres', [{'nertag': 'B-PER'}]),\n",
       "Span('Pung', [{'nertag': 'I-PER'}]),\n",
       "Span('märkis', [{'nertag': 'O'}]),\n",
       "Span(',', [{'nertag': 'O'}]),\n",
       "Span('et', [{'nertag': 'O'}]),\n",
       "Span('kutsekooliõpetajate', [{'nertag': 'O'}]),\n",
       "Span('hindamise', [{'nertag': 'O'}]),\n",
       "Span('kriteeriume', [{'nertag': 'O'}]),\n",
       "Span('senisest', [{'nertag': 'O'}]),\n",
       "Span('leebemaks', [{'nertag': 'O'}]),\n",
       "Span('muutmine', [{'nertag': 'O'}]),\n",
       "Span('tooks', [{'nertag': 'O'}]),\n",
       "Span('koolidesse', [{'nertag': 'O'}]),\n",
       "Span('rohkem', [{'nertag': 'O'}]),\n",
       "Span('oma', [{'nertag': 'O'}]),\n",
       "Span('ala', [{'nertag': 'O'}]),\n",
       "Span('praktikuid', [{'nertag': 'O'}]),\n",
       "Span('.', [{'nertag': 'O'}]),\n",
       "Span('Kehtiva', [{'nertag': 'O'}]),\n",
       "Span('korra', [{'nertag': 'O'}]),\n",
       "Span('järgi', [{'nertag': 'O'}]),\n",
       "Span('võib', [{'nertag': 'O'}]),\n",
       "Span('praktik', [{'nertag': 'O'}]),\n",
       "Span('küll', [{'nertag': 'O'}]),\n",
       "Span('koolis', [{'nertag': 'O'}]),\n",
       "Span('töötada', [{'nertag': 'O'}]),\n",
       "Span(',', [{'nertag': 'O'}]),\n",
       "Span('kui', [{'nertag': 'O'}]),\n",
       "Span('ta', [{'nertag': 'O'}]),\n",
       "Span('on', [{'nertag': 'O'}]),\n",
       "Span('vähemalt', [{'nertag': 'O'}]),\n",
       "Span('kolm', [{'nertag': 'O'}]),\n",
       "Span('aastat', [{'nertag': 'O'}]),\n",
       "Span('töötanud', [{'nertag': 'O'}]),\n",
       "Span('oma', [{'nertag': 'O'}]),\n",
       "Span('erialal', [{'nertag': 'O'}]),\n",
       "Span('ja', [{'nertag': 'O'}]),\n",
       "Span('jätkab', [{'nertag': 'O'}]),\n",
       "Span('põhitööd', [{'nertag': 'O'}]),\n",
       "Span('ka', [{'nertag': 'O'}]),\n",
       "Span('kooli', [{'nertag': 'O'}]),\n",
       "Span('kõrvalt', [{'nertag': 'O'}]),\n",
       "Span('.', [{'nertag': 'O'}]),\n",
       "Span('Põhikohaga', [{'nertag': 'O'}]),\n",
       "Span('tööd', [{'nertag': 'O'}]),\n",
       "Span('tegevad', [{'nertag': 'O'}]),\n",
       "Span('õpetajad', [{'nertag': 'O'}]),\n",
       "Span(',', [{'nertag': 'O'}]),\n",
       "Span('kel', [{'nertag': 'O'}]),\n",
       "Span('pole', [{'nertag': 'O'}]),\n",
       "Span('pedagoogilist', [{'nertag': 'O'}]),\n",
       "Span('haridus', [{'nertag': 'O'}]),\n",
       "Span(',', [{'nertag': 'O'}]),\n",
       "Span('peavad', [{'nertag': 'O'}]),\n",
       "Span('läbima', [{'nertag': 'O'}]),\n",
       "Span('320', [{'nertag': 'O'}]),\n",
       "Span('tunni', [{'nertag': 'O'}]),\n",
       "Span('pikkuse', [{'nertag': 'O'}]),\n",
       "Span('õpetajakoolituse', [{'nertag': 'O'}]),\n",
       "Span('.', [{'nertag': 'O'}]),\n",
       "Span('“', [{'nertag': 'O'}]),\n",
       "Span('Tundub', [{'nertag': 'O'}]),\n",
       "Span(',', [{'nertag': 'O'}]),\n",
       "Span('et', [{'nertag': 'O'}]),\n",
       "Span('see', [{'nertag': 'O'}]),\n",
       "Span('osa', [{'nertag': 'O'}]),\n",
       "Span('on', [{'nertag': 'O'}]),\n",
       "Span('küll', [{'nertag': 'O'}]),\n",
       "Span('natuke', [{'nertag': 'O'}]),\n",
       "Span('ülepingutatud', [{'nertag': 'O'}]),\n",
       "Span('ning', [{'nertag': 'O'}]),\n",
       "Span('neid', [{'nertag': 'O'}]),\n",
       "Span('mahtusid', [{'nertag': 'O'}]),\n",
       "Span('saaks', [{'nertag': 'O'}]),\n",
       "Span('kindlasti', [{'nertag': 'O'}]),\n",
       "Span('vähendada', [{'nertag': 'O'}]),\n",
       "Span(',', [{'nertag': 'O'}]),\n",
       "Span('”', [{'nertag': 'O'}]),\n",
       "Span('sõnas', [{'nertag': 'O'}]),\n",
       "Span('Pung', [{'nertag': 'B-PER'}]),\n",
       "Span('.', [{'nertag': 'O'}]),\n",
       "Span('15-aastase', [{'nertag': 'O'}]),\n",
       "Span('Leedu', [{'nertag': 'B-LOC'}]),\n",
       "Span('poisi', [{'nertag': 'O'}]),\n",
       "Span('tapjad', [{'nertag': 'O'}]),\n",
       "Span('on', [{'nertag': 'O'}]),\n",
       "Span('tabatud', [{'nertag': 'O'}]),\n",
       "Span('.', [{'nertag': 'O'}]),\n",
       "Span('Leedu', [{'nertag': 'B-LOC'}]),\n",
       "Span('linnas', [{'nertag': 'O'}]),\n",
       "Span('Visaginases', [{'nertag': 'B-LOC'}]),\n",
       "Span('võttis', [{'nertag': 'O'}]),\n",
       "Span('politsei', [{'nertag': 'O'}]),\n",
       "Span('kinni', [{'nertag': 'O'}]),\n",
       "Span('kaks', [{'nertag': 'O'}]),\n",
       "Span('noormeest', [{'nertag': 'O'}]),\n",
       "Span(',', [{'nertag': 'O'}]),\n",
       "Span('keda', [{'nertag': 'O'}]),\n",
       "Span('kahtlustatakse', [{'nertag': 'O'}]),\n",
       "Span('15-aastase', [{'nertag': 'O'}]),\n",
       "Span('koolipoisi', [{'nertag': 'O'}]),\n",
       "Span('tapmises', [{'nertag': 'O'}]),\n",
       "Span('.', [{'nertag': 'O'}]),\n",
       "Span('Kaheksanda', [{'nertag': 'O'}]),\n",
       "Span('klassi', [{'nertag': 'O'}]),\n",
       "Span('õpilase', [{'nertag': 'O'}]),\n",
       "Span('Aleksei', [{'nertag': 'B-PER'}]),\n",
       "Span('Selivanovi', [{'nertag': 'I-PER'}]),\n",
       "Span('läbilõigatud', [{'nertag': 'O'}]),\n",
       "Span('kõri', [{'nertag': 'O'}]),\n",
       "Span('ning', [{'nertag': 'O'}]),\n",
       "Span('rohkete', [{'nertag': 'O'}]),\n",
       "Span('torke', [{'nertag': 'O'}]),\n",
       "Span('-', [{'nertag': 'O'}]),\n",
       "Span('ja', [{'nertag': 'O'}]),\n",
       "Span('lõikehaavadega', [{'nertag': 'O'}]),\n",
       "Span('laip', [{'nertag': 'O'}]),\n",
       "Span('leiti', [{'nertag': 'O'}]),\n",
       "Span('kolmapäeva', [{'nertag': 'O'}]),\n",
       "Span('õhtul', [{'nertag': 'O'}]),\n",
       "Span('.', [{'nertag': 'O'}]),\n",
       "Span('Poiss', [{'nertag': 'O'}]),\n",
       "Span('oli', [{'nertag': 'O'}]),\n",
       "Span('tapetud', [{'nertag': 'O'}]),\n",
       "Span('oma', [{'nertag': 'O'}]),\n",
       "Span('kodu', [{'nertag': 'O'}]),\n",
       "Span('lähedal', [{'nertag': 'O'}]),\n",
       "Span('.', [{'nertag': 'O'}]),\n",
       "Span('Politsei', [{'nertag': 'O'}]),\n",
       "Span('pidas', [{'nertag': 'O'}]),\n",
       "Span('neljapäeval', [{'nertag': 'O'}]),\n",
       "Span('mõrvas', [{'nertag': 'O'}]),\n",
       "Span('kahtlustatutena', [{'nertag': 'O'}]),\n",
       "Span('kinni', [{'nertag': 'O'}]),\n",
       "Span('kaks', [{'nertag': 'O'}]),\n",
       "Span('17-aastast', [{'nertag': 'O'}]),\n",
       "Span('Visaginase', [{'nertag': 'B-LOC'}]),\n",
       "Span('elanikku', [{'nertag': 'O'}]),\n",
       "Span('.', [{'nertag': 'O'}]),\n",
       "Span('Üks', [{'nertag': 'O'}]),\n",
       "Span('neist', [{'nertag': 'O'}]),\n",
       "Span('oli', [{'nertag': 'O'}]),\n",
       "Span('nähtavasti', [{'nertag': 'O'}]),\n",
       "Span('mõrva', [{'nertag': 'O'}]),\n",
       "Span('tellija', [{'nertag': 'O'}]),\n",
       "Span(',', [{'nertag': 'O'}]),\n",
       "Span('teine', [{'nertag': 'O'}]),\n",
       "Span('aga', [{'nertag': 'O'}]),\n",
       "Span('täideviija', [{'nertag': 'O'}]),\n",
       "Span('.', [{'nertag': 'O'}]),\n",
       "Span('Kinnipeetud', [{'nertag': 'O'}]),\n",
       "Span('on', [{'nertag': 'O'}]),\n",
       "Span('oma', [{'nertag': 'O'}]),\n",
       "Span('süü', [{'nertag': 'O'}]),\n",
       "Span('üles', [{'nertag': 'O'}]),\n",
       "Span('tunnistanud', [{'nertag': 'O'}]),\n",
       "Span('.', [{'nertag': 'O'}]),\n",
       "Span('Visaginase', [{'nertag': 'B-ORG'}]),\n",
       "Span('politsei', [{'nertag': 'I-ORG'}]),\n",
       "Span('otsib', [{'nertag': 'O'}]),\n",
       "Span('taga', [{'nertag': 'O'}]),\n",
       "Span('veel', [{'nertag': 'O'}]),\n",
       "Span('kaht', [{'nertag': 'O'}]),\n",
       "Span('mõrvas', [{'nertag': 'O'}]),\n",
       "Span('osalenut', [{'nertag': 'O'}]),\n",
       "Span('.', [{'nertag': 'O'}]),\n",
       "Span('Esialgsetel', [{'nertag': 'O'}]),\n",
       "Span('andmetel', [{'nertag': 'O'}]),\n",
       "Span('tapeti', [{'nertag': 'O'}]),\n",
       "Span('15-aastane', [{'nertag': 'O'}]),\n",
       "Span('poiss', [{'nertag': 'O'}]),\n",
       "Span('ühe', [{'nertag': 'O'}]),\n",
       "Span('tüdruku', [{'nertag': 'O'}]),\n",
       "Span('pärast', [{'nertag': 'O'}]),\n",
       "Span('.', [{'nertag': 'O'}]),\n",
       "Span('Pärast', [{'nertag': 'O'}]),\n",
       "Span('kuriteo', [{'nertag': 'O'}]),\n",
       "Span('avastamist', [{'nertag': 'O'}]),\n",
       "Span('on', [{'nertag': 'O'}]),\n",
       "Span('Visaginase', [{'nertag': 'B-LOC'}]),\n",
       "Span('linna', [{'nertag': 'O'}]),\n",
       "Span('haaranud', [{'nertag': 'O'}]),\n",
       "Span('paanika', [{'nertag': 'O'}]),\n",
       "Span('.', [{'nertag': 'O'}]),\n",
       "Span('Vanemad', [{'nertag': 'O'}]),\n",
       "Span('kardavad', [{'nertag': 'O'}]),\n",
       "Span('oma', [{'nertag': 'O'}]),\n",
       "Span('lapsi', [{'nertag': 'O'}]),\n",
       "Span('kooli', [{'nertag': 'O'}]),\n",
       "Span('saata', [{'nertag': 'O'}]),\n",
       "Span('.', [{'nertag': 'O'}]),\n",
       "Span('Leedu', [{'nertag': 'B-LOC'}]),\n",
       "Span('noores', [{'nertag': 'O'}]),\n",
       "Span('linnas', [{'nertag': 'O'}]),\n",
       "Span('Visaginases', [{'nertag': 'B-LOC'}]),\n",
       "Span(',', [{'nertag': 'O'}]),\n",
       "Span('mis', [{'nertag': 'O'}]),\n",
       "Span('ehitati', [{'nertag': 'O'}]),\n",
       "Span('20', [{'nertag': 'O'}]),\n",
       "Span('aastat', [{'nertag': 'O'}]),\n",
       "Span('tagasi', [{'nertag': 'O'}]),\n",
       "Span('koos', [{'nertag': 'O'}]),\n",
       "Span('Ignalina', [{'nertag': 'B-LOC'}]),\n",
       "Span('aatomielektrijaamaga', [{'nertag': 'O'}]),\n",
       "Span(',', [{'nertag': 'O'}]),\n",
       "Span('oli', [{'nertag': 'O'}]),\n",
       "Span('see', [{'nertag': 'O'}]),\n",
       "Span('esimene', [{'nertag': 'O'}]),\n",
       "Span('alaealise', [{'nertag': 'O'}]),\n",
       "Span('mõrv', [{'nertag': 'O'}]),\n",
       "Span('.', [{'nertag': 'O'}]),\n",
       "Span('Kümned', [{'nertag': 'O'}]),\n",
       "Span('kalamehed', [{'nertag': 'O'}]),\n",
       "Span('jäid', [{'nertag': 'O'}]),\n",
       "Span('taas', [{'nertag': 'O'}]),\n",
       "Span('Peipsil', [{'nertag': 'B-LOC'}]),\n",
       "Span('hätta', [{'nertag': 'O'}]),\n",
       "Span('.', [{'nertag': 'O'}]),\n",
       "Span('Peipsil', [{'nertag': 'B-LOC'}]),\n",
       "Span('jäid', [{'nertag': 'O'}]),\n",
       "Span('pühapäeval', [{'nertag': 'O'}]),\n",
       "Span('taas', [{'nertag': 'O'}]),\n",
       "Span('hätta', [{'nertag': 'O'}]),\n",
       "Span('kümned', [{'nertag': 'O'}]),\n",
       "Span('kalamehed', [{'nertag': 'O'}]),\n",
       "Span(',', [{'nertag': 'O'}]),\n",
       "Span('kes', [{'nertag': 'O'}]),\n",
       "Span('kaldale', [{'nertag': 'O'}]),\n",
       "Span('saamiseks', [{'nertag': 'O'}]),\n",
       "Span('abi', [{'nertag': 'O'}]),\n",
       "Span('vajasid', [{'nertag': 'O'}]),\n",
       "Span('.', [{'nertag': 'O'}]),\n",
       "Span('Järvejäässe', [{'nertag': 'O'}]),\n",
       "Span('tekkis', [{'nertag': 'O'}]),\n",
       "Span('läänetuulega', [{'nertag': 'O'}]),\n",
       "Span('Peipsi', [{'nertag': 'B-LOC'}]),\n",
       "Span('Eesti', [{'nertag': 'I-LOC'}]),\n",
       "Span('poolele', [{'nertag': 'O'}]),\n",
       "Span('kümne', [{'nertag': 'O'}]),\n",
       "Span('kuni', [{'nertag': 'O'}]),\n",
       "Span('200', [{'nertag': 'O'}]),\n",
       "Span('meetri', [{'nertag': 'O'}]),\n",
       "Span('laiune', [{'nertag': 'O'}]),\n",
       "Span('lõhe', [{'nertag': 'O'}]),\n",
       "Span(',', [{'nertag': 'O'}]),\n",
       "Span('mis', [{'nertag': 'O'}]),\n",
       "Span('jääb', [{'nertag': 'O'}]),\n",
       "Span('400', [{'nertag': 'O'}]),\n",
       "Span('meetri', [{'nertag': 'O'}]),\n",
       "Span('kuni', [{'nertag': 'O'}]),\n",
       "Span('kahe', [{'nertag': 'O'}]),\n",
       "Span('kilomeetri', [{'nertag': 'O'}]),\n",
       "Span('kaugusele', [{'nertag': 'O'}]),\n",
       "Span('kaldast', [{'nertag': 'O'}]),\n",
       "Span('.', [{'nertag': 'O'}]),\n",
       "Span('Piirivalveameti', [{'nertag': 'B-ORG'}]),\n",
       "Span('pressiesindaja', [{'nertag': 'O'}]),\n",
       "Span('ütles', [{'nertag': 'O'}]),\n",
       "Span('BNS-ile', [{'nertag': 'B-ORG'}]),\n",
       "Span(',', [{'nertag': 'O'}]),\n",
       "Span('et', [{'nertag': 'O'}]),\n",
       "Span('ennelõunal', [{'nertag': 'O'}]),\n",
       "Span('tõi', [{'nertag': 'O'}]),\n",
       "Span('piirivalve', [{'nertag': 'O'}]),\n",
       "Span('hõljuk', [{'nertag': 'O'}]),\n",
       "Span('Kauksi', [{'nertag': 'B-LOC'}]),\n",
       "Span('alt', [{'nertag': 'O'}]),\n",
       "Span('ära', [{'nertag': 'O'}]),\n",
       "Span('neli', [{'nertag': 'O'}]),\n",
       "Span('kalurit', [{'nertag': 'O'}]),\n",
       "Span(',', [{'nertag': 'O'}]),\n",
       "Span('kuid', [{'nertag': 'O'}]),\n",
       "Span('12.30', [{'nertag': 'O'}]),\n",
       "Span('paiku', [{'nertag': 'O'}]),\n",
       "Span('tuli', [{'nertag': 'O'}]),\n",
       "Span('teade', [{'nertag': 'O'}]),\n",
       "Span('suuremast', [{'nertag': 'O'}]),\n",
       "Span('hulgast', [{'nertag': 'O'}]),\n",
       "Span('hädalistest', [{'nertag': 'O'}]),\n",
       "Span('.', [{'nertag': 'O'}]),\n",
       "Span('Pala', [{'nertag': 'B-LOC'}]),\n",
       "Span('vallas', [{'nertag': 'I-LOC'}]),\n",
       "Span('Ranna', [{'nertag': 'B-LOC'}]),\n",
       "Span('asula', [{'nertag': 'I-LOC'}]),\n",
       "Span('juures', [{'nertag': 'O'}]),\n",
       "Span('olid', [{'nertag': 'O'}]),\n",
       "Span('teisele', [{'nertag': 'O'}]),\n",
       "Span('poole', [{'nertag': 'O'}]),\n",
       "Span('jääpragu', [{'nertag': 'O'}]),\n",
       "Span('jäänud', [{'nertag': 'O'}]),\n",
       "Span('hinnanguliselt', [{'nertag': 'O'}]),\n",
       "Span('50-60', [{'nertag': 'O'}]),\n",
       "Span('kalameest', [{'nertag': 'O'}]),\n",
       "Span('.', [{'nertag': 'O'}]),\n",
       "Span('Kella', [{'nertag': 'O'}]),\n",
       "Span('16', [{'nertag': 'O'}]),\n",
       "Span('oli', [{'nertag': 'O'}]),\n",
       "Span('piirivalve', [{'nertag': 'O'}]),\n",
       "Span('ja', [{'nertag': 'O'}]),\n",
       "Span('kohalikud', [{'nertag': 'O'}]),\n",
       "Span('elanikud', [{'nertag': 'O'}]),\n",
       "Span('oma', [{'nertag': 'O'}]),\n",
       "Span('paatidega', [{'nertag': 'O'}]),\n",
       "Span('neist', [{'nertag': 'O'}]),\n",
       "Span('paarkümmend', [{'nertag': 'O'}]),\n",
       "Span('maale', [{'nertag': 'O'}]),\n",
       "Span('toimetanud', [{'nertag': 'O'}]),\n",
       "Span('.', [{'nertag': 'O'}]),\n",
       "Span('Pressiesindaja', [{'nertag': 'O'}]),\n",
       "Span('sõnul', [{'nertag': 'O'}]),\n",
       "Span('ohtlikku', [{'nertag': 'O'}]),\n",
       "Span('olukorda', [{'nertag': 'O'}]),\n",
       "Span('kalameeste', [{'nertag': 'O'}]),\n",
       "Span('jaoks', [{'nertag': 'O'}]),\n",
       "Span('tekkinud', [{'nertag': 'O'}]),\n",
       "Span('ei', [{'nertag': 'O'}]),\n",
       "Span('ole', [{'nertag': 'O'}]),\n",
       "Span('ja', [{'nertag': 'O'}]),\n",
       "Span('päästetööd', [{'nertag': 'O'}]),\n",
       "Span('sujuvad', [{'nertag': 'O'}]),\n",
       "Span('plaanipäraselt', [{'nertag': 'O'}]),\n",
       "Span('.', [{'nertag': 'O'}]),\n",
       "Span('“', [{'nertag': 'O'}]),\n",
       "Span('Täiesti', [{'nertag': 'O'}]),\n",
       "Span('võimatu', [{'nertag': 'O'}]),\n",
       "Span('oleks', [{'nertag': 'O'}]),\n",
       "Span('kustutada', [{'nertag': 'O'}]),\n",
       "Span('põlevaid', [{'nertag': 'O'}]),\n",
       "Span('kütusemahuteid', [{'nertag': 'O'}]),\n",
       "Span('ning', [{'nertag': 'O'}]),\n",
       "Span('tuleks', [{'nertag': 'O'}]),\n",
       "Span('oodata', [{'nertag': 'O'}]),\n",
       "Span('kuni', [{'nertag': 'O'}]),\n",
       "Span('kütuse', [{'nertag': 'O'}]),\n",
       "Span('täieliku', [{'nertag': 'O'}]),\n",
       "Span('väljapõlemiseni', [{'nertag': 'O'}]),\n",
       "Span('mahutitest', [{'nertag': 'O'}]),\n",
       "Span('.', [{'nertag': 'O'}]),\n",
       "Span('Bensiini', [{'nertag': 'O'}]),\n",
       "Span('ja', [{'nertag': 'O'}]),\n",
       "Span('muude', [{'nertag': 'O'}]),\n",
       "Span('vedelkütuste', [{'nertag': 'O'}]),\n",
       "Span('mahutite', [{'nertag': 'O'}]),\n",
       "Span('plahvatuste', [{'nertag': 'O'}]),\n",
       "Span('juhul', [{'nertag': 'O'}]),\n",
       "Span('ei', [{'nertag': 'O'}]),\n",
       "Span('oleks', [{'nertag': 'O'}]),\n",
       "Span('võimalik', [{'nertag': 'O'}]),\n",
       "Span('päästa', [{'nertag': 'O'}]),\n",
       "Span('terminalide', [{'nertag': 'O'}]),\n",
       "Span('töötajaid', [{'nertag': 'O'}]),\n",
       "Span('ega', [{'nertag': 'O'}]),\n",
       "Span('ka', [{'nertag': 'O'}]),\n",
       "Span('terminalis', [{'nertag': 'O'}]),\n",
       "Span('olevate', [{'nertag': 'O'}]),\n",
       "Span('laevade', [{'nertag': 'O'}]),\n",
       "Span('meeskonnaliikmeid', [{'nertag': 'O'}]),\n",
       "Span(',', [{'nertag': 'O'}]),\n",
       "Span('rääkimata', [{'nertag': 'O'}]),\n",
       "Span('juba', [{'nertag': 'O'}]),\n",
       "Span('kahjustavast', [{'nertag': 'O'}]),\n",
       "Span('mõjust', [{'nertag': 'O'}]),\n",
       "Span('ümbritsevale', [{'nertag': 'O'}]),\n",
       "Span('keskkonnale', [{'nertag': 'O'}]),\n",
       "Span(',', [{'nertag': 'O'}]),\n",
       "Span('Eesti', [{'nertag': 'B-LOC'}]),\n",
       "Span('majandusele', [{'nertag': 'O'}]),\n",
       "Span('ja', [{'nertag': 'O'}]),\n",
       "Span('rahvusvahelisele', [{'nertag': 'O'}]),\n",
       "Span('mainele', [{'nertag': 'O'}]),\n",
       "Span(',', [{'nertag': 'O'}]),\n",
       "Span('”', [{'nertag': 'O'}]),\n",
       "Span('hoiatab', [{'nertag': 'O'}]),\n",
       "Span('turvafirma', [{'nertag': 'O'}]),\n",
       "Span('juhatuse', [{'nertag': 'O'}]),\n",
       "Span('esimees', [{'nertag': 'O'}]),\n",
       "Span('Aleksander', [{'nertag': 'B-PER'}]),\n",
       "Span('Kaspin', [{'nertag': 'I-PER'}]),\n",
       "Span('riigikantseleile', [{'nertag': 'O'}]),\n",
       "Span('saadetud', [{'nertag': 'O'}]),\n",
       "Span('kirjas', [{'nertag': 'O'}]),\n",
       "Span('.', [{'nertag': 'O'}])])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.pop_layer('wordner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td><div align = \"left\">Riigi kutsekoolidest sai kõige viletsama tulemuse Põltsamaa Kodu - ja Põllumajanduskool , kus kvaliteedistandarditele ei vastanud 33 protsenti kutseõpetajatest ja 27 protsenti üldharidusainete õpetajatest . Kooli direktori asetäitja Tambet Valdma sõnul peetakse nende koolis õpetajatena lugu ka väga headest oma ala spetsialistidest ja praktikutest , kel ei pruugi vastava ainevaldkonna paberit taskus olla . Vajadust kaasata praktikuid kinnitas ka tööandjate keskliidu tööturunõunik Thor-Sten Vertmann . Tema sõnul on kutsekoolides erialasid , mis jääksid kõigilt õpetajatelt erialast kõrgharidust nõudes täielikult ajast maha . Haridusministeeriumi kutse - ja täiskasvanuhariduse osakonna juhataja Andres Pung märkis , et kutsekooliõpetajate hindamise kriteeriume senisest leebemaks muutmine tooks koolidesse rohkem oma ala praktikuid . Kehtiva korra järgi võib praktik küll koolis töötada , kui ta on vähemalt kolm aastat töötanud oma erialal ja jätkab põhitööd ka kooli kõrvalt . Põhikohaga tööd tegevad õpetajad , kel pole pedagoogilist haridus , peavad läbima 320 tunni pikkuse õpetajakoolituse . “ Tundub , et see osa on küll natuke ülepingutatud ning neid mahtusid saaks kindlasti vähendada , ” sõnas Pung . 15-aastase Leedu poisi tapjad on tabatud . Leedu linnas Visaginases võttis politsei kinni kaks noormeest , keda kahtlustatakse 15-aastase koolipoisi tapmises . Kaheksanda klassi õpilase Aleksei Selivanovi läbilõigatud kõri ning rohkete torke - ja lõikehaavadega laip leiti kolmapäeva õhtul . Poiss oli tapetud oma kodu lähedal . Politsei pidas neljapäeval mõrvas kahtlustatutena kinni kaks 17-aastast Visaginase elanikku . Üks neist oli nähtavasti mõrva tellija , teine aga täideviija . Kinnipeetud on oma süü üles tunnistanud . Visaginase politsei otsib taga veel kaht mõrvas osalenut . Esialgsetel andmetel tapeti 15-aastane poiss ühe tüdruku pärast . Pärast kuriteo avastamist on Visaginase linna haaranud paanika . Vanemad kardavad oma lapsi kooli saata . Leedu noores linnas Visaginases , mis ehitati 20 aastat tagasi koos Ignalina aatomielektrijaamaga , oli see esimene alaealise mõrv . Kümned kalamehed jäid taas Peipsil hätta . Peipsil jäid pühapäeval taas hätta kümned kalamehed , kes kaldale saamiseks abi vajasid . Järvejäässe tekkis läänetuulega Peipsi Eesti poolele kümne kuni 200 meetri laiune lõhe , mis jääb 400 meetri kuni kahe kilomeetri kaugusele kaldast . Piirivalveameti pressiesindaja ütles BNS-ile , et ennelõunal tõi piirivalve hõljuk Kauksi alt ära neli kalurit , kuid 12.30 paiku tuli teade suuremast hulgast hädalistest . Pala vallas Ranna asula juures olid teisele poole jääpragu jäänud hinnanguliselt 50-60 kalameest . Kella 16 oli piirivalve ja kohalikud elanikud oma paatidega neist paarkümmend maale toimetanud . Pressiesindaja sõnul ohtlikku olukorda kalameeste jaoks tekkinud ei ole ja päästetööd sujuvad plaanipäraselt . “ Täiesti võimatu oleks kustutada põlevaid kütusemahuteid ning tuleks oodata kuni kütuse täieliku väljapõlemiseni mahutitest . Bensiini ja muude vedelkütuste mahutite plahvatuste juhul ei oleks võimalik päästa terminalide töötajaid ega ka terminalis olevate laevade meeskonnaliikmeid , rääkimata juba kahjustavast mõjust ümbritsevale keskkonnale , Eesti majandusele ja rahvusvahelisele mainele , ” hoiatab turvafirma juhatuse esimees Aleksander Kaspin riigikantseleile saadetud kirjas .</div></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>layer name</th>\n",
       "      <th>attributes</th>\n",
       "      <th>parent</th>\n",
       "      <th>enveloping</th>\n",
       "      <th>ambiguous</th>\n",
       "      <th>span count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>sentences</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>words</td>\n",
       "      <td>False</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>compound_tokens</td>\n",
       "      <td>type, normalized</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>words</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>morph_analysis</td>\n",
       "      <td>normalized_text, lemma, root, root_tokens, ending, clitic, form, partofspeech</td>\n",
       "      <td>words</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>471</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "Text(text='Riigi kutsekoolidest sai kõige viletsama tulemuse Põltsamaa Kodu - ja Põllumajanduskool , kus kvaliteedistandarditele ei vastanud 33 protsenti kutseõpetajatest ja 27 protsenti üldharidusainete õpetajatest . Kooli direktori asetäitja Tambet Valdma sõnul peetakse nende koolis õpetajatena lugu ka väga headest oma ala spetsialistidest ja praktikutest , kel ei pruugi vastava ainevaldkonna paberit taskus olla . Vajadust kaasata praktikuid kinnitas ka tööandjate keskliidu tööturunõunik Thor-Sten Vertmann . Tema sõnul on kutsekoolides erialasid , mis jääksid kõigilt õpetajatelt erialast kõrgharidust nõudes täielikult ajast maha . Haridusministeeriumi kutse - ja täiskasvanuhariduse osakonna juhataja Andres Pung märkis , et kutsekooliõpetajate hindamise kriteeriume senisest leebemaks muutmine tooks koolidesse rohkem oma ala praktikuid . Kehtiva korra järgi võib praktik küll koolis töötada , kui ta on vähemalt kolm aastat töötanud oma erialal ja jätkab põhitööd ka kooli kõrvalt . Põhikohaga tööd tegevad õpetajad , kel pole pedagoogilist haridus , peavad läbima 320 tunni pikkuse õpetajakoolituse . “ Tundub , et see osa on küll natuke ülepingutatud ning neid mahtusid saaks kindlasti vähendada , ” sõnas Pung . 15-aastase Leedu poisi tapjad on tabatud . Leedu linnas Visaginases võttis politsei kinni kaks noormeest , keda kahtlustatakse 15-aastase koolipoisi tapmises . Kaheksanda klassi õpilase Aleksei Selivanovi läbilõigatud kõri ning rohkete torke - ja lõikehaavadega laip leiti kolmapäeva õhtul . Poiss oli tapetud oma kodu lähedal . Politsei pidas neljapäeval mõrvas kahtlustatutena kinni kaks 17-aastast Visaginase elanikku . Üks neist oli nähtavasti mõrva tellija , teine aga täideviija . Kinnipeetud on oma süü üles tunnistanud . Visaginase politsei otsib taga veel kaht mõrvas osalenut . Esialgsetel andmetel tapeti 15-aastane poiss ühe tüdruku pärast . Pärast kuriteo avastamist on Visaginase linna haaranud paanika . Vanemad kardavad oma lapsi kooli saata . Leedu noores linnas Visaginases , mis ehitati 20 aastat tagasi koos Ignalina aatomielektrijaamaga , oli see esimene alaealise mõrv . Kümned kalamehed jäid taas Peipsil hätta . Peipsil jäid pühapäeval taas hätta kümned kalamehed , kes kaldale saamiseks abi vajasid . Järvejäässe tekkis läänetuulega Peipsi Eesti poolele kümne kuni 200 meetri laiune lõhe , mis jääb 400 meetri kuni kahe kilomeetri kaugusele kaldast . Piirivalveameti pressiesindaja ütles BNS-ile , et ennelõunal tõi piirivalve hõljuk Kauksi alt ära neli kalurit , kuid 12.30 paiku tuli teade suuremast hulgast hädalistest . Pala vallas Ranna asula juures olid teisele poole jääpragu jäänud hinnanguliselt 50-60 kalameest . Kella 16 oli piirivalve ja kohalikud elanikud oma paatidega neist paarkümmend maale toimetanud . Pressiesindaja sõnul ohtlikku olukorda kalameeste jaoks tekkinud ei ole ja päästetööd sujuvad plaanipäraselt . “ Täiesti võimatu oleks kustutada põlevaid kütusemahuteid ning tuleks oodata kuni kütuse täieliku väljapõlemiseni mahutitest . Bensiini ja muude vedelkütuste mahutite plahvatuste juhul ei oleks võimalik päästa terminalide töötajaid ega ka terminalis olevate laevade meeskonnaliikmeid , rääkimata juba kahjustavast mõjust ümbritsevale keskkonnale , Eesti majandusele ja rahvusvahelisele mainele , ” hoiatab turvafirma juhatuse esimees Aleksander Kaspin riigikantseleile saadetud kirjas .')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "nertagger = WordLevelNerTagger(model_dir = 'ner_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td><div align = \"left\">Riigi kutsekoolidest sai kõige viletsama tulemuse Põltsamaa Kodu - ja Põllumajanduskool , kus kvaliteedistandarditele ei vastanud 33 protsenti kutseõpetajatest ja 27 protsenti üldharidusainete õpetajatest . Kooli direktori asetäitja Tambet Valdma sõnul peetakse nende koolis õpetajatena lugu ka väga headest oma ala spetsialistidest ja praktikutest , kel ei pruugi vastava ainevaldkonna paberit taskus olla . Vajadust kaasata praktikuid kinnitas ka tööandjate keskliidu tööturunõunik Thor-Sten Vertmann . Tema sõnul on kutsekoolides erialasid , mis jääksid kõigilt õpetajatelt erialast kõrgharidust nõudes täielikult ajast maha . Haridusministeeriumi kutse - ja täiskasvanuhariduse osakonna juhataja Andres Pung märkis , et kutsekooliõpetajate hindamise kriteeriume senisest leebemaks muutmine tooks koolidesse rohkem oma ala praktikuid . Kehtiva korra järgi võib praktik küll koolis töötada , kui ta on vähemalt kolm aastat töötanud oma erialal ja jätkab põhitööd ka kooli kõrvalt . Põhikohaga tööd tegevad õpetajad , kel pole pedagoogilist haridus , peavad läbima 320 tunni pikkuse õpetajakoolituse . “ Tundub , et see osa on küll natuke ülepingutatud ning neid mahtusid saaks kindlasti vähendada , ” sõnas Pung . 15-aastase Leedu poisi tapjad on tabatud . Leedu linnas Visaginases võttis politsei kinni kaks noormeest , keda kahtlustatakse 15-aastase koolipoisi tapmises . Kaheksanda klassi õpilase Aleksei Selivanovi läbilõigatud kõri ning rohkete torke - ja lõikehaavadega laip leiti kolmapäeva õhtul . Poiss oli tapetud oma kodu lähedal . Politsei pidas neljapäeval mõrvas kahtlustatutena kinni kaks 17-aastast Visaginase elanikku . Üks neist oli nähtavasti mõrva tellija , teine aga täideviija . Kinnipeetud on oma süü üles tunnistanud . Visaginase politsei otsib taga veel kaht mõrvas osalenut . Esialgsetel andmetel tapeti 15-aastane poiss ühe tüdruku pärast . Pärast kuriteo avastamist on Visaginase linna haaranud paanika . Vanemad kardavad oma lapsi kooli saata . Leedu noores linnas Visaginases , mis ehitati 20 aastat tagasi koos Ignalina aatomielektrijaamaga , oli see esimene alaealise mõrv . Kümned kalamehed jäid taas Peipsil hätta . Peipsil jäid pühapäeval taas hätta kümned kalamehed , kes kaldale saamiseks abi vajasid . Järvejäässe tekkis läänetuulega Peipsi Eesti poolele kümne kuni 200 meetri laiune lõhe , mis jääb 400 meetri kuni kahe kilomeetri kaugusele kaldast . Piirivalveameti pressiesindaja ütles BNS-ile , et ennelõunal tõi piirivalve hõljuk Kauksi alt ära neli kalurit , kuid 12.30 paiku tuli teade suuremast hulgast hädalistest . Pala vallas Ranna asula juures olid teisele poole jääpragu jäänud hinnanguliselt 50-60 kalameest . Kella 16 oli piirivalve ja kohalikud elanikud oma paatidega neist paarkümmend maale toimetanud . Pressiesindaja sõnul ohtlikku olukorda kalameeste jaoks tekkinud ei ole ja päästetööd sujuvad plaanipäraselt . “ Täiesti võimatu oleks kustutada põlevaid kütusemahuteid ning tuleks oodata kuni kütuse täieliku väljapõlemiseni mahutitest . Bensiini ja muude vedelkütuste mahutite plahvatuste juhul ei oleks võimalik päästa terminalide töötajaid ega ka terminalis olevate laevade meeskonnaliikmeid , rääkimata juba kahjustavast mõjust ümbritsevale keskkonnale , Eesti majandusele ja rahvusvahelisele mainele , ” hoiatab turvafirma juhatuse esimees Aleksander Kaspin riigikantseleile saadetud kirjas .</div></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>layer name</th>\n",
       "      <th>attributes</th>\n",
       "      <th>parent</th>\n",
       "      <th>enveloping</th>\n",
       "      <th>ambiguous</th>\n",
       "      <th>span count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>sentences</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>words</td>\n",
       "      <td>False</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>compound_tokens</td>\n",
       "      <td>type, normalized</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>words</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>morph_analysis</td>\n",
       "      <td>normalized_text, lemma, root, root_tokens, ending, clitic, form, partofspeech</td>\n",
       "      <td>words</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>wordner</td>\n",
       "      <td>nertag</td>\n",
       "      <td>None</td>\n",
       "      <td>words</td>\n",
       "      <td>False</td>\n",
       "      <td>471</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "Text(text='Riigi kutsekoolidest sai kõige viletsama tulemuse Põltsamaa Kodu - ja Põllumajanduskool , kus kvaliteedistandarditele ei vastanud 33 protsenti kutseõpetajatest ja 27 protsenti üldharidusainete õpetajatest . Kooli direktori asetäitja Tambet Valdma sõnul peetakse nende koolis õpetajatena lugu ka väga headest oma ala spetsialistidest ja praktikutest , kel ei pruugi vastava ainevaldkonna paberit taskus olla . Vajadust kaasata praktikuid kinnitas ka tööandjate keskliidu tööturunõunik Thor-Sten Vertmann . Tema sõnul on kutsekoolides erialasid , mis jääksid kõigilt õpetajatelt erialast kõrgharidust nõudes täielikult ajast maha . Haridusministeeriumi kutse - ja täiskasvanuhariduse osakonna juhataja Andres Pung märkis , et kutsekooliõpetajate hindamise kriteeriume senisest leebemaks muutmine tooks koolidesse rohkem oma ala praktikuid . Kehtiva korra järgi võib praktik küll koolis töötada , kui ta on vähemalt kolm aastat töötanud oma erialal ja jätkab põhitööd ka kooli kõrvalt . Põhikohaga tööd tegevad õpetajad , kel pole pedagoogilist haridus , peavad läbima 320 tunni pikkuse õpetajakoolituse . “ Tundub , et see osa on küll natuke ülepingutatud ning neid mahtusid saaks kindlasti vähendada , ” sõnas Pung . 15-aastase Leedu poisi tapjad on tabatud . Leedu linnas Visaginases võttis politsei kinni kaks noormeest , keda kahtlustatakse 15-aastase koolipoisi tapmises . Kaheksanda klassi õpilase Aleksei Selivanovi läbilõigatud kõri ning rohkete torke - ja lõikehaavadega laip leiti kolmapäeva õhtul . Poiss oli tapetud oma kodu lähedal . Politsei pidas neljapäeval mõrvas kahtlustatutena kinni kaks 17-aastast Visaginase elanikku . Üks neist oli nähtavasti mõrva tellija , teine aga täideviija . Kinnipeetud on oma süü üles tunnistanud . Visaginase politsei otsib taga veel kaht mõrvas osalenut . Esialgsetel andmetel tapeti 15-aastane poiss ühe tüdruku pärast . Pärast kuriteo avastamist on Visaginase linna haaranud paanika . Vanemad kardavad oma lapsi kooli saata . Leedu noores linnas Visaginases , mis ehitati 20 aastat tagasi koos Ignalina aatomielektrijaamaga , oli see esimene alaealise mõrv . Kümned kalamehed jäid taas Peipsil hätta . Peipsil jäid pühapäeval taas hätta kümned kalamehed , kes kaldale saamiseks abi vajasid . Järvejäässe tekkis läänetuulega Peipsi Eesti poolele kümne kuni 200 meetri laiune lõhe , mis jääb 400 meetri kuni kahe kilomeetri kaugusele kaldast . Piirivalveameti pressiesindaja ütles BNS-ile , et ennelõunal tõi piirivalve hõljuk Kauksi alt ära neli kalurit , kuid 12.30 paiku tuli teade suuremast hulgast hädalistest . Pala vallas Ranna asula juures olid teisele poole jääpragu jäänud hinnanguliselt 50-60 kalameest . Kella 16 oli piirivalve ja kohalikud elanikud oma paatidega neist paarkümmend maale toimetanud . Pressiesindaja sõnul ohtlikku olukorda kalameeste jaoks tekkinud ei ole ja päästetööd sujuvad plaanipäraselt . “ Täiesti võimatu oleks kustutada põlevaid kütusemahuteid ning tuleks oodata kuni kütuse täieliku väljapõlemiseni mahutitest . Bensiini ja muude vedelkütuste mahutite plahvatuste juhul ei oleks võimalik päästa terminalide töötajaid ega ka terminalis olevate laevade meeskonnaliikmeid , rääkimata juba kahjustavast mõjust ümbritsevale keskkonnale , Eesti majandusele ja rahvusvahelisele mainele , ” hoiatab turvafirma juhatuse esimees Aleksander Kaspin riigikantseleile saadetud kirjas .')"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nertagger.tag(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct = 0\n",
    "predicted_layer = test.wordner\n",
    "\n",
    "for i, tag in enumerate(nerlayer.nertag):\n",
    "    if tag == predicted_layer[i].nertag:\n",
    "        correct += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 97.45222929936305 %\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy:\", correct/len(nerlayer) * 100, \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparison on non-labelled text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparing the tagger that uses the newly trained model with a tagger that uses the default model that EstNLTK has. For the default model, model_dir doesn't need to be specified."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "nonlabelled = Text('''Eesti Vabariik on riik Põhja-Euroopas.\n",
    "    Eesti piirneb põhjas üle Soome lahe Soome Vabariigiga.\n",
    "    Riigikogu on Eesti Vabariigi parlament. Riigikogule kuulub Eestis seadusandlik võim.\n",
    "    2005. aastal sai peaministriks Andrus Ansip, kes püsis sellel kohal 2014. aastani.\n",
    "    2006. aastal valiti presidendiks Toomas Hendrik Ilves.\n",
    "    ''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td><div align = \"left\">Eesti Vabariik on riik Põhja-Euroopas.</br>    Eesti piirneb põhjas üle Soome lahe Soome Vabariigiga.</br>    Riigikogu on Eesti Vabariigi parlament. Riigikogule kuulub Eestis seadusandlik võim.</br>    2005. aastal sai peaministriks Andrus Ansip, kes püsis sellel kohal 2014. aastani.</br>    2006. aastal valiti presidendiks Toomas Hendrik Ilves.</br>    </div></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>layer name</th>\n",
       "      <th>attributes</th>\n",
       "      <th>parent</th>\n",
       "      <th>enveloping</th>\n",
       "      <th>ambiguous</th>\n",
       "      <th>span count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>sentences</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>words</td>\n",
       "      <td>False</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>tokens</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>compound_tokens</td>\n",
       "      <td>type, normalized</td>\n",
       "      <td>None</td>\n",
       "      <td>tokens</td>\n",
       "      <td>False</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>words</td>\n",
       "      <td>normalized_form</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>morph_analysis</td>\n",
       "      <td>normalized_text, lemma, root, root_tokens, ending, clitic, form, partofspeech</td>\n",
       "      <td>words</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "Text(text='Eesti Vabariik on riik Põhja-Euroopas.\\n    Eesti piirneb põhjas üle Soome lahe Soome Vabariigiga.\\n    Riigikogu on Eesti Vabariigi parlament. Riigikogule kuulub Eestis seadusandlik võim.\\n    2005. aastal sai peaministriks Andrus Ansip, kes püsis sellel kohal 2014. aastani.\\n    2006. aastal valiti presidendiks Toomas Hendrik Ilves.\\n    ')"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nonlabelled.tag_layer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting layer name for both so they could later be easily compared using DiffTagger\n",
    "defaulttagger = WordLevelNerTagger(output_layer='wordner_default')\n",
    "trainedtagger = WordLevelNerTagger(output_layer='wordner_trained', model_dir = 'ner_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td><div align = \"left\">Eesti Vabariik on riik Põhja-Euroopas.</br>    Eesti piirneb põhjas üle Soome lahe Soome Vabariigiga.</br>    Riigikogu on Eesti Vabariigi parlament. Riigikogule kuulub Eestis seadusandlik võim.</br>    2005. aastal sai peaministriks Andrus Ansip, kes püsis sellel kohal 2014. aastani.</br>    2006. aastal valiti presidendiks Toomas Hendrik Ilves.</br>    </div></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>layer name</th>\n",
       "      <th>attributes</th>\n",
       "      <th>parent</th>\n",
       "      <th>enveloping</th>\n",
       "      <th>ambiguous</th>\n",
       "      <th>span count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>sentences</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>words</td>\n",
       "      <td>False</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>tokens</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>compound_tokens</td>\n",
       "      <td>type, normalized</td>\n",
       "      <td>None</td>\n",
       "      <td>tokens</td>\n",
       "      <td>False</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>words</td>\n",
       "      <td>normalized_form</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>morph_analysis</td>\n",
       "      <td>normalized_text, lemma, root, root_tokens, ending, clitic, form, partofspeech</td>\n",
       "      <td>words</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>wordner_default</td>\n",
       "      <td>nertag</td>\n",
       "      <td>None</td>\n",
       "      <td>words</td>\n",
       "      <td>False</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "Text(text='Eesti Vabariik on riik Põhja-Euroopas.\\n    Eesti piirneb põhjas üle Soome lahe Soome Vabariigiga.\\n    Riigikogu on Eesti Vabariigi parlament. Riigikogule kuulub Eestis seadusandlik võim.\\n    2005. aastal sai peaministriks Andrus Ansip, kes püsis sellel kohal 2014. aastani.\\n    2006. aastal valiti presidendiks Toomas Hendrik Ilves.\\n    ')"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "defaulttagger.tag(nonlabelled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td><div align = \"left\">Eesti Vabariik on riik Põhja-Euroopas.</br>    Eesti piirneb põhjas üle Soome lahe Soome Vabariigiga.</br>    Riigikogu on Eesti Vabariigi parlament. Riigikogule kuulub Eestis seadusandlik võim.</br>    2005. aastal sai peaministriks Andrus Ansip, kes püsis sellel kohal 2014. aastani.</br>    2006. aastal valiti presidendiks Toomas Hendrik Ilves.</br>    </div></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>layer name</th>\n",
       "      <th>attributes</th>\n",
       "      <th>parent</th>\n",
       "      <th>enveloping</th>\n",
       "      <th>ambiguous</th>\n",
       "      <th>span count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>sentences</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>words</td>\n",
       "      <td>False</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>tokens</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>compound_tokens</td>\n",
       "      <td>type, normalized</td>\n",
       "      <td>None</td>\n",
       "      <td>tokens</td>\n",
       "      <td>False</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>words</td>\n",
       "      <td>normalized_form</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>morph_analysis</td>\n",
       "      <td>normalized_text, lemma, root, root_tokens, ending, clitic, form, partofspeech</td>\n",
       "      <td>words</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>wordner_default</td>\n",
       "      <td>nertag</td>\n",
       "      <td>None</td>\n",
       "      <td>words</td>\n",
       "      <td>False</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>wordner_trained</td>\n",
       "      <td>nertag</td>\n",
       "      <td>None</td>\n",
       "      <td>words</td>\n",
       "      <td>False</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "Text(text='Eesti Vabariik on riik Põhja-Euroopas.\\n    Eesti piirneb põhjas üle Soome lahe Soome Vabariigiga.\\n    Riigikogu on Eesti Vabariigi parlament. Riigikogule kuulub Eestis seadusandlik võim.\\n    2005. aastal sai peaministriks Andrus Ansip, kes püsis sellel kohal 2014. aastani.\\n    2006. aastal valiti presidendiks Toomas Hendrik Ilves.\\n    ')"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainedtagger.tag(nonlabelled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from estnltk.taggers import DiffTagger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "difftagger = DiffTagger('wordner_default', 'wordner_trained', 'ner_differences', ['nertag'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "difflayer = difftagger.make_layer(nonlabelled, layers={'wordner_default': nonlabelled.wordner_default, 'wordner_trained': nonlabelled.wordner_trained})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h4>Layer</h4>\n",
       "<h4>Metadata</h4>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>conflicts</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>extra_annotations</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>extra_spans</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>missing_annotations</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>missing_spans</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>modified_spans</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>overlapped</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>prolonged</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>shortened</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>unchanged_annotations</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>unchanged_spans</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>layer name</th>\n",
       "      <th>attributes</th>\n",
       "      <th>parent</th>\n",
       "      <th>enveloping</th>\n",
       "      <th>ambiguous</th>\n",
       "      <th>span count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>ner_differences</td>\n",
       "      <td>span_status, input_layer_name, nertag</td>\n",
       "      <td>None</td>\n",
       "      <td>words</td>\n",
       "      <td>True</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>text</th>\n",
       "      <th>span_status</th>\n",
       "      <th>input_layer_name</th>\n",
       "      <th>nertag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>lahe</td>\n",
       "      <td>modified</td>\n",
       "      <td>wordner_default</td>\n",
       "      <td>I-LOC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td></td>\n",
       "      <td>modified</td>\n",
       "      <td>wordner_trained</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Riigikogu</td>\n",
       "      <td>modified</td>\n",
       "      <td>wordner_default</td>\n",
       "      <td>B-ORG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td></td>\n",
       "      <td>modified</td>\n",
       "      <td>wordner_trained</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Riigikogule</td>\n",
       "      <td>modified</td>\n",
       "      <td>wordner_default</td>\n",
       "      <td>B-ORG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td></td>\n",
       "      <td>modified</td>\n",
       "      <td>wordner_trained</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "Layer(name='ner_differences', attributes=('span_status', 'input_layer_name', 'nertag'), spans=SL[EnvelopingSpan('lahe', [{'span_status': 'modified', 'input_layer_name': 'wordner_default', 'nertag': 'I-LOC'}, {'span_status': 'modified', 'input_layer_name': 'wordner_trained', 'nertag': 'O'}]),\n",
       "EnvelopingSpan('Riigikogu', [{'span_status': 'modified', 'input_layer_name': 'wordner_default', 'nertag': 'B-ORG'}, {'span_status': 'modified', 'input_layer_name': 'wordner_trained', 'nertag': 'O'}]),\n",
       "EnvelopingSpan('Riigikogule', [{'span_status': 'modified', 'input_layer_name': 'wordner_default', 'nertag': 'B-ORG'}, {'span_status': 'modified', 'input_layer_name': 'wordner_trained', 'nertag': 'O'}])])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "difflayer"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
