{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "861e5656",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../../../../../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "83d1eec6",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Too many parameters for typing.Iterator; actual 3, expected 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-2e0b36894872>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mcda_data_cleaning\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestnltk_patches\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtaggers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdict_taggers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mRuleset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mcda_data_cleaning\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestnltk_patches\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtaggers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdict_taggers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mStaticExtractionRule\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mcda_data_cleaning\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestnltk_patches\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtaggers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdict_taggers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDynamicExtractionRule\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mcda_data_cleaning\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestnltk_patches\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtaggers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdict_taggers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSubstringTagger\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/GIT/cda-data-cleaning/cda_data_cleaning/estnltk_patches/taggers/dict_taggers/tests/../../../../../cda_data_cleaning/estnltk_patches/taggers/dict_taggers/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mextraction_rules\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdynamic_extraction_rule\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDynamicExtractionRule\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mextraction_rules\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mruleset\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mRuleset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mtaggers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubstring_tagger\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSubstringTagger\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Documents/GIT/cda-data-cleaning/cda_data_cleaning/estnltk_patches/taggers/dict_taggers/tests/../../../../../cda_data_cleaning/estnltk_patches/taggers/dict_taggers/taggers/substring_tagger.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0;32mclass\u001b[0m \u001b[0mSubstringTagger\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTagger\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m     \"\"\"\n\u001b[1;32m     13\u001b[0m     \u001b[0mTags\u001b[0m \u001b[0moccurrences\u001b[0m \u001b[0mof\u001b[0m \u001b[0msubstrings\u001b[0m \u001b[0mon\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msolves\u001b[0m \u001b[0mpossible\u001b[0m \u001b[0mconflicts\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mcreates\u001b[0m \u001b[0ma\u001b[0m \u001b[0mnew\u001b[0m \u001b[0mlayer\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mmatches\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/GIT/cda-data-cleaning/cda_data_cleaning/estnltk_patches/taggers/dict_taggers/tests/../../../../../cda_data_cleaning/estnltk_patches/taggers/dict_taggers/taggers/substring_tagger.py\u001b[0m in \u001b[0;36mSubstringTagger\u001b[0;34m()\u001b[0m\n\u001b[1;32m    214\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m             \u001b[0mlayer\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mLayer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m             sorted_tuples: Iterator[Tuple[ElementaryBaseSpan, str], None, None]) -> Layer:\n\u001b[0m\u001b[1;32m    217\u001b[0m         \"\"\"\n\u001b[1;32m    218\u001b[0m         \u001b[0mAdds\u001b[0m \u001b[0mannotations\u001b[0m \u001b[0mto\u001b[0m \u001b[0mextracted\u001b[0m \u001b[0mmatches\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0massembles\u001b[0m \u001b[0mthem\u001b[0m \u001b[0minto\u001b[0m \u001b[0ma\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/precise4q/lib/python3.8/typing.py\u001b[0m in \u001b[0;36minner\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    259\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    260\u001b[0m             \u001b[0;32mpass\u001b[0m  \u001b[0;31m# All real errors (not unhashable args) are raised below.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 261\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    262\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0minner\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    263\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/precise4q/lib/python3.8/typing.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, params)\u001b[0m\n\u001b[1;32m    684\u001b[0m         \u001b[0mmsg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"Parameters to generic types must be types.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    685\u001b[0m         \u001b[0mparams\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_type_check\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 686\u001b[0;31m         \u001b[0m_check_generic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    687\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_subs_tvars\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__parameters__\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    688\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/precise4q/lib/python3.8/typing.py\u001b[0m in \u001b[0;36m_check_generic\u001b[0;34m(cls, parameters)\u001b[0m\n\u001b[1;32m    213\u001b[0m     \u001b[0melen\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__parameters__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0malen\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0melen\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 215\u001b[0;31m         raise TypeError(f\"Too {'many' if alen > elen else 'few'} parameters for {cls};\"\n\u001b[0m\u001b[1;32m    216\u001b[0m                         f\" actual {alen}, expected {elen}\")\n\u001b[1;32m    217\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Too many parameters for typing.Iterator; actual 3, expected 1"
     ]
    }
   ],
   "source": [
    "from cda_data_cleaning.estnltk_patches.taggers.dict_taggers import Ruleset\n",
    "from cda_data_cleaning.estnltk_patches.taggers.dict_taggers import StaticExtractionRule\n",
    "from cda_data_cleaning.estnltk_patches.taggers.dict_taggers import DynamicExtractionRule\n",
    "from cda_data_cleaning.estnltk_patches.taggers.dict_taggers import SubstringTagger\n",
    "\n",
    "from estnltk import Text, Layer, Span"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0808cab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def layer_to_dict(layer: Layer):\n",
    "    return [\n",
    "        {'start': span.start, \n",
    "         'end': span.end, \n",
    "         'text': span.text, \n",
    "         **dict(span.annotations[0])\n",
    "        } for span in layer\n",
    "    ] "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed0a1a9a",
   "metadata": {},
   "source": [
    "### I. Test matching without separators "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dc107fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "rules = Ruleset([\n",
    "    StaticExtractionRule('first'),\n",
    "    StaticExtractionRule('firs'),\n",
    "    StaticExtractionRule('irst'),\n",
    "    StaticExtractionRule('last')\n",
    "])\n",
    "\n",
    "text = Text('first second last')\n",
    "tagger = SubstringTagger(rules)\n",
    "tagger(text)\n",
    "\n",
    "expected_output = [\n",
    "    {'start': 0, 'end': 5, 'text': 'first'},\n",
    "    {'start': 13, 'end': 17, 'text': 'last'}]\n",
    "\n",
    "assert layer_to_dict(text.terms) == expected_output, \"Maximal matches must be returned\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d280b93",
   "metadata": {},
   "outputs": [],
   "source": [
    "rules = Ruleset([\n",
    "    StaticExtractionRule('First'),\n",
    "    StaticExtractionRule('firs'),\n",
    "    StaticExtractionRule('irst'),\n",
    "    StaticExtractionRule('LAST')\n",
    "])\n",
    "\n",
    "text = Text('first second last')\n",
    "tagger = SubstringTagger(rules, ignore_case=True)\n",
    "tagger(text)\n",
    "\n",
    "expected_output = [\n",
    "    {'start': 0, 'end': 5, 'text': 'first'},\n",
    "    {'start': 13, 'end': 17, 'text': 'last'}]\n",
    "\n",
    "assert layer_to_dict(text.terms) == expected_output, \"Maximal matches must be returned\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24571edb",
   "metadata": {},
   "source": [
    "### II. Test the effect of separators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96135595",
   "metadata": {},
   "outputs": [],
   "source": [
    "rules = Ruleset([StaticExtractionRule('match')])\n",
    "\n",
    "text = Text('match|match| match| match| match |match')\n",
    "separators = '|'\n",
    "tagger = SubstringTagger(rules, token_separators=separators)\n",
    "tagger(text)\n",
    "\n",
    "expected_output = [\n",
    "    {'start': 0, 'end': 5, 'text': 'match'},\n",
    "    {'start': 6, 'end': 11, 'text': 'match'},\n",
    "    {'start': 34, 'end': 39, 'text': 'match'}]\n",
    "assert layer_to_dict(text.terms) == expected_output, \"Separators are not correctly handled\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c017180",
   "metadata": {},
   "outputs": [],
   "source": [
    "rules = Ruleset([StaticExtractionRule('match')])\n",
    "text = Text('match match, :match, match')\n",
    "separators = ' , :'\n",
    "tagger = SubstringTagger(rules, token_separators=separators)\n",
    "tagger(text)\n",
    "\n",
    "expected_output = [\n",
    "    {'start': 0, 'end': 5, 'text': 'match'},\n",
    "    {'start': 6, 'end': 11, 'text': 'match'},\n",
    "    {'start': 14, 'end': 19, 'text': 'match'},\n",
    "    {'start': 21, 'end': 26, 'text': 'match'}]\n",
    "assert layer_to_dict(text.terms) == expected_output, \"Multiple separators do not work\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e57eb31a",
   "metadata": {},
   "source": [
    "### III. Test annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bee236bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "rules = Ruleset([\n",
    "    StaticExtractionRule('first', {'a': 1, 'b': 1}),\n",
    "    StaticExtractionRule('second', {'b': 2, 'a': 3}),\n",
    "    StaticExtractionRule('last', {'a': 3, 'b': 5})])\n",
    "text = Text('first second last')\n",
    "tagger = SubstringTagger(rules, output_attributes = ['a', 'b'])\n",
    "tagger(text)\n",
    "\n",
    "expected_outcome = [\n",
    "    {'start': 0, 'end': 5, 'text': 'first', 'a': 1, 'b': 1},\n",
    "    {'start': 6, 'end': 12, 'text': 'second', 'b': 2, 'a': 3},\n",
    "    {'start': 13, 'end': 17, 'text': 'last', 'a': 3, 'b': 5 }]\n",
    "assert layer_to_dict(text.terms) == expected_outcome, \"Annotations do not work\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67a57e76",
   "metadata": {},
   "source": [
    "### IV. Test global decorator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42b99fde",
   "metadata": {},
   "outputs": [],
   "source": [
    "rules = Ruleset([\n",
    "    StaticExtractionRule('first'),\n",
    "    StaticExtractionRule('second'),\n",
    "    StaticExtractionRule('third'),\n",
    "    StaticExtractionRule('fourth'),\n",
    "    StaticExtractionRule('last')\n",
    "])\n",
    "\n",
    "def decorator(text, span):\n",
    "    if span.text == 'first':\n",
    "        return {'value': 1}\n",
    "    elif span.text == 'second':\n",
    "        return {'value': 2}\n",
    "    elif span.text == 'third':\n",
    "        return {'value': 3}\n",
    "    elif span.text == 'fourth':\n",
    "        return {'value': 4}\n",
    "    \n",
    "    return None\n",
    "\n",
    "text = Text('first, second, third and last')\n",
    "tagger = SubstringTagger(rules, output_attributes = ['value'], global_decorator=decorator)    \n",
    "tagger(text)\n",
    "\n",
    "expected_outcome = [\n",
    "    {'start': 0, 'end': 5, 'text': 'first', 'value': 1},\n",
    "    {'start': 7, 'end': 13, 'text': 'second', 'value': 2},\n",
    "    {'start': 15, 'end': 20, 'text': 'third', 'value': 3}]\n",
    "assert layer_to_dict(text.terms) == expected_outcome, \"Global decorator does not work\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39a2f955",
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_analyzer(text, span):\n",
    "    layer = span.layer\n",
    "    value = -1\n",
    "    for prev in layer:\n",
    "        if prev == span:\n",
    "            break\n",
    "        value = max(value, prev['value'])\n",
    "    \n",
    "    return {'value': value + 1}\n",
    "\n",
    "\n",
    "def decorator(text, span):\n",
    "    if span.text == 'first':\n",
    "        return {'value': 1}\n",
    "    elif span.text == 'second':\n",
    "        return {'value': 2}\n",
    "    elif span.text == 'third':\n",
    "        return {'value': 3}\n",
    "    elif span.text == 'fourth':\n",
    "        return {'value': 4}\n",
    "    \n",
    "    return {'value': None}\n",
    "    \n",
    "rules = Ruleset([\n",
    "    StaticExtractionRule('first'),\n",
    "    StaticExtractionRule('second'),\n",
    "    StaticExtractionRule('third'),\n",
    "    StaticExtractionRule('fourth'),\n",
    "    DynamicExtractionRule('last', decorator=text_analyzer)\n",
    "])\n",
    "\n",
    "text = Text('first, second, third and last')\n",
    "tagger = SubstringTagger(rules, output_attributes = ['value'], global_decorator=decorator)    \n",
    "tagger(text)\n",
    "\n",
    "expected_outcome = [\n",
    "    {'start': 0, 'end': 5, 'text': 'first', 'value': 1},\n",
    "    {'start': 7, 'end': 13, 'text': 'second', 'value': 2},\n",
    "    {'start': 15, 'end': 20, 'text': 'third', 'value': 3},\n",
    "    {'start': 25, 'end': 29, 'text': 'last', 'value': 4}]\n",
    "assert layer_to_dict(text.terms) == expected_outcome, \"Dynamic decorator does not work\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25fd5d6c",
   "metadata": {},
   "source": [
    "## V. Test minimal and maximal matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "314d2518",
   "metadata": {},
   "outputs": [],
   "source": [
    "rules = Ruleset([\n",
    "    StaticExtractionRule('abcd'),\n",
    "    StaticExtractionRule('abc'),\n",
    "    StaticExtractionRule('bc'),\n",
    "    StaticExtractionRule('bcd'),\n",
    "    StaticExtractionRule('bcde'),\n",
    "    StaticExtractionRule('f'),\n",
    "    StaticExtractionRule('ef')\n",
    "])\n",
    "\n",
    "text = Text('abcdea--efg')\n",
    "tagger = SubstringTagger(rules, output_attributes=[], conflict_resolver='KEEP_MINIMAL')\n",
    "tagger(text)\n",
    "\n",
    "expected_outcome=[\n",
    "    {'start': 1, 'end': 3, 'text': 'bc'},\n",
    "    {'start': 9, 'end': 10, 'text': 'f'}]\n",
    "assert layer_to_dict(text.terms) == expected_outcome, \"Minimal matching does not work\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a54c0b78",
   "metadata": {},
   "outputs": [],
   "source": [
    "rules = Ruleset([\n",
    "    StaticExtractionRule('abcd'),\n",
    "    StaticExtractionRule('abc'),\n",
    "    StaticExtractionRule('bc'),\n",
    "    StaticExtractionRule('bcd'),\n",
    "    StaticExtractionRule('bcde'),\n",
    "    StaticExtractionRule('f'),\n",
    "    StaticExtractionRule('ef')\n",
    "])\n",
    "\n",
    "text = Text('abcdea--efg')\n",
    "tagger = SubstringTagger(rules, output_attributes=[], conflict_resolver='KEEP_MAXIMAL')\n",
    "tagger(text)\n",
    "\n",
    "expected_outcome = [\n",
    "    {'start': 0, 'end': 4, 'text': 'abcd'},\n",
    "    {'start': 1, 'end': 5, 'text': 'bcde'},\n",
    "    {'start': 8, 'end': 10, 'text': 'ef'}]\n",
    "\n",
    "assert layer_to_dict(text.terms) == expected_outcome, \"Maximal matching does not work\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cd0a19e",
   "metadata": {},
   "outputs": [],
   "source": [
    "rules = Ruleset([\n",
    "    StaticExtractionRule('abcd'),\n",
    "    StaticExtractionRule('abc'),\n",
    "    StaticExtractionRule('bc'),\n",
    "    StaticExtractionRule('bcd'),\n",
    "    StaticExtractionRule('bcde'),\n",
    "    StaticExtractionRule('f'),\n",
    "    StaticExtractionRule('ef')\n",
    "])\n",
    "\n",
    "text = Text('abcdea--efg')\n",
    "tagger = SubstringTagger(rules, output_attributes=[], conflict_resolver='KEEP_ALL')\n",
    "tagger(text)\n",
    "\n",
    "expected_outcome = [\n",
    "    {'start': 0, 'end': 3, 'text': 'abc'},\n",
    "    {'start': 0, 'end': 4, 'text': 'abcd'},\n",
    "    {'start': 1, 'end': 3, 'text': 'bc'},\n",
    "    {'start': 1, 'end': 4, 'text': 'bcd'},\n",
    "    {'start': 1, 'end': 5, 'text': 'bcde'},\n",
    "    {'start': 8, 'end': 10, 'text': 'ef'},\n",
    "    {'start': 9, 'end': 10, 'text': 'f'}]\n",
    "\n",
    "assert layer_to_dict(text.terms) == expected_outcome, \"All matches does not work\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
