{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Morphological analysis with user dictionary\n",
    "\n",
    "If you need to analyse non-standard Estonian texts (such as the Internet language, transcribed spoken language, or written texts heavily influenced by regional dialects), the standard morphological analyser will probably have suboptimal performance. \n",
    "But if the errors are regular enough, you can compose (either manually or semi-automatically) a user dictionary with corrections.\n",
    "You can apply the dictionary to rewrite `'morph_analysis'` layer, so that words with erroneous analyses will have correct analyses from the dictionary."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, there are two ways for correcting morphological analyses, depending on the types of errors you have:\n",
    "  * if non-standard words can be mapped to standard words (e.g. words with incorrect spelling can be mapped to words with correct spelling, such as 'sellged' => 'selged' or 'vxi' => 'või'), then you can use `make_userdict` function to automatically create `UserDictTagger` based on given mappings, and you can use it to make corrections;\n",
    "  \n",
    "  \n",
    "  * if spelling of words is correct, but the morphological analyser does not produce correct analyses (e.g. compound word 'abieluettepanek' is analysed with root 'abi_elu_ette_panek', although root 'abielu_ettepanek' would be more preferable), then you can manually create `UserDictTagger` which makes specific corrections for analyses;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `make_userdict` function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic usage\n",
    "\n",
    "The function `make_userdict` can be used to automatically create `UserDictTagger` based on given mappings from non-standard words to standard words."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's consider an example sentence from the Internet language:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_str = \"see onn hädavajalik vajd merel, xhus vxi metsas\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's try to analyse it with the standard morphological analyser:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h4>Layer</h4>\n",
       "\n",
       "\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>layer name</th>\n",
       "      <th>attributes</th>\n",
       "      <th>parent</th>\n",
       "      <th>enveloping</th>\n",
       "      <th>ambiguous</th>\n",
       "      <th>span count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>morph_analysis</td>\n",
       "      <td>normalized_text, lemma, root, root_tokens, ending, clitic, form, partofspeech</td>\n",
       "      <td>words</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>text</th>\n",
       "      <th>normalized_text</th>\n",
       "      <th>lemma</th>\n",
       "      <th>root</th>\n",
       "      <th>root_tokens</th>\n",
       "      <th>ending</th>\n",
       "      <th>clitic</th>\n",
       "      <th>form</th>\n",
       "      <th>partofspeech</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>see</td>\n",
       "      <td>see</td>\n",
       "      <td>see</td>\n",
       "      <td>see</td>\n",
       "      <td>['see']</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>sg n</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>onn</td>\n",
       "      <td>onn</td>\n",
       "      <td>onn</td>\n",
       "      <td>onn</td>\n",
       "      <td>['onn']</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>sg n</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>hädavajalik</td>\n",
       "      <td>hädavajalik</td>\n",
       "      <td>hädavajalik</td>\n",
       "      <td>häda_vajalik</td>\n",
       "      <td>['häda', 'vajalik']</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>sg n</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>vajd</td>\n",
       "      <td>vajd</td>\n",
       "      <td>vajd</td>\n",
       "      <td>vajd</td>\n",
       "      <td>['vajd']</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>sg n</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>merel</td>\n",
       "      <td>merel</td>\n",
       "      <td>meri</td>\n",
       "      <td>meri</td>\n",
       "      <td>['meri']</td>\n",
       "      <td>l</td>\n",
       "      <td></td>\n",
       "      <td>sg ad</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>,</td>\n",
       "      <td>,</td>\n",
       "      <td>,</td>\n",
       "      <td>,</td>\n",
       "      <td>[',']</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>xhus</td>\n",
       "      <td>xhus</td>\n",
       "      <td>xhu</td>\n",
       "      <td>xhu</td>\n",
       "      <td>['xhu']</td>\n",
       "      <td>s</td>\n",
       "      <td></td>\n",
       "      <td>sg in</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>vxi</td>\n",
       "      <td>vxi</td>\n",
       "      <td>vxi</td>\n",
       "      <td>vxi</td>\n",
       "      <td>['vxi']</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>sg g</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>metsas</td>\n",
       "      <td>metsas</td>\n",
       "      <td>mets</td>\n",
       "      <td>mets</td>\n",
       "      <td>['mets']</td>\n",
       "      <td>s</td>\n",
       "      <td></td>\n",
       "      <td>sg in</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "Layer(name='morph_analysis', attributes=('normalized_text', 'lemma', 'root', 'root_tokens', 'ending', 'clitic', 'form', 'partofspeech'), spans=SL[Span('see', [{'normalized_text': 'see', 'lemma': 'see', 'root': 'see', 'root_tokens': ['see'], 'ending': '0', 'clitic': '', 'form': 'sg n', 'partofspeech': 'P'}]),\n",
       "Span('onn', [{'normalized_text': 'onn', 'lemma': 'onn', 'root': 'onn', 'root_tokens': ['onn'], 'ending': '0', 'clitic': '', 'form': 'sg n', 'partofspeech': 'S'}]),\n",
       "Span('hädavajalik', [{'normalized_text': 'hädavajalik', 'lemma': 'hädavajalik', 'root': 'häda_vajalik', 'root_tokens': ['häda', 'vajalik'], 'ending': '0', 'clitic': '', 'form': 'sg n', 'partofspeech': 'A'}]),\n",
       "Span('vajd', [{'normalized_text': 'vajd', 'lemma': 'vajd', 'root': 'vajd', 'root_tokens': ['vajd'], 'ending': '0', 'clitic': '', 'form': 'sg n', 'partofspeech': 'S'}]),\n",
       "Span('merel', [{'normalized_text': 'merel', 'lemma': 'meri', 'root': 'meri', 'root_tokens': ['meri'], 'ending': 'l', 'clitic': '', 'form': 'sg ad', 'partofspeech': 'S'}]),\n",
       "Span(',', [{'normalized_text': ',', 'lemma': ',', 'root': ',', 'root_tokens': [','], 'ending': '', 'clitic': '', 'form': '', 'partofspeech': 'Z'}]),\n",
       "Span('xhus', [{'normalized_text': 'xhus', 'lemma': 'xhu', 'root': 'xhu', 'root_tokens': ['xhu'], 'ending': 's', 'clitic': '', 'form': 'sg in', 'partofspeech': 'S'}]),\n",
       "Span('vxi', [{'normalized_text': 'vxi', 'lemma': 'vxi', 'root': 'vxi', 'root_tokens': ['vxi'], 'ending': '0', 'clitic': '', 'form': 'sg g', 'partofspeech': 'S'}]),\n",
       "Span('metsas', [{'normalized_text': 'metsas', 'lemma': 'mets', 'root': 'mets', 'root_tokens': ['mets'], 'ending': 's', 'clitic': '', 'form': 'sg in', 'partofspeech': 'S'}])])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from estnltk import Text\n",
    "text = Text(text_str)\n",
    "text.tag_layer(['morph_analysis'])\n",
    "text.morph_analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, the results were not so good."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But we can create a dictionary that maps each misspelled word to a standard word (a correctly spelled word):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from estnltk.taggers import make_userdict\n",
    "\n",
    "# Create UserDictTagger based on given corrections\n",
    "userdict = make_userdict({'onn': 'on',\n",
    "                          'vajd': 'vaid',\n",
    "                          'xhus': 'õhus',\n",
    "                          'vxi': 'või'}, ignore_case=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`make_userdict` returns an instance of `UserDictTagger`. The parameter `ignore_case` specifies that case differences will be ignored when searching misspelled words from text. \n",
    "Now, we can apply `UserDictTagger` to correct the analyses (\"retag morphological analyses\"):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h4>Layer</h4>\n",
       "\n",
       "\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>layer name</th>\n",
       "      <th>attributes</th>\n",
       "      <th>parent</th>\n",
       "      <th>enveloping</th>\n",
       "      <th>ambiguous</th>\n",
       "      <th>span count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>morph_analysis</td>\n",
       "      <td>normalized_text, lemma, root, root_tokens, ending, clitic, form, partofspeech</td>\n",
       "      <td>words</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>text</th>\n",
       "      <th>normalized_text</th>\n",
       "      <th>lemma</th>\n",
       "      <th>root</th>\n",
       "      <th>root_tokens</th>\n",
       "      <th>ending</th>\n",
       "      <th>clitic</th>\n",
       "      <th>form</th>\n",
       "      <th>partofspeech</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>see</td>\n",
       "      <td>see</td>\n",
       "      <td>see</td>\n",
       "      <td>see</td>\n",
       "      <td>['see']</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>sg n</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>onn</td>\n",
       "      <td>on</td>\n",
       "      <td>olema</td>\n",
       "      <td>ole</td>\n",
       "      <td>['ole']</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>b</td>\n",
       "      <td>V</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td></td>\n",
       "      <td>on</td>\n",
       "      <td>olema</td>\n",
       "      <td>ole</td>\n",
       "      <td>['ole']</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>vad</td>\n",
       "      <td>V</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>hädavajalik</td>\n",
       "      <td>hädavajalik</td>\n",
       "      <td>hädavajalik</td>\n",
       "      <td>häda_vajalik</td>\n",
       "      <td>['häda', 'vajalik']</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>sg n</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>vajd</td>\n",
       "      <td>vaid</td>\n",
       "      <td>vaid</td>\n",
       "      <td>vaid</td>\n",
       "      <td>['vaid']</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td></td>\n",
       "      <td>vaid</td>\n",
       "      <td>vaid</td>\n",
       "      <td>vaid</td>\n",
       "      <td>['vaid']</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>J</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>merel</td>\n",
       "      <td>merel</td>\n",
       "      <td>meri</td>\n",
       "      <td>meri</td>\n",
       "      <td>['meri']</td>\n",
       "      <td>l</td>\n",
       "      <td></td>\n",
       "      <td>sg ad</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>,</td>\n",
       "      <td>,</td>\n",
       "      <td>,</td>\n",
       "      <td>,</td>\n",
       "      <td>[',']</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>xhus</td>\n",
       "      <td>õhus</td>\n",
       "      <td>õhk</td>\n",
       "      <td>õhk</td>\n",
       "      <td>['õhk']</td>\n",
       "      <td>s</td>\n",
       "      <td></td>\n",
       "      <td>sg in</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>vxi</td>\n",
       "      <td>või</td>\n",
       "      <td>või</td>\n",
       "      <td>või</td>\n",
       "      <td>['või']</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>sg g</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td></td>\n",
       "      <td>või</td>\n",
       "      <td>võima</td>\n",
       "      <td>või</td>\n",
       "      <td>['või']</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>o</td>\n",
       "      <td>V</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td></td>\n",
       "      <td>või</td>\n",
       "      <td>või</td>\n",
       "      <td>või</td>\n",
       "      <td>['või']</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td></td>\n",
       "      <td>või</td>\n",
       "      <td>või</td>\n",
       "      <td>või</td>\n",
       "      <td>['või']</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>J</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td></td>\n",
       "      <td>või</td>\n",
       "      <td>või</td>\n",
       "      <td>või</td>\n",
       "      <td>['või']</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>sg n</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>metsas</td>\n",
       "      <td>metsas</td>\n",
       "      <td>mets</td>\n",
       "      <td>mets</td>\n",
       "      <td>['mets']</td>\n",
       "      <td>s</td>\n",
       "      <td></td>\n",
       "      <td>sg in</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "Layer(name='morph_analysis', attributes=('normalized_text', 'lemma', 'root', 'root_tokens', 'ending', 'clitic', 'form', 'partofspeech'), spans=SL[Span('see', [{'normalized_text': 'see', 'lemma': 'see', 'root': 'see', 'root_tokens': ['see'], 'ending': '0', 'clitic': '', 'form': 'sg n', 'partofspeech': 'P'}]),\n",
       "Span('onn', [{'normalized_text': 'on', 'lemma': 'olema', 'root': 'ole', 'root_tokens': ['ole'], 'ending': '0', 'clitic': '', 'form': 'b', 'partofspeech': 'V'}, {'normalized_text': 'on', 'lemma': 'olema', 'root': 'ole', 'root_tokens': ['ole'], 'ending': '0', 'clitic': '', 'form': 'vad', 'partofspeech': 'V'}]),\n",
       "Span('hädavajalik', [{'normalized_text': 'hädavajalik', 'lemma': 'hädavajalik', 'root': 'häda_vajalik', 'root_tokens': ['häda', 'vajalik'], 'ending': '0', 'clitic': '', 'form': 'sg n', 'partofspeech': 'A'}]),\n",
       "Span('vajd', [{'normalized_text': 'vaid', 'lemma': 'vaid', 'root': 'vaid', 'root_tokens': ['vaid'], 'ending': '0', 'clitic': '', 'form': '', 'partofspeech': 'D'}, {'normalized_text': 'vaid', 'lemma': 'vaid', 'root': 'vaid', 'root_tokens': ['vaid'], 'ending': '0', 'clitic': '', 'form': '', 'partofspeech': 'J'}]),\n",
       "Span('merel', [{'normalized_text': 'merel', 'lemma': 'meri', 'root': 'meri', 'root_tokens': ['meri'], 'ending': 'l', 'clitic': '', 'form': 'sg ad', 'partofspeech': 'S'}]),\n",
       "Span(',', [{'normalized_text': ',', 'lemma': ',', 'root': ',', 'root_tokens': [','], 'ending': '', 'clitic': '', 'form': '', 'partofspeech': 'Z'}]),\n",
       "Span('xhus', [{'normalized_text': 'õhus', 'lemma': 'õhk', 'root': 'õhk', 'root_tokens': ['õhk'], 'ending': 's', 'clitic': '', 'form': 'sg in', 'partofspeech': 'S'}]),\n",
       "Span('vxi', [{'normalized_text': 'või', 'lemma': 'või', 'root': 'või', 'root_tokens': ['või'], 'ending': '0', 'clitic': '', 'form': 'sg g', 'partofspeech': 'S'}, {'normalized_text': 'või', 'lemma': 'võima', 'root': 'või', 'root_tokens': ['või'], 'ending': '0', 'clitic': '', 'form': 'o', 'partofspeech': 'V'}, {'normalized_text': 'või', 'lemma': 'või', 'root': 'või', 'root_tokens': ['või'], 'ending': '0', 'clitic': '', 'form': '', 'partofspeech': 'D'}, {'normalized_text': 'või', 'lemma': 'või', 'root': 'või', 'root_tokens': ['või'], 'ending': '0', 'clitic': '', 'form': '', 'partofspeech': 'J'}, {'normalized_text': 'või', 'lemma': 'või', 'root': 'või', 'root_tokens': ['või'], 'ending': '0', 'clitic': '', 'form': 'sg n', 'partofspeech': 'S'}]),\n",
       "Span('metsas', [{'normalized_text': 'metsas', 'lemma': 'mets', 'root': 'mets', 'root_tokens': ['mets'], 'ending': 's', 'clitic': '', 'form': 'sg in', 'partofspeech': 'S'}])])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "userdict.retag(text)\n",
    "text.morph_analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And — _voilà_ — we have obtained corrected analyses for misspelled words."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inspecting dictionary. Saving and loading dictionary's contents\n",
    "\n",
    "If you need to inspect the content of the user dictionary (list all words and their corrected analyses), you can use `UserDictTagger`'s method `save_as_csv( None )`, which returns dictionary's content as a CSV formatted string:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text\tnormalized_text\troot\tending\tclitic\tform\tpartofspeech\r\n",
      "onn\ton\tole\t0\t\tb\tV\r\n",
      "onn\ton\tole\t0\t\tvad\tV\r\n",
      "vajd\tvaid\tvaid\t0\t\t\tD\r\n",
      "vajd\tvaid\tvaid\t0\t\t\tJ\r\n",
      "vxi\tvõi\tvõi\t0\t\tsg g\tS\r\n",
      "vxi\tvõi\tvõi\t0\t\to\tV\r\n",
      "vxi\tvõi\tvõi\t0\t\t\tD\r\n",
      "vxi\tvõi\tvõi\t0\t\t\tJ\r\n",
      "vxi\tvõi\tvõi\t0\t\tsg n\tS\r\n",
      "xhus\tõhus\tõhk\ts\t\tsg in\tS\r\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# NBVAL_IGNORE_OUTPUT\n",
    "print( userdict.save_as_csv( None ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you pass a file name to the method `save_as_csv`, then dictionary content will be saved to the corresponding file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save user dictionary into file 'my_corrections.csv'\n",
    "userdict.save_as_csv( 'my_corrections.csv' )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to create `UserDictTagger` from a CSV file, you need to import the tagger and initialize it with `csv_file` parameter pointing to the name of the file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load user dictionary from file 'my_corrections.csv'\n",
    "from estnltk.taggers import UserDictTagger\n",
    "userdict2 = UserDictTagger(csv_file='my_corrections.csv', ignore_case=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text\tnormalized_text\troot\tending\tclitic\tform\tpartofspeech\r\n",
      "onn\ton\tole\t0\t\tb\tV\r\n",
      "onn\ton\tole\t0\t\tvad\tV\r\n",
      "vajd\tvaid\tvaid\t0\t\t\tD\r\n",
      "vajd\tvaid\tvaid\t0\t\t\tJ\r\n",
      "vxi\tvõi\tvõi\t0\t\tsg g\tS\r\n",
      "vxi\tvõi\tvõi\t0\t\to\tV\r\n",
      "vxi\tvõi\tvõi\t0\t\t\tD\r\n",
      "vxi\tvõi\tvõi\t0\t\t\tJ\r\n",
      "vxi\tvõi\tvõi\t0\t\tsg n\tS\r\n",
      "xhus\tõhus\tõhk\ts\t\tsg in\tS\r\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Check contents of the loaded user dictionary\n",
    "# NBVAL_IGNORE_OUTPUT\n",
    "print( userdict2.save_as_csv( None ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While saving dictionary to a file or loading dictionary from a file, you can also change the formatting parameters of the CSV file. See the sections \"Loading analyses from CSV file\" and \"Saving analyses to CSV file\" below for details."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configuration of morphological analysis\n",
    "\n",
    "For creating morphological analyses, the function `make_userdict` uses `VabamorfAnalyzer` with default settings. \n",
    "If you want to change the parameters of morphological analysis, you can create an instance of `VabamorfAnalyzer` with desired settings and pass it to `make_userdict` as an argument:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create VabamorfAnalyzer that does not guess proper names\n",
    "from estnltk.taggers import VabamorfAnalyzer\n",
    "vm_analyzer = VabamorfAnalyzer(propername=False)\n",
    "\n",
    "# Create UserDictTagger based on given corrections\n",
    "# and using given VabamorfAnalyzer\n",
    "userdict = make_userdict({'Jänenene': 'Jänes',\n",
    "                          'Kissu': 'Kiisu',\n",
    "                          'Tsuksu':'Suksu'}, \n",
    "                          vm_analyzer=vm_analyzer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text\tnormalized_text\troot\tending\tclitic\tform\tpartofspeech\r\n",
      "Jänenene\tJänes\tjänes\t0\t\tsg n\tS\r\n",
      "Kissu\tKiisu\tkiisu\t0\t\tsg g\tS\r\n",
      "Kissu\tKiisu\tkiisu\t0\t\tsg n\tS\r\n",
      "Tsuksu\tSuksu\tsuksu\t0\t\tsg g\tS\r\n",
      "Tsuksu\tSuksu\tsuksu\t0\t\tsg n\tS\r\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# NBVAL_IGNORE_OUTPUT\n",
    "# Inspect user dictionary content\n",
    "print( userdict.save_as_csv( None ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "<h4>Notes on morphological ambiguity and disambiguation</h4>\n",
    "<br>\n",
    "While creating an user dictionary with <code>make_userdict</code>, you can also define a mapping from a non-standard word to a list of corresponding standard words in case there is an ambiguity.\n",
    "For instance, in the previous example, we could define:\n",
    "<pre>\n",
    "userdict = make_userdict({'Jänenene': ['Jänes', 'Jänku'],\n",
    "                          'Kissu': 'Kiisu'\n",
    "                          'Tsuksu':'Suksu'}, \n",
    "                          vm_analyzer=vm_analyzer)\n",
    "</pre>\n",
    "As a result, <code>VabamorfAnalyzer</code> generates analyses for each of the listed words, and the entry for word 'Jänenene' will be:\n",
    "<pre>\n",
    "text\tnormalized_text\troot\tending\tclitic\tform\tpartofspeech\n",
    "Jänenene\tJänes\tjänes\t0\t\tsg n\tS\n",
    "Jänenene\tJänku\tjänku\t0\t\tsg g\tS\n",
    "Jänenene\tJänku\tjänku\t0\t\tsg n\tS\n",
    "</pre>\n",
    "<i>Be aware</i> that applying this correction on <code>'morph_analysis'</code> layer produces words with multiple <code>normalized_text</code>-s.\n",
    "However, with multiple <code>normalized_text</code>-s, there is no guarantee for correct morphological disambiguation. Therefore, if you have made corrections that produce multiple normalized forms, we do not recommend applying disambiguation.\n",
    "If you really need to do it, you should definitely check first if the disambiguation quality is satisfactory.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `UserDictTagger`\n",
    "\n",
    "### Basic usage: partial overwriting\n",
    "\n",
    "If you want a more fine-grained control over corrections made on morphological analyses, then you can manually initialize `UserDictTagger` with the corrections you want to make.\n",
    "\n",
    "Let's consider an example when we want to correct root of a compound word:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h4>Layer</h4>\n",
       "\n",
       "\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>layer name</th>\n",
       "      <th>attributes</th>\n",
       "      <th>parent</th>\n",
       "      <th>enveloping</th>\n",
       "      <th>ambiguous</th>\n",
       "      <th>span count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>morph_analysis</td>\n",
       "      <td>normalized_text, lemma, root, root_tokens, ending, clitic, form, partofspeech</td>\n",
       "      <td>words</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>text</th>\n",
       "      <th>normalized_text</th>\n",
       "      <th>lemma</th>\n",
       "      <th>root</th>\n",
       "      <th>root_tokens</th>\n",
       "      <th>ending</th>\n",
       "      <th>clitic</th>\n",
       "      <th>form</th>\n",
       "      <th>partofspeech</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>Abieluettepanek</td>\n",
       "      <td>Abieluettepanek</td>\n",
       "      <td>abieluettepanek</td>\n",
       "      <td>abi_elu_ette_panek</td>\n",
       "      <td>['abi', 'elu', 'ette', 'panek']</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>sg n</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>lükati</td>\n",
       "      <td>lükati</td>\n",
       "      <td>lükkama</td>\n",
       "      <td>lükka</td>\n",
       "      <td>['lükka']</td>\n",
       "      <td>ti</td>\n",
       "      <td></td>\n",
       "      <td>ti</td>\n",
       "      <td>V</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>tagasi</td>\n",
       "      <td>tagasi</td>\n",
       "      <td>tagasi</td>\n",
       "      <td>tagasi</td>\n",
       "      <td>['tagasi']</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "Layer(name='morph_analysis', attributes=('normalized_text', 'lemma', 'root', 'root_tokens', 'ending', 'clitic', 'form', 'partofspeech'), spans=SL[Span('Abieluettepanek', [{'normalized_text': 'Abieluettepanek', 'lemma': 'abieluettepanek', 'root': 'abi_elu_ette_panek', 'root_tokens': ['abi', 'elu', 'ette', 'panek'], 'ending': '0', 'clitic': '', 'form': 'sg n', 'partofspeech': 'S'}]),\n",
       "Span('lükati', [{'normalized_text': 'lükati', 'lemma': 'lükkama', 'root': 'lükka', 'root_tokens': ['lükka'], 'ending': 'ti', 'clitic': '', 'form': 'ti', 'partofspeech': 'V'}]),\n",
       "Span('tagasi', [{'normalized_text': 'tagasi', 'lemma': 'tagasi', 'root': 'tagasi', 'root_tokens': ['tagasi'], 'ending': '0', 'clitic': '', 'form': '', 'partofspeech': 'D'}])])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from estnltk import Text\n",
    "text = Text('Abieluettepanek lükati tagasi')\n",
    "text.tag_layer(['morph_analysis'])\n",
    "text.morph_analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to change `root` of the word _Abieluettepanek_ from `abi_elu_ette_panek` to `abielu_ettepanek`.\n",
    "For this, we can create a mapping from _'abieluettepanek'_ to a dictionary that specifies correct attribute values.\n",
    "In addition to specifying new value for `root`, we also need to specify `partofspeech`, as this is required for automatically creating new values for `lemma` and `root_tokens`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define corrections for root (and partofspeech)\n",
    "my_corrections = {\n",
    "    'abieluettepanek': { 'root': 'abielu_ettepanek', 'partofspeech': 'S' } \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create UserDictTagger based on given corrections\n",
    "from estnltk.taggers import UserDictTagger\n",
    "userdict = UserDictTagger( words_dict = my_corrections, ignore_case=True )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h4>Layer</h4>\n",
       "\n",
       "\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>layer name</th>\n",
       "      <th>attributes</th>\n",
       "      <th>parent</th>\n",
       "      <th>enveloping</th>\n",
       "      <th>ambiguous</th>\n",
       "      <th>span count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>morph_analysis</td>\n",
       "      <td>normalized_text, lemma, root, root_tokens, ending, clitic, form, partofspeech</td>\n",
       "      <td>words</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>text</th>\n",
       "      <th>normalized_text</th>\n",
       "      <th>lemma</th>\n",
       "      <th>root</th>\n",
       "      <th>root_tokens</th>\n",
       "      <th>ending</th>\n",
       "      <th>clitic</th>\n",
       "      <th>form</th>\n",
       "      <th>partofspeech</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>Abieluettepanek</td>\n",
       "      <td>Abieluettepanek</td>\n",
       "      <td>abieluettepanek</td>\n",
       "      <td>abielu_ettepanek</td>\n",
       "      <td>['abielu', 'ettepanek']</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>sg n</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>lükati</td>\n",
       "      <td>lükati</td>\n",
       "      <td>lükkama</td>\n",
       "      <td>lükka</td>\n",
       "      <td>['lükka']</td>\n",
       "      <td>ti</td>\n",
       "      <td></td>\n",
       "      <td>ti</td>\n",
       "      <td>V</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>tagasi</td>\n",
       "      <td>tagasi</td>\n",
       "      <td>tagasi</td>\n",
       "      <td>tagasi</td>\n",
       "      <td>['tagasi']</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "Layer(name='morph_analysis', attributes=('normalized_text', 'lemma', 'root', 'root_tokens', 'ending', 'clitic', 'form', 'partofspeech'), spans=SL[Span('Abieluettepanek', [{'normalized_text': 'Abieluettepanek', 'lemma': 'abieluettepanek', 'root': 'abielu_ettepanek', 'root_tokens': ['abielu', 'ettepanek'], 'ending': '0', 'clitic': '', 'form': 'sg n', 'partofspeech': 'S'}]),\n",
       "Span('lükati', [{'normalized_text': 'lükati', 'lemma': 'lükkama', 'root': 'lükka', 'root_tokens': ['lükka'], 'ending': 'ti', 'clitic': '', 'form': 'ti', 'partofspeech': 'V'}]),\n",
       "Span('tagasi', [{'normalized_text': 'tagasi', 'lemma': 'tagasi', 'root': 'tagasi', 'root_tokens': ['tagasi'], 'ending': '0', 'clitic': '', 'form': '', 'partofspeech': 'D'}])])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Apply corrections\n",
    "userdict.retag(text)\n",
    "text.morph_analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note:\n",
    "\n",
    "  * If you need to change any of the attributes `root`, `lemma` or `root_tokens`, you should update all of them in order to keep the data consistent. The systematic way how to do it is to restrict your dictionary entries only to `root` and `partofspeech` (and `ending`, if required). Attributes `lemma` and `root_tokens` will then be automatically generated based on `root` and `partofspeech`. So, no need to manually provide entries for `lemma` and `root_tokens`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mapping a changeable word to a dictionary of new attribute values initiates **partial overwriting** -- only specific attributes will be corrected and other attributes will remain as they are.\n",
    "\n",
    "Let's consider another example of partial overwriting:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h4>Layer</h4>\n",
       "\n",
       "\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>layer name</th>\n",
       "      <th>attributes</th>\n",
       "      <th>parent</th>\n",
       "      <th>enveloping</th>\n",
       "      <th>ambiguous</th>\n",
       "      <th>span count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>morph_analysis</td>\n",
       "      <td>normalized_text, lemma, root, root_tokens, ending, clitic, form, partofspeech</td>\n",
       "      <td>words</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>text</th>\n",
       "      <th>normalized_text</th>\n",
       "      <th>lemma</th>\n",
       "      <th>root</th>\n",
       "      <th>root_tokens</th>\n",
       "      <th>ending</th>\n",
       "      <th>clitic</th>\n",
       "      <th>form</th>\n",
       "      <th>partofspeech</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>igapäävased</td>\n",
       "      <td>igapäävased</td>\n",
       "      <td>igapäävask</td>\n",
       "      <td>igapää_vask</td>\n",
       "      <td>['igapää', 'vask']</td>\n",
       "      <td>d</td>\n",
       "      <td></td>\n",
       "      <td>pl n</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>toimetused</td>\n",
       "      <td>toimetused</td>\n",
       "      <td>toimetus</td>\n",
       "      <td>toimetus</td>\n",
       "      <td>['toimetus']</td>\n",
       "      <td>d</td>\n",
       "      <td></td>\n",
       "      <td>pl n</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "Layer(name='morph_analysis', attributes=('normalized_text', 'lemma', 'root', 'root_tokens', 'ending', 'clitic', 'form', 'partofspeech'), spans=SL[Span('igapäävased', [{'normalized_text': 'igapäävased', 'lemma': 'igapäävask', 'root': 'igapää_vask', 'root_tokens': ['igapää', 'vask'], 'ending': 'd', 'clitic': '', 'form': 'pl n', 'partofspeech': 'S'}]),\n",
       "Span('toimetused', [{'normalized_text': 'toimetused', 'lemma': 'toimetus', 'root': 'toimetus', 'root_tokens': ['toimetus'], 'ending': 'd', 'clitic': '', 'form': 'pl n', 'partofspeech': 'S'}])])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example: word thad needs corrections only in the root and partofspeech\n",
    "text = Text('igapäävased toimetused')\n",
    "text.tag_layer(['morph_analysis'])\n",
    "text.morph_analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Corrections only for 'root' and 'partofspeech' of the word (leave other attributes as they are)\n",
    "my_corrections = {\n",
    "    'igapäävased': { 'root': 'iga_päevane', 'partofspeech': 'A'} \n",
    "}\n",
    "# Create new user dictionary\n",
    "userdict = UserDictTagger( words_dict=my_corrections )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h4>Layer</h4>\n",
       "\n",
       "\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>layer name</th>\n",
       "      <th>attributes</th>\n",
       "      <th>parent</th>\n",
       "      <th>enveloping</th>\n",
       "      <th>ambiguous</th>\n",
       "      <th>span count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>morph_analysis</td>\n",
       "      <td>normalized_text, lemma, root, root_tokens, ending, clitic, form, partofspeech</td>\n",
       "      <td>words</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>text</th>\n",
       "      <th>normalized_text</th>\n",
       "      <th>lemma</th>\n",
       "      <th>root</th>\n",
       "      <th>root_tokens</th>\n",
       "      <th>ending</th>\n",
       "      <th>clitic</th>\n",
       "      <th>form</th>\n",
       "      <th>partofspeech</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>igapäävased</td>\n",
       "      <td>igapäävased</td>\n",
       "      <td>igapäevane</td>\n",
       "      <td>iga_päevane</td>\n",
       "      <td>['iga', 'päevane']</td>\n",
       "      <td>d</td>\n",
       "      <td></td>\n",
       "      <td>pl n</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>toimetused</td>\n",
       "      <td>toimetused</td>\n",
       "      <td>toimetus</td>\n",
       "      <td>toimetus</td>\n",
       "      <td>['toimetus']</td>\n",
       "      <td>d</td>\n",
       "      <td></td>\n",
       "      <td>pl n</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "Layer(name='morph_analysis', attributes=('normalized_text', 'lemma', 'root', 'root_tokens', 'ending', 'clitic', 'form', 'partofspeech'), spans=SL[Span('igapäävased', [{'normalized_text': 'igapäävased', 'lemma': 'igapäevane', 'root': 'iga_päevane', 'root_tokens': ['iga', 'päevane'], 'ending': 'd', 'clitic': '', 'form': 'pl n', 'partofspeech': 'A'}]),\n",
       "Span('toimetused', [{'normalized_text': 'toimetused', 'lemma': 'toimetus', 'root': 'toimetus', 'root_tokens': ['toimetus'], 'ending': 'd', 'clitic': '', 'form': 'pl n', 'partofspeech': 'S'}])])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Apply corrections:\n",
    "userdict.retag(text)\n",
    "text.morph_analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The minimum requirement for the dictionary of partial overwriting: it must specify at least one of the fields: `'root'`, `'ending'`, `'clitic'`, `'form'`, and `'partofspeech'`. Note: if `'root'` is provided, then `'partofspeech'` must also be provided (so that `'root_tokens'` and `'lemma'` can be automatically created)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Complete overwriting\n",
    "\n",
    "If the correction entry maps a word to a list of dictionaries, then all old anayses of the word will be replaced by the listed analyses. \n",
    "A list with a single dictionary means that the word is unambiguous, and multiple dictionaries represent different analysis variants of an ambiguous word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create new user dictionary with multiple analysis variants\n",
    "my_corrections = {\n",
    "    'onn': [{'form': 'b', 'root': 'ole', 'ending':'0', 'partofspeech': 'V', 'clitic':''},\\\n",
    "            {'form': 'vad', 'root': 'ole', 'ending':'0', 'partofspeech': 'V', 'clitic':''} ]\n",
    "}\n",
    "userdict = UserDictTagger( words_dict = my_corrections )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h4>Layer</h4>\n",
       "\n",
       "\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>layer name</th>\n",
       "      <th>attributes</th>\n",
       "      <th>parent</th>\n",
       "      <th>enveloping</th>\n",
       "      <th>ambiguous</th>\n",
       "      <th>span count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>morph_analysis</td>\n",
       "      <td>normalized_text, lemma, root, root_tokens, ending, clitic, form, partofspeech</td>\n",
       "      <td>words</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>text</th>\n",
       "      <th>normalized_text</th>\n",
       "      <th>lemma</th>\n",
       "      <th>root</th>\n",
       "      <th>root_tokens</th>\n",
       "      <th>ending</th>\n",
       "      <th>clitic</th>\n",
       "      <th>form</th>\n",
       "      <th>partofspeech</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>vist</td>\n",
       "      <td>vist</td>\n",
       "      <td>vist</td>\n",
       "      <td>vist</td>\n",
       "      <td>['vist']</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>onn</td>\n",
       "      <td>onn</td>\n",
       "      <td>onn</td>\n",
       "      <td>onn</td>\n",
       "      <td>['onn']</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>sg n</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>rahul</td>\n",
       "      <td>rahul</td>\n",
       "      <td>rahul</td>\n",
       "      <td>rahul</td>\n",
       "      <td>['rahul']</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "Layer(name='morph_analysis', attributes=('normalized_text', 'lemma', 'root', 'root_tokens', 'ending', 'clitic', 'form', 'partofspeech'), spans=SL[Span('vist', [{'normalized_text': 'vist', 'lemma': 'vist', 'root': 'vist', 'root_tokens': ['vist'], 'ending': '0', 'clitic': '', 'form': '', 'partofspeech': 'D'}]),\n",
       "Span('onn', [{'normalized_text': 'onn', 'lemma': 'onn', 'root': 'onn', 'root_tokens': ['onn'], 'ending': '0', 'clitic': '', 'form': 'sg n', 'partofspeech': 'S'}]),\n",
       "Span('rahul', [{'normalized_text': 'rahul', 'lemma': 'rahul', 'root': 'rahul', 'root_tokens': ['rahul'], 'ending': '0', 'clitic': '', 'form': '', 'partofspeech': 'D'}])])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example: verb needs corrections, but the ambiguities should remain\n",
    "#          ( because it is not clear from the context, which form is correct )\n",
    "text = Text('vist onn rahul')\n",
    "text.tag_layer(['morph_analysis'])\n",
    "text.morph_analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h4>Layer</h4>\n",
       "\n",
       "\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>layer name</th>\n",
       "      <th>attributes</th>\n",
       "      <th>parent</th>\n",
       "      <th>enveloping</th>\n",
       "      <th>ambiguous</th>\n",
       "      <th>span count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>morph_analysis</td>\n",
       "      <td>normalized_text, lemma, root, root_tokens, ending, clitic, form, partofspeech</td>\n",
       "      <td>words</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>text</th>\n",
       "      <th>normalized_text</th>\n",
       "      <th>lemma</th>\n",
       "      <th>root</th>\n",
       "      <th>root_tokens</th>\n",
       "      <th>ending</th>\n",
       "      <th>clitic</th>\n",
       "      <th>form</th>\n",
       "      <th>partofspeech</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>vist</td>\n",
       "      <td>vist</td>\n",
       "      <td>vist</td>\n",
       "      <td>vist</td>\n",
       "      <td>['vist']</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>onn</td>\n",
       "      <td>None</td>\n",
       "      <td>olema</td>\n",
       "      <td>ole</td>\n",
       "      <td>['ole']</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>b</td>\n",
       "      <td>V</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>olema</td>\n",
       "      <td>ole</td>\n",
       "      <td>['ole']</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>vad</td>\n",
       "      <td>V</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>rahul</td>\n",
       "      <td>rahul</td>\n",
       "      <td>rahul</td>\n",
       "      <td>rahul</td>\n",
       "      <td>['rahul']</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "Layer(name='morph_analysis', attributes=('normalized_text', 'lemma', 'root', 'root_tokens', 'ending', 'clitic', 'form', 'partofspeech'), spans=SL[Span('vist', [{'normalized_text': 'vist', 'lemma': 'vist', 'root': 'vist', 'root_tokens': ['vist'], 'ending': '0', 'clitic': '', 'form': '', 'partofspeech': 'D'}]),\n",
       "Span('onn', [{'normalized_text': None, 'lemma': 'olema', 'root': 'ole', 'root_tokens': ['ole'], 'ending': '0', 'clitic': '', 'form': 'b', 'partofspeech': 'V'}, {'normalized_text': None, 'lemma': 'olema', 'root': 'ole', 'root_tokens': ['ole'], 'ending': '0', 'clitic': '', 'form': 'vad', 'partofspeech': 'V'}]),\n",
       "Span('rahul', [{'normalized_text': 'rahul', 'lemma': 'rahul', 'root': 'rahul', 'root_tokens': ['rahul'], 'ending': '0', 'clitic': '', 'form': '', 'partofspeech': 'D'}])])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Apply corrections\n",
    "userdict.retag(text)\n",
    "text.morph_analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The minimum requirement for the dictionary used in complete overwriting: it must specify all the fields `'root'`, `'ending'`, `'clitic'`, `'form'`, and `'partofspeech'`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### More details on `UserDictTagger`\n",
    "\n",
    "#### About `normalized_text` attribute\n",
    "\n",
    "Dictionary's entry for a word may contain `normalized_text` value, but this is not mandatory. Note, however, that if  `normalized_text` is missing from the entry (and you are using complete overwriting), then by default, the value of `normalized_text` will be set to `None` in the `'morph_analysis'` layer;\n",
    "\n",
    "You can initialize `UserDictTagger` with the parameter `replace_missing_normalized_text_with_text=True`. After that, if a `normalized_text` is missing from the dictionary entry, then its value will be replaced with word's text. Note, however, that if word's text is a non-standard word form (such as _vajd_, _xhus_, _vxi_ in the previous example), then the outcome will be misleading (a normalized_text is actually the non-standard one). So, you should use this option if you are correcting analyses of words which already follow orthographic standard;\n",
    "\n",
    "#### About dictionary lookup\n",
    "\n",
    "Words that you add to `UserDictTagger` will be matched against `normalized_text` values of text's morphological analyses. \n",
    "If a morphological analysis has `normalized_text` equal to `None`, then the dictionary word will be matched against `text` of the morphological analysis. By default, the matching is case sensitive, but you can turn it off by setting `ignore_case=True` when initializing `UserDictTagger`.\n",
    "\n",
    "#### About matching and matching priorities\n",
    "\n",
    "If a match is found, and `UserDictTagger`'s entry for the word corresponds to a dictionary, then the _partial overwriting strategy_ will be applied: only those morphological analysis' attributes that are in the dictionary will overwritten, and all other attributes remain as they are.\n",
    "If matching word's entry is a list of dictionaries, the _complete overwriting strategy_ will be applied: all morphological analyses of the word will be replaced by analyses from the corresponding `UserDictTagger`'s entry.\n",
    "\n",
    "If some of word's morphological analyses obtain _partial overwriting_ matches, and some obtain _complete overwriting_ matches, then the final result will be complete overwriting according to the last complete overwriting match.\n",
    "In similar vein, if there is more than one morphological analysis that obtains a complete overwriting match, then the final result will be overwriting according to the last complete overwriting match (so, all matches previous to the last will be ignored).\n",
    "\n",
    "#### How to overwrite only unknown words\n",
    "\n",
    "By default, `UserDictTagger` overwrites all words that can be matched to the user dictionary. This means that unknown words with `None` analyses are overwritten as well as known words with existing analyses.\n",
    "However, you can use the setting `overwrite_existing=False` on initializing `UserDictTagger` to turn off overwriting of existing analyses.\n",
    "With this setting, only words with `None` analyses will obtain analyses from the user dictionary, and all words with existing analyses will remain as they are.\n",
    "\n",
    "#### How to turn off category validation [Advanced]\n",
    "\n",
    "Analyses added to the `UserDictTagger` will be checked for validity of partofspeech and form categories. \n",
    "The validation checks if the respective category values are valid category values for Vabamorf. \n",
    "If you want to introduce new categories, then you can turn off category validation with the flag `validate_vm_categories=False` upon initialization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading analyses from CSV file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`UserDictTagger` takes a parameter `csv_file`, which specifies the name of the CSV file from which the content of the dictionary will be loaded.\n",
    "\n",
    "Let's consider an example of loading corrections from a customized CSV file. First, create the file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a CSV file with correct analyses\n",
    "import tempfile\n",
    "fp = tempfile.NamedTemporaryFile(mode='w', encoding='utf-8', suffix='.csv', delete=False)\n",
    "# Add header\n",
    "fp.write('text,form,root,ending,partofspeech,clitic\\n')\n",
    "# Add analyses\n",
    "fp.write('mxnel,sg ad,mõni,l,P,\\n')\n",
    "fp.write('igapäävased,pl n,iga_päevane,d,A,\\n')\n",
    "fp.write('kxnekeeleväljändid,pl n,kõne_keele_väljend,d,S,\\n')\n",
    "fp.write('sellged,pl n,selge,d,A,\\n')\n",
    "fp.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is required that the first line of the CSV file is the header, and uses the heading names `'root'`, `'ending'`, `'clitic'`, `'form'`, `'partofspeech'`, `'text'`. This is required to determine in which order the data has to be loaded from the file.\n",
    "\n",
    "Each line following the heading specifies a single analysis for a word. The word itself must be under the column `'text'`. Note that like in case of the _complete overwriting_, all the fields `'root'`, `'ending'`, `'clitic'`, `'form'` and `'partofspeech'` must be specified. You can also provide multiple lines describing a single word: these will be then considered as different analysis variants of an ambiguous word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create new user dictionary with the analyses loaded from the CSV file\n",
    "userdict = UserDictTagger( csv_file=fp.name, encoding='utf-8', delimiter=',' )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: you can pass optional parameters, such as `dialect` and `delimiter`, to the constructor in order to specify the formatting of the CSV file. Basically, you can use the same parameters as can be used with the method `csv.reader`: https://docs.python.org/3/library/csv.html#csv.reader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h4>Layer</h4>\n",
       "\n",
       "\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>layer name</th>\n",
       "      <th>attributes</th>\n",
       "      <th>parent</th>\n",
       "      <th>enveloping</th>\n",
       "      <th>ambiguous</th>\n",
       "      <th>span count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>morph_analysis</td>\n",
       "      <td>normalized_text, lemma, root, root_tokens, ending, clitic, form, partofspeech</td>\n",
       "      <td>words</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>text</th>\n",
       "      <th>normalized_text</th>\n",
       "      <th>lemma</th>\n",
       "      <th>root</th>\n",
       "      <th>root_tokens</th>\n",
       "      <th>ending</th>\n",
       "      <th>clitic</th>\n",
       "      <th>form</th>\n",
       "      <th>partofspeech</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>mxnel</td>\n",
       "      <td>mxnel</td>\n",
       "      <td>mxne</td>\n",
       "      <td>mxne</td>\n",
       "      <td>['mxne']</td>\n",
       "      <td>l</td>\n",
       "      <td></td>\n",
       "      <td>sg ad</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>ka</td>\n",
       "      <td>ka</td>\n",
       "      <td>ka</td>\n",
       "      <td>ka</td>\n",
       "      <td>['ka']</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>igapäävased</td>\n",
       "      <td>igapäävased</td>\n",
       "      <td>igapäävask</td>\n",
       "      <td>igapää_vask</td>\n",
       "      <td>['igapää', 'vask']</td>\n",
       "      <td>d</td>\n",
       "      <td></td>\n",
       "      <td>pl n</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>kxnekeeleväljändid</td>\n",
       "      <td>kxnekeeleväljändid</td>\n",
       "      <td>kxnekeeleväljänd</td>\n",
       "      <td>kxnekeeleväljänd</td>\n",
       "      <td>['kxnekeeleväljänd']</td>\n",
       "      <td>d</td>\n",
       "      <td></td>\n",
       "      <td>pl n</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td></td>\n",
       "      <td>kxnekeeleväljändid</td>\n",
       "      <td>kxnekeeleväljändi</td>\n",
       "      <td>kxnekeeleväljändi</td>\n",
       "      <td>['kxnekeeleväljändi']</td>\n",
       "      <td>d</td>\n",
       "      <td></td>\n",
       "      <td>pl n</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td></td>\n",
       "      <td>kxnekeeleväljändid</td>\n",
       "      <td>kxnekeeleväljänt</td>\n",
       "      <td>kxnekeeleväljänt</td>\n",
       "      <td>['kxnekeeleväljänt']</td>\n",
       "      <td>d</td>\n",
       "      <td></td>\n",
       "      <td>pl n</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>sellged</td>\n",
       "      <td>sellged</td>\n",
       "      <td>sellge</td>\n",
       "      <td>sellge</td>\n",
       "      <td>['sellge']</td>\n",
       "      <td>d</td>\n",
       "      <td></td>\n",
       "      <td>pl n</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td></td>\n",
       "      <td>sellged</td>\n",
       "      <td>sellged</td>\n",
       "      <td>sellged</td>\n",
       "      <td>['sellged']</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>sg n</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "Layer(name='morph_analysis', attributes=('normalized_text', 'lemma', 'root', 'root_tokens', 'ending', 'clitic', 'form', 'partofspeech'), spans=SL[Span('mxnel', [{'normalized_text': 'mxnel', 'lemma': 'mxne', 'root': 'mxne', 'root_tokens': ['mxne'], 'ending': 'l', 'clitic': '', 'form': 'sg ad', 'partofspeech': 'S'}]),\n",
       "Span('ka', [{'normalized_text': 'ka', 'lemma': 'ka', 'root': 'ka', 'root_tokens': ['ka'], 'ending': '0', 'clitic': '', 'form': '', 'partofspeech': 'D'}]),\n",
       "Span('igapäävased', [{'normalized_text': 'igapäävased', 'lemma': 'igapäävask', 'root': 'igapää_vask', 'root_tokens': ['igapää', 'vask'], 'ending': 'd', 'clitic': '', 'form': 'pl n', 'partofspeech': 'S'}]),\n",
       "Span('kxnekeeleväljändid', [{'normalized_text': 'kxnekeeleväljändid', 'lemma': 'kxnekeeleväljänd', 'root': 'kxnekeeleväljänd', 'root_tokens': ['kxnekeeleväljänd'], 'ending': 'd', 'clitic': '', 'form': 'pl n', 'partofspeech': 'S'}, {'normalized_text': 'kxnekeeleväljändid', 'lemma': 'kxnekeeleväljändi', 'root': 'kxnekeeleväljändi', 'root_tokens': ['kxnekeeleväljändi'], 'ending': 'd', 'clitic': '', 'form': 'pl n', 'partofspeech': 'S'}, {'normalized_text': 'kxnekeeleväljändid', 'lemma': 'kxnekeeleväljänt', 'root': 'kxnekeeleväljänt', 'root_tokens': ['kxnekeeleväljänt'], 'ending': 'd', 'clitic': '', 'form': 'pl n', 'partofspeech': 'S'}]),\n",
       "Span('sellged', [{'normalized_text': 'sellged', 'lemma': 'sellge', 'root': 'sellge', 'root_tokens': ['sellge'], 'ending': 'd', 'clitic': '', 'form': 'pl n', 'partofspeech': 'S'}, {'normalized_text': 'sellged', 'lemma': 'sellged', 'root': 'sellged', 'root_tokens': ['sellged'], 'ending': '0', 'clitic': '', 'form': 'sg n', 'partofspeech': 'S'}])])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example: a difficult-to-analyse sentence from the Internet language\n",
    "text = Text(\"mxnel ka igapäävased kxnekeeleväljändid sellged\")\n",
    "text.tag_layer(['morph_analysis'])\n",
    "text.morph_analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h4>Layer</h4>\n",
       "\n",
       "\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>layer name</th>\n",
       "      <th>attributes</th>\n",
       "      <th>parent</th>\n",
       "      <th>enveloping</th>\n",
       "      <th>ambiguous</th>\n",
       "      <th>span count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>morph_analysis</td>\n",
       "      <td>normalized_text, lemma, root, root_tokens, ending, clitic, form, partofspeech</td>\n",
       "      <td>words</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>text</th>\n",
       "      <th>normalized_text</th>\n",
       "      <th>lemma</th>\n",
       "      <th>root</th>\n",
       "      <th>root_tokens</th>\n",
       "      <th>ending</th>\n",
       "      <th>clitic</th>\n",
       "      <th>form</th>\n",
       "      <th>partofspeech</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>mxnel</td>\n",
       "      <td>None</td>\n",
       "      <td>mõni</td>\n",
       "      <td>mõni</td>\n",
       "      <td>['mõni']</td>\n",
       "      <td>l</td>\n",
       "      <td></td>\n",
       "      <td>sg ad</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>ka</td>\n",
       "      <td>ka</td>\n",
       "      <td>ka</td>\n",
       "      <td>ka</td>\n",
       "      <td>['ka']</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>igapäävased</td>\n",
       "      <td>None</td>\n",
       "      <td>igapäevane</td>\n",
       "      <td>iga_päevane</td>\n",
       "      <td>['iga', 'päevane']</td>\n",
       "      <td>d</td>\n",
       "      <td></td>\n",
       "      <td>pl n</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>kxnekeeleväljändid</td>\n",
       "      <td>None</td>\n",
       "      <td>kõnekeeleväljend</td>\n",
       "      <td>kõne_keele_väljend</td>\n",
       "      <td>['kõne', 'keele', 'väljend']</td>\n",
       "      <td>d</td>\n",
       "      <td></td>\n",
       "      <td>pl n</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>sellged</td>\n",
       "      <td>None</td>\n",
       "      <td>selge</td>\n",
       "      <td>selge</td>\n",
       "      <td>['selge']</td>\n",
       "      <td>d</td>\n",
       "      <td></td>\n",
       "      <td>pl n</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "Layer(name='morph_analysis', attributes=('normalized_text', 'lemma', 'root', 'root_tokens', 'ending', 'clitic', 'form', 'partofspeech'), spans=SL[Span('mxnel', [{'normalized_text': None, 'lemma': 'mõni', 'root': 'mõni', 'root_tokens': ['mõni'], 'ending': 'l', 'clitic': '', 'form': 'sg ad', 'partofspeech': 'P'}]),\n",
       "Span('ka', [{'normalized_text': 'ka', 'lemma': 'ka', 'root': 'ka', 'root_tokens': ['ka'], 'ending': '0', 'clitic': '', 'form': '', 'partofspeech': 'D'}]),\n",
       "Span('igapäävased', [{'normalized_text': None, 'lemma': 'igapäevane', 'root': 'iga_päevane', 'root_tokens': ['iga', 'päevane'], 'ending': 'd', 'clitic': '', 'form': 'pl n', 'partofspeech': 'A'}]),\n",
       "Span('kxnekeeleväljändid', [{'normalized_text': None, 'lemma': 'kõnekeeleväljend', 'root': 'kõne_keele_väljend', 'root_tokens': ['kõne', 'keele', 'väljend'], 'ending': 'd', 'clitic': '', 'form': 'pl n', 'partofspeech': 'S'}]),\n",
       "Span('sellged', [{'normalized_text': None, 'lemma': 'selge', 'root': 'selge', 'root_tokens': ['selge'], 'ending': 'd', 'clitic': '', 'form': 'pl n', 'partofspeech': 'A'}])])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Apply corrections\n",
    "userdict.retag(text)\n",
    "text.morph_analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean-up: remove temporary file\n",
    "import os\n",
    "os.remove(fp.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving analyses to CSV file\n",
    "\n",
    "`UserDictTagger`'s method `save_as_csv( filename )` can be used for saving the content of the dictionary to a CSV format file. Once the data is saved via `save_as_csv`, it can be loaded via initializing `UserDictTagger` with the parameter `csv_file`. \n",
    "\n",
    "Note 1: you can also pass optional parameters, such as `dialect` and `delimiter`, to the `save_as_csv( filename )` in order to change the formatting of the CSV. Basically, you can use the same parameters as can be used with the method `csv.writer`: https://docs.python.org/3/library/csv.html#csv.writer "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note 2: if you use `None` in place of _filename_, then the method constructs and returns a CSV formatted string instead:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text\troot\tending\tclitic\tform\tpartofspeech\r\n",
      "igapäävased\tiga_päevane\td\t\tpl n\tA\r\n",
      "kxnekeeleväljändid\tkõne_keele_väljend\td\t\tpl n\tS\r\n",
      "mxnel\tmõni\tl\t\tsg ad\tP\r\n",
      "sellged\tselge\td\t\tpl n\tA\r\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# NBVAL_IGNORE_OUTPUT\n",
    "print( userdict.save_as_csv( None ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note 3: if the dictionary contains partial overwriting entries, then the output CSV will have `'----------'` in places of attribute values that were not described in the (partial overwriting) dictionary."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
