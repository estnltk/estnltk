{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:purple\"> Text segmentation: Tokens </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### General overview\n",
    "\n",
    "Tagging the tokens means that we determine the start and end position of each token, based on whitespace and/or punctuation. There are many whitespace symbols, out of which spaces, tabs, and newlines occur most frequently. When tokens are tagged on the text, the type of whitespace does not matter, but in later analysis, it may be taken into consideration if there was a whitespace between the tokens or not.\n",
    "\n",
    "Note that segmenting the text into tokens is the most automic segmentation: in later analysis steps, tokens won't be split anymore, but only joined if necessary (e.g. to create words or phrases).\n",
    "\n",
    "In the following example, we create a text object with the tokens layer and print out the tokens layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h4>Layer</h4>\n",
       "\n",
       "\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>layer name</th>\n",
       "      <th>attributes</th>\n",
       "      <th>parent</th>\n",
       "      <th>enveloping</th>\n",
       "      <th>ambiguous</th>\n",
       "      <th>span count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>tokens</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>Mis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>aias</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>sa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>das</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3me</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>sorti</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>saia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>?</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "Layer(name='tokens', attributes=(), spans=SL[Span('Mis', [{}]),\n",
       "Span('aias', [{}]),\n",
       "Span('sa', [{}]),\n",
       "Span('-', [{}]),\n",
       "Span('das', [{}]),\n",
       "Span('3me', [{}]),\n",
       "Span('sorti', [{}]),\n",
       "Span('s', [{}]),\n",
       "Span('-', [{}]),\n",
       "Span('saia', [{}]),\n",
       "Span('?', [{}])])"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from estnltk import Text\n",
    "from estnltk.taggers import TokensTagger\n",
    "text = TokensTagger().tag(Text('Mis aias sa-das 3me sorti s-saia?'))\n",
    "text['tokens']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we have 11 tokens in the text. In order to see the start and end position of each token, execute:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h4>AttributeTupleList (spans)</h4>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Mis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>aias</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>11</td>\n",
       "      <td>sa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "      <td>12</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>12</td>\n",
       "      <td>15</td>\n",
       "      <td>das</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>16</td>\n",
       "      <td>19</td>\n",
       "      <td>3me</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>20</td>\n",
       "      <td>25</td>\n",
       "      <td>sorti</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>26</td>\n",
       "      <td>27</td>\n",
       "      <td>s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>27</td>\n",
       "      <td>28</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>28</td>\n",
       "      <td>32</td>\n",
       "      <td>saia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>32</td>\n",
       "      <td>33</td>\n",
       "      <td>?</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "AttributeTupleList([[0, 3, 'Mis'], [4, 8, 'aias'], [9, 11, 'sa'], [11, 12, '-'], [12, 15, 'das'], [16, 19, '3me'], [20, 25, 'sorti'], [26, 27, 's'], [27, 28, '-'], [28, 32, 'saia'], [32, 33, '?']], ('start', 'end', 'text'))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text.tokens[['start','end','text']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Under the hood\n",
    " The `TokensTagger` applies NLTK's [WordPunctTokenizer](https://www.nltk.org/api/nltk.tokenize.regexp.html#nltk.tokenize.regexp.WordPunctTokenizer) to split the text into tokens. The aim is to produce a tokenization where words (\"alphanumeric sequences\") are separated from each other, and where punctuation symbols are also separated from words and from each other. However, `WordPunctTokenizer` leaves punctuation symbols unsplit in some cases, and thus, `TokensTagger` applies an additional post-correction step to ensure that all punctuation symbols are split into single tokens. For instance, the string `\"(1989.a.).\"` is tokenized by  `WordPunctTokenizer` into tokens  `['(', '1989', '.', 'a', '.).']`, and in our post-correction step, it is further split into tokens `['(', '1989', '.', 'a', '.', ')', '.']`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding new splitting rules\n",
    "\n",
    "In some situations, applying `TokensTagger` is not enough and you need to add your own, text- or domain-specific splitting rules. \n",
    "In the following, we'll show how to add extra splitting rules via `TokenSplitter` and `LocalTokenSplitter`.\n",
    "\n",
    "### `TokenSplitter`\n",
    "\n",
    "Use `TokenSplitter` to make additional splits if you can determine splitting locations solely based on regular expression patterns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h4>Layer</h4>\n",
       "\n",
       "\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>layer name</th>\n",
       "      <th>attributes</th>\n",
       "      <th>parent</th>\n",
       "      <th>enveloping</th>\n",
       "      <th>ambiguous</th>\n",
       "      <th>span count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>tokens</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>Esimene</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>peatükkKui</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Arno</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>isaga</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>koolijõudis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>olid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>tunnid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>juba</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>alanud</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "Layer(name='tokens', attributes=(), spans=SL[Span('Esimene', [{}]),\n",
       "Span('peatükkKui', [{}]),\n",
       "Span('Arno', [{}]),\n",
       "Span('isaga', [{}]),\n",
       "Span('koolijõudis', [{}]),\n",
       "Span(',', [{}]),\n",
       "Span('olid', [{}]),\n",
       "Span('tunnid', [{}]),\n",
       "Span('juba', [{}]),\n",
       "Span('alanud', [{}]),\n",
       "Span('.', [{}])])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from estnltk import Text\n",
    "from estnltk.taggers import TokenSplitter\n",
    "\n",
    "# Create an example Text that requires specific token splitting\n",
    "text = Text('Esimene peatükkKui Arno isaga koolijõudis, olid tunnid juba alanud.')\n",
    "# Add the tokens layer\n",
    "text.tag_layer('tokens')\n",
    "# Browse results\n",
    "text.tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, create a `TokenSplitter` with spltting patterns. Each pattern must contain a named group ('end'), which marks a substring in the token after which the token will be split into two pieces:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "token_splitter = TokenSplitter(patterns=[re.compile(r'(?P<end>peatükk)Kui'),\\\n",
    "                                         re.compile(r'(?P<end>kooli)jõudis') ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h4>Layer</h4>\n",
       "\n",
       "\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>layer name</th>\n",
       "      <th>attributes</th>\n",
       "      <th>parent</th>\n",
       "      <th>enveloping</th>\n",
       "      <th>ambiguous</th>\n",
       "      <th>span count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>tokens</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>Esimene</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>peatükk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Kui</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Arno</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>isaga</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>kooli</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>jõudis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>olid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>tunnid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>juba</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>alanud</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "Layer(name='tokens', attributes=(), spans=SL[Span('Esimene', [{}]),\n",
       "Span('peatükk', [{}]),\n",
       "Span('Kui', [{}]),\n",
       "Span('Arno', [{}]),\n",
       "Span('isaga', [{}]),\n",
       "Span('kooli', [{}]),\n",
       "Span('jõudis', [{}]),\n",
       "Span(',', [{}]),\n",
       "Span('olid', [{}]),\n",
       "Span('tunnid', [{}]),\n",
       "Span('juba', [{}]),\n",
       "Span('alanud', [{}]),\n",
       "Span('.', [{}])])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Apply token splitter on text\n",
    "token_splitter.retag( text )\n",
    "# Browse results\n",
    "text.tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Restrictions:\n",
    "* One token can be split only once. No recursive splitting strategies are supported.\n",
    "* If several patterns match then the first in the pattern list is applied.\n",
    "* Decisions to split or not can depend only on the token itself and not general context."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `LocalTokenSplitter`\n",
    "\n",
    "Use `LocalTokenSplitter` if you need a more fine-grained control over determining the splitting location. In addition to regular expression, you also provide a customized function to determine the exact split point based on the matching token and the match object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h4>Layer</h4>\n",
       "\n",
       "\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>layer name</th>\n",
       "      <th>attributes</th>\n",
       "      <th>parent</th>\n",
       "      <th>enveloping</th>\n",
       "      <th>ambiguous</th>\n",
       "      <th>span count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>tokens</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>Pindala¹</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>oli</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>umbes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>m²</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>ruumala</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>aga</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>võrratult</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>suur²</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "Layer(name='tokens', attributes=(), spans=SL[Span('Pindala¹', [{}]),\n",
       "Span('oli', [{}]),\n",
       "Span('umbes', [{}]),\n",
       "Span('20', [{}]),\n",
       "Span('m²', [{}]),\n",
       "Span(',', [{}]),\n",
       "Span('ruumala', [{}]),\n",
       "Span('aga', [{}]),\n",
       "Span('võrratult', [{}]),\n",
       "Span('suur²', [{}]),\n",
       "Span('.', [{}])])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "from estnltk import Text\n",
    "from estnltk.taggers import LocalTokenSplitter\n",
    "\n",
    "from estnltk.taggers.standard.morph_analysis.proxy import MorphAnalyzedToken\n",
    "\n",
    "SUPERSCRIPT_SYMBOLS = '[⁰¹²³⁴⁵⁶⁷⁸⁹]'\n",
    "\n",
    "def split_if_prefix_is_word(text: str, match: re.Match) -> int:\n",
    "    prefix = text[0:match.start()]\n",
    "    if re.match('^[0-9]+$', prefix):\n",
    "        return -1\n",
    "    return match.start() if MorphAnalyzedToken(prefix).is_word else -1\n",
    "\n",
    "token_splitter = LocalTokenSplitter(\n",
    "    split_rules=[\n",
    "        # separate prefix from a superscript number only if prefix is a word\n",
    "        (re.compile(f'({SUPERSCRIPT_SYMBOLS})$'), split_if_prefix_is_word),\n",
    "    ])\n",
    "\n",
    "# Create an example Text that requires specific token splitting\n",
    "text = Text('Pindala¹ oli umbes 20 m², ruumala aga võrratult suur².')\n",
    "# Add the tokens layer\n",
    "text.tag_layer('tokens')\n",
    "# Browse results\n",
    "text.tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h4>Layer</h4>\n",
       "\n",
       "\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>layer name</th>\n",
       "      <th>attributes</th>\n",
       "      <th>parent</th>\n",
       "      <th>enveloping</th>\n",
       "      <th>ambiguous</th>\n",
       "      <th>span count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>tokens</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>Pindala</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>¹</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>oli</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>umbes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>m²</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>ruumala</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>aga</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>võrratult</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>suur</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>²</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "Layer(name='tokens', attributes=(), spans=SL[Span('Pindala', [{}]),\n",
       "Span('¹', [{}]),\n",
       "Span('oli', [{}]),\n",
       "Span('umbes', [{}]),\n",
       "Span('20', [{}]),\n",
       "Span('m²', [{}]),\n",
       "Span(',', [{}]),\n",
       "Span('ruumala', [{}]),\n",
       "Span('aga', [{}]),\n",
       "Span('võrratult', [{}]),\n",
       "Span('suur', [{}]),\n",
       "Span('²', [{}]),\n",
       "Span('.', [{}])])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_splitter.retag(text)\n",
    "# Browse results\n",
    "text.tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* More about [MorphAnalyzedToken](https://github.com/estnltk/estnltk/blob/789c32c64dbf6e0508a640002f469d24eba5720b/tutorials/nlp_pipeline/B_morphology/xx_MorphAnalyzedToken.ipynb);\n",
    "* More examples about using [LocalTokenSplitter](https://github.com/estnltk/smart-search/blob/469f54a1382d5cb2e717cdc7224774b7678a647e/demod/toovood/riigi_teataja_pealkirjaotsing/01_dokumentide_indekseerimine/estnltk_patches/tests/test_local_token_splitter.ipynb);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
