{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:purple\"> Text segmentation: Tokens </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### General overview\n",
    "\n",
    "Tagging the tokens means that we determine the start and end position of each token, based on whitespace and/or punctuation. There are many whitespace symbols, out of which spaces, tabs, and newlines occur most frequently. When tokens are tagged on the text, the type of whitespace does not matter, but in later analysis, it may be taken into consideration if there was a whitespace between the tokens or not.\n",
    "\n",
    "Note that segmenting the text into tokens is the most automic segmentation: in later analysis steps, tokens won't be split anymore, but only joined if necessary (e.g. to create words or phrases).\n",
    "\n",
    "In the following example, we create a text object with the tokens layer and print out the tokens layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h4>Layer</h4>\n",
       "\n",
       "\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>layer name</th>\n",
       "      <th>attributes</th>\n",
       "      <th>parent</th>\n",
       "      <th>enveloping</th>\n",
       "      <th>ambiguous</th>\n",
       "      <th>span count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>tokens</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>Mis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>aias</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>sa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>das</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3me</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>sorti</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>saia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>?</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "Layer(name='tokens', attributes=(), spans=SL[Span('Mis', [{}]),\n",
       "Span('aias', [{}]),\n",
       "Span('sa', [{}]),\n",
       "Span('-', [{}]),\n",
       "Span('das', [{}]),\n",
       "Span('3me', [{}]),\n",
       "Span('sorti', [{}]),\n",
       "Span('s', [{}]),\n",
       "Span('-', [{}]),\n",
       "Span('saia', [{}]),\n",
       "Span('?', [{}])])"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from estnltk import Text\n",
    "from estnltk.taggers import TokensTagger\n",
    "text = TokensTagger().tag(Text('Mis aias sa-das 3me sorti s-saia?'))\n",
    "text['tokens']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we have 11 tokens in the text. In order to see the start and end position of each token, execute:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h4>AttributeTupleList (spans)</h4>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Mis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>aias</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>11</td>\n",
       "      <td>sa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "      <td>12</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>12</td>\n",
       "      <td>15</td>\n",
       "      <td>das</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>16</td>\n",
       "      <td>19</td>\n",
       "      <td>3me</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>20</td>\n",
       "      <td>25</td>\n",
       "      <td>sorti</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>26</td>\n",
       "      <td>27</td>\n",
       "      <td>s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>27</td>\n",
       "      <td>28</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>28</td>\n",
       "      <td>32</td>\n",
       "      <td>saia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>32</td>\n",
       "      <td>33</td>\n",
       "      <td>?</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "AttributeTupleList([[0, 3, 'Mis'], [4, 8, 'aias'], [9, 11, 'sa'], [11, 12, '-'], [12, 15, 'das'], [16, 19, '3me'], [20, 25, 'sorti'], [26, 27, 's'], [27, 28, '-'], [28, 32, 'saia'], [32, 33, '?']], ('start', 'end', 'text'))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text.tokens[['start','end','text']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Under the hood\n",
    " The `TokensTagger` applies NLTK's [WordPunctTokenizer](http://www.nltk.org/api/nltk.tokenize.html#nltk.tokenize.regexp.WordPunctTokenizer) to split the text into tokens. The aim is to produce a tokenization where words (\"alphanumeric sequences\") are separated from each other, and where punctuation symbols are also separated from words and from each other. However, `WordPunctTokenizer` leaves punctuation symbols unsplit in some cases, and thus, `TokensTagger` applies an additional post-correction step to ensure that all punctuation symbols are split into single tokens. For instance, the string `\"(1989.a.).\"` is tokenized by  `WordPunctTokenizer` into tokens  `['(', '1989', '.', 'a', '.).']`, and in our post-correction step, it is further split into tokens `['(', '1989', '.', 'a', '.', ')', '.']`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding new splitting rules with `TokenSplitter`\n",
    "\n",
    "In some situations, applying `TokensTagger` is not enough and you need to add your own, text- or domain-specific splitting rules. You can use `TokenSplitter` to make additional splits based on regular expression patterns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h4>Layer</h4>\n",
       "\n",
       "\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>layer name</th>\n",
       "      <th>attributes</th>\n",
       "      <th>parent</th>\n",
       "      <th>enveloping</th>\n",
       "      <th>ambiguous</th>\n",
       "      <th>span count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>tokens</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>Esimene</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>peatükkKui</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Arno</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>isaga</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>koolijõudis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>olid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>tunnid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>juba</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>alanud</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "Layer(name='tokens', attributes=(), spans=SL[Span('Esimene', [{}]),\n",
       "Span('peatükkKui', [{}]),\n",
       "Span('Arno', [{}]),\n",
       "Span('isaga', [{}]),\n",
       "Span('koolijõudis', [{}]),\n",
       "Span(',', [{}]),\n",
       "Span('olid', [{}]),\n",
       "Span('tunnid', [{}]),\n",
       "Span('juba', [{}]),\n",
       "Span('alanud', [{}]),\n",
       "Span('.', [{}])])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from estnltk import Text\n",
    "from estnltk.taggers import TokenSplitter\n",
    "\n",
    "# Create an example Text that requires specific token splitting\n",
    "text = Text('Esimene peatükkKui Arno isaga koolijõudis, olid tunnid juba alanud.')\n",
    "# Add the tokens layer\n",
    "text.tag_layer('tokens')\n",
    "# Browse results\n",
    "text.tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, create a `TokenSplitter` with spltting patterns. Each pattern must contain a named group ('end'), which marks a substring in the token after which the token will be split into two pieces:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "token_splitter = TokenSplitter(patterns=[re.compile(r'(?P<end>peatükk)Kui'),\\\n",
    "                                         re.compile(r'(?P<end>kooli)jõudis') ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h4>Layer</h4>\n",
       "\n",
       "\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>layer name</th>\n",
       "      <th>attributes</th>\n",
       "      <th>parent</th>\n",
       "      <th>enveloping</th>\n",
       "      <th>ambiguous</th>\n",
       "      <th>span count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>tokens</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>Esimene</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>peatükk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Kui</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Arno</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>isaga</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>kooli</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>jõudis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>olid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>tunnid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>juba</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>alanud</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "Layer(name='tokens', attributes=(), spans=SL[Span('Esimene', [{}]),\n",
       "Span('peatükk', [{}]),\n",
       "Span('Kui', [{}]),\n",
       "Span('Arno', [{}]),\n",
       "Span('isaga', [{}]),\n",
       "Span('kooli', [{}]),\n",
       "Span('jõudis', [{}]),\n",
       "Span(',', [{}]),\n",
       "Span('olid', [{}]),\n",
       "Span('tunnid', [{}]),\n",
       "Span('juba', [{}]),\n",
       "Span('alanud', [{}]),\n",
       "Span('.', [{}])])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Apply token splitter on text\n",
    "token_splitter.retag( text )\n",
    "# Browse results\n",
    "text.tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
