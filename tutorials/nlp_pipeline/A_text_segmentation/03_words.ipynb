{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:purple\"> Text segmentation: Words </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Words\n",
    "\n",
    "Words are often considered as the smallest meaningful units of language, especially from the perspective of syntactic or semantic analysis.\n",
    "In order to get words, outputs of the `TokensTagger` and `CompoundTokenTagger` have to be combined. \n",
    "This is done by `WordTagger` and it is quite straightforward: every compound token is a word, and every token that is not a part of a compound token is also a word. The words are tagged on the raw text the same way as the tokens were. It means that the `words` layer does not depend on `tokens` layer or `compound_tokens` layer and so these layers may be deleted after the words are tagged.\n",
    "\n",
    "In the following example, a text object is created, prerequisite layers (`tokens`, `compound_tokens`) are added to it, and then the layer `words` is tagged:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h4>Layer</h4>\n",
       "\n",
       "\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>layer name</th>\n",
       "      <th>attributes</th>\n",
       "      <th>parent</th>\n",
       "      <th>enveloping</th>\n",
       "      <th>ambiguous</th>\n",
       "      <th>span count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>words</td>\n",
       "      <td>normalized_form</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<style type=\"text/css\">\n",
       "#T_5d497_row0_col1, #T_5d497_row1_col1, #T_5d497_row3_col1, #T_5d497_row4_col1, #T_5d497_row5_col1, #T_5d497_row6_col1, #T_5d497_row7_col1, #T_5d497_row9_col1 {\n",
       "  opacity: 20%;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_5d497\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th id=\"T_5d497_level0_col0\" class=\"col_heading level0 col0\" >text</th>\n",
       "      <th id=\"T_5d497_level0_col1\" class=\"col_heading level0 col1\" >normalized_form</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td id=\"T_5d497_row0_col0\" class=\"data row0 col0\" >See</td>\n",
       "      <td id=\"T_5d497_row0_col1\" class=\"data row0 col1\" >None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_5d497_row1_col0\" class=\"data row1 col0\" >on</td>\n",
       "      <td id=\"T_5d497_row1_col1\" class=\"data row1 col1\" >None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_5d497_row2_col0\" class=\"data row2 col0\" >v-vä-väga</td>\n",
       "      <td id=\"T_5d497_row2_col1\" class=\"data row2 col1\" >väga</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_5d497_row3_col0\" class=\"data row3 col0\" >huvitav</td>\n",
       "      <td id=\"T_5d497_row3_col1\" class=\"data row3 col1\" >None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_5d497_row4_col0\" class=\"data row4 col0\" >,</td>\n",
       "      <td id=\"T_5d497_row4_col1\" class=\"data row4 col1\" >None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_5d497_row5_col0\" class=\"data row5 col0\" >aga</td>\n",
       "      <td id=\"T_5d497_row5_col1\" class=\"data row5 col1\" >None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_5d497_row6_col0\" class=\"data row6 col0\" >kas</td>\n",
       "      <td id=\"T_5d497_row6_col1\" class=\"data row6 col1\" >None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_5d497_row7_col0\" class=\"data row7 col0\" >ka</td>\n",
       "      <td id=\"T_5d497_row7_col1\" class=\"data row7 col1\" >None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_5d497_row8_col0\" class=\"data row8 col0\" >ka-su-lik</td>\n",
       "      <td id=\"T_5d497_row8_col1\" class=\"data row8 col1\" >kasulik</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_5d497_row9_col0\" class=\"data row9 col0\" >?!</td>\n",
       "      <td id=\"T_5d497_row9_col1\" class=\"data row9 col1\" >None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "Layer(name='words', attributes=('normalized_form',), spans=SL[Span('See', [{'normalized_form': None}]),\n",
       "Span('on', [{'normalized_form': None}]),\n",
       "Span('v-vä-väga', [{'normalized_form': 'väga'}]),\n",
       "Span('huvitav', [{'normalized_form': None}]),\n",
       "Span(',', [{'normalized_form': None}]),\n",
       "Span('aga', [{'normalized_form': None}]),\n",
       "Span('kas', [{'normalized_form': None}]),\n",
       "Span('ka', [{'normalized_form': None}]),\n",
       "Span('ka-su-lik', [{'normalized_form': 'kasulik'}]),\n",
       "Span('?!', [{'normalized_form': None}])])"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from estnltk import Text\n",
    "\n",
    "# Prepare text: add tokens and compound tokens\n",
    "text = Text('See on v-vä-väga huvitav, aga kas ka ka-su-lik?!')\n",
    "text.tag_layer(['tokens', 'compound_tokens'])\n",
    "\n",
    "# Add words\n",
    "from estnltk.taggers import WordTagger\n",
    "WordTagger().tag(text)\n",
    "text['words']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalized word forms. Ambiguity of words\n",
    "\n",
    "The `words` layer has an attribute `normalized_form`, which can contain normalized forms of the surface word. \n",
    "By default, this information is taken from the layer `compound_tokens`: if a compound token has the attribute `normalized` filled in, then this information is also carried over to the `normalized_form` of the corresponding word. Otherwise, `normalized_form` remains `None`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the words layer is _ambiguous_ : it can hold multiple normalized forms for each word. \n",
    "The reason is that when you analyse misspelled words, slang words and/or words of a dialect, there are often several candidates for the correct word.\n",
    "All the candidates can be stored as normalized forms, and they will also be analysed by the downstream morphological analyzer.\n",
    "However, applying morphological analysis on multiple normalized forms is a bit advanced feature: before using it, please read carefully the documentation below and make sure you understand the limitations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Word normalization is also closely related to spelling correction. \n",
    "If the input text contains spelling mistakes, you can use `SpellCheckRetagger` to fill in `normalized_form`-s of misspelled words with correct forms.\n",
    "See [this tutorial](https://github.com/estnltk/estnltk/blob/main/tutorials/nlp_pipeline/B_morphology/spelling_correction.ipynb) for details.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [Advanced] Normalized word forms and morphological analysis\n",
    "\n",
    "If a word has `normalized_form` set to `None`, then only its surface form (`text`) will be analysed morphologically. But if `normalized_form` contains one or more alternative forms (strings), all of these alternatives will be processed by the morphological analyser (`VabamorfAnalyzer`), and the surface form (`text`) will be ignored. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An example. Let's first change the normalized forms of a word, and introduce new alternative forms:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h4>Layer</h4>\n",
       "\n",
       "\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>layer name</th>\n",
       "      <th>attributes</th>\n",
       "      <th>parent</th>\n",
       "      <th>enveloping</th>\n",
       "      <th>ambiguous</th>\n",
       "      <th>span count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>words</td>\n",
       "      <td>normalized_form</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<style type=\"text/css\">\n",
       "#T_77d35_row0_col1, #T_77d35_row3_col1 {\n",
       "  opacity: 20%;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_77d35\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th id=\"T_77d35_level0_col0\" class=\"col_heading level0 col0\" >text</th>\n",
       "      <th id=\"T_77d35_level0_col1\" class=\"col_heading level0 col1\" >normalized_form</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td id=\"T_77d35_row0_col0\" class=\"data row0 col0\" >Üsna</td>\n",
       "      <td id=\"T_77d35_row0_col1\" class=\"data row0 col1\" >None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_77d35_row1_col0\" class=\"data row1 col0\" >hää</td>\n",
       "      <td id=\"T_77d35_row1_col1\" class=\"data row1 col1\" >hea</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_77d35_row2_col0\" class=\"data row2 col0\" ></td>\n",
       "      <td id=\"T_77d35_row2_col1\" class=\"data row2 col1\" >head</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_77d35_row3_col0\" class=\"data row3 col0\" >!</td>\n",
       "      <td id=\"T_77d35_row3_col1\" class=\"data row3 col1\" >None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "Layer(name='words', attributes=('normalized_form',), spans=SL[Span('Üsna', [{'normalized_form': None}]),\n",
       "Span('hää', [{'normalized_form': 'hea'}, {'normalized_form': 'head'}]),\n",
       "Span('!', [{'normalized_form': None}])])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from estnltk import Text, Annotation\n",
    "text=Text('Üsna hää!')\n",
    "text.tag_layer(['tokens', 'compound_tokens', 'words'])\n",
    "\n",
    "for word in text.words:\n",
    "    if word.text=='hää':\n",
    "        # Change word's annotations\n",
    "        word.clear_annotations()\n",
    "        word.add_annotation( Annotation(word, normalized_form='hea') )\n",
    "        word.add_annotation( Annotation(word, normalized_form='head') )\n",
    "text.words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's use `VabamorfAnalyzer` to provide analyses for all variants:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h4>Layer</h4>\n",
       "\n",
       "\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>layer name</th>\n",
       "      <th>attributes</th>\n",
       "      <th>parent</th>\n",
       "      <th>enveloping</th>\n",
       "      <th>ambiguous</th>\n",
       "      <th>span count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>morph_analysis</td>\n",
       "      <td>normalized_text, lemma, root, root_tokens, ending, clitic, form, partofspeech</td>\n",
       "      <td>words</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_d0758\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th id=\"T_d0758_level0_col0\" class=\"col_heading level0 col0\" >text</th>\n",
       "      <th id=\"T_d0758_level0_col1\" class=\"col_heading level0 col1\" >normalized_text</th>\n",
       "      <th id=\"T_d0758_level0_col2\" class=\"col_heading level0 col2\" >lemma</th>\n",
       "      <th id=\"T_d0758_level0_col3\" class=\"col_heading level0 col3\" >root</th>\n",
       "      <th id=\"T_d0758_level0_col4\" class=\"col_heading level0 col4\" >root_tokens</th>\n",
       "      <th id=\"T_d0758_level0_col5\" class=\"col_heading level0 col5\" >ending</th>\n",
       "      <th id=\"T_d0758_level0_col6\" class=\"col_heading level0 col6\" >clitic</th>\n",
       "      <th id=\"T_d0758_level0_col7\" class=\"col_heading level0 col7\" >form</th>\n",
       "      <th id=\"T_d0758_level0_col8\" class=\"col_heading level0 col8\" >partofspeech</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td id=\"T_d0758_row0_col0\" class=\"data row0 col0\" >Üsna</td>\n",
       "      <td id=\"T_d0758_row0_col1\" class=\"data row0 col1\" >Üsna</td>\n",
       "      <td id=\"T_d0758_row0_col2\" class=\"data row0 col2\" >üsna</td>\n",
       "      <td id=\"T_d0758_row0_col3\" class=\"data row0 col3\" >üsna</td>\n",
       "      <td id=\"T_d0758_row0_col4\" class=\"data row0 col4\" >['üsna']</td>\n",
       "      <td id=\"T_d0758_row0_col5\" class=\"data row0 col5\" >0</td>\n",
       "      <td id=\"T_d0758_row0_col6\" class=\"data row0 col6\" ></td>\n",
       "      <td id=\"T_d0758_row0_col7\" class=\"data row0 col7\" ></td>\n",
       "      <td id=\"T_d0758_row0_col8\" class=\"data row0 col8\" >D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_d0758_row1_col0\" class=\"data row1 col0\" >hää</td>\n",
       "      <td id=\"T_d0758_row1_col1\" class=\"data row1 col1\" >hea</td>\n",
       "      <td id=\"T_d0758_row1_col2\" class=\"data row1 col2\" >hea</td>\n",
       "      <td id=\"T_d0758_row1_col3\" class=\"data row1 col3\" >hea</td>\n",
       "      <td id=\"T_d0758_row1_col4\" class=\"data row1 col4\" >['hea']</td>\n",
       "      <td id=\"T_d0758_row1_col5\" class=\"data row1 col5\" >0</td>\n",
       "      <td id=\"T_d0758_row1_col6\" class=\"data row1 col6\" ></td>\n",
       "      <td id=\"T_d0758_row1_col7\" class=\"data row1 col7\" >sg g</td>\n",
       "      <td id=\"T_d0758_row1_col8\" class=\"data row1 col8\" >A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_d0758_row2_col0\" class=\"data row2 col0\" ></td>\n",
       "      <td id=\"T_d0758_row2_col1\" class=\"data row2 col1\" >hea</td>\n",
       "      <td id=\"T_d0758_row2_col2\" class=\"data row2 col2\" >hea</td>\n",
       "      <td id=\"T_d0758_row2_col3\" class=\"data row2 col3\" >hea</td>\n",
       "      <td id=\"T_d0758_row2_col4\" class=\"data row2 col4\" >['hea']</td>\n",
       "      <td id=\"T_d0758_row2_col5\" class=\"data row2 col5\" >0</td>\n",
       "      <td id=\"T_d0758_row2_col6\" class=\"data row2 col6\" ></td>\n",
       "      <td id=\"T_d0758_row2_col7\" class=\"data row2 col7\" >sg n</td>\n",
       "      <td id=\"T_d0758_row2_col8\" class=\"data row2 col8\" >A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_d0758_row3_col0\" class=\"data row3 col0\" ></td>\n",
       "      <td id=\"T_d0758_row3_col1\" class=\"data row3 col1\" >hea</td>\n",
       "      <td id=\"T_d0758_row3_col2\" class=\"data row3 col2\" >hea</td>\n",
       "      <td id=\"T_d0758_row3_col3\" class=\"data row3 col3\" >hea</td>\n",
       "      <td id=\"T_d0758_row3_col4\" class=\"data row3 col4\" >['hea']</td>\n",
       "      <td id=\"T_d0758_row3_col5\" class=\"data row3 col5\" >0</td>\n",
       "      <td id=\"T_d0758_row3_col6\" class=\"data row3 col6\" ></td>\n",
       "      <td id=\"T_d0758_row3_col7\" class=\"data row3 col7\" >sg g</td>\n",
       "      <td id=\"T_d0758_row3_col8\" class=\"data row3 col8\" >S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_d0758_row4_col0\" class=\"data row4 col0\" ></td>\n",
       "      <td id=\"T_d0758_row4_col1\" class=\"data row4 col1\" >hea</td>\n",
       "      <td id=\"T_d0758_row4_col2\" class=\"data row4 col2\" >hea</td>\n",
       "      <td id=\"T_d0758_row4_col3\" class=\"data row4 col3\" >hea</td>\n",
       "      <td id=\"T_d0758_row4_col4\" class=\"data row4 col4\" >['hea']</td>\n",
       "      <td id=\"T_d0758_row4_col5\" class=\"data row4 col5\" >0</td>\n",
       "      <td id=\"T_d0758_row4_col6\" class=\"data row4 col6\" ></td>\n",
       "      <td id=\"T_d0758_row4_col7\" class=\"data row4 col7\" >sg n</td>\n",
       "      <td id=\"T_d0758_row4_col8\" class=\"data row4 col8\" >S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_d0758_row5_col0\" class=\"data row5 col0\" ></td>\n",
       "      <td id=\"T_d0758_row5_col1\" class=\"data row5 col1\" >head</td>\n",
       "      <td id=\"T_d0758_row5_col2\" class=\"data row5 col2\" >hea</td>\n",
       "      <td id=\"T_d0758_row5_col3\" class=\"data row5 col3\" >hea</td>\n",
       "      <td id=\"T_d0758_row5_col4\" class=\"data row5 col4\" >['hea']</td>\n",
       "      <td id=\"T_d0758_row5_col5\" class=\"data row5 col5\" >d</td>\n",
       "      <td id=\"T_d0758_row5_col6\" class=\"data row5 col6\" ></td>\n",
       "      <td id=\"T_d0758_row5_col7\" class=\"data row5 col7\" >pl n</td>\n",
       "      <td id=\"T_d0758_row5_col8\" class=\"data row5 col8\" >A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_d0758_row6_col0\" class=\"data row6 col0\" ></td>\n",
       "      <td id=\"T_d0758_row6_col1\" class=\"data row6 col1\" >head</td>\n",
       "      <td id=\"T_d0758_row6_col2\" class=\"data row6 col2\" >hea</td>\n",
       "      <td id=\"T_d0758_row6_col3\" class=\"data row6 col3\" >hea</td>\n",
       "      <td id=\"T_d0758_row6_col4\" class=\"data row6 col4\" >['hea']</td>\n",
       "      <td id=\"T_d0758_row6_col5\" class=\"data row6 col5\" >d</td>\n",
       "      <td id=\"T_d0758_row6_col6\" class=\"data row6 col6\" ></td>\n",
       "      <td id=\"T_d0758_row6_col7\" class=\"data row6 col7\" >sg p</td>\n",
       "      <td id=\"T_d0758_row6_col8\" class=\"data row6 col8\" >A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_d0758_row7_col0\" class=\"data row7 col0\" ></td>\n",
       "      <td id=\"T_d0758_row7_col1\" class=\"data row7 col1\" >head</td>\n",
       "      <td id=\"T_d0758_row7_col2\" class=\"data row7 col2\" >hea</td>\n",
       "      <td id=\"T_d0758_row7_col3\" class=\"data row7 col3\" >hea</td>\n",
       "      <td id=\"T_d0758_row7_col4\" class=\"data row7 col4\" >['hea']</td>\n",
       "      <td id=\"T_d0758_row7_col5\" class=\"data row7 col5\" >d</td>\n",
       "      <td id=\"T_d0758_row7_col6\" class=\"data row7 col6\" ></td>\n",
       "      <td id=\"T_d0758_row7_col7\" class=\"data row7 col7\" >pl n</td>\n",
       "      <td id=\"T_d0758_row7_col8\" class=\"data row7 col8\" >S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_d0758_row8_col0\" class=\"data row8 col0\" ></td>\n",
       "      <td id=\"T_d0758_row8_col1\" class=\"data row8 col1\" >head</td>\n",
       "      <td id=\"T_d0758_row8_col2\" class=\"data row8 col2\" >hea</td>\n",
       "      <td id=\"T_d0758_row8_col3\" class=\"data row8 col3\" >hea</td>\n",
       "      <td id=\"T_d0758_row8_col4\" class=\"data row8 col4\" >['hea']</td>\n",
       "      <td id=\"T_d0758_row8_col5\" class=\"data row8 col5\" >d</td>\n",
       "      <td id=\"T_d0758_row8_col6\" class=\"data row8 col6\" ></td>\n",
       "      <td id=\"T_d0758_row8_col7\" class=\"data row8 col7\" >sg p</td>\n",
       "      <td id=\"T_d0758_row8_col8\" class=\"data row8 col8\" >S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_d0758_row9_col0\" class=\"data row9 col0\" >!</td>\n",
       "      <td id=\"T_d0758_row9_col1\" class=\"data row9 col1\" >!</td>\n",
       "      <td id=\"T_d0758_row9_col2\" class=\"data row9 col2\" >!</td>\n",
       "      <td id=\"T_d0758_row9_col3\" class=\"data row9 col3\" >!</td>\n",
       "      <td id=\"T_d0758_row9_col4\" class=\"data row9 col4\" >['!']</td>\n",
       "      <td id=\"T_d0758_row9_col5\" class=\"data row9 col5\" ></td>\n",
       "      <td id=\"T_d0758_row9_col6\" class=\"data row9 col6\" ></td>\n",
       "      <td id=\"T_d0758_row9_col7\" class=\"data row9 col7\" ></td>\n",
       "      <td id=\"T_d0758_row9_col8\" class=\"data row9 col8\" >Z</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "Layer(name='morph_analysis', attributes=('normalized_text', 'lemma', 'root', 'root_tokens', 'ending', 'clitic', 'form', 'partofspeech'), spans=SL[Span('Üsna', [{'normalized_text': 'Üsna', 'lemma': 'üsna', 'root': 'üsna', 'root_tokens': ['üsna'], 'ending': '0', 'clitic': '', 'form': '', 'partofspeech': 'D'}]),\n",
       "Span('hää', [{'normalized_text': 'hea', 'lemma': 'hea', 'root': 'hea', 'root_tokens': ['hea'], 'ending': '0', 'clitic': '', 'form': 'sg g', 'partofspeech': 'A'}, {'normalized_text': 'hea', 'lemma': 'hea', 'root': 'hea', 'root_tokens': ['hea'], 'ending': '0', 'clitic': '', 'form': 'sg n', 'partofspeech': 'A'}, {'normalized_text': 'hea', 'lemma': 'hea', 'root': 'hea', 'root_tokens': ['hea'], 'ending': '0', 'clitic': '', 'form': 'sg g', 'partofspeech': 'S'}, {'normalized_text': 'hea', 'lemma': 'hea', 'root': 'hea', 'root_tokens': ['hea'], 'ending': '0', 'clitic': '', 'form': 'sg n', 'partofspeech': 'S'}, {'normalized_text': 'head', 'lemma': 'hea', 'root': 'hea', 'root_tokens': ['hea'], 'ending': 'd', 'clitic': '', 'form': 'pl n', 'partofspeech': 'A'}, {'normalized_text': 'head', 'lemma': 'hea', 'root': 'hea', 'root_tokens': ['hea'], 'ending': 'd', 'clitic': '', 'form': 'sg p', 'partofspeech': 'A'}, {'normalized_text': 'head', 'lemma': 'hea', 'root': 'hea', 'root_tokens': ['hea'], 'ending': 'd', 'clitic': '', 'form': 'pl n', 'partofspeech': 'S'}, {'normalized_text': 'head', 'lemma': 'hea', 'root': 'hea', 'root_tokens': ['hea'], 'ending': 'd', 'clitic': '', 'form': 'sg p', 'partofspeech': 'S'}]),\n",
       "Span('!', [{'normalized_text': '!', 'lemma': '!', 'root': '!', 'root_tokens': ['!'], 'ending': '', 'clitic': '', 'form': '', 'partofspeech': 'Z'}])])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from estnltk.taggers import VabamorfAnalyzer\n",
    "vm_analyser = VabamorfAnalyzer()\n",
    "text.tag_layer(['sentences'])\n",
    "vm_analyser.tag(text)\n",
    "text.morph_analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the `morph_analysis` layer has as a special attribute `normalized_text` which holds the string value of the `normalized_form` (or the surface form) that was used as a basis on generating the analysis.\n",
    "From the previous example, we can see that the surface word _'hää'_ has both analyses of the word _'hea'_ and the word _'head'_."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "<h4>Warning: <i>correct morphological disambiguation not guaranteed!</i></h4>\n",
    "<br>\n",
    "If all words in text have at most one <code>normalized_form</code> (that is: all analyses of a word in the <code>morph_analysis</code> layer correspond to analyses of a single normalized form), then <code>VabamorfDisambiguator</code> should be able to provide a high quality morphological disambiguation.\n",
    "However, if there are words with multiple <code>normalized_form</code>-s , there is no guarantee on the high quality of disambiguation results.\n",
    "The reason is that the disambiguator has only been trained on the corpus of standard language, and it is not aware of the specifics of texts where words have multiple normalizations.\n",
    "Therefore, we do not recommend applying disambiguation on such situations.\n",
    "If you really need to do it, you should definitely check first if the disambiguation quality is satisfactory.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
