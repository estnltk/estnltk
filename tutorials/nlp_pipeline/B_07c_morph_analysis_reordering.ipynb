{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reordering ambiguous morphological analyses\n",
    "\n",
    "By design, Vabamorf's morphological analysis tool is \"agnostic\" on solving all the morphological ambiguities: rather than solving hard cases incorrectly, the tool opts to leave hard ambiguities unresolved, so that the end user can decide how to approach these. \n",
    "As a result, even after applying `VabamorfTagger` or `VabamorfCorpusTagger` with full disambiguation, some of the words still have morphological ambiguities.\n",
    "It is important to note that these ambiguous morphological analyses _are not sorted by probability_, and so, picking the first analysis is not a good strategy on handling these (there is approx 50% chance of getting the correct analysis with that strategy)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`MorphAnalysisReorderer` reorders ambiguous analyses in a way that the first analysis has a higher likelihood of being the correct one.\n",
    "For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h4>Layer</h4>\n",
       "\n",
       "\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>layer name</th>\n",
       "      <th>attributes</th>\n",
       "      <th>parent</th>\n",
       "      <th>enveloping</th>\n",
       "      <th>ambiguous</th>\n",
       "      <th>span count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>morph_analysis</td>\n",
       "      <td>normalized_text, lemma, root, root_tokens, end...</td>\n",
       "      <td>words</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>text</th>\n",
       "      <th>normalized_text</th>\n",
       "      <th>lemma</th>\n",
       "      <th>root</th>\n",
       "      <th>root_tokens</th>\n",
       "      <th>ending</th>\n",
       "      <th>clitic</th>\n",
       "      <th>form</th>\n",
       "      <th>partofspeech</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>Üks</td>\n",
       "      <td>Üks</td>\n",
       "      <td>üks</td>\n",
       "      <td>üks</td>\n",
       "      <td>['üks']</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>sg n</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td></td>\n",
       "      <td>Üks</td>\n",
       "      <td>üks</td>\n",
       "      <td>üks</td>\n",
       "      <td>['üks']</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>sg n</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>ütles</td>\n",
       "      <td>ütles</td>\n",
       "      <td>ütlema</td>\n",
       "      <td>ütle</td>\n",
       "      <td>['ütle']</td>\n",
       "      <td>s</td>\n",
       "      <td></td>\n",
       "      <td>s</td>\n",
       "      <td>V</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>,</td>\n",
       "      <td>,</td>\n",
       "      <td>,</td>\n",
       "      <td>,</td>\n",
       "      <td>[',']</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>et</td>\n",
       "      <td>et</td>\n",
       "      <td>et</td>\n",
       "      <td>et</td>\n",
       "      <td>['et']</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>J</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1.</td>\n",
       "      <td>1.</td>\n",
       "      <td>1.</td>\n",
       "      <td>1.</td>\n",
       "      <td>['1.']</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>?</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>mail</td>\n",
       "      <td>mail</td>\n",
       "      <td>maa</td>\n",
       "      <td>maa</td>\n",
       "      <td>['maa']</td>\n",
       "      <td>il</td>\n",
       "      <td></td>\n",
       "      <td>pl ad</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td></td>\n",
       "      <td>mail</td>\n",
       "      <td>mai</td>\n",
       "      <td>mai</td>\n",
       "      <td>['mai']</td>\n",
       "      <td>l</td>\n",
       "      <td></td>\n",
       "      <td>sg ad</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>tähistab</td>\n",
       "      <td>tähistab</td>\n",
       "      <td>tähistama</td>\n",
       "      <td>tähista</td>\n",
       "      <td>['tähista']</td>\n",
       "      <td>b</td>\n",
       "      <td></td>\n",
       "      <td>b</td>\n",
       "      <td>V</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>palju</td>\n",
       "      <td>palju</td>\n",
       "      <td>palju</td>\n",
       "      <td>palju</td>\n",
       "      <td>['palju']</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>maid</td>\n",
       "      <td>maid</td>\n",
       "      <td>maa</td>\n",
       "      <td>maa</td>\n",
       "      <td>['maa']</td>\n",
       "      <td>id</td>\n",
       "      <td></td>\n",
       "      <td>pl p</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td></td>\n",
       "      <td>maid</td>\n",
       "      <td>mai</td>\n",
       "      <td>mai</td>\n",
       "      <td>['mai']</td>\n",
       "      <td>d</td>\n",
       "      <td></td>\n",
       "      <td>sg p</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>töörahvapüha</td>\n",
       "      <td>töörahvapüha</td>\n",
       "      <td>töörahvapüha</td>\n",
       "      <td>töö_rahva_püha</td>\n",
       "      <td>['töö', 'rahva', 'püha']</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>sg n</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>['.']</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Z</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "Layer(name='morph_analysis', attributes=('normalized_text', 'lemma', 'root', 'root_tokens', 'ending', 'clitic', 'form', 'partofspeech'), spans=SL[Span('Üks', [{'normalized_text': 'Üks', 'lemma': 'üks', 'root': 'üks', 'root_tokens': ['üks'], 'ending': '0', 'clitic': '', 'form': 'sg n', 'partofspeech': 'N'}, {'normalized_text': 'Üks', 'lemma': 'üks', 'root': 'üks', 'root_tokens': ['üks'], 'ending': '0', 'clitic': '', 'form': 'sg n', 'partofspeech': 'P'}]),\n",
       "Span('ütles', [{'normalized_text': 'ütles', 'lemma': 'ütlema', 'root': 'ütle', 'root_tokens': ['ütle'], 'ending': 's', 'clitic': '', 'form': 's', 'partofspeech': 'V'}]),\n",
       "Span(',', [{'normalized_text': ',', 'lemma': ',', 'root': ',', 'root_tokens': [','], 'ending': '', 'clitic': '', 'form': '', 'partofspeech': 'Z'}]),\n",
       "Span('et', [{'normalized_text': 'et', 'lemma': 'et', 'root': 'et', 'root_tokens': ['et'], 'ending': '0', 'clitic': '', 'form': '', 'partofspeech': 'J'}]),\n",
       "Span('1.', [{'normalized_text': '1.', 'lemma': '1.', 'root': '1.', 'root_tokens': ['1.'], 'ending': '0', 'clitic': '', 'form': '?', 'partofspeech': 'O'}]),\n",
       "Span('mail', [{'normalized_text': 'mail', 'lemma': 'maa', 'root': 'maa', 'root_tokens': ['maa'], 'ending': 'il', 'clitic': '', 'form': 'pl ad', 'partofspeech': 'S'}, {'normalized_text': 'mail', 'lemma': 'mai', 'root': 'mai', 'root_tokens': ['mai'], 'ending': 'l', 'clitic': '', 'form': 'sg ad', 'partofspeech': 'S'}]),\n",
       "Span('tähistab', [{'normalized_text': 'tähistab', 'lemma': 'tähistama', 'root': 'tähista', 'root_tokens': ['tähista'], 'ending': 'b', 'clitic': '', 'form': 'b', 'partofspeech': 'V'}]),\n",
       "Span('palju', [{'normalized_text': 'palju', 'lemma': 'palju', 'root': 'palju', 'root_tokens': ['palju'], 'ending': '0', 'clitic': '', 'form': '', 'partofspeech': 'D'}]),\n",
       "Span('maid', [{'normalized_text': 'maid', 'lemma': 'maa', 'root': 'maa', 'root_tokens': ['maa'], 'ending': 'id', 'clitic': '', 'form': 'pl p', 'partofspeech': 'S'}, {'normalized_text': 'maid', 'lemma': 'mai', 'root': 'mai', 'root_tokens': ['mai'], 'ending': 'd', 'clitic': '', 'form': 'sg p', 'partofspeech': 'S'}]),\n",
       "Span('töörahvapüha', [{'normalized_text': 'töörahvapüha', 'lemma': 'töörahvapüha', 'root': 'töö_rahva_püha', 'root_tokens': ['töö', 'rahva', 'püha'], 'ending': '0', 'clitic': '', 'form': 'sg n', 'partofspeech': 'S'}]),\n",
       "Span('.', [{'normalized_text': '.', 'lemma': '.', 'root': '.', 'root_tokens': ['.'], 'ending': '', 'clitic': '', 'form': '', 'partofspeech': 'Z'}])])"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from estnltk import Text\n",
    "\n",
    "# Create a text with hard-to-solve ambiguities\n",
    "text=Text(\"Üks ütles, et 1. mail tähistab palju maid töörahvapüha.\")\n",
    "# Tag morph analysis\n",
    "text.tag_layer(['morph_analysis'])\n",
    "\n",
    "# Examine remaining ambiguities\n",
    "text.morph_analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's use `MorphAnalysisReorderer` (a `Retagger` of `morph_analysis` layer) to reorder morphological ambiguities:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h4>Layer</h4>\n",
       "\n",
       "\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>layer name</th>\n",
       "      <th>attributes</th>\n",
       "      <th>parent</th>\n",
       "      <th>enveloping</th>\n",
       "      <th>ambiguous</th>\n",
       "      <th>span count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>morph_analysis</td>\n",
       "      <td>normalized_text, lemma, root, root_tokens, ending, clitic, form, partofspeech</td>\n",
       "      <td>words</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>text</th>\n",
       "      <th>normalized_text</th>\n",
       "      <th>lemma</th>\n",
       "      <th>root</th>\n",
       "      <th>root_tokens</th>\n",
       "      <th>ending</th>\n",
       "      <th>clitic</th>\n",
       "      <th>form</th>\n",
       "      <th>partofspeech</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>Üks</td>\n",
       "      <td>Üks</td>\n",
       "      <td>üks</td>\n",
       "      <td>üks</td>\n",
       "      <td>['üks']</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>sg n</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td></td>\n",
       "      <td>Üks</td>\n",
       "      <td>üks</td>\n",
       "      <td>üks</td>\n",
       "      <td>['üks']</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>sg n</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>ütles</td>\n",
       "      <td>ütles</td>\n",
       "      <td>ütlema</td>\n",
       "      <td>ütle</td>\n",
       "      <td>['ütle']</td>\n",
       "      <td>s</td>\n",
       "      <td></td>\n",
       "      <td>s</td>\n",
       "      <td>V</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>,</td>\n",
       "      <td>,</td>\n",
       "      <td>,</td>\n",
       "      <td>,</td>\n",
       "      <td>[',']</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>et</td>\n",
       "      <td>et</td>\n",
       "      <td>et</td>\n",
       "      <td>et</td>\n",
       "      <td>['et']</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>J</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1.</td>\n",
       "      <td>1.</td>\n",
       "      <td>1.</td>\n",
       "      <td>1.</td>\n",
       "      <td>['1.']</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>?</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>mail</td>\n",
       "      <td>mail</td>\n",
       "      <td>mai</td>\n",
       "      <td>mai</td>\n",
       "      <td>['mai']</td>\n",
       "      <td>l</td>\n",
       "      <td></td>\n",
       "      <td>sg ad</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td></td>\n",
       "      <td>mail</td>\n",
       "      <td>maa</td>\n",
       "      <td>maa</td>\n",
       "      <td>['maa']</td>\n",
       "      <td>il</td>\n",
       "      <td></td>\n",
       "      <td>pl ad</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>tähistab</td>\n",
       "      <td>tähistab</td>\n",
       "      <td>tähistama</td>\n",
       "      <td>tähista</td>\n",
       "      <td>['tähista']</td>\n",
       "      <td>b</td>\n",
       "      <td></td>\n",
       "      <td>b</td>\n",
       "      <td>V</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>palju</td>\n",
       "      <td>palju</td>\n",
       "      <td>palju</td>\n",
       "      <td>palju</td>\n",
       "      <td>['palju']</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>maid</td>\n",
       "      <td>maid</td>\n",
       "      <td>maa</td>\n",
       "      <td>maa</td>\n",
       "      <td>['maa']</td>\n",
       "      <td>id</td>\n",
       "      <td></td>\n",
       "      <td>pl p</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td></td>\n",
       "      <td>maid</td>\n",
       "      <td>mai</td>\n",
       "      <td>mai</td>\n",
       "      <td>['mai']</td>\n",
       "      <td>d</td>\n",
       "      <td></td>\n",
       "      <td>sg p</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>töörahvapüha</td>\n",
       "      <td>töörahvapüha</td>\n",
       "      <td>töörahvapüha</td>\n",
       "      <td>töö_rahva_püha</td>\n",
       "      <td>['töö', 'rahva', 'püha']</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>sg n</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>['.']</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Z</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "Layer(name='morph_analysis', attributes=('normalized_text', 'lemma', 'root', 'root_tokens', 'ending', 'clitic', 'form', 'partofspeech'), spans=SL[Span('Üks', [{'normalized_text': 'Üks', 'lemma': 'üks', 'root': 'üks', 'root_tokens': ['üks'], 'ending': '0', 'clitic': '', 'form': 'sg n', 'partofspeech': 'P'}, {'normalized_text': 'Üks', 'lemma': 'üks', 'root': 'üks', 'root_tokens': ['üks'], 'ending': '0', 'clitic': '', 'form': 'sg n', 'partofspeech': 'N'}]),\n",
       "Span('ütles', [{'normalized_text': 'ütles', 'lemma': 'ütlema', 'root': 'ütle', 'root_tokens': ['ütle'], 'ending': 's', 'clitic': '', 'form': 's', 'partofspeech': 'V'}]),\n",
       "Span(',', [{'normalized_text': ',', 'lemma': ',', 'root': ',', 'root_tokens': [','], 'ending': '', 'clitic': '', 'form': '', 'partofspeech': 'Z'}]),\n",
       "Span('et', [{'normalized_text': 'et', 'lemma': 'et', 'root': 'et', 'root_tokens': ['et'], 'ending': '0', 'clitic': '', 'form': '', 'partofspeech': 'J'}]),\n",
       "Span('1.', [{'normalized_text': '1.', 'lemma': '1.', 'root': '1.', 'root_tokens': ['1.'], 'ending': '0', 'clitic': '', 'form': '?', 'partofspeech': 'O'}]),\n",
       "Span('mail', [{'normalized_text': 'mail', 'lemma': 'mai', 'root': 'mai', 'root_tokens': ['mai'], 'ending': 'l', 'clitic': '', 'form': 'sg ad', 'partofspeech': 'S'}, {'normalized_text': 'mail', 'lemma': 'maa', 'root': 'maa', 'root_tokens': ['maa'], 'ending': 'il', 'clitic': '', 'form': 'pl ad', 'partofspeech': 'S'}]),\n",
       "Span('tähistab', [{'normalized_text': 'tähistab', 'lemma': 'tähistama', 'root': 'tähista', 'root_tokens': ['tähista'], 'ending': 'b', 'clitic': '', 'form': 'b', 'partofspeech': 'V'}]),\n",
       "Span('palju', [{'normalized_text': 'palju', 'lemma': 'palju', 'root': 'palju', 'root_tokens': ['palju'], 'ending': '0', 'clitic': '', 'form': '', 'partofspeech': 'D'}]),\n",
       "Span('maid', [{'normalized_text': 'maid', 'lemma': 'maa', 'root': 'maa', 'root_tokens': ['maa'], 'ending': 'id', 'clitic': '', 'form': 'pl p', 'partofspeech': 'S'}, {'normalized_text': 'maid', 'lemma': 'mai', 'root': 'mai', 'root_tokens': ['mai'], 'ending': 'd', 'clitic': '', 'form': 'sg p', 'partofspeech': 'S'}]),\n",
       "Span('töörahvapüha', [{'normalized_text': 'töörahvapüha', 'lemma': 'töörahvapüha', 'root': 'töö_rahva_püha', 'root_tokens': ['töö', 'rahva', 'püha'], 'ending': '0', 'clitic': '', 'form': 'sg n', 'partofspeech': 'S'}]),\n",
       "Span('.', [{'normalized_text': '.', 'lemma': '.', 'root': '.', 'root_tokens': ['.'], 'ending': '', 'clitic': '', 'form': '', 'partofspeech': 'Z'}])])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from estnltk.taggers import MorphAnalysisReorderer\n",
    "\n",
    "morph_reorderer = MorphAnalysisReorderer()\n",
    "morph_reorderer.retag( text )\n",
    "\n",
    "# Examine the order of ambiguities\n",
    "text.morph_analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note the improvements on analysis order of words _üks_ and _mail_."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For reordering analyses, `MorphAnalysisReorderer` uses a simple frequency-dictionary based approach.\n",
    "If a word with ambiguous analyses is in its dictionary of words and frequency-sorted analyses, then word's ambiguous analyses are re-sorted according to the ordering in the dictionary.\n",
    "The default dictionary of `MorphAnalysisReorderer` has been acquired from the training part of the [Estonian Dependency Treebank](https://github.com/UniversalDependencies/UD_Estonian-EDT/tree/5eba261d1ed63507a44063a4e05b77b1db5f4aac).\n",
    "Evaluation on the dev and test parts of the corpus showed that after reorderings, the chance of having the first analysis as the correct one increased from ~50% to ~70%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Things to keep in mind:\n",
    "\n",
    "   * You get a full effect of `MorphAnalysisReorderer` only on morphologically disambiguated texts, e.g. applying it after `VabamorfTagger` or `VabamorfCorpusTagger`. If you apply it after `VabamorfAnalyzer` (on ambiguous `morph_analysis` layer), then the reordering performance is suboptimal, because its dictionary contains only information about words that were left ambiguous after morphological disambiguation process.\n",
    "   \n",
    "   \n",
    "   * The default dictionary of `MorphAnalysisReorderer` may not be the most optimal reorderer for texts of your specific domain. If this is the case, then you can make your of own dictionary of reorderings and use it in `MorphAnalysisReorderer`. See below for details."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using a custom dictionary\n",
    "\n",
    "`MorphAnalysisReorderer` loads its reordering data from a tab-separated-values format CSV file. The first line in the file must be a header specifying (at minimum) the following attributes:\n",
    " * `text` -- word surface form;\n",
    " * `lemma` -- 'lemma' attribute from 'morph_analysis';\n",
    " * `partofspeech` -- 'partofspeech' attribute from 'morph_analysis';\n",
    " * `form` -- 'form' attribute from 'morph_analysis';\n",
    " * `prob` or `freq` -- probability or frequency of the analysis;\n",
    " \n",
    "Other attributes from the `morph_analysis` layer can also be used if higher precision is needed for differentiating analyses. \n",
    "The header is required to determine in which order the data  needs to be loaded from the file. \n",
    "Each line following the header specifies a single analysis for a word. \n",
    "Naturally, a word having multiple analyses should be described on multiple successive lines.\n",
    "Important: we assume that analyses in CSV file are already in the correct order: sorted from most probable to least probable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a CSV file with correct orderings\n",
    "import tempfile\n",
    "fp = tempfile.NamedTemporaryFile(mode='w', encoding='utf-8', suffix='.csv', delete=False)\n",
    "# Add header\n",
    "fp.write( ('\\t'.join(['text','lemma','partofspeech','form','prob'])) + '\\n' )\n",
    "# Add analysis reorderings:\n",
    "# word 'teine'\n",
    "fp.write( ('\\t'.join(['teine','teine','P','sg n','0.75'])) + '\\n' )\n",
    "fp.write( ('\\t'.join(['teine','teine','N','sg n','0.25'])) + '\\n' )\n",
    "# word 'maid'\n",
    "fp.write( ('\\t'.join(['maid','mai','S','sg p','0.8'])) + '\\n' )\n",
    "fp.write( ('\\t'.join(['maid','maa','S','pl p','0.2'])) + '\\n' )\n",
    "fp.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create new reorderer that loads its dictionary from the CSV file\n",
    "from estnltk.taggers import MorphAnalysisReorderer\n",
    "\n",
    "morph_reorderer = MorphAnalysisReorderer( reorderings_csv_file = fp.name )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h4>Layer</h4>\n",
       "\n",
       "\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>layer name</th>\n",
       "      <th>attributes</th>\n",
       "      <th>parent</th>\n",
       "      <th>enveloping</th>\n",
       "      <th>ambiguous</th>\n",
       "      <th>span count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>morph_analysis</td>\n",
       "      <td>normalized_text, lemma, root, root_tokens, ending, clitic, form, partofspeech</td>\n",
       "      <td>words</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>text</th>\n",
       "      <th>normalized_text</th>\n",
       "      <th>lemma</th>\n",
       "      <th>root</th>\n",
       "      <th>root_tokens</th>\n",
       "      <th>ending</th>\n",
       "      <th>clitic</th>\n",
       "      <th>form</th>\n",
       "      <th>partofspeech</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>Teine</td>\n",
       "      <td>Teine</td>\n",
       "      <td>teine</td>\n",
       "      <td>teine</td>\n",
       "      <td>['teine']</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>sg n</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td></td>\n",
       "      <td>Teine</td>\n",
       "      <td>teine</td>\n",
       "      <td>teine</td>\n",
       "      <td>['teine']</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>sg n</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>jälle</td>\n",
       "      <td>jälle</td>\n",
       "      <td>jälle</td>\n",
       "      <td>jälle</td>\n",
       "      <td>['jälle']</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>kirus</td>\n",
       "      <td>kirus</td>\n",
       "      <td>kiruma</td>\n",
       "      <td>kiru</td>\n",
       "      <td>['kiru']</td>\n",
       "      <td>s</td>\n",
       "      <td></td>\n",
       "      <td>s</td>\n",
       "      <td>V</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1.</td>\n",
       "      <td>1.</td>\n",
       "      <td>1.</td>\n",
       "      <td>1.</td>\n",
       "      <td>['1.']</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>?</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>maid</td>\n",
       "      <td>maid</td>\n",
       "      <td>mai</td>\n",
       "      <td>mai</td>\n",
       "      <td>['mai']</td>\n",
       "      <td>d</td>\n",
       "      <td></td>\n",
       "      <td>sg p</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td></td>\n",
       "      <td>maid</td>\n",
       "      <td>maa</td>\n",
       "      <td>maa</td>\n",
       "      <td>['maa']</td>\n",
       "      <td>id</td>\n",
       "      <td></td>\n",
       "      <td>pl p</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>['.']</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Z</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "Layer(name='morph_analysis', attributes=('normalized_text', 'lemma', 'root', 'root_tokens', 'ending', 'clitic', 'form', 'partofspeech'), spans=SL[Span('Teine', [{'normalized_text': 'Teine', 'lemma': 'teine', 'root': 'teine', 'root_tokens': ['teine'], 'ending': '0', 'clitic': '', 'form': 'sg n', 'partofspeech': 'P'}, {'normalized_text': 'Teine', 'lemma': 'teine', 'root': 'teine', 'root_tokens': ['teine'], 'ending': '0', 'clitic': '', 'form': 'sg n', 'partofspeech': 'O'}]),\n",
       "Span('jälle', [{'normalized_text': 'jälle', 'lemma': 'jälle', 'root': 'jälle', 'root_tokens': ['jälle'], 'ending': '0', 'clitic': '', 'form': '', 'partofspeech': 'D'}]),\n",
       "Span('kirus', [{'normalized_text': 'kirus', 'lemma': 'kiruma', 'root': 'kiru', 'root_tokens': ['kiru'], 'ending': 's', 'clitic': '', 'form': 's', 'partofspeech': 'V'}]),\n",
       "Span('1.', [{'normalized_text': '1.', 'lemma': '1.', 'root': '1.', 'root_tokens': ['1.'], 'ending': '0', 'clitic': '', 'form': '?', 'partofspeech': 'O'}]),\n",
       "Span('maid', [{'normalized_text': 'maid', 'lemma': 'mai', 'root': 'mai', 'root_tokens': ['mai'], 'ending': 'd', 'clitic': '', 'form': 'sg p', 'partofspeech': 'S'}, {'normalized_text': 'maid', 'lemma': 'maa', 'root': 'maa', 'root_tokens': ['maa'], 'ending': 'id', 'clitic': '', 'form': 'pl p', 'partofspeech': 'S'}]),\n",
       "Span('.', [{'normalized_text': '.', 'lemma': '.', 'root': '.', 'root_tokens': ['.'], 'ending': '', 'clitic': '', 'form': '', 'partofspeech': 'Z'}])])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from estnltk import Text\n",
    "\n",
    "# Create a text with hard-to-solve ambiguities\n",
    "text=Text(\"Teine jälle kirus 1. maid.\")\n",
    "# Tag morph analysis\n",
    "text.tag_layer(['morph_analysis'])\n",
    "\n",
    "# Apply reorderer\n",
    "morph_reorderer.retag(text)\n",
    "\n",
    "# Examine remaining ambiguities\n",
    "text.morph_analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean-up: remove temporary file\n",
    "import os\n",
    "os.remove(fp.name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
