{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:purple\"> Experimental: noun phrase chunker </span>\n",
    "\n",
    "EstNLTK includes an experimental noun phrase chunker, which can be used to detect non-overlapping noun phrases from the text.\n",
    "\n",
    "You can use noun phrase chunking directly via default resolver. This handles all the necessary preprocessing for you:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h4>Layer</h4>\n",
       "\n",
       "\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>layer name</th>\n",
       "      <th>attributes</th>\n",
       "      <th>parent</th>\n",
       "      <th>enveloping</th>\n",
       "      <th>ambiguous</th>\n",
       "      <th>span count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>np_chunks</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>words</td>\n",
       "      <td>False</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>['Suur', 'karvane', 'kass']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>['punasel', 'diivanil']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>['väike', 'hiir']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>['temast']</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "Layer(name='np_chunks', attributes=(), spans=SL[EnvelopingSpan(['Suur', 'karvane', 'kass'], [{}]),\n",
       "EnvelopingSpan(['punasel', 'diivanil'], [{}]),\n",
       "EnvelopingSpan(['väike', 'hiir'], [{}]),\n",
       "EnvelopingSpan(['temast'], [{}])])"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from estnltk import Text\n",
    "\n",
    "text = Text('Suur karvane kass nurrus punasel diivanil, väike hiir aga hiilis temast mööda.')\n",
    "\n",
    "text.tag_layer('np_chunks')\n",
    "\n",
    "text.np_chunks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can use `enclosing_text` for obtaining exact strings corresponding to the chunks:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Suur karvane kass', 'punasel diivanil', 'väike hiir', 'temast']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get phrase strings\n",
    "[chunk.enclosing_text for chunk in text.np_chunks]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As `np_chunks` is an enveloping layer around `words`, you can iterate over all words of each chunk, and you can also access lemmas of these words via `morph_analysis` layer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Suur ['suur']\n",
      "karvane ['karvane']\n",
      "kass ['kass']\n",
      "\n",
      "punasel ['punane']\n",
      "diivanil ['diivan']\n",
      "\n",
      "väike ['väike']\n",
      "hiir ['hiir']\n",
      "\n",
      "temast ['tema']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Get lemmas of the words from chunks\n",
    "for chunk in text.np_chunks:\n",
    "    for word in chunk:\n",
    "        print(word.text, word.lemma)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**_Technical note_**: as the default noun phrase chunker relies on MaltParser syntactic analysis, you'll need to have Java installed in the system to use the chunker. \n",
    "See [the syntactic analysis tutorial](https://github.com/estnltk/estnltk/blob/113cec7af026597d8e45ec9bf06e8492ab3d24e9/tutorials/nlp_pipeline/C_syntax/03_syntactic_analysis_with_maltparser.ipynb) for details."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using NounPhraseChunker directly\n",
    "\n",
    "The chunker uses Vabamorf's morphological analyses and dependency syntactic relations for detecting potential noun phrases.\n",
    "\n",
    "In the following example, we use `MaltParserTagger` for creating the prerequisite syntactic analysis layer, but you can use any [dependency syntactic layer](https://github.com/estnltk/estnltk/tree/113cec7af026597d8e45ec9bf06e8492ab3d24e9/tutorials/nlp_pipeline/C_syntax) that has `'deprel'` and `'head'` attributes marking the relations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from estnltk import Text\n",
    "from estnltk.taggers import ConllMorphTagger\n",
    "from estnltk.taggers import MaltParserTagger\n",
    "\n",
    "conll_morph_tagger = ConllMorphTagger( no_visl=True,  morph_extended_layer='morph_analysis' )\n",
    "maltparser_tagger = MaltParserTagger( input_conll_morph_layer='conll_morph', \n",
    "                                      input_type='morph_analysis', \n",
    "                                      version='conllu', add_parent_and_children=False )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'compound_tokens',\n",
       " 'conll_morph',\n",
       " 'maltparser_syntax',\n",
       " 'morph_analysis',\n",
       " 'sentences',\n",
       " 'tokens',\n",
       " 'words'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create text for analysis\n",
    "text = Text('Autojuhi lapitekk pälvis linna koduleheküljel paljude kodanike tähelepanu.')\n",
    "# Add prerequisite layers\n",
    "text.tag_layer('morph_analysis')\n",
    "conll_morph_tagger.tag( text )\n",
    "maltparser_tagger.tag( text )\n",
    "text.layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can use `NounPhraseChunker`. The tagger must be initialized with the name of the syntax layer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h4>Layer</h4>\n",
       "\n",
       "\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>layer name</th>\n",
       "      <th>attributes</th>\n",
       "      <th>parent</th>\n",
       "      <th>enveloping</th>\n",
       "      <th>ambiguous</th>\n",
       "      <th>span count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>np_chunks</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>words</td>\n",
       "      <td>False</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>['Autojuhi', 'lapitekk']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>['linna', 'koduleheküljel']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>['paljude', 'kodanike', 'tähelepanu']</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "Layer(name='np_chunks', attributes=(), spans=SL[EnvelopingSpan(['Autojuhi', 'lapitekk'], [{}]),\n",
       "EnvelopingSpan(['linna', 'koduleheküljel'], [{}]),\n",
       "EnvelopingSpan(['paljude', 'kodanike', 'tähelepanu'], [{}])])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from estnltk.taggers.miscellaneous.np_chunker import NounPhraseChunker\n",
    "\n",
    "np_chunker = NounPhraseChunker('maltparser_syntax')\n",
    "np_chunker.tag(text)\n",
    "text.np_chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Autojuhi lapitekk', 'linna koduleheküljel', 'paljude kodanike tähelepanu']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get phrase strings\n",
    "[chunk.enclosing_text for chunk in text.np_chunks]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chunking based on VislTagger\n",
    "\n",
    "In the following example, we use `VislTagger` to provide the input syntax layer required for chunking:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": [
     "nbval-skip"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'compound_tokens',\n",
       " 'morph_analysis',\n",
       " 'morph_extended',\n",
       " 'sentences',\n",
       " 'tokens',\n",
       " 'visl',\n",
       " 'words'}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from estnltk import Text\n",
    "from estnltk.taggers import VislTagger\n",
    "\n",
    "# Create text for analysis\n",
    "text = Text('Juunikuu suveseiklused ootavad Sind juba täna meie uues reisiportaalis.')\n",
    "# Add prerequisite layers\n",
    "text.tag_layer(['morph_extended'])\n",
    "syntactic_parser = VislTagger()\n",
    "syntactic_parser.tag(text)\n",
    "text.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": [
     "nbval-skip"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h4>Layer</h4>\n",
       "\n",
       "\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>layer name</th>\n",
       "      <th>attributes</th>\n",
       "      <th>parent</th>\n",
       "      <th>enveloping</th>\n",
       "      <th>ambiguous</th>\n",
       "      <th>span count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>np_chunks</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>words</td>\n",
       "      <td>False</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>['Juunikuu', 'suveseiklused']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>['Sind']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>['meie']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>['uues', 'reisiportaalis']</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "Layer(name='np_chunks', attributes=(), spans=SL[EnvelopingSpan(['Juunikuu', 'suveseiklused'], [{}]),\n",
       "EnvelopingSpan(['Sind'], [{}]),\n",
       "EnvelopingSpan(['meie'], [{}]),\n",
       "EnvelopingSpan(['uues', 'reisiportaalis'], [{}])])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create NP chunker based on vislcg3 syntactic analysis\n",
    "from estnltk.taggers.miscellaneous.np_chunker import NounPhraseChunker\n",
    "np_chunker = NounPhraseChunker('visl')\n",
    "np_chunker.tag(text)\n",
    "text.np_chunks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
