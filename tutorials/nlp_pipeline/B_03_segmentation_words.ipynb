{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color:blue\"> B. Specific details for programmers: how it works</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:purple\"> Text segmentation: Words </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Words\n",
    "\n",
    "Words are often considered as the smallest meaningful units of language, especially from the perspective of syntactic or semantic analysis.\n",
    "In order to get words, outputs of the `TokensTagger` and `CompoundTokenTagger` have to be combined. \n",
    "This is done by `WordTagger` and it is quite straightforward: every compound token is a word, and every token that is not a part of a compound token is also a word. The words are tagged on the raw text the same way as the tokens were. It means that the `words` layer does not depend on `tokens` layer or `compound_tokens` layer and so these layers may be deleted after the words are tagged.\n",
    "\n",
    "In the following example, a text object is created, prerequisite layers (`tokens`, `compound_tokens`) are added to it, and then the layer `words` is tagged:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h4>Layer</h4>\n",
       "\n",
       "\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>layer name</th>\n",
       "      <th>attributes</th>\n",
       "      <th>parent</th>\n",
       "      <th>enveloping</th>\n",
       "      <th>ambiguous</th>\n",
       "      <th>span count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>words</td>\n",
       "      <td>normalized_form</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>text</th>\n",
       "      <th>normalized_form</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>See</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>on</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>v-vä-väga</td>\n",
       "      <td>väga</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>huvitav</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>,</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>aga</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>kas</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>ka</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>ka-su-lik</td>\n",
       "      <td>kasulik</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>?!</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "Layer(name='words', attributes=('normalized_form',), spans=SL[Span('See', [{'normalized_form': None}]),\n",
       "Span('on', [{'normalized_form': None}]),\n",
       "Span('v-vä-väga', [{'normalized_form': 'väga'}]),\n",
       "Span('huvitav', [{'normalized_form': None}]),\n",
       "Span(',', [{'normalized_form': None}]),\n",
       "Span('aga', [{'normalized_form': None}]),\n",
       "Span('kas', [{'normalized_form': None}]),\n",
       "Span('ka', [{'normalized_form': None}]),\n",
       "Span('ka-su-lik', [{'normalized_form': 'kasulik'}]),\n",
       "Span('?!', [{'normalized_form': None}])])"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from estnltk import Text\n",
    "\n",
    "# Prepare text: add tokens and compound tokens\n",
    "text = Text('See on v-vä-väga huvitav, aga kas ka ka-su-lik?!')\n",
    "text.tag_layer(['tokens', 'compound_tokens'])\n",
    "\n",
    "# Add words\n",
    "from estnltk.taggers import WordTagger\n",
    "WordTagger().tag(text)\n",
    "text['words']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalized word forms. Ambiguity of words\n",
    "\n",
    "The `words` layer has an attribute `normalized_form`, which can contain normalized forms of the surface word. \n",
    "By default, this information is taken from the layer `compound_tokens`: if a compound token has the attribute `normalized` filled in, then this information is also carried over to the `normalized_form` of the corresponding word. Otherwise, `normalized_form` remains `None`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the words layer is _ambiguous_ : it can hold multiple normalized forms for each word. \n",
    "The reason is that when you analyse misspelled words, slang words and/or words of a dialect, there are often several candidates for the correct word.\n",
    "All the candidates can be stored as normalized forms, and they will also be analysed by the downstream morphological analyzer.\n",
    "However, applying morphological analysis on multiple normalized forms is a bit advanced feature: before using it, please read carefully the documentation below and make sure you understand the limitations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Word normalization is also closely related to spelling correction. \n",
    "If the input text contains spelling mistakes, you can use `SpellCheckRetagger` to fill in `normalized_form`-s of misspelled words with correct forms.\n",
    "See [this tutorial](B_03_segmentation_words_spelling_normalization.ipynb) for details.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [Advanced] Normalized word forms and morphological analysis\n",
    "\n",
    "If a word has `normalized_form` set to `None`, then only its surface form (`text`) will be analysed morphologically. But if `normalized_form` contains one or more alternative forms (strings), all of these alternatives will be processed by the morphological analyser (`VabamorfAnalyzer`), and the surface form (`text`) will be ignored. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An example. Let's first change the normalized forms of a word, and introduce new alternative forms:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h4>Layer</h4>\n",
       "\n",
       "\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>layer name</th>\n",
       "      <th>attributes</th>\n",
       "      <th>parent</th>\n",
       "      <th>enveloping</th>\n",
       "      <th>ambiguous</th>\n",
       "      <th>span count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>words</td>\n",
       "      <td>normalized_form</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>text</th>\n",
       "      <th>normalized_form</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>Üsna</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>hää</td>\n",
       "      <td>hea</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td></td>\n",
       "      <td>head</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>!</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "Layer(name='words', attributes=('normalized_form',), spans=SL[Span('Üsna', [{'normalized_form': None}]),\n",
       "Span('hää', [{'normalized_form': 'hea'}, {'normalized_form': 'head'}]),\n",
       "Span('!', [{'normalized_form': None}])])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from estnltk import Text, Annotation\n",
    "text=Text('Üsna hää!')\n",
    "text.tag_layer(['tokens', 'compound_tokens', 'words'])\n",
    "\n",
    "for word in text.words:\n",
    "    if word.text=='hää':\n",
    "        # Change word's annotations\n",
    "        word.clear_annotations()\n",
    "        word.add_annotation( Annotation(word, normalized_form='hea') )\n",
    "        word.add_annotation( Annotation(word, normalized_form='head') )\n",
    "text.words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's use `VabamorfAnalyzer` to provide analyses for all variants:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h4>Layer</h4>\n",
       "\n",
       "\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>layer name</th>\n",
       "      <th>attributes</th>\n",
       "      <th>parent</th>\n",
       "      <th>enveloping</th>\n",
       "      <th>ambiguous</th>\n",
       "      <th>span count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>morph_analysis</td>\n",
       "      <td>normalized_text, lemma, root, root_tokens, ending, clitic, form, partofspeech</td>\n",
       "      <td>words</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>text</th>\n",
       "      <th>normalized_text</th>\n",
       "      <th>lemma</th>\n",
       "      <th>root</th>\n",
       "      <th>root_tokens</th>\n",
       "      <th>ending</th>\n",
       "      <th>clitic</th>\n",
       "      <th>form</th>\n",
       "      <th>partofspeech</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>Üsna</td>\n",
       "      <td>Üsna</td>\n",
       "      <td>üsna</td>\n",
       "      <td>üsna</td>\n",
       "      <td>['üsna']</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>hää</td>\n",
       "      <td>hea</td>\n",
       "      <td>hea</td>\n",
       "      <td>hea</td>\n",
       "      <td>['hea']</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>sg g</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td></td>\n",
       "      <td>hea</td>\n",
       "      <td>hea</td>\n",
       "      <td>hea</td>\n",
       "      <td>['hea']</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>sg n</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td></td>\n",
       "      <td>hea</td>\n",
       "      <td>hea</td>\n",
       "      <td>hea</td>\n",
       "      <td>['hea']</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>sg g</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td></td>\n",
       "      <td>hea</td>\n",
       "      <td>hea</td>\n",
       "      <td>hea</td>\n",
       "      <td>['hea']</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>sg n</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td></td>\n",
       "      <td>head</td>\n",
       "      <td>hea</td>\n",
       "      <td>hea</td>\n",
       "      <td>['hea']</td>\n",
       "      <td>d</td>\n",
       "      <td></td>\n",
       "      <td>pl n</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td></td>\n",
       "      <td>head</td>\n",
       "      <td>hea</td>\n",
       "      <td>hea</td>\n",
       "      <td>['hea']</td>\n",
       "      <td>d</td>\n",
       "      <td></td>\n",
       "      <td>sg p</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td></td>\n",
       "      <td>head</td>\n",
       "      <td>hea</td>\n",
       "      <td>hea</td>\n",
       "      <td>['hea']</td>\n",
       "      <td>d</td>\n",
       "      <td></td>\n",
       "      <td>pl n</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td></td>\n",
       "      <td>head</td>\n",
       "      <td>hea</td>\n",
       "      <td>hea</td>\n",
       "      <td>['hea']</td>\n",
       "      <td>d</td>\n",
       "      <td></td>\n",
       "      <td>sg p</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>!</td>\n",
       "      <td>!</td>\n",
       "      <td>!</td>\n",
       "      <td>!</td>\n",
       "      <td>['!']</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Z</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "Layer(name='morph_analysis', attributes=('normalized_text', 'lemma', 'root', 'root_tokens', 'ending', 'clitic', 'form', 'partofspeech'), spans=SL[Span('Üsna', [{'normalized_text': 'Üsna', 'lemma': 'üsna', 'root': 'üsna', 'root_tokens': ['üsna'], 'ending': '0', 'clitic': '', 'form': '', 'partofspeech': 'D'}]),\n",
       "Span('hää', [{'normalized_text': 'hea', 'lemma': 'hea', 'root': 'hea', 'root_tokens': ['hea'], 'ending': '0', 'clitic': '', 'form': 'sg g', 'partofspeech': 'A'}, {'normalized_text': 'hea', 'lemma': 'hea', 'root': 'hea', 'root_tokens': ['hea'], 'ending': '0', 'clitic': '', 'form': 'sg n', 'partofspeech': 'A'}, {'normalized_text': 'hea', 'lemma': 'hea', 'root': 'hea', 'root_tokens': ['hea'], 'ending': '0', 'clitic': '', 'form': 'sg g', 'partofspeech': 'S'}, {'normalized_text': 'hea', 'lemma': 'hea', 'root': 'hea', 'root_tokens': ['hea'], 'ending': '0', 'clitic': '', 'form': 'sg n', 'partofspeech': 'S'}, {'normalized_text': 'head', 'lemma': 'hea', 'root': 'hea', 'root_tokens': ['hea'], 'ending': 'd', 'clitic': '', 'form': 'pl n', 'partofspeech': 'A'}, {'normalized_text': 'head', 'lemma': 'hea', 'root': 'hea', 'root_tokens': ['hea'], 'ending': 'd', 'clitic': '', 'form': 'sg p', 'partofspeech': 'A'}, {'normalized_text': 'head', 'lemma': 'hea', 'root': 'hea', 'root_tokens': ['hea'], 'ending': 'd', 'clitic': '', 'form': 'pl n', 'partofspeech': 'S'}, {'normalized_text': 'head', 'lemma': 'hea', 'root': 'hea', 'root_tokens': ['hea'], 'ending': 'd', 'clitic': '', 'form': 'sg p', 'partofspeech': 'S'}]),\n",
       "Span('!', [{'normalized_text': '!', 'lemma': '!', 'root': '!', 'root_tokens': ['!'], 'ending': '', 'clitic': '', 'form': '', 'partofspeech': 'Z'}])])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from estnltk.taggers import VabamorfAnalyzer\n",
    "vm_analyser = VabamorfAnalyzer()\n",
    "text.tag_layer(['sentences'])\n",
    "vm_analyser.tag(text)\n",
    "text.morph_analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the `morph_analysis` layer has as a special attribute `normalized_text` which holds the string value of the `normalized_form` (or the surface form) that was used as a basis on generating the analysis.\n",
    "From the previous example, we can see that the surface word _'hää'_ has both analyses of the word _'hea'_ and the word _'head'_."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "<h4>Warning: <i>correct morphological disambiguation not guaranteed!</i></h4>\n",
    "<br>\n",
    "If all words in text have at most one <code>normalized_form</code> (that is: all analyses of a word in the <code>morph_analysis</code> layer correspond to analyses of a single normalized form), then <code>VabamorfDisambiguator</code> should be able to provide a high quality morphological disambiguation.\n",
    "However, if there are words with multiple <code>normalized_form</code>-s , there is no guarantee on the high quality of disambiguation results.\n",
    "The reason is that the disambiguator has only been trained on the corpus of standard language, and it is not aware of the specifics of texts where words have multiple normalizations.\n",
    "Therefore, we do not recommend applying disambiguation on such situations.\n",
    "If you really need to do it, you should definitely check first if the disambiguation quality is satisfactory.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
