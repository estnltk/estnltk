{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basics of EstNLTK 1.7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<ul>\n",
    " <li><a href=\"#Text-object\">Text object</a></li>\n",
    "  <ul><li><a href=\"#Metadata-about-Text\">Metadata about Text</a></li>\n",
    "  <li><a href=\"#Layers\">Layers</a></li>\n",
    "    <ul><ul><li><a href=\"#Adding-layers-via-tag_layer\">Adding layers via tag_layer</a></li>\n",
    "    <li><a href=\"#Which-layers-can-be-created-via-tag_layer?-(-DEFAULT_RESOLVER-)\">Which layers can be created via tag_layer? ( DEFAULT_RESOLVER )</a></li>\n",
    "    <li><a href=\"#Importing-taggers-from-estnltk.taggers.-Applying-a-tagger-directly-(-the-method-tag-)\">Importing taggers from estnltk.taggers. Applying a tagger directly ( the method tag )</a></li>\n",
    "    <li><a href=\"#Changing-taggers-of-the-pipeline-(-make_resolver-)\">Changing taggers of the pipeline ( make_resolver )</a></li>\n",
    "    <li><a href=\"#Removing-a-layer\">Removing a layer</a></li>\n",
    "  </ul></ul><li><a href=\"#Accessing-annotations-of-Text.-Iterating-and-querying-annotations\">Accessing annotations of Text. Iterating and querying annotations</a></li>\n",
    "    <ul><ul><li><a href=\"#Textual-span-of-annotation-(-Span-and-EnvelopingSpan-)\">Textual span of annotation ( Span and EnvelopingSpan )</a></li>\n",
    "    <li><a href=\"#Informational-content-of-annotation-(-Annotation-)\">Informational content of annotation ( Annotation )</a></li>\n",
    "    <li><a href=\"#Selecting-multiple-annotations:-indexing-operators\">Selecting multiple annotations: indexing operators</a></li>\n",
    "    <li><a href=\"#Iterating-over-multiple-layers:-an-example\">Iterating over multiple layers: an example</a></li>\n",
    "    <li><a href=\"#Grouping-annotations-(-Layer.groupby-)\">Grouping annotations ( Layer.groupby )</a></li>\n",
    "    <li><a href=\"#Sliding-window-over-annotations-(-Layer.rolling-)\">Sliding window over annotations ( Layer.rolling )</a></li>\n",
    "  </ul></ul><li><a href=\"#Dividing-Text-object-into-smaller-Text-objects\">Dividing Text object into smaller Text objects</a></li>\n",
    "    <ul><ul><li><a href=\"#Making-extracts-from-Text-(-extract_sections-)\">Making extracts from Text ( extract_sections )</a></li>\n",
    "    <li><a href=\"#Splitting-Text-(-split_by-)\">Splitting Text ( split_by )</a></li>\n",
    "  </ul></ul><li><a href=\"#Removing-layer's-dependencies-(-flatten-)\">Removing layer's dependencies ( flatten )</a></li>\n",
    " </ul>\n",
    "</ul>\n",
    "\n",
    "Online documentation is best viewed with https://nbviewer.jupyter.org/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# `Text` object\n",
    "\n",
    "The central component of EstNLTK is Text class.\n",
    "It encapsulates the raw text and allows to call for text analysers (_taggers_).\n",
    "Text analysis results (_annotations_) can also be accessed via the Text object.\n",
    "\n",
    "Example: creating a Text object:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td><div align = \"left\">Ära mine sinna, kuhu viib rada. Mine selle asemel sinna, kus pole ühtki rada ja ole teerajaja.</div></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "Text(text='Ära mine sinna, kuhu viib rada. Mine selle asemel sinna, kus pole ühtki rada ja ole teerajaja.')"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from estnltk import Text\n",
    "text = Text('Ära mine sinna, kuhu viib rada. Mine selle asemel sinna, kus pole ühtki rada ja ole teerajaja.')\n",
    "text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The attribute `text` can be used to get the initial raw text as a string:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Ära mine sinna, kuhu viib rada. Mine selle asemel sinna, kus pole ühtki rada ja ole teerajaja.'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text.text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>\n",
    "<div class=\"alert alert-block alert-warning\"> \n",
    "<h4><i>Initial text is immutable</i></h4> \n",
    "<br>\n",
    "EstNTLK adheres to a principle that the initial raw text should always remain immutable. \n",
    "If you need to change the raw text, you should create a new <code>Text</code> object corresponding to the changed text.\n",
    "<br>\n",
    "Remark: However, the raw text can be indirectly altered through changing annotations. An example is word normalization: normalized word forms are stored as annotations and thus can be changed in order to improve downstream linguistic analysis. For details, see <a href=\"nlp_pipeline/A_text_segmentation/03_words.ipynb\">this tutorial</a>.\n",
    "</div>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metadata about Text\n",
    "\n",
    "Metadata of a `Text` object is a simple dictionary, which can be accessed via `meta` attribute:\n",
    "\n",
    "```python\n",
    "# setting metadata dictionary\n",
    "text.meta = {'author': 'Tundmatu', 'date': 2015}\n",
    "# setting metadata items one by one\n",
    "text.meta['origin'] = 'tsitaadid.ee'\n",
    "text.meta['url'] = 'https://tsitaadid.ee/quote/576/14'\n",
    "```\n",
    "By default, the created `Text` object does not have any metadata -- metadata needs to be added by the user. \n",
    "However, EstNLTK's [corpus importing functions](corpus_processing/importing_text_objects_from_corpora.ipynb) try to populate the imported texts with metadata if possible.\n",
    "\n",
    "Note: if you need to serialize `Text` objects and/or use the Postgres storage, then it is advised to use only the data types `str`, `int`, `float` and `datetime` for metadata."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Layers\n",
    "\n",
    "Layer is a collection of annotations with the same set of attributes. Each annotation refers to a span that specifies a text region and a list of attributes.\n",
    "\n",
    "### Adding layers via `tag_layer`\n",
    "\n",
    "Method `tag_layer` creates annotation layers to the Text by using EstNLTK's basic NLP pipeline:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td><div align = \"left\">Ära mine sinna, kuhu viib rada. Mine selle asemel sinna, kus pole ühtki rada ja ole teerajaja.</div></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>layer name</th>\n",
       "      <th>attributes</th>\n",
       "      <th>parent</th>\n",
       "      <th>enveloping</th>\n",
       "      <th>ambiguous</th>\n",
       "      <th>span count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>tokens</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>compound_tokens</td>\n",
       "      <td>type, normalized</td>\n",
       "      <td>None</td>\n",
       "      <td>tokens</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>words</td>\n",
       "      <td>normalized_form</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "Text(text='Ära mine sinna, kuhu viib rada. Mine selle asemel sinna, kus pole ühtki rada ja ole teerajaja.')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text.tag_layer(['tokens', 'words'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most of the layers created by the basic pipeline have **dependencies** (an exception is the layer `'tokens'`).\n",
    "If a layer has dependencies, it can only be created after dependency layers have been created.\n",
    "The method `tag_layer` resolves dependencies automatically and creates all the prerequisite layers.\n",
    "In the previous example: in addition to the layers `'tokens'` and `'words'`, the layer `'compound_tokens'` was also created, because it was required by the layer `'words'`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If `tag_layer` is called without input arguments, the default value `['morph_analysis', 'sentences']` is used:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td><div align = \"left\">Ära mine sinna, kuhu viib rada. Mine selle asemel sinna, kus pole ühtki rada ja ole teerajaja.</div></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>layer name</th>\n",
       "      <th>attributes</th>\n",
       "      <th>parent</th>\n",
       "      <th>enveloping</th>\n",
       "      <th>ambiguous</th>\n",
       "      <th>span count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>sentences</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>words</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>tokens</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>compound_tokens</td>\n",
       "      <td>type, normalized</td>\n",
       "      <td>None</td>\n",
       "      <td>tokens</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>words</td>\n",
       "      <td>normalized_form</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>morph_analysis</td>\n",
       "      <td>normalized_text, lemma, root, root_tokens, ending, clitic, form, partofspeech</td>\n",
       "      <td>words</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "Text(text='Ära mine sinna, kuhu viib rada. Mine selle asemel sinna, kus pole ühtki rada ja ole teerajaja.')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text.tag_layer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remark: if `tag_layer` is called on a `Text` object that already has the input layers, the existing layers remain as they are: there will be no updating nor overwriting.\n",
    "If you need to update an existing layer (e.g. perform morphological analysis with different settings), then you first need to remove the old layer, and then tag it once again."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What does `tag_layer` return? It returns the `Text` object on which it was called:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotated_text = text.tag_layer()\n",
    "assert text == annotated_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>\n",
    "<div class=\"alert alert-block alert-warning\"> \n",
    "<h4><i>Adding layers via <code>analyse</code> [Deprecated]</i></h4> \n",
    "<br>\n",
    "EstNTLK's versions 1.6.0beta - 1.6.9beta also allowed adding layers via method <code>Text.analyse</code>, but this is no longer supported. If your code is using the deprecated <code>analyse</code> method, you can replace it with <code>tag_layer</code> in the following ways:\n",
    "<ul>\n",
    "    <li><code>text.analyse('segmentation')</code> is same as <code>text.tag_layer('paragraphs'); text.pop_layer('tokens');</code></li>\n",
    "    <li><code>text.analyse('morphology')</code> is same as <code>text.tag_layer('morph_analysis'); text.pop_layer('tokens');</code></li>\n",
    "    <li><code>text.analyse('syntax_preprocessing')</code> is same as <code>text.tag_layer(['sentences','morph_extended']); text.pop_layer('tokens');</code></li>\n",
    "    <li><code>text.analyse('all')</code> is same as <code>text.tag_layer(['paragraphs','morph_extended']);</code></li>\n",
    "<ul>\n",
    "</div>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Which layers can be created via `tag_layer`? ( `DEFAULT_RESOLVER` )\n",
    "\n",
    "The method `tag_layer` knows how to create layers and how to resolve dependencies between layers thanks to a special component called `LayerResolver`.\n",
    "You can access this component via `Text` object's attribute `layer_resolver`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h4>LayerResolver</h4>\n",
       "<br>Default layers: <b>morph_analysis, sentences</b>\n",
       "</br><h4>TaggersRegistry</h4>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>layer</th>\n",
       "      <th>depends_on</th>\n",
       "      <th>tagger_name</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>tokens</td>\n",
       "      <td>[]</td>\n",
       "      <td>TokensTagger</td>\n",
       "      <td>Preprocessing for word segmentation: segments text into tokens.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>compound_tokens</td>\n",
       "      <td>[tokens]</td>\n",
       "      <td>CompoundTokenTagger</td>\n",
       "      <td>Preprocessing for word segmentation: joins tokens into compound tokens.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>words</td>\n",
       "      <td>[tokens, compound_tokens]</td>\n",
       "      <td>WordTagger</td>\n",
       "      <td>Segments text into words.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>sentences</td>\n",
       "      <td>[compound_tokens, words]</td>\n",
       "      <td>SentenceTokenizer</td>\n",
       "      <td>Segments text into sentences.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>paragraphs</td>\n",
       "      <td>[sentences]</td>\n",
       "      <td>ParagraphTokenizer</td>\n",
       "      <td>Segments text into paragraphs.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>morph_analysis</td>\n",
       "      <td>[compound_tokens, words, sentences]</td>\n",
       "      <td>VabamorfTagger</td>\n",
       "      <td>Tags morphological analysis with Vabamorf.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>clauses</td>\n",
       "      <td>[words, sentences, morph_analysis]</td>\n",
       "      <td>ClauseSegmenter</td>\n",
       "      <td>Segments sentences into clauses. (requires Java)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>morph_analysis_est</td>\n",
       "      <td>[morph_analysis]</td>\n",
       "      <td>VabamorfEstCatConverter</td>\n",
       "      <td>Translates category names of Vabamorf's morphological analyses into Estonian (for educational purposes).</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>morph_extended</td>\n",
       "      <td>[morph_analysis]</td>\n",
       "      <td>MorphExtendedTagger</td>\n",
       "      <td>Converts Vabamorf's morphological analyses to syntax preprocessing (CG3) format.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>gt_morph_analysis</td>\n",
       "      <td>[words, sentences, morph_analysis, clauses]</td>\n",
       "      <td>GTMorphConverter</td>\n",
       "      <td>Converts Vabamorf's morphological analyses to giellatekno's (GT) format.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>ner</td>\n",
       "      <td>[morph_analysis, words, sentences]</td>\n",
       "      <td>NerTagger</td>\n",
       "      <td>Detects named entities: person, location and organization names.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>timexes</td>\n",
       "      <td>[]</td>\n",
       "      <td>TimexTagger</td>\n",
       "      <td>Detects temporal expressions and normalizes to corresponding dates, times, durations and recurrences. (requires Java)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>address_parts</td>\n",
       "      <td>[words]</td>\n",
       "      <td>AddressPartTagger</td>\n",
       "      <td>Preprocessing for address detection.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>addresses</td>\n",
       "      <td>[address_parts]</td>\n",
       "      <td>AddressGrammarTagger</td>\n",
       "      <td>Detects addresses.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>maltparser_conll_morph</td>\n",
       "      <td>[sentences, morph_analysis]</td>\n",
       "      <td>ConllMorphTagger</td>\n",
       "      <td>Preprocessing for MaltParser based syntactic analysis.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>maltparser_syntax</td>\n",
       "      <td>[words, sentences, maltparser_conll_morph]</td>\n",
       "      <td>MaltParserTagger</td>\n",
       "      <td>Tags dependency syntactic analysis with MaltParser. (requires Java)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>verb_chains</td>\n",
       "      <td>[words, sentences, morph_analysis, clauses]</td>\n",
       "      <td>VerbChainDetector</td>\n",
       "      <td>Tags main verbs and their extensions (verb chains) in clauses. (experimental)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>np_chunks</td>\n",
       "      <td>[words, sentences, morph_analysis, maltparser_syntax]</td>\n",
       "      <td>NounPhraseChunker</td>\n",
       "      <td>Tags noun phrase chunks in sentences. (experimental)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "LayerResolver(default_layers=['morph_analysis', 'sentences'])\n",
       "TaggersRegistry\n",
       "layer               depends_on                    tagger_name          description                   \n",
       "=====               ==========                    ===========          ===========                   \n",
       "\n",
       "tokens              []                            TokensTagger         Preprocessing for word        \n",
       "                                                                       segmentation: segments text   \n",
       "                                                                       into tokens.                  \n",
       "\n",
       "compound_tokens     ['tokens']                    CompoundTokenTagger  Preprocessing for word        \n",
       "                                                                       segmentation: joins tokens    \n",
       "                                                                       into compound tokens.         \n",
       "\n",
       "words               ['tokens',                    WordTagger           Segments text into words.     \n",
       "                    'compound_tokens']                                                               \n",
       "\n",
       "sentences           ['compound_tokens', 'words']  SentenceTokenizer    Segments text into            \n",
       "                                                                       sentences.                    \n",
       "\n",
       "paragraphs          ['sentences']                 ParagraphTokenizer   Segments text into            \n",
       "                                                                       paragraphs.                   \n",
       "\n",
       "morph_analysis      ['compound_tokens', 'words',  VabamorfTagger       Tags morphological analysis   \n",
       "                    'sentences']                                       with Vabamorf.                \n",
       "\n",
       "clauses             ['words', 'sentences',        ClauseSegmenter      Segments sentences into       \n",
       "                    'morph_analysis']                                  clauses. (requires Java)      \n",
       "\n",
       "morph_analysis_est  ['morph_analysis']            VabamorfEstCatConve  Translates category names of  \n",
       "                                                  rter                 Vabamorf's morphological      \n",
       "                                                                       analyses into Estonian (for   \n",
       "                                                                       educational purposes).        \n",
       "\n",
       "morph_extended      ['morph_analysis']            MorphExtendedTagger  Converts Vabamorf's           \n",
       "                                                                       morphological analyses to     \n",
       "                                                                       syntax preprocessing (CG3)    \n",
       "                                                                       format.                       \n",
       "\n",
       "gt_morph_analysis   ['words', 'sentences',        GTMorphConverter     Converts Vabamorf's           \n",
       "                    'morph_analysis', 'clauses']                       morphological analyses to     \n",
       "                                                                       giellatekno's (GT) format.    \n",
       "\n",
       "ner                 ['morph_analysis', 'words',   NerTagger            Detects named entities:       \n",
       "                    'sentences']                                       person, location and          \n",
       "                                                                       organization names.           \n",
       "\n",
       "timexes             []                            TimexTagger          Detects temporal expressions  \n",
       "                                                                       and normalizes to             \n",
       "                                                                       corresponding dates, times,   \n",
       "                                                                       durations and recurrences.    \n",
       "                                                                       (requires Java)               \n",
       "\n",
       "address_parts       ['words']                     AddressPartTagger    Preprocessing for address     \n",
       "                                                                       detection.                    \n",
       "\n",
       "addresses           ['address_parts']             AddressGrammarTagge  Detects addresses.            \n",
       "                                                  r                                                  \n",
       "\n",
       "maltparser_conll_m  ['sentences',                 ConllMorphTagger     Preprocessing for MaltParser  \n",
       "orph                'morph_analysis']                                  based syntactic analysis.     \n",
       "\n",
       "maltparser_syntax   ['words', 'sentences',        MaltParserTagger     Tags dependency syntactic     \n",
       "                    'maltparser_conll_morph']                          analysis with MaltParser.     \n",
       "                                                                       (requires Java)               \n",
       "\n",
       "verb_chains         ['words', 'sentences',        VerbChainDetector    Tags main verbs and their     \n",
       "                    'morph_analysis', 'clauses']                       extensions (verb chains) in   \n",
       "                                                                       clauses. (experimental)       \n",
       "\n",
       "np_chunks           ['words', 'sentences',        NounPhraseChunker    Tags noun phrase chunks in    \n",
       "                    'morph_analysis',                                  sentences. (experimental)     \n",
       "                    'maltparser_syntax']                                                             \n"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# NBVAL_IGNORE_OUTPUT\n",
    "text.layer_resolver"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By default, `LayerResolver`'s representation shows which layers can be created via `tag_layer`, what are their dependency  layers, and which are the taggers responsible for creating the layers. \n",
    "\n",
    "If you want to see attributes of layers, you can change the representation via calling `text.layer_resolver.layer_attributes`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h4>LayerResolver</h4>\n",
       "<br>Default layers: <b>morph_analysis, sentences</b>\n",
       "</br><h4>TaggersRegistry</h4>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>layer</th>\n",
       "      <th>attributes</th>\n",
       "      <th>tagger_name</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>tokens</td>\n",
       "      <td>()</td>\n",
       "      <td>TokensTagger</td>\n",
       "      <td>Preprocessing for word segmentation: segments text into tokens.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>compound_tokens</td>\n",
       "      <td>(type, normalized)</td>\n",
       "      <td>CompoundTokenTagger</td>\n",
       "      <td>Preprocessing for word segmentation: joins tokens into compound tokens.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>words</td>\n",
       "      <td>(normalized_form,)</td>\n",
       "      <td>WordTagger</td>\n",
       "      <td>Segments text into words.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>sentences</td>\n",
       "      <td>()</td>\n",
       "      <td>SentenceTokenizer</td>\n",
       "      <td>Segments text into sentences.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>paragraphs</td>\n",
       "      <td>()</td>\n",
       "      <td>ParagraphTokenizer</td>\n",
       "      <td>Segments text into paragraphs.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>morph_analysis</td>\n",
       "      <td>(normalized_text, lemma, root, root_tokens, ending, clitic, form, partofspeech)</td>\n",
       "      <td>VabamorfTagger</td>\n",
       "      <td>Tags morphological analysis with Vabamorf.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>clauses</td>\n",
       "      <td>(clause_type,)</td>\n",
       "      <td>ClauseSegmenter</td>\n",
       "      <td>Segments sentences into clauses. (requires Java)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>morph_analysis_est</td>\n",
       "      <td>(normaliseeritud_sõne, algvorm, lõpp, sõnaliik, vormi_nimetus, kliitik)</td>\n",
       "      <td>VabamorfEstCatConverter</td>\n",
       "      <td>Translates category names of Vabamorf's morphological analyses into Estonian (for educational purposes).</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>morph_extended</td>\n",
       "      <td>(normalized_text, lemma, root, root_tokens, ending, clitic, form, partofspeech, punctuation_type, pronoun_type, letter_case, fin, verb_extension_suffix, subcat)</td>\n",
       "      <td>MorphExtendedTagger</td>\n",
       "      <td>Converts Vabamorf's morphological analyses to syntax preprocessing (CG3) format.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>gt_morph_analysis</td>\n",
       "      <td>(normalized_text, lemma, root, root_tokens, ending, clitic, form, partofspeech)</td>\n",
       "      <td>GTMorphConverter</td>\n",
       "      <td>Converts Vabamorf's morphological analyses to giellatekno's (GT) format.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>ner</td>\n",
       "      <td>(nertag,)</td>\n",
       "      <td>NerTagger</td>\n",
       "      <td>Detects named entities: person, location and organization names.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>timexes</td>\n",
       "      <td>(tid, type, value, temporal_function, anchor_time_id, mod, quant, freq, begin_point, end_point, part_of_interval)</td>\n",
       "      <td>TimexTagger</td>\n",
       "      <td>Detects temporal expressions and normalizes to corresponding dates, times, durations and recurrences. (requires Java)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>address_parts</td>\n",
       "      <td>(grammar_symbol, type)</td>\n",
       "      <td>AddressPartTagger</td>\n",
       "      <td>Preprocessing for address detection.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>addresses</td>\n",
       "      <td>(grammar_symbol, TÄNAV, MAJA, ASULA, MAAKOND, INDEKS)</td>\n",
       "      <td>AddressGrammarTagger</td>\n",
       "      <td>Detects addresses.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>maltparser_conll_morph</td>\n",
       "      <td>(id, form, lemma, upostag, xpostag, feats, head, deprel, deps, misc)</td>\n",
       "      <td>ConllMorphTagger</td>\n",
       "      <td>Preprocessing for MaltParser based syntactic analysis.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>maltparser_syntax</td>\n",
       "      <td>(id, lemma, upostag, xpostag, feats, head, deprel, deps, misc, parent_span, children)</td>\n",
       "      <td>MaltParserTagger</td>\n",
       "      <td>Tags dependency syntactic analysis with MaltParser. (requires Java)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>verb_chains</td>\n",
       "      <td>(pattern, roots, word_ids, mood, polarity, tense, voice, remaining_verbs)</td>\n",
       "      <td>VerbChainDetector</td>\n",
       "      <td>Tags main verbs and their extensions (verb chains) in clauses. (experimental)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>np_chunks</td>\n",
       "      <td>()</td>\n",
       "      <td>NounPhraseChunker</td>\n",
       "      <td>Tags noun phrase chunks in sentences. (experimental)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "LayerResolver(default_layers=['morph_analysis', 'sentences'])\n",
       "TaggersRegistry\n",
       "layer               attributes                    tagger_name          description                   \n",
       "=====               ==========                    ===========          ===========                   \n",
       "\n",
       "tokens              ()                            TokensTagger         Preprocessing for word        \n",
       "                                                                       segmentation: segments text   \n",
       "                                                                       into tokens.                  \n",
       "\n",
       "compound_tokens     ('type', 'normalized')        CompoundTokenTagger  Preprocessing for word        \n",
       "                                                                       segmentation: joins tokens    \n",
       "                                                                       into compound tokens.         \n",
       "\n",
       "words               ('normalized_form',)          WordTagger           Segments text into words.     \n",
       "\n",
       "sentences           ()                            SentenceTokenizer    Segments text into            \n",
       "                                                                       sentences.                    \n",
       "\n",
       "paragraphs          ()                            ParagraphTokenizer   Segments text into            \n",
       "                                                                       paragraphs.                   \n",
       "\n",
       "morph_analysis      ('normalized_text', 'lemma',  VabamorfTagger       Tags morphological analysis   \n",
       "                    'root', 'root_tokens',                             with Vabamorf.                \n",
       "                    'ending', 'clitic', 'form',                                                      \n",
       "                    'partofspeech')                                                                  \n",
       "\n",
       "clauses             ('clause_type',)              ClauseSegmenter      Segments sentences into       \n",
       "                                                                       clauses. (requires Java)      \n",
       "\n",
       "morph_analysis_est  ('normaliseeritud_sõne',      VabamorfEstCatConve  Translates category names of  \n",
       "                    'algvorm', 'lõpp',            rter                 Vabamorf's morphological      \n",
       "                    'sõnaliik', 'vormi_nimetus',                       analyses into Estonian (for   \n",
       "                    'kliitik')                                         educational purposes).        \n",
       "\n",
       "morph_extended      ('normalized_text', 'lemma',  MorphExtendedTagger  Converts Vabamorf's           \n",
       "                    'root', 'root_tokens',                             morphological analyses to     \n",
       "                    'ending', 'clitic', 'form',                        syntax preprocessing (CG3)    \n",
       "                    'partofspeech',                                    format.                       \n",
       "                    'punctuation_type',                                                              \n",
       "                    'pronoun_type',                                                                  \n",
       "                    'letter_case', 'fin',                                                            \n",
       "                    'verb_extension_suffix',                                                         \n",
       "                    'subcat')                                                                        \n",
       "\n",
       "gt_morph_analysis   ('normalized_text', 'lemma',  GTMorphConverter     Converts Vabamorf's           \n",
       "                    'root', 'root_tokens',                             morphological analyses to     \n",
       "                    'ending', 'clitic', 'form',                        giellatekno's (GT) format.    \n",
       "                    'partofspeech')                                                                  \n",
       "\n",
       "ner                 ('nertag',)                   NerTagger            Detects named entities:       \n",
       "                                                                       person, location and          \n",
       "                                                                       organization names.           \n",
       "\n",
       "timexes             ('tid', 'type', 'value',      TimexTagger          Detects temporal expressions  \n",
       "                    'temporal_function',                               and normalizes to             \n",
       "                    'anchor_time_id', 'mod',                           corresponding dates, times,   \n",
       "                    'quant', 'freq',                                   durations and recurrences.    \n",
       "                    'begin_point', 'end_point',                        (requires Java)               \n",
       "                    'part_of_interval')                                                              \n",
       "\n",
       "address_parts       ('grammar_symbol', 'type')    AddressPartTagger    Preprocessing for address     \n",
       "                                                                       detection.                    \n",
       "\n",
       "addresses           ('grammar_symbol', 'TÄNAV',   AddressGrammarTagge  Detects addresses.            \n",
       "                    'MAJA', 'ASULA', 'MAAKOND',   r                                                  \n",
       "                    'INDEKS')                                                                        \n",
       "\n",
       "maltparser_conll_m  ('id', 'form', 'lemma',       ConllMorphTagger     Preprocessing for MaltParser  \n",
       "orph                'upostag', 'xpostag',                              based syntactic analysis.     \n",
       "                    'feats', 'head', 'deprel',                                                       \n",
       "                    'deps', 'misc')                                                                  \n",
       "\n",
       "maltparser_syntax   ('id', 'lemma', 'upostag',    MaltParserTagger     Tags dependency syntactic     \n",
       "                    'xpostag', 'feats', 'head',                        analysis with MaltParser.     \n",
       "                    'deprel', 'deps', 'misc',                          (requires Java)               \n",
       "                    'parent_span', 'children')                                                       \n",
       "\n",
       "verb_chains         ('pattern', 'roots',          VerbChainDetector    Tags main verbs and their     \n",
       "                    'word_ids', 'mood',                                extensions (verb chains) in   \n",
       "                    'polarity', 'tense',                               clauses. (experimental)       \n",
       "                    'voice', 'remaining_verbs')                                                      \n",
       "\n",
       "np_chunks           ()                            NounPhraseChunker    Tags noun phrase chunks in    \n",
       "                                                                       sentences. (experimental)     \n"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# NBVAL_IGNORE_OUTPUT\n",
    "text.layer_resolver.layer_attributes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calling `text.layer_resolver.layer_dependencies` switches back to the representation listing dependencies of each layer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`LayerResolver` available via `text.layer_resolver` corresponds to EstNLTK's basic NLP pipeline. \n",
    "This pipeline can also be imported separately as `DEFAULT_RESOLVER`:\n",
    "\n",
    "```python\n",
    "    from estnltk.default_resolver import DEFAULT_RESOLVER\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`LayerResolver`'s method `get_tagger(layer)` returns the tagger responsible for creating `layer`.\n",
    "This also allows to examine configuration of the tagger. \n",
    "Example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h4>Tagger</h4>\n",
       "Tags morphological analysis on words. Uses Vabamorf's analyzer and disambiguator.\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>name</th>\n",
       "      <th>output layer</th>\n",
       "      <th>output attributes</th>\n",
       "      <th>input layers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>VabamorfTagger</td>\n",
       "      <td>morph_analysis</td>\n",
       "      <td>('normalized_text', 'lemma', 'root', 'root_tokens', 'ending', 'clitic', 'form', 'partofspeech')</td>\n",
       "      <td>('words', 'sentences', 'compound_tokens')</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<h4>Configuration</h4>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>guess</th>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>propername</th>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>disambiguate</th>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>compound</th>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>phonetic</th>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>slang_lex</th>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>postanalysis_tagger</th>\n",
       "      <td>PostMorphAnalysisTagger(('compound_tokens', 'words', 'morph_analysis')-&gt;morph_analysis)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>use_postanalysis</th>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>analysis_reorderer</th>\n",
       "      <td>MorphAnalysisReorderer(('morph_analysis',)-&gt;morph_analysis)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>use_reorderer</th>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>textbased_disambiguator</th>\n",
       "      <td>CorpusBasedMorphDisambiguator(['words', 'sentences', 'morph_analysis']*-&gt;morph_analysis*)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>predisambiguate</th>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>postdisambiguate</th>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "VabamorfTagger(input_layers=('words', 'sentences', 'compound_tokens'), output_layer=morph_analysis, output_attributes=('normalized_text', 'lemma', 'root', 'root_tokens', 'ending', 'clitic', 'form', 'partofspeech'), guess=True, propername=True, disambiguate=True, compound=True, phonetic=False, slang_lex=False, postanalysis_tagger=PostMorphAnalysisTagger(('compound_tokens', 'words', 'morph_analysis')->morph_analysis), use_postanalysis=True, analysis_reorderer=MorphAnalysisReorderer(('morph_analysis',)->morph_analysis), use_reorderer=True, textbased_disambiguator=CorpusBasedMorphDisambiguator(['words', 'sentences', 'morph_analysis']*->morph_analysis*), predisambiguate=False, postdisambiguate=False)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " text.layer_resolver.get_tagger('morph_analysis')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`LayerResolver` has attribute `default_layers` which lists names of the layers that are created if `tag_layer` is called without input arguments:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('morph_analysis', 'sentences')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " text.layer_resolver.default_layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This attribute can also be changed to different default values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td><div align = \"left\">Ma ei hooli juveelidest. Mulle meeldivad lilled.</div></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>layer name</th>\n",
       "      <th>attributes</th>\n",
       "      <th>parent</th>\n",
       "      <th>enveloping</th>\n",
       "      <th>ambiguous</th>\n",
       "      <th>span count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>sentences</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>words</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>tokens</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>compound_tokens</td>\n",
       "      <td>type, normalized</td>\n",
       "      <td>None</td>\n",
       "      <td>tokens</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>words</td>\n",
       "      <td>normalized_form</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>morph_analysis</td>\n",
       "      <td>normalized_text, lemma, root, root_tokens, ending, clitic, form, partofspeech</td>\n",
       "      <td>words</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>clauses</td>\n",
       "      <td>clause_type</td>\n",
       "      <td>None</td>\n",
       "      <td>words</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>gt_morph_analysis</td>\n",
       "      <td>normalized_text, lemma, root, root_tokens, ending, clitic, form, partofspeech</td>\n",
       "      <td>morph_analysis</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "Text(text='Ma ei hooli juveelidest. Mulle meeldivad lilled.')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from estnltk import Text\n",
    "text = Text('Ma ei hooli juveelidest. Mulle meeldivad lilled.')\n",
    "\n",
    "# Change default layer to gt_morph_analysis\n",
    "text.layer_resolver.default_layers = ['gt_morph_analysis']\n",
    "\n",
    "# Tag gt_morph_analysis (and all its prerequisites)\n",
    "text.tag_layer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Taggers inside `LayerResolver` can also be updated, see below for details."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing taggers from `estnltk.taggers`. Applying a tagger directly ( the method `tag` )\n",
    "\n",
    "`DEFAULT_RESOLVER` does not include all the taggers available in EstNLTK.\n",
    "There are several reasons why. \n",
    "Some taggers can be applied only in specific contexts, some taggers depend on specific resources (e.g. large models that need to be downloaded separately), and some address specific tasks in specific domains (e.g. detect dates from medical texts).\n",
    "However, most EstNLTK's taggers (except taggers meant for internal usage) can be imported from `estnltk.taggers`, and then applied when needed:\n",
    "\n",
    "```python\n",
    "import estnltk.taggers\n",
    "# List names of taggers that can be imported\n",
    "dir( estnltk.taggers )\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example. Let's create a new text for analysis:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from estnltk import Text\n",
    "text = Text('Ma ei hooli juveelidest. Mulle meeldivad lilled.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This time, we want to analyse the text morphologically by applying the corresponding tagger directly on text. \n",
    "First, let's import the `VabamorfTagger`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h4>Tagger</h4>\n",
       "Tags morphological analysis on words. Uses Vabamorf's analyzer and disambiguator.\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>name</th>\n",
       "      <th>output layer</th>\n",
       "      <th>output attributes</th>\n",
       "      <th>input layers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>VabamorfTagger</td>\n",
       "      <td>morph_analysis</td>\n",
       "      <td>('normalized_text', 'lemma', 'root', 'root_tokens', 'ending', 'clitic', 'form', 'partofspeech')</td>\n",
       "      <td>('words', 'sentences', 'compound_tokens')</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<h4>Configuration</h4>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>guess</th>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>propername</th>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>disambiguate</th>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>compound</th>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>phonetic</th>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>slang_lex</th>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>postanalysis_tagger</th>\n",
       "      <td>PostMorphAnalysisTagger(('compound_tokens', 'words', 'morph_analysis')-&gt;morph_analysis)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>use_postanalysis</th>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>analysis_reorderer</th>\n",
       "      <td>MorphAnalysisReorderer(('morph_analysis',)-&gt;morph_analysis)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>use_reorderer</th>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>textbased_disambiguator</th>\n",
       "      <td>CorpusBasedMorphDisambiguator(['words', 'sentences', 'morph_analysis']*-&gt;morph_analysis*)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>predisambiguate</th>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>postdisambiguate</th>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "VabamorfTagger(input_layers=('words', 'sentences', 'compound_tokens'), output_layer=morph_analysis, output_attributes=('normalized_text', 'lemma', 'root', 'root_tokens', 'ending', 'clitic', 'form', 'partofspeech'), guess=True, propername=True, disambiguate=True, compound=True, phonetic=False, slang_lex=False, postanalysis_tagger=PostMorphAnalysisTagger(('compound_tokens', 'words', 'morph_analysis')->morph_analysis), use_postanalysis=True, analysis_reorderer=MorphAnalysisReorderer(('morph_analysis',)->morph_analysis), use_reorderer=True, textbased_disambiguator=CorpusBasedMorphDisambiguator(['words', 'sentences', 'morph_analysis']*->morph_analysis*), predisambiguate=False, postdisambiguate=False)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from estnltk.taggers import VabamorfTagger\n",
    "# Create morphological tagger with default settings\n",
    "morph_tagger = VabamorfTagger()\n",
    "morph_tagger"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, taggers themselves do not create their dependencies automatically: they will raise an expection if a dependency layer is missing.\n",
    "So, before applying a tagger, you need to make sure that the input text has all the prerequisite layers ( _input layers_ ).\n",
    "\n",
    "In our example, the input `Text` misses required layers `'words'`, `'sentences'`, `'compound_tokens'`. \n",
    "We can add these via `tag_layer`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td><div align = \"left\">Ma ei hooli juveelidest. Mulle meeldivad lilled.</div></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>layer name</th>\n",
       "      <th>attributes</th>\n",
       "      <th>parent</th>\n",
       "      <th>enveloping</th>\n",
       "      <th>ambiguous</th>\n",
       "      <th>span count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>sentences</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>words</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>tokens</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>compound_tokens</td>\n",
       "      <td>type, normalized</td>\n",
       "      <td>None</td>\n",
       "      <td>tokens</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>words</td>\n",
       "      <td>normalized_form</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "Text(text='Ma ei hooli juveelidest. Mulle meeldivad lilled.')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add prerequisite input layers\n",
    "text.tag_layer(['words', 'sentences', 'compound_tokens'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we have added all depenencies,  we can use the method `tag`, which creates a new layer and adds it to the `Text` object:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td><div align = \"left\">Ma ei hooli juveelidest. Mulle meeldivad lilled.</div></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>layer name</th>\n",
       "      <th>attributes</th>\n",
       "      <th>parent</th>\n",
       "      <th>enveloping</th>\n",
       "      <th>ambiguous</th>\n",
       "      <th>span count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>sentences</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>words</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>tokens</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>compound_tokens</td>\n",
       "      <td>type, normalized</td>\n",
       "      <td>None</td>\n",
       "      <td>tokens</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>words</td>\n",
       "      <td>normalized_form</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>morph_analysis</td>\n",
       "      <td>normalized_text, lemma, root, root_tokens, ending, clitic, form, partofspeech</td>\n",
       "      <td>words</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "Text(text='Ma ei hooli juveelidest. Mulle meeldivad lilled.')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# apply tagger on the text\n",
    "morph_tagger.tag( text )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Further details about EstNLTK's taggers:\n",
    "\n",
    "🔗 Introduction to the basic NLP pipeline and morphological tagging: [nlp_pipeline/introduction_to_nlp_pipeline.ipynb](nlp_pipeline/introduction_to_nlp_pipeline.ipynb)\n",
    "\n",
    "🔗 Detailed tutorials about the NLP components: [nlp_pipeline](nlp_pipeline)\n",
    "\n",
    "🔗 Detailed tutorials about using system taggers and creating your own taggers: [taggers](taggers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>\n",
    "<div class=\"alert alert-block alert-warning\"> \n",
    "<h4><i>Taggers and Retaggers</i></h4> \n",
    "<br>\n",
    "Some of EstNTLK's taggers create new layers, while others rewrite existing layers (fix or update annotations).\n",
    "A tagger inheriting from <b><code>Retagger</code></b> class rewrites an existing layer.\n",
    "If you use a <b><code>Retagger</code></b>, make sure the target layer (<code>output_layer</code>) has already been created.\n",
    "Then you can use the method <code>retag( text )</code> to rewrite the layer.\n",
    "</div>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>\n",
    "<div class=\"alert alert-block alert-warning\"> \n",
    "<h4><i>The name of the output layer</i></h4> \n",
    "<br>\n",
    "If you import a tagger via <code>estnltk.taggers</code>, then you can also change the name of the <code>output_layer</code> via constructor's parameter. For instance:\n",
    "<pre>\n",
    "from estnltk.taggers import VabamorfTagger\n",
    "morph_tagger = VabamorfTagger(output_layer='my_morph_analysis')\n",
    "</pre>\n",
    "Changing layer names is useful if you need to compare different configurations or versions of a tagger.\n",
    "For example, if we would name morph analysis layers according to versions of the tagger (such as <code>'morph_analysis_v1'</code>, <code>'morph_analysis_v2'</code>), then we could compare these to one another with <a href=\"taggers/system/diff_tagger.ipynb\"><code>DiffTagger</code></a>.\n",
    "</div>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Changing taggers of the pipeline ( `make_resolver` )\n",
    "\n",
    "The function `make_resolver` is responsible for creating the `DEFAULT_RESOLVER`. The easiest way of modifying the pipeline is by making a copy of the default pipeline with `make_resolver` and then updating its taggers according to your needs.\n",
    "\n",
    "An example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from estnltk.default_resolver import make_resolver\n",
    "\n",
    "my_resolver = make_resolver()  # Make a copy of the default resolver"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can use the method `update` to replace an existing tagger in the pipeline with a new one:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new morphological tagger that has disambiguation and guesser components switched off\n",
    "from estnltk.taggers import VabamorfTagger\n",
    "vabamorf_tagger = VabamorfTagger( disambiguate=False, guess=False, propername=False )\n",
    "\n",
    "# Replace the existing tagger in the pipeline with a new one\n",
    "my_resolver.update( vabamorf_tagger )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to apply the new pipeline, you need to specify which `resolver` is to be used when calling `tag_layer`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h4>Layer</h4>\n",
       "\n",
       "\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>layer name</th>\n",
       "      <th>attributes</th>\n",
       "      <th>parent</th>\n",
       "      <th>enveloping</th>\n",
       "      <th>ambiguous</th>\n",
       "      <th>span count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>morph_analysis</td>\n",
       "      <td>normalized_text, lemma, root, root_tokens, ending, clitic, form, partofspeech, _ignore</td>\n",
       "      <td>words</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>text</th>\n",
       "      <th>normalized_text</th>\n",
       "      <th>lemma</th>\n",
       "      <th>root</th>\n",
       "      <th>root_tokens</th>\n",
       "      <th>ending</th>\n",
       "      <th>clitic</th>\n",
       "      <th>form</th>\n",
       "      <th>partofspeech</th>\n",
       "      <th>_ignore</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>Metsawahi</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>hobusele</td>\n",
       "      <td>hobusele</td>\n",
       "      <td>hobune</td>\n",
       "      <td>hobune</td>\n",
       "      <td>['hobune']</td>\n",
       "      <td>le</td>\n",
       "      <td></td>\n",
       "      <td>sg all</td>\n",
       "      <td>S</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>om</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>uus</td>\n",
       "      <td>uus</td>\n",
       "      <td>uus</td>\n",
       "      <td>uus</td>\n",
       "      <td>['uus']</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>sg n</td>\n",
       "      <td>A</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>laut</td>\n",
       "      <td>laut</td>\n",
       "      <td>laut</td>\n",
       "      <td>laut</td>\n",
       "      <td>['laut']</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>sg n</td>\n",
       "      <td>S</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>ehitet</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>.</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "Layer(name='morph_analysis', attributes=('normalized_text', 'lemma', 'root', 'root_tokens', 'ending', 'clitic', 'form', 'partofspeech', '_ignore'), spans=SL[Span('Metsawahi', [{'normalized_text': None, 'lemma': None, 'root': None, 'root_tokens': None, 'ending': None, 'clitic': None, 'form': None, 'partofspeech': None, '_ignore': False}]),\n",
       "Span('hobusele', [{'normalized_text': 'hobusele', 'lemma': 'hobune', 'root': 'hobune', 'root_tokens': ['hobune'], 'ending': 'le', 'clitic': '', 'form': 'sg all', 'partofspeech': 'S', '_ignore': False}]),\n",
       "Span('om', [{'normalized_text': None, 'lemma': None, 'root': None, 'root_tokens': None, 'ending': None, 'clitic': None, 'form': None, 'partofspeech': None, '_ignore': False}]),\n",
       "Span('uus', [{'normalized_text': 'uus', 'lemma': 'uus', 'root': 'uus', 'root_tokens': ['uus'], 'ending': '0', 'clitic': '', 'form': 'sg n', 'partofspeech': 'A', '_ignore': False}]),\n",
       "Span('laut', [{'normalized_text': 'laut', 'lemma': 'laut', 'root': 'laut', 'root_tokens': ['laut'], 'ending': '0', 'clitic': '', 'form': 'sg n', 'partofspeech': 'S', '_ignore': False}]),\n",
       "Span('ehitet', [{'normalized_text': None, 'lemma': None, 'root': None, 'root_tokens': None, 'ending': None, 'clitic': None, 'form': None, 'partofspeech': None, '_ignore': False}]),\n",
       "Span('.', [{'normalized_text': None, 'lemma': None, 'root': None, 'root_tokens': None, 'ending': None, 'clitic': None, 'form': None, 'partofspeech': None, '_ignore': False}])])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from estnltk import Text\n",
    "text = Text('Metsawahi hobusele om uus laut ehitet.')\n",
    "text.tag_layer(['morph_analysis'], resolver=my_resolver)\n",
    "text.morph_analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the previous example: because guessing of unknown words was switched off, words with old spelling ( _Metsawahi_ , _om_ , _ehitet_ ) obtained zero analysis (`None` attribute values) during the morphological analysis.\n",
    "So by changing parameters of morphological tagging, we have successfully detected spelling variants that are unknown to contemporary Estonian."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>\n",
    "<div class=\"alert alert-block alert-warning\"> \n",
    "<h4><i><code>make_resolver</code> and the parameters of morphological analysis</i></h4> \n",
    "<br>\n",
    "As morphological tagger is the central component of EstNLTK's linguistic analysis, it is also possible to directly change the parameters of morphological analysis via <code>make_resolver</code>. \n",
    "For details, see the tutorial: <a href=\"nlp_pipeline/introduction_to_nlp_pipeline.ipynb\">introduction_to_nlp_pipeline.ipynb</a>.\n",
    "</div>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>\n",
    "<div class=\"alert alert-block alert-warning\"> \n",
    "<h4><i>Warning: updating layer resolver can lead to conflicts in the pipeline</i></h4> \n",
    "<br>\n",
    "<code>make_resolver</code> and <code>DEFAULT_RESOLVER</code> provide a working version of EstNLTK's pipeline. However, there are no guarantees that the pipeline remains fully functional if you change / update of some of its taggers. \n",
    "As a matter of fact, in the example above, switching off morphological disambiguation and guesser components <b>will tamper the quality</b> of the components that are dependent of morphological analysis, and some of the components will also became non-functional (the <code>my_resolver</code> cannot be used for named entity recognition, and for syntactic preprocessing and analysis). We recommend to change the pipeline only when you understand the risks and dependencies between taggers.\n",
    "</div>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you have accidentially updated the default pipeline (available via `Text.tag_layer`) in a way that some taggers have became non-functional, you can use `make_resolver` to reset the pipeline:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from estnltk.default_resolver import make_resolver\n",
    "# Reset default resolver\n",
    "Text.layer_resolver = make_resolver()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>\n",
    "<div class=\"alert alert-block alert-warning\"> \n",
    "<h4><i><code>make_resolver</code> and Python's multiprocessing</i></h4> \n",
    "<br>\n",
    "If you want to use EstNLTK's morphological analysis with Python's multiprocessing, you should make a separate <code>LayerResolver</code> for each job, and pass to <code>tag_layer</code> via <code>resolver</code> argument inside a job.\n",
    "Using a single resolver (<code>DEFAULT_RESOLVER</code>) for multiple jobs will result in error <code>('CFSException: internal error with vabamorf' ... )</code>.\n",
    "</div>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Removing a layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The method `pop_layer` removes the layer from the `Text` object and returns it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'compound_tokens', 'sentences', 'tokens', 'words'}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove morph analysis layer\n",
    "text.pop_layer('morph_analysis')\n",
    "\n",
    "# Make sure the layer is no longer there\n",
    "text.layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_NB!_ If a `Text` object has other layers depending on the removable layer, then these layers will also be removed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>\n",
    "<div class=\"alert alert-block alert-warning\"> \n",
    "<h4><i>Remark about older versions</i></h4> \n",
    "<br>\n",
    "In EstNTLK's versions 1.6.0b to 1.6.5b, the <code>del</code> operator was used for removing layers. For instance:\n",
    "<pre>\n",
    ">> del text.morph_analysis\n",
    "</pre>\n",
    "However, deleting layers with the <code>del</code> operator is no longer supported in newer versions.\n",
    "</div>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accessing annotations of `Text`. Iterating and querying annotations\n",
    "\n",
    "There are two equivalent ways to access layers:\n",
    "\n",
    "* access via index operator:\n",
    "`text['tokens']`\n",
    "* access via attribute:\n",
    "`text.tokens`\n",
    "\n",
    "Both ways give a `Layer` object, which is basically a collection of annotations.\n",
    "\n",
    "Example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h4>Layer</h4>\n",
       "\n",
       "\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>layer name</th>\n",
       "      <th>attributes</th>\n",
       "      <th>parent</th>\n",
       "      <th>enveloping</th>\n",
       "      <th>ambiguous</th>\n",
       "      <th>span count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>morph_analysis</td>\n",
       "      <td>normalized_text, lemma, root, root_tokens, ending, clitic, form, partofspeech</td>\n",
       "      <td>words</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>text</th>\n",
       "      <th>normalized_text</th>\n",
       "      <th>lemma</th>\n",
       "      <th>root</th>\n",
       "      <th>root_tokens</th>\n",
       "      <th>ending</th>\n",
       "      <th>clitic</th>\n",
       "      <th>form</th>\n",
       "      <th>partofspeech</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>Ma</td>\n",
       "      <td>Ma</td>\n",
       "      <td>mina</td>\n",
       "      <td>mina</td>\n",
       "      <td>['mina']</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>sg n</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>ei</td>\n",
       "      <td>ei</td>\n",
       "      <td>ei</td>\n",
       "      <td>ei</td>\n",
       "      <td>['ei']</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>neg</td>\n",
       "      <td>V</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>hooli</td>\n",
       "      <td>hooli</td>\n",
       "      <td>hoolima</td>\n",
       "      <td>hooli</td>\n",
       "      <td>['hooli']</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>o</td>\n",
       "      <td>V</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>juveelidest</td>\n",
       "      <td>juveelidest</td>\n",
       "      <td>juveel</td>\n",
       "      <td>juveel</td>\n",
       "      <td>['juveel']</td>\n",
       "      <td>dest</td>\n",
       "      <td></td>\n",
       "      <td>pl el</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>['.']</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Mulle</td>\n",
       "      <td>Mulle</td>\n",
       "      <td>mina</td>\n",
       "      <td>mina</td>\n",
       "      <td>['mina']</td>\n",
       "      <td>lle</td>\n",
       "      <td></td>\n",
       "      <td>sg all</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>meeldivad</td>\n",
       "      <td>meeldivad</td>\n",
       "      <td>meeldima</td>\n",
       "      <td>meeldi</td>\n",
       "      <td>['meeldi']</td>\n",
       "      <td>vad</td>\n",
       "      <td></td>\n",
       "      <td>vad</td>\n",
       "      <td>V</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>lilled</td>\n",
       "      <td>lilled</td>\n",
       "      <td>lill</td>\n",
       "      <td>lill</td>\n",
       "      <td>['lill']</td>\n",
       "      <td>d</td>\n",
       "      <td></td>\n",
       "      <td>pl n</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>['.']</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Z</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "Layer(name='morph_analysis', attributes=('normalized_text', 'lemma', 'root', 'root_tokens', 'ending', 'clitic', 'form', 'partofspeech'), spans=SL[Span('Ma', [{'normalized_text': 'Ma', 'lemma': 'mina', 'root': 'mina', 'root_tokens': ['mina'], 'ending': '0', 'clitic': '', 'form': 'sg n', 'partofspeech': 'P'}]),\n",
       "Span('ei', [{'normalized_text': 'ei', 'lemma': 'ei', 'root': 'ei', 'root_tokens': ['ei'], 'ending': '0', 'clitic': '', 'form': 'neg', 'partofspeech': 'V'}]),\n",
       "Span('hooli', [{'normalized_text': 'hooli', 'lemma': 'hoolima', 'root': 'hooli', 'root_tokens': ['hooli'], 'ending': '0', 'clitic': '', 'form': 'o', 'partofspeech': 'V'}]),\n",
       "Span('juveelidest', [{'normalized_text': 'juveelidest', 'lemma': 'juveel', 'root': 'juveel', 'root_tokens': ['juveel'], 'ending': 'dest', 'clitic': '', 'form': 'pl el', 'partofspeech': 'S'}]),\n",
       "Span('.', [{'normalized_text': '.', 'lemma': '.', 'root': '.', 'root_tokens': ['.'], 'ending': '', 'clitic': '', 'form': '', 'partofspeech': 'Z'}]),\n",
       "Span('Mulle', [{'normalized_text': 'Mulle', 'lemma': 'mina', 'root': 'mina', 'root_tokens': ['mina'], 'ending': 'lle', 'clitic': '', 'form': 'sg all', 'partofspeech': 'P'}]),\n",
       "Span('meeldivad', [{'normalized_text': 'meeldivad', 'lemma': 'meeldima', 'root': 'meeldi', 'root_tokens': ['meeldi'], 'ending': 'vad', 'clitic': '', 'form': 'vad', 'partofspeech': 'V'}]),\n",
       "Span('lilled', [{'normalized_text': 'lilled', 'lemma': 'lill', 'root': 'lill', 'root_tokens': ['lill'], 'ending': 'd', 'clitic': '', 'form': 'pl n', 'partofspeech': 'S'}]),\n",
       "Span('.', [{'normalized_text': '.', 'lemma': '.', 'root': '.', 'root_tokens': ['.'], 'ending': '', 'clitic': '', 'form': '', 'partofspeech': 'Z'}])])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a text with words, sentences and morph_analysis annotations\n",
    "from estnltk import Text\n",
    "text = Text('Ma ei hooli juveelidest. Mulle meeldivad lilled.')\n",
    "text.tag_layer(['words', 'sentences', 'morph_analysis'])\n",
    "\n",
    "# Ask for morph_analysis layer\n",
    "text['morph_analysis']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Textual span of annotation ( `Span` and `EnvelopingSpan` )\n",
    "\n",
    "A typical _annotation_ consists of a `Span`, which specifies the location of annotated text fragment, and `Annotation` objects, which specify the information contained in the annotation (attribute-value pairs). \n",
    "\n",
    "When accessing a single element of a layer, you will get a span:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<b>Span</b>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>text</th>\n",
       "      <th>normalized_text</th>\n",
       "      <th>lemma</th>\n",
       "      <th>root</th>\n",
       "      <th>root_tokens</th>\n",
       "      <th>ending</th>\n",
       "      <th>clitic</th>\n",
       "      <th>form</th>\n",
       "      <th>partofspeech</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td><span style=\"font-family: monospace; white-space: pre-wrap;\"><span style=\"text-decoration: underline;\">Ma</span></span></td>\n",
       "      <td>Ma</td>\n",
       "      <td>mina</td>\n",
       "      <td>mina</td>\n",
       "      <td>[&#x27;mina&#x27;]</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>sg n</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "Span('Ma', [{'normalized_text': 'Ma', 'lemma': 'mina', 'root': 'mina', 'root_tokens': ['mina'], 'ending': '0', 'clitic': '', 'form': 'sg n', 'partofspeech': 'P'}])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ask for the first element of 'morph_analysis'\n",
    "text['morph_analysis'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In case of an **_enveloping layer_** , the span is defined as a sequence of spans from some other layer, and it's called `EnvelopingSpan`.\n",
    "For example, a sentence consists of the words inside the sentence:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<b>EnvelopingSpan</b>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td><span style=\"font-family: monospace; white-space: pre-wrap;\"><span style=\"text-decoration: underline;\">Ma</span> <span style=\"text-decoration: underline;\">ei</span> <span style=\"text-decoration: underline;\">hooli</span> <span style=\"text-decoration: underline;\">juveelidest</span><span style=\"text-decoration: underline;\">.</span></span></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "EnvelopingSpan(['Ma', 'ei', 'hooli', 'juveelidest', '.'], [{}])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# First sentence (a list of words)\n",
    "text['sentences'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each span has attributes `start`, `end` and `text`, which specify start/end indexes of the annotated text fragment, and the corresponding textual fragment.\n",
    "\n",
    "Examples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text['words'][0].start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text['words'][0].end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Ma'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text['words'][0].text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In case of an _enveloping layer_ , the attribute `text` returns a list of strings instead of a single string. \n",
    "For instance, when asking for sentences  `text`, you will get a list of  `text` values from the words belonging to the sentence:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Ma', 'ei', 'hooli', 'juveelidest', '.']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# \"text\" value of the first sentence\n",
    "text['sentences'][0].text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you need to get the raw string corresponding to an _enveloping span_ , you should use the attribute `enclosing_text` instead:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Ma ei hooli juveelidest.'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Enclosing text of the first sentence\n",
    "text['sentences'][0].enclosing_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In addition to the `'sentences'` layer, `'clauses'`, `'compound_tokens'` and `'paragraphs'` are also enveloping layers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>\n",
    "<div class=\"alert alert-block alert-warning\"> \n",
    "<h4><i>Warning: <code>enclosing_text</code> and discontinuous spans</i></h4> \n",
    "<br>\n",
    "The attribute <code>enclosing_text</code> gives a substring of initial text between indexes <code>start</code> and <code>end</code>.\n",
    "This holds true even if we have an enveloping span that does not contain a continuous region of spans, but has some gaps in its span list.\n",
    "This is the reason you should be careful when using <code>enclosing_text</code> with the layer <code>'clauses'</code>, because a clause can be made of discontinuous snippets of word spans, and <code>enclosing_text</code> can give a false impression about the extent of the clause.\n",
    "</div>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>\n",
    "<div class=\"alert alert-block alert-warning\"> \n",
    "<h4><i>Comparing spans</i> (<code>estnltk_core.layer.span_operations</code>) </h4> \n",
    "<br>\n",
    "EstNLTK has operators for systematic comparison of <code>Span</code> objects. For instance:\n",
    "<ul> \n",
    " <li> <code>conflict(span_x, span_y)</code> checks if <code>span_x</code> and <code>span_y</code> are nested (one of them is inside the other), or if there is an overlap between them from right or from left side;</li>\n",
    " <li> <code>nested(span_x, span_y)</code> checks if one of the spans is inside the other;</li>\n",
    " <li> <code>equal(span_x, span_y)</code> checks if the spans are totally overlapping / equal;</li>\n",
    "</ul>\n",
    "    \n",
    "🔗 There are more comparing operators available, see the source for details: <a href=\"https://github.com/estnltk/estnltk/blob/main/estnltk_core/estnltk_core/layer/span_operations.py\">https://github.com/estnltk/estnltk/blob/main/estnltk_core/estnltk_core/layer/span_operations.py</a>\n",
    "    \n",
    "NB! Please keep in mind that these functions only compare locations (spans) of annotations, ignoring their informational content (<code>Annotation</code> objects).\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Informational content of annotation ( `Annotation` )\n",
    "\n",
    "The informational content of annotation -- e.g. lemma and part of speech information in morphological analysis -- resides in  `Annotation` object. \n",
    "`Span` and `EnvelopingSpan` objects have attribute `annotations`, which gives access to `Annotation` objects:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Annotation('Ma', {'normalized_text': 'Ma', 'lemma': 'mina', 'root': 'mina', 'root_tokens': ['mina'], 'ending': '0', 'clitic': '', 'form': 'sg n', 'partofspeech': 'P'})]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text['morph_analysis'][0].annotations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Annotation` object is similar to a _dict_ object : it contains **attributes** and their **values**, which can be accessed via  indexing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'mina'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the first annotation\n",
    "annotation = text['morph_analysis'][0].annotations[0]\n",
    "# Get attribute 'lemma' from the annotation\n",
    "annotation['lemma']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, if you need to access many attributes at once and/or you need to make queries over annotations, accessing via `annotations` can be cumbersome.\n",
    "For this reason, EstNLTK also contains convenient shortcuts for accessing/querying annotations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selecting multiple annotations: indexing operators\n",
    "\n",
    "In similar to accessing elements of list, you can use **slice notation** to select a subset of a layer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h4>Layer</h4>\n",
       "\n",
       "\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>layer name</th>\n",
       "      <th>attributes</th>\n",
       "      <th>parent</th>\n",
       "      <th>enveloping</th>\n",
       "      <th>ambiguous</th>\n",
       "      <th>span count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>words</td>\n",
       "      <td>normalized_form</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>text</th>\n",
       "      <th>normalized_form</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>Mulle</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>meeldivad</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>lilled</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "Layer(name='words', attributes=('normalized_form',), spans=SL[Span('Mulle', [{'normalized_form': None}]),\n",
       "Span('meeldivad', [{'normalized_form': None}]),\n",
       "Span('lilled', [{'normalized_form': None}])])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text['words'][5:8]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also **select specific spans** via indexing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h4>Layer</h4>\n",
       "\n",
       "\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>layer name</th>\n",
       "      <th>attributes</th>\n",
       "      <th>parent</th>\n",
       "      <th>enveloping</th>\n",
       "      <th>ambiguous</th>\n",
       "      <th>span count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>words</td>\n",
       "      <td>normalized_form</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>text</th>\n",
       "      <th>normalized_form</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>juveelidest</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>lilled</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "Layer(name='words', attributes=('normalized_form',), spans=SL[Span('juveelidest', [{'normalized_form': None}]),\n",
       "Span('lilled', [{'normalized_form': None}])])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text['words'][[3,7]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can use a **`lambda` function** to select only spans that satisfy some specific criterion.\n",
    "\n",
    "For instance, let's select words with length of 2:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h4>Layer</h4>\n",
       "\n",
       "\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>layer name</th>\n",
       "      <th>attributes</th>\n",
       "      <th>parent</th>\n",
       "      <th>enveloping</th>\n",
       "      <th>ambiguous</th>\n",
       "      <th>span count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>words</td>\n",
       "      <td>normalized_form</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>text</th>\n",
       "      <th>normalized_form</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>Ma</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>ei</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "Layer(name='words', attributes=('normalized_form',), spans=SL[Span('Ma', [{'normalized_form': None}]),\n",
       "Span('ei', [{'normalized_form': None}])])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text['words'][ lambda span: len(span.text) == 2 ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can **combine selecting spans with selecting specific attributes** of annotations. In this case, the result of selection is no longer a layer, but an `AttributeList` (if one attribute is selected) or `AttributeTupleList` (in case of selecting multiple attributes). If the layer is ambiguous, the result is `AmbiguousAttributeList` / `AmbiguousAttributeTupleList`.\n",
    "\n",
    "For instance, we can select only _part of speech_ values of morphological analysis:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h4>AmbiguousAttributeList (spans)</h4>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>partofspeech</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>V</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>V</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "AmbiguousAttributeList([['P'], ['V'], ['V'], ['S']], ('partofspeech',))"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Select partofspeech of the first 4 words\n",
    "text.morph_analysis[0:4, 'partofspeech']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h4>AmbiguousAttributeTupleList (spans)</h4>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lemma</th>\n",
       "      <th>partofspeech</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>mina</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>ei</td>\n",
       "      <td>V</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>hoolima</td>\n",
       "      <td>V</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>juveel</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "AmbiguousAttributeTupleList([[['mina', 'P']], [['ei', 'V']], [['hoolima', 'V']], [['juveel', 'S']]], ('lemma', 'partofspeech'))"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Select lemma and partofspeech of the first 4 words\n",
    "text.morph_analysis[0:4, ['lemma','partofspeech']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h4>AmbiguousAttributeTupleList (spans)</h4>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "      <th>text</th>\n",
       "      <th>lemma</th>\n",
       "      <th>partofspeech</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>Ma</td>\n",
       "      <td>mina</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>ei</td>\n",
       "      <td>ei</td>\n",
       "      <td>V</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>11</td>\n",
       "      <td>hooli</td>\n",
       "      <td>hoolima</td>\n",
       "      <td>V</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>12</td>\n",
       "      <td>23</td>\n",
       "      <td>juveelidest</td>\n",
       "      <td>juveel</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>23</td>\n",
       "      <td>24</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>25</td>\n",
       "      <td>30</td>\n",
       "      <td>Mulle</td>\n",
       "      <td>mina</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>31</td>\n",
       "      <td>40</td>\n",
       "      <td>meeldivad</td>\n",
       "      <td>meeldima</td>\n",
       "      <td>V</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>41</td>\n",
       "      <td>47</td>\n",
       "      <td>lilled</td>\n",
       "      <td>lill</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>47</td>\n",
       "      <td>48</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>Z</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "AmbiguousAttributeTupleList([[[0, 2, 'Ma', 'mina', 'P']], [[3, 5, 'ei', 'ei', 'V']], [[6, 11, 'hooli', 'hoolima', 'V']], [[12, 23, 'juveelidest', 'juveel', 'S']], [[23, 24, '.', '.', 'Z']], [[25, 30, 'Mulle', 'mina', 'P']], [[31, 40, 'meeldivad', 'meeldima', 'V']], [[41, 47, 'lilled', 'lill', 'S']], [[47, 48, '.', '.', 'Z']]], ('start', 'end', 'text', 'lemma', 'partofspeech'))"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Select index attributes start, end, text along with lemma and partofspeech\n",
    "text.morph_analysis[['start', 'end', 'text', 'lemma','partofspeech']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you only need to access a single attribute, you can **combine indexing with the attribute access**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h4>AmbiguousAttributeList (spans)</h4>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lemma</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>mina</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>meeldima</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>lill</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "AmbiguousAttributeList([['mina'], ['meeldima'], ['lill'], ['.']], ('lemma',))"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Select lemmas\n",
    "text.morph_analysis[5:].lemma"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, if an annotation layer has a parent layer, you can also select its annotations via the parent layer.\n",
    "An example -- selecting a `'morph_analysis'` attribute `'lemma'` via `'words'`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h4>AmbiguousAttributeList (spans)</h4>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lemma</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>mina</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>meeldima</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>lill</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "AmbiguousAttributeList([['mina'], ['meeldima'], ['lill'], ['.']], ('lemma',))"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Select lemmas\n",
    "text.words[5:].lemma"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>\n",
    "<div class=\"alert alert-block alert-warning\"> \n",
    "<h4><i>Remark about ambiguity</i></h4> \n",
    "<br>\n",
    "As names <code>AmbiguousAttributeTupleList</code> and <code>AmbiguousAttributeList</code> indicate, the selection was made from an ambiguous layer in previous examples.\n",
    "When selecting an attribute from an ambiguous layer, please keep in mind that the result is not a single value, but a list of values.\n",
    "For instance:\n",
    "<pre>\n",
    ">> text.words[5].lemma\n",
    "['mina']\n",
    ">> text.words[5].partofspeech\n",
    "['P']\n",
    "</pre>\n",
    "</div>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Iterating over multiple layers: an example\n",
    "\n",
    "Frequently, one needs to select information from multiple layers in combination.\n",
    "Let's consider an example of processing morphological analyses sentence by sentence.\n",
    "Because the 'sentences' layer envelops the 'words' layer, and the 'words' layer is parent for 'morph_analysis' layer, we can iterate over sentences and access 'morph_analysis' attributes within the sentence:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence: Ma ei hooli juveelidest.\n",
      "  Lemma:  mina \t\tPOS: P\n",
      "  Lemma:  ei \t\tPOS: V\n",
      "  Lemma:  hoolima \t\tPOS: V\n",
      "  Lemma:  juveel \t\tPOS: S\n",
      "  Lemma:  . \t\tPOS: Z\n",
      "\n",
      "Sentence: Mulle meeldivad lilled.\n",
      "  Lemma:  mina \t\tPOS: P\n",
      "  Lemma:  meeldima \t\tPOS: V\n",
      "  Lemma:  lill \t\tPOS: S\n",
      "  Lemma:  . \t\tPOS: Z\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for sentence in text.sentences:\n",
    "    print('Sentence:', sentence.enclosing_text)\n",
    "    for word in sentence:\n",
    "        print( '  Lemma: ', word.morph_analysis.lemma[0], \\\n",
    "               '\\t\\tPOS:', word.morph_analysis.partofspeech[0] )\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grouping annotations ( `Layer.groupby` )\n",
    "\n",
    "EstNLTK's `Layer` has method `groupby`, which groups annotations **by attributes or by enveloping layers**.\n",
    "\n",
    "For instance, we can group 'morph_analysis' by 'partofspeech' attributes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "groups = text.morph_analysis.groupby('partofspeech', return_type='spans')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we can use `count` to get frequencies of 'partofspeech':"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{('P',): 2, ('V',): 3, ('S',): 2, ('Z',): 2}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "groups.count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the group of annotations, we can get a subselection of annotations that have specific attribute value (or values).\n",
    "For instance, let us fetch all verbs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Span('ei', [{'normalized_text': 'ei', 'lemma': 'ei', 'root': 'ei', 'root_tokens': ['ei'], 'ending': '0', 'clitic': '', 'form': 'neg', 'partofspeech': 'V'}]),\n",
       " Span('hooli', [{'normalized_text': 'hooli', 'lemma': 'hoolima', 'root': 'hooli', 'root_tokens': ['hooli'], 'ending': '0', 'clitic': '', 'form': 'o', 'partofspeech': 'V'}]),\n",
       " Span('meeldivad', [{'normalized_text': 'meeldivad', 'lemma': 'meeldima', 'root': 'meeldi', 'root_tokens': ['meeldi'], 'ending': 'vad', 'clitic': '', 'form': 'vad', 'partofspeech': 'V'}])]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "groups.groups[('V',)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also group by multiple attributes, e.g. group by 'partofspeech' and 'form' attributes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{('P', 'sg n'): 1,\n",
       " ('V', 'neg'): 1,\n",
       " ('V', 'o'): 1,\n",
       " ('S', 'pl el'): 1,\n",
       " ('Z', ''): 2,\n",
       " ('P', 'sg all'): 1,\n",
       " ('V', 'vad'): 1,\n",
       " ('S', 'pl n'): 1}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "groups = text.morph_analysis.groupby(['partofspeech', 'form'], return_type='spans')\n",
    "groups.count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we can group by _enveloping layers_ .\n",
    "For example, let's group morphological analyses by sentences and then output text and partofspeech of every word:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Ma', 'ei', 'hooli', 'juveelidest', '.']\n",
      "    Ma \t ['P']\n",
      "    ei \t ['V']\n",
      "    hooli \t ['V']\n",
      "    juveelidest \t ['S']\n",
      "    . \t ['Z']\n",
      "['Mulle', 'meeldivad', 'lilled', '.']\n",
      "    Mulle \t ['P']\n",
      "    meeldivad \t ['V']\n",
      "    lilled \t ['S']\n",
      "    . \t ['Z']\n"
     ]
    }
   ],
   "source": [
    "for sentence_id, sentence_spanlist in text.morph_analysis.groupby( text.sentences ):\n",
    "    print([span.text for span in sentence_spanlist])\n",
    "    for morph_span in sentence_spanlist:\n",
    "        print('   ',morph_span.text,'\\t',morph_span.partofspeech)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "🔗 For more detailed information about `groupby` can be found from the tutorial [layer_operations.ipynb](system/layer_operations.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sliding window over annotations ( `Layer.rolling` )\n",
    "\n",
    "EstNLTK's method `Layer.rolling` allows to process layer's annotations through **a sliding window**. It can be used for making _n_-grams from the annotations.\n",
    "\n",
    "For instance, we can make trigrams out of lemmas from the morphological analysis layer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Ma', 'ei', 'hooli'] => ['mina'] ['ei'] ['hoolima']\n",
      "['ei', 'hooli', 'juveelidest'] => ['ei'] ['hoolima'] ['juveel']\n",
      "['hooli', 'juveelidest', '.'] => ['hoolima'] ['juveel'] ['.']\n",
      "['juveelidest', '.', 'Mulle'] => ['juveel'] ['.'] ['mina']\n",
      "['.', 'Mulle', 'meeldivad'] => ['.'] ['mina'] ['meeldima']\n",
      "['Mulle', 'meeldivad', 'lilled'] => ['mina'] ['meeldima'] ['lill']\n",
      "['meeldivad', 'lilled', '.'] => ['meeldima'] ['lill'] ['.']\n"
     ]
    }
   ],
   "source": [
    "for spans in text.morph_analysis.rolling( window=3 ):\n",
    "    print(spans.text, '=>', spans[0].lemma, spans[1].lemma, spans[2].lemma)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In addition to specifying the size of the window, you can also specify the (enveloping) layer to constrain the process, and the minimal length of the _n_-gram (which applies in the border situations, e.g. at the beginning or the end of the text).\n",
    "\n",
    "🔗 For more detailed information about `rolling`, see the tutorial: [layer_operations.ipynb](system/layer_operations.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dividing `Text` object into smaller `Text` objects\n",
    "\n",
    "### Making extracts from `Text` ( `extract_sections` )\n",
    "\n",
    "The function `extract_sections` can be used to extract sections from a `Text` object. For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Text(text='juveelidest.'), Text(text='Mulle meeldivad')]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from estnltk_core.layer_operations import extract_sections\n",
    "\n",
    "sections = extract_sections(text, sections=[(12, 24), (25,40)])\n",
    "sections"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Resulting sections are also `Text` objects and all layers are preserved by default:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td><div align = \"left\">juveelidest.</div></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>layer name</th>\n",
       "      <th>attributes</th>\n",
       "      <th>parent</th>\n",
       "      <th>enveloping</th>\n",
       "      <th>ambiguous</th>\n",
       "      <th>span count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>sentences</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>words</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>tokens</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>compound_tokens</td>\n",
       "      <td>type, normalized</td>\n",
       "      <td>None</td>\n",
       "      <td>tokens</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>words</td>\n",
       "      <td>normalized_form</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>morph_analysis</td>\n",
       "      <td>normalized_text, lemma, root, root_tokens, ending, clitic, form, partofspeech</td>\n",
       "      <td>words</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "Text(text='juveelidest.')"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sections[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, the default setting only preserves annotations that fit completely inside the extracted sections.\n",
    "In the previous example, none of the sentence annotations were preserved because they did not fit into the section.\n",
    "\n",
    "If `trim_overlapping=True` is set, then `extract_sections` tries to preserve annotations by trimming them shorter if they do not fit into section that overlaps them. \n",
    "In the previous example, `trim_overlapping=True` would have preserved the first sentence annotation in `sections[0]`, but would have caused it to be trimmed into a 2-word sentence ( _juveelidest._ ).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "🔗 More detailed tutorial about `extract_sections` can be found at [layer_operations.ipynb](system/layer_operations.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting `Text` ( `split_by` )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function `split_by` can be used to **split `Text` object by a specific layer.**\n",
    "For instance, we can split our text into smaller `Text` objects so that each `Text` object corresponds to a sentence:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Text(text='Ma ei hooli juveelidest.'), Text(text='Mulle meeldivad lilled.')]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from estnltk_core.layer_operations import split_by\n",
    "\n",
    "sentence_texts = split_by(text, 'sentences')\n",
    "sentence_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td><div align = \"left\">Ma ei hooli juveelidest.</div></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>layer name</th>\n",
       "      <th>attributes</th>\n",
       "      <th>parent</th>\n",
       "      <th>enveloping</th>\n",
       "      <th>ambiguous</th>\n",
       "      <th>span count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>sentences</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>words</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>words</td>\n",
       "      <td>normalized_form</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>morph_analysis</td>\n",
       "      <td>normalized_text, lemma, root, root_tokens, ending, clitic, form, partofspeech</td>\n",
       "      <td>words</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "Text(text='Ma ei hooli juveelidest.')"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_texts[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While `extract_sections` preserves all layers, `split_by` keeps only the layer that was used for splitting, and its (indirect or direct) dependent layers.\n",
    "In the previous example, `'sentences'` layer was kept because it was used for splitting, `'words'` layer was kept because `'sentences'` envelops `'words'`, and `'morph_analysis'` was kept because `'words'`  is its parent. However, layers `'tokens'` and `'compound_tokens'` were removed, as they do not depend directly nor indirectly from the aforementioned 3 layers.\n",
    "Still, there is also possible to preserve all layers while splitting, see the documentation for details."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "🔗 More detailed tutorial about `split_by` can be found at [layer_operations.ipynb](system/layer_operations.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "🔗 Splitting can also be reversed (to an extent): you can join multiple `Text` objects back into a single `Text` object. Details at [layer_operations.ipynb](system/layer_operations.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Removing layer's dependencies ( `flatten` )\n",
    "\n",
    "The function `flatten` turns a layer into **a simple layer** (a layer that is not enveloping nor a child of some other layer).\n",
    "This is useful when you are only interested in specific layers and you want to reduce the size of the `Text` object -- you can flatten the layers of interest, and then delete other layers.\n",
    "\n",
    "For instance, let's flatten the sentences layer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h4>Layer</h4>\n",
       "\n",
       "\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>layer name</th>\n",
       "      <th>attributes</th>\n",
       "      <th>parent</th>\n",
       "      <th>enveloping</th>\n",
       "      <th>ambiguous</th>\n",
       "      <th>span count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>flat_sentences</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>Tere, maailm!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Kuidas läheb?</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "Layer(name='flat_sentences', attributes=(), spans=SL[Span('Tere, maailm!', [{}]),\n",
       "Span('Kuidas läheb?', [{}])])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from estnltk_core.layer_operations import flatten\n",
    "\n",
    "# Make text and add sentences layer\n",
    "text = Text('Tere, maailm! Kuidas läheb?').tag_layer(['sentences'])\n",
    "\n",
    "# create flat sentences layer\n",
    "flat_sentences = flatten(text['sentences'], 'flat_sentences')\n",
    "\n",
    "# add new layer to the Text\n",
    "text.add_layer( flat_sentences )\n",
    "\n",
    "# examine new layer\n",
    "text.flat_sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While the original sentences layer was enveloping around the words layer, the new layer no longer has that dependency.\n",
    "\n",
    "If we now remove the words layer, the original sentences layer will also be deleted. \n",
    "But the flat sentences layer will remain:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td><div align = \"left\">Tere, maailm! Kuidas läheb?</div></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>layer name</th>\n",
       "      <th>attributes</th>\n",
       "      <th>parent</th>\n",
       "      <th>enveloping</th>\n",
       "      <th>ambiguous</th>\n",
       "      <th>span count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>tokens</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>compound_tokens</td>\n",
       "      <td>type, normalized</td>\n",
       "      <td>None</td>\n",
       "      <td>tokens</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>flat_sentences</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "Text(text='Tere, maailm! Kuidas läheb?')"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text.pop_layer( 'words' )\n",
    "text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "🔗 For more detailed information about `flatten`, see the tutorial [layer_operations.ipynb](system/layer_operations.ipynb)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
