{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color:darkblue\"> Basic NLP toolchain</span> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<ul> <li><a href=\"#-Basic-NLP-toolchain\"> Basic NLP toolchain</a></li>\n",
    "  <ul><li><a href=\"#A-Short-Introduction-and-Tutorial\">A Short Introduction and Tutorial</a></li>\n",
    "  <li><a href=\"#-Text-segmentation-\"> Text segmentation </a></li>\n",
    "    <ul><ul><li><a href=\"#Tokens-vs-words\">Tokens vs words</a></li>\n",
    "    <li><a href=\"#Sentences\">Sentences</a></li>\n",
    "  </ul></ul><li><a href=\"#Morphological-analysis\">Morphological analysis</a></li>\n",
    "    <ul><ul><li><a href=\"#Accessing-details-of-the-morphological-analysis\">Accessing details of the morphological analysis</a></li>\n",
    "    <li><a href=\"#Parameters-of-morphological-analysis:-disambiguation,-guessing...\">Parameters of morphological analysis: disambiguation, guessing...</a></li>\n",
    "     <ul><li><a href=\"#Note:\">Note:</a></li>\n",
    "     <li><a href=\"#Warning:\">Warning:</a></li>\n",
    "    </ul><li><a href=\"#Unknown-words\">Unknown words</a></li>\n",
    "     <ul><li><a href=\"#Remarks-on-morphological-analysis:\">Remarks on morphological analysis:</a></li>\n",
    "  </ul></ul></ul><li><a href=\"#-Examples\"> Examples</a></li>\n",
    "    <ul><ul><li><a href=\"#Example-1:-Finding-all-different-nouns-from-the-text\">Example 1: Finding all different nouns from the text</a></li>\n",
    "    <li><a href=\"#Example-2:-Finding-all-sentences-that-contain-an-infinitive-verb\">Example 2: Finding all sentences that contain an infinitive verb</a></li>\n",
    "  </ul></ul><li><a href=\"#-Further-details-\"> Further details </a></li>\n",
    "</ul></ul>\n",
    "\n",
    "Online documentation is best viewed with https://nbviewer.jupyter.org/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:blue\">A Short Introduction and Tutorial</span> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This tutorial gives an overview of how to use EstNLTK for the basic analysis of text: splitting it into linguistically meaningful units - words, sentences, - and performing morphological analysis. These steps are necessary in tackling most language-related problems: if we are able to extract words and sentences from text and filter them by lemmas, part-of-speech tags and morphological forms, we can solve numerous tasks, e.g. automatically find example sentences of different grammatical constructions from large corpora, compose word/lemma frequency lists, compare texts in terms of sentence lengths/structures, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The most important class in Estnltk is Text, which is essentally the main interface for doing everything Estnltk is capable of. To use it, we have to import it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from estnltk import Text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To start working on our text, we have to create a new Text class object of it. Let's use a simple sentence  as an example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = Text(\"Müüja tatsas rahulikult külmiku juurde.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td><div align = \"left\">Müüja tatsas rahulikult külmiku juurde.</div></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "Text(text='Müüja tatsas rahulikult külmiku juurde.')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The basic way to use EstNLTK toolchain is to use the tag_layer() method that automatically segments the text and performs morphological analysis. From its output, we can see which layers have been tagged on text, which attributes the layers have and how many elements belong to every layer (column span count). The details about each layer come in Section B."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td><div align = \"left\">Müüja tatsas rahulikult külmiku juurde.</div></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>layer name</th>\n",
       "      <th>attributes</th>\n",
       "      <th>parent</th>\n",
       "      <th>enveloping</th>\n",
       "      <th>ambiguous</th>\n",
       "      <th>span count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>sentences</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>words</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>tokens</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>compound_tokens</td>\n",
       "      <td>type, normalized</td>\n",
       "      <td>None</td>\n",
       "      <td>tokens</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>words</td>\n",
       "      <td>normalized_form</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>morph_analysis</td>\n",
       "      <td>normalized_text, lemma, root, root_tokens, ending, clitic, form, partofspeech</td>\n",
       "      <td>words</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "Text(text='Müüja tatsas rahulikult külmiku juurde.')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text.tag_layer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  <span style=\"color:purple\"> Text segmentation </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One of the most basic tasks of any NLP pipeline is text segmentation: splitting the text into smaller meaningful units - words, sentences, paragraphs, etc. This might seem like a trivial task at first - aren't words separated by spaces and sentences by full stops? And yes, question marks and exclamation marks. However, if we take an existing text, we will see that there are lots of exceptions to these rules. Therefore, EstNLTK has dedicated methods for these kinds of tasks that try to tackle the frequent segmentation issues."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Tokens vs words\n",
    "To make a distinction between properly tagged words (incl. punctuation, abbreviations, e-mail addresses, etc) and elements in text that are separated from each other by whitespace (or not... in case of punctuation), we use the term 'tokens' for the latter. For the most part, tokens overlap with words, but a token might also be a part of a word: in later analysis, tokens are not broken into any smaller parts, but only joined if necessary. If we look at our first example above, we can see that the number of words and tokens is equal. However, there are cases where some tokens are joined into one word:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td><div align = \"left\">Mis aias sa-das 3me sorti s-saia?</div></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>layer name</th>\n",
       "      <th>attributes</th>\n",
       "      <th>parent</th>\n",
       "      <th>enveloping</th>\n",
       "      <th>ambiguous</th>\n",
       "      <th>span count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>sentences</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>words</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>tokens</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>compound_tokens</td>\n",
       "      <td>type, normalized</td>\n",
       "      <td>None</td>\n",
       "      <td>tokens</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>words</td>\n",
       "      <td>normalized_form</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>morph_analysis</td>\n",
       "      <td>normalized_text, lemma, root, root_tokens, ending, clitic, form, partofspeech</td>\n",
       "      <td>words</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "Text(text='Mis aias sa-das 3me sorti s-saia?')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = Text('Mis aias sa-das 3me sorti s-saia?')\n",
    "text.tag_layer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, in this (quite weird) example sentence, there are 11 tokens but 7 words. To see the tokens (or words for that matter) that have been tagged on text using the tag_layer() method, we can either use the Text object as a typical Python dict:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h4>Layer</h4>\n",
       "\n",
       "\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>layer name</th>\n",
       "      <th>attributes</th>\n",
       "      <th>parent</th>\n",
       "      <th>enveloping</th>\n",
       "      <th>ambiguous</th>\n",
       "      <th>span count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>tokens</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_cc5d5\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th id=\"T_cc5d5_level0_col0\" class=\"col_heading level0 col0\" >text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td id=\"T_cc5d5_row0_col0\" class=\"data row0 col0\" >Mis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_cc5d5_row1_col0\" class=\"data row1 col0\" >aias</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_cc5d5_row2_col0\" class=\"data row2 col0\" >sa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_cc5d5_row3_col0\" class=\"data row3 col0\" >-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_cc5d5_row4_col0\" class=\"data row4 col0\" >das</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_cc5d5_row5_col0\" class=\"data row5 col0\" >3me</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_cc5d5_row6_col0\" class=\"data row6 col0\" >sorti</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_cc5d5_row7_col0\" class=\"data row7 col0\" >s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_cc5d5_row8_col0\" class=\"data row8 col0\" >-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_cc5d5_row9_col0\" class=\"data row9 col0\" >saia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_cc5d5_row10_col0\" class=\"data row10 col0\" >?</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "Layer(name='tokens', attributes=(), spans=SL[Span('Mis', [{}]),\n",
       "Span('aias', [{}]),\n",
       "Span('sa', [{}]),\n",
       "Span('-', [{}]),\n",
       "Span('das', [{}]),\n",
       "Span('3me', [{}]),\n",
       "Span('sorti', [{}]),\n",
       "Span('s', [{}]),\n",
       "Span('-', [{}]),\n",
       "Span('saia', [{}]),\n",
       "Span('?', [{}])])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text['tokens']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or, we can use the class variable 'tokens' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h4>Layer</h4>\n",
       "\n",
       "\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>layer name</th>\n",
       "      <th>attributes</th>\n",
       "      <th>parent</th>\n",
       "      <th>enveloping</th>\n",
       "      <th>ambiguous</th>\n",
       "      <th>span count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>tokens</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_63d77\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th id=\"T_63d77_level0_col0\" class=\"col_heading level0 col0\" >text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td id=\"T_63d77_row0_col0\" class=\"data row0 col0\" >Mis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_63d77_row1_col0\" class=\"data row1 col0\" >aias</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_63d77_row2_col0\" class=\"data row2 col0\" >sa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_63d77_row3_col0\" class=\"data row3 col0\" >-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_63d77_row4_col0\" class=\"data row4 col0\" >das</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_63d77_row5_col0\" class=\"data row5 col0\" >3me</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_63d77_row6_col0\" class=\"data row6 col0\" >sorti</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_63d77_row7_col0\" class=\"data row7 col0\" >s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_63d77_row8_col0\" class=\"data row8 col0\" >-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_63d77_row9_col0\" class=\"data row9 col0\" >saia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_63d77_row10_col0\" class=\"data row10 col0\" >?</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "Layer(name='tokens', attributes=(), spans=SL[Span('Mis', [{}]),\n",
       "Span('aias', [{}]),\n",
       "Span('sa', [{}]),\n",
       "Span('-', [{}]),\n",
       "Span('das', [{}]),\n",
       "Span('3me', [{}]),\n",
       "Span('sorti', [{}]),\n",
       "Span('s', [{}]),\n",
       "Span('-', [{}]),\n",
       "Span('saia', [{}]),\n",
       "Span('?', [{}])])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text.tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get words - smallest meaningful units of language - some tokens might need to be combined. That's why there are layers `tokens` and `compound_tokens` which are combined together to create words. This happens when the raw text needs some kind of normalization in order to comply with standard ortography. In addition to the hyphenated words as in the previous example, also some numbers ( _'10 000'_ ), e-mail addresses ( 'example@example.com' ), abbreviations ( _'s.t.'_ ) and other entities that have been tagged as separate tokens have to be joined together.\n",
    "\n",
    "We can see and use `words` layer (and all the other layers) the same way as the `tokens` layer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h4>Layer</h4>\n",
       "\n",
       "\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>layer name</th>\n",
       "      <th>attributes</th>\n",
       "      <th>parent</th>\n",
       "      <th>enveloping</th>\n",
       "      <th>ambiguous</th>\n",
       "      <th>span count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>words</td>\n",
       "      <td>normalized_form</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<style type=\"text/css\">\n",
       "#T_e3de1_row0_col1, #T_e3de1_row1_col1, #T_e3de1_row3_col1, #T_e3de1_row4_col1, #T_e3de1_row6_col1 {\n",
       "  opacity: 20%;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_e3de1\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th id=\"T_e3de1_level0_col0\" class=\"col_heading level0 col0\" >text</th>\n",
       "      <th id=\"T_e3de1_level0_col1\" class=\"col_heading level0 col1\" >normalized_form</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td id=\"T_e3de1_row0_col0\" class=\"data row0 col0\" >Mis</td>\n",
       "      <td id=\"T_e3de1_row0_col1\" class=\"data row0 col1\" >None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_e3de1_row1_col0\" class=\"data row1 col0\" >aias</td>\n",
       "      <td id=\"T_e3de1_row1_col1\" class=\"data row1 col1\" >None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_e3de1_row2_col0\" class=\"data row2 col0\" >sa-das</td>\n",
       "      <td id=\"T_e3de1_row2_col1\" class=\"data row2 col1\" >sadas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_e3de1_row3_col0\" class=\"data row3 col0\" >3me</td>\n",
       "      <td id=\"T_e3de1_row3_col1\" class=\"data row3 col1\" >None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_e3de1_row4_col0\" class=\"data row4 col0\" >sorti</td>\n",
       "      <td id=\"T_e3de1_row4_col1\" class=\"data row4 col1\" >None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_e3de1_row5_col0\" class=\"data row5 col0\" >s-saia</td>\n",
       "      <td id=\"T_e3de1_row5_col1\" class=\"data row5 col1\" >saia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_e3de1_row6_col0\" class=\"data row6 col0\" >?</td>\n",
       "      <td id=\"T_e3de1_row6_col1\" class=\"data row6 col1\" >None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "Layer(name='words', attributes=('normalized_form',), spans=SL[Span('Mis', [{'normalized_form': None}]),\n",
       "Span('aias', [{'normalized_form': None}]),\n",
       "Span('sa-das', [{'normalized_form': 'sadas'}]),\n",
       "Span('3me', [{'normalized_form': None}]),\n",
       "Span('sorti', [{'normalized_form': None}]),\n",
       "Span('s-saia', [{'normalized_form': 'saia'}]),\n",
       "Span('?', [{'normalized_form': None}])])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text.words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A sentence is a list of sequential words and so the sentence layer is a list of lists of words. This means that first, the text is split into words, and then, sentence borders are determined so that no sentence border would end up inside a word. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see an example that has multiple sentences:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = Text('''Ka köögis oli kõik endine: vana elektripliit, koorunud värviga ahjutruup ja vanamehe töövorm — rippumas ikka sealsamas ukse küljes nagis. Jälk. Köögi akna all laual oli vanaaegne arvuti. Juba aastaid. Selline kaasaskantav väike kastike, mille klaviatuur ekraani ette kinnitus. See oli sini-valge pildi ja DOS-opsüsteemiga mänguasi.''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td><div align = \"left\">Ka köögis oli kõik endine: vana elektripliit, koorunud värviga ahjutruup ja vanamehe töövorm — rippumas ikka sealsamas ukse küljes nagis. Jälk. Köögi akna all laual oli vanaaegne arvuti. Juba aastaid. Selline kaasaskantav väike kastike, mille klaviatuur ekraani ette kinnitus. See oli sini-valge pildi ja DOS-opsüsteemiga mänguasi.</div></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>layer name</th>\n",
       "      <th>attributes</th>\n",
       "      <th>parent</th>\n",
       "      <th>enveloping</th>\n",
       "      <th>ambiguous</th>\n",
       "      <th>span count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>sentences</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>words</td>\n",
       "      <td>False</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>tokens</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>compound_tokens</td>\n",
       "      <td>type, normalized</td>\n",
       "      <td>None</td>\n",
       "      <td>tokens</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>words</td>\n",
       "      <td>normalized_form</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>morph_analysis</td>\n",
       "      <td>normalized_text, lemma, root, root_tokens, ending, clitic, form, partofspeech</td>\n",
       "      <td>words</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "Text(text='Ka köögis oli kõik endine: vana elektripliit, koorunud värviga ahjutruup ja vanamehe töövorm — rippumas ikka sealsamas ukse küljes nagis. Jälk. Köögi akna all laual oli vanaaegne arvuti. Juba aastaid. Selline kaasaskantav väike kastike, mille klaviatuur ekraani ette kinnitus. See oli sini-valge pildi ja DOS-opsüsteemiga mänguasi.')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text.tag_layer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see the text split into sentences by using the `sentences` class variable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h4>Layer</h4>\n",
       "\n",
       "\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>layer name</th>\n",
       "      <th>attributes</th>\n",
       "      <th>parent</th>\n",
       "      <th>enveloping</th>\n",
       "      <th>ambiguous</th>\n",
       "      <th>span count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>sentences</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>words</td>\n",
       "      <td>False</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_0f2b8\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th id=\"T_0f2b8_level0_col0\" class=\"col_heading level0 col0\" >text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td id=\"T_0f2b8_row0_col0\" class=\"data row0 col0\" >['Ka', 'köögis', 'oli', 'kõik', 'endine', ':', 'vana', 'elektripliit', ',', 'koo ..., type: <class 'list'>, length: 23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_0f2b8_row1_col0\" class=\"data row1 col0\" >['Jälk', '.']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_0f2b8_row2_col0\" class=\"data row2 col0\" >['Köögi', 'akna', 'all', 'laual', 'oli', 'vanaaegne', 'arvuti', '.']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_0f2b8_row3_col0\" class=\"data row3 col0\" >['Juba', 'aastaid', '.']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_0f2b8_row4_col0\" class=\"data row4 col0\" >['Selline', 'kaasaskantav', 'väike', 'kastike', ',', 'mille', 'klaviatuur', 'ekr ..., type: <class 'list'>, length: 11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_0f2b8_row5_col0\" class=\"data row5 col0\" >['See', 'oli', 'sini-valge', 'pildi', 'ja', 'DOS-opsüsteemiga', 'mänguasi', '.']</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "Layer(name='sentences', attributes=(), spans=SL[EnvelopingSpan(['Ka', 'köögis', 'oli', 'kõik', 'endine', ':', 'vana', 'elektripliit', ',', 'koorunud', 'värviga', 'ahjutruup', 'ja', 'vanamehe', 'töövorm', '—', 'rippumas', 'ikka', 'sealsamas', 'ukse', 'küljes', 'nagis', '.'], [{}]),\n",
       "EnvelopingSpan(['Jälk', '.'], [{}]),\n",
       "EnvelopingSpan(['Köögi', 'akna', 'all', 'laual', 'oli', 'vanaaegne', 'arvuti', '.'], [{}]),\n",
       "EnvelopingSpan(['Juba', 'aastaid', '.'], [{}]),\n",
       "EnvelopingSpan(['Selline', 'kaasaskantav', 'väike', 'kastike', ',', 'mille', 'klaviatuur', 'ekraani', 'ette', 'kinnitus', '.'], [{}]),\n",
       "EnvelopingSpan(['See', 'oli', 'sini-valge', 'pildi', 'ja', 'DOS-opsüsteemiga', 'mänguasi', '.'], [{}])])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text.sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:purple\">Morphological analysis</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In linguistics, morphology is the identification, analysis, and description of the structure of a given language’s morphemes and related linguistic units, such as root words, lemmas, suffixes, parts of speech etc. When we are processing a morphologically rich language - that Estonian certainly is -, getting this kind of information is essential for even the simplest tasks. For example, if we want to find all the mentions of 'maja' from the corpus, we are probably not eager to spell out the 27 different forms that we are interested in ( _'maja'_ , _'majale'_ , _'majadega'_ ...), but we also do not want to get things like _'majandus'_ or _'majakas'_ . If we have morphologically analysed the text, we can just state that we are interested in the lemma _'maja'_ ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Estnltk wraps [Vabamorf's](https://github.com/Filosoft/vabamorf) morphological analyzer. Morphological analysis is also performed with no extra hassle when we use the tag_layer() method on our text. When we look at the text object, we can see that there is the morph_analysis layer and it has several attributes: lemma, root, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = Text(\"Aga kõik juhtus iseenesest.\").tag_layer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td><div align = \"left\">Aga kõik juhtus iseenesest.</div></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>layer name</th>\n",
       "      <th>attributes</th>\n",
       "      <th>parent</th>\n",
       "      <th>enveloping</th>\n",
       "      <th>ambiguous</th>\n",
       "      <th>span count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>sentences</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>words</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>tokens</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>compound_tokens</td>\n",
       "      <td>type, normalized</td>\n",
       "      <td>None</td>\n",
       "      <td>tokens</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>words</td>\n",
       "      <td>normalized_form</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>morph_analysis</td>\n",
       "      <td>normalized_text, lemma, root, root_tokens, ending, clitic, form, partofspeech</td>\n",
       "      <td>words</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "Text(text='Aga kõik juhtus iseenesest.')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Therefore, we can either view the whole analysis as a table:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h4>Layer</h4>\n",
       "\n",
       "\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>layer name</th>\n",
       "      <th>attributes</th>\n",
       "      <th>parent</th>\n",
       "      <th>enveloping</th>\n",
       "      <th>ambiguous</th>\n",
       "      <th>span count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>morph_analysis</td>\n",
       "      <td>normalized_text, lemma, root, root_tokens, ending, clitic, form, partofspeech</td>\n",
       "      <td>words</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_97f43\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th id=\"T_97f43_level0_col0\" class=\"col_heading level0 col0\" >text</th>\n",
       "      <th id=\"T_97f43_level0_col1\" class=\"col_heading level0 col1\" >normalized_text</th>\n",
       "      <th id=\"T_97f43_level0_col2\" class=\"col_heading level0 col2\" >lemma</th>\n",
       "      <th id=\"T_97f43_level0_col3\" class=\"col_heading level0 col3\" >root</th>\n",
       "      <th id=\"T_97f43_level0_col4\" class=\"col_heading level0 col4\" >root_tokens</th>\n",
       "      <th id=\"T_97f43_level0_col5\" class=\"col_heading level0 col5\" >ending</th>\n",
       "      <th id=\"T_97f43_level0_col6\" class=\"col_heading level0 col6\" >clitic</th>\n",
       "      <th id=\"T_97f43_level0_col7\" class=\"col_heading level0 col7\" >form</th>\n",
       "      <th id=\"T_97f43_level0_col8\" class=\"col_heading level0 col8\" >partofspeech</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td id=\"T_97f43_row0_col0\" class=\"data row0 col0\" >Aga</td>\n",
       "      <td id=\"T_97f43_row0_col1\" class=\"data row0 col1\" >Aga</td>\n",
       "      <td id=\"T_97f43_row0_col2\" class=\"data row0 col2\" >aga</td>\n",
       "      <td id=\"T_97f43_row0_col3\" class=\"data row0 col3\" >aga</td>\n",
       "      <td id=\"T_97f43_row0_col4\" class=\"data row0 col4\" >['aga']</td>\n",
       "      <td id=\"T_97f43_row0_col5\" class=\"data row0 col5\" >0</td>\n",
       "      <td id=\"T_97f43_row0_col6\" class=\"data row0 col6\" ></td>\n",
       "      <td id=\"T_97f43_row0_col7\" class=\"data row0 col7\" ></td>\n",
       "      <td id=\"T_97f43_row0_col8\" class=\"data row0 col8\" >J</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_97f43_row1_col0\" class=\"data row1 col0\" >kõik</td>\n",
       "      <td id=\"T_97f43_row1_col1\" class=\"data row1 col1\" >kõik</td>\n",
       "      <td id=\"T_97f43_row1_col2\" class=\"data row1 col2\" >kõik</td>\n",
       "      <td id=\"T_97f43_row1_col3\" class=\"data row1 col3\" >kõik</td>\n",
       "      <td id=\"T_97f43_row1_col4\" class=\"data row1 col4\" >['kõik']</td>\n",
       "      <td id=\"T_97f43_row1_col5\" class=\"data row1 col5\" >0</td>\n",
       "      <td id=\"T_97f43_row1_col6\" class=\"data row1 col6\" ></td>\n",
       "      <td id=\"T_97f43_row1_col7\" class=\"data row1 col7\" >pl n</td>\n",
       "      <td id=\"T_97f43_row1_col8\" class=\"data row1 col8\" >P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_97f43_row2_col0\" class=\"data row2 col0\" ></td>\n",
       "      <td id=\"T_97f43_row2_col1\" class=\"data row2 col1\" >kõik</td>\n",
       "      <td id=\"T_97f43_row2_col2\" class=\"data row2 col2\" >kõik</td>\n",
       "      <td id=\"T_97f43_row2_col3\" class=\"data row2 col3\" >kõik</td>\n",
       "      <td id=\"T_97f43_row2_col4\" class=\"data row2 col4\" >['kõik']</td>\n",
       "      <td id=\"T_97f43_row2_col5\" class=\"data row2 col5\" >0</td>\n",
       "      <td id=\"T_97f43_row2_col6\" class=\"data row2 col6\" ></td>\n",
       "      <td id=\"T_97f43_row2_col7\" class=\"data row2 col7\" >sg n</td>\n",
       "      <td id=\"T_97f43_row2_col8\" class=\"data row2 col8\" >P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_97f43_row3_col0\" class=\"data row3 col0\" >juhtus</td>\n",
       "      <td id=\"T_97f43_row3_col1\" class=\"data row3 col1\" >juhtus</td>\n",
       "      <td id=\"T_97f43_row3_col2\" class=\"data row3 col2\" >juhtuma</td>\n",
       "      <td id=\"T_97f43_row3_col3\" class=\"data row3 col3\" >juhtu</td>\n",
       "      <td id=\"T_97f43_row3_col4\" class=\"data row3 col4\" >['juhtu']</td>\n",
       "      <td id=\"T_97f43_row3_col5\" class=\"data row3 col5\" >s</td>\n",
       "      <td id=\"T_97f43_row3_col6\" class=\"data row3 col6\" ></td>\n",
       "      <td id=\"T_97f43_row3_col7\" class=\"data row3 col7\" >s</td>\n",
       "      <td id=\"T_97f43_row3_col8\" class=\"data row3 col8\" >V</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_97f43_row4_col0\" class=\"data row4 col0\" >iseenesest</td>\n",
       "      <td id=\"T_97f43_row4_col1\" class=\"data row4 col1\" >iseenesest</td>\n",
       "      <td id=\"T_97f43_row4_col2\" class=\"data row4 col2\" >iseenesest</td>\n",
       "      <td id=\"T_97f43_row4_col3\" class=\"data row4 col3\" >ise_enesest</td>\n",
       "      <td id=\"T_97f43_row4_col4\" class=\"data row4 col4\" >['ise', 'enesest']</td>\n",
       "      <td id=\"T_97f43_row4_col5\" class=\"data row4 col5\" >0</td>\n",
       "      <td id=\"T_97f43_row4_col6\" class=\"data row4 col6\" ></td>\n",
       "      <td id=\"T_97f43_row4_col7\" class=\"data row4 col7\" ></td>\n",
       "      <td id=\"T_97f43_row4_col8\" class=\"data row4 col8\" >D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_97f43_row5_col0\" class=\"data row5 col0\" >.</td>\n",
       "      <td id=\"T_97f43_row5_col1\" class=\"data row5 col1\" >.</td>\n",
       "      <td id=\"T_97f43_row5_col2\" class=\"data row5 col2\" >.</td>\n",
       "      <td id=\"T_97f43_row5_col3\" class=\"data row5 col3\" >.</td>\n",
       "      <td id=\"T_97f43_row5_col4\" class=\"data row5 col4\" >['.']</td>\n",
       "      <td id=\"T_97f43_row5_col5\" class=\"data row5 col5\" ></td>\n",
       "      <td id=\"T_97f43_row5_col6\" class=\"data row5 col6\" ></td>\n",
       "      <td id=\"T_97f43_row5_col7\" class=\"data row5 col7\" ></td>\n",
       "      <td id=\"T_97f43_row5_col8\" class=\"data row5 col8\" >Z</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "Layer(name='morph_analysis', attributes=('normalized_text', 'lemma', 'root', 'root_tokens', 'ending', 'clitic', 'form', 'partofspeech'), spans=SL[Span('Aga', [{'normalized_text': 'Aga', 'lemma': 'aga', 'root': 'aga', 'root_tokens': ['aga'], 'ending': '0', 'clitic': '', 'form': '', 'partofspeech': 'J'}]),\n",
       "Span('kõik', [{'normalized_text': 'kõik', 'lemma': 'kõik', 'root': 'kõik', 'root_tokens': ['kõik'], 'ending': '0', 'clitic': '', 'form': 'pl n', 'partofspeech': 'P'}, {'normalized_text': 'kõik', 'lemma': 'kõik', 'root': 'kõik', 'root_tokens': ['kõik'], 'ending': '0', 'clitic': '', 'form': 'sg n', 'partofspeech': 'P'}]),\n",
       "Span('juhtus', [{'normalized_text': 'juhtus', 'lemma': 'juhtuma', 'root': 'juhtu', 'root_tokens': ['juhtu'], 'ending': 's', 'clitic': '', 'form': 's', 'partofspeech': 'V'}]),\n",
       "Span('iseenesest', [{'normalized_text': 'iseenesest', 'lemma': 'iseenesest', 'root': 'ise_enesest', 'root_tokens': ['ise', 'enesest'], 'ending': '0', 'clitic': '', 'form': '', 'partofspeech': 'D'}]),\n",
       "Span('.', [{'normalized_text': '.', 'lemma': '.', 'root': '.', 'root_tokens': ['.'], 'ending': '', 'clitic': '', 'form': '', 'partofspeech': 'Z'}])])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text['morph_analysis']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For explanations of categories used in `partofspeech` and `form` attributes, please see: [tables_of_morphological_categories.ipynb](../nlp_pipeline/B_morphology/00_tables_of_morphological_categories.ipynb)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also convert morphological analysis category names to Estonian:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h4>Layer</h4>\n",
       "\n",
       "\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>layer name</th>\n",
       "      <th>attributes</th>\n",
       "      <th>parent</th>\n",
       "      <th>enveloping</th>\n",
       "      <th>ambiguous</th>\n",
       "      <th>span count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>morph_analysis_est</td>\n",
       "      <td>normaliseeritud_sõne, algvorm, lõpp, sõnaliik, vormi_nimetus, kliitik</td>\n",
       "      <td>morph_analysis</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_df7ad\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th id=\"T_df7ad_level0_col0\" class=\"col_heading level0 col0\" >text</th>\n",
       "      <th id=\"T_df7ad_level0_col1\" class=\"col_heading level0 col1\" >normaliseeritud_sõne</th>\n",
       "      <th id=\"T_df7ad_level0_col2\" class=\"col_heading level0 col2\" >algvorm</th>\n",
       "      <th id=\"T_df7ad_level0_col3\" class=\"col_heading level0 col3\" >lõpp</th>\n",
       "      <th id=\"T_df7ad_level0_col4\" class=\"col_heading level0 col4\" >sõnaliik</th>\n",
       "      <th id=\"T_df7ad_level0_col5\" class=\"col_heading level0 col5\" >vormi_nimetus</th>\n",
       "      <th id=\"T_df7ad_level0_col6\" class=\"col_heading level0 col6\" >kliitik</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td id=\"T_df7ad_row0_col0\" class=\"data row0 col0\" >Aga</td>\n",
       "      <td id=\"T_df7ad_row0_col1\" class=\"data row0 col1\" >Aga</td>\n",
       "      <td id=\"T_df7ad_row0_col2\" class=\"data row0 col2\" >aga</td>\n",
       "      <td id=\"T_df7ad_row0_col3\" class=\"data row0 col3\" >0</td>\n",
       "      <td id=\"T_df7ad_row0_col4\" class=\"data row0 col4\" >sidesõna</td>\n",
       "      <td id=\"T_df7ad_row0_col5\" class=\"data row0 col5\" ></td>\n",
       "      <td id=\"T_df7ad_row0_col6\" class=\"data row0 col6\" ></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_df7ad_row1_col0\" class=\"data row1 col0\" >kõik</td>\n",
       "      <td id=\"T_df7ad_row1_col1\" class=\"data row1 col1\" >kõik</td>\n",
       "      <td id=\"T_df7ad_row1_col2\" class=\"data row1 col2\" >kõik</td>\n",
       "      <td id=\"T_df7ad_row1_col3\" class=\"data row1 col3\" >0</td>\n",
       "      <td id=\"T_df7ad_row1_col4\" class=\"data row1 col4\" >asesõna</td>\n",
       "      <td id=\"T_df7ad_row1_col5\" class=\"data row1 col5\" >mitmus nimetav (nominatiiv)</td>\n",
       "      <td id=\"T_df7ad_row1_col6\" class=\"data row1 col6\" ></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_df7ad_row2_col0\" class=\"data row2 col0\" ></td>\n",
       "      <td id=\"T_df7ad_row2_col1\" class=\"data row2 col1\" >kõik</td>\n",
       "      <td id=\"T_df7ad_row2_col2\" class=\"data row2 col2\" >kõik</td>\n",
       "      <td id=\"T_df7ad_row2_col3\" class=\"data row2 col3\" >0</td>\n",
       "      <td id=\"T_df7ad_row2_col4\" class=\"data row2 col4\" >asesõna</td>\n",
       "      <td id=\"T_df7ad_row2_col5\" class=\"data row2 col5\" >ainsus nimetav (nominatiiv)</td>\n",
       "      <td id=\"T_df7ad_row2_col6\" class=\"data row2 col6\" ></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_df7ad_row3_col0\" class=\"data row3 col0\" >juhtus</td>\n",
       "      <td id=\"T_df7ad_row3_col1\" class=\"data row3 col1\" >juhtus</td>\n",
       "      <td id=\"T_df7ad_row3_col2\" class=\"data row3 col2\" >juhtuma</td>\n",
       "      <td id=\"T_df7ad_row3_col3\" class=\"data row3 col3\" >s</td>\n",
       "      <td id=\"T_df7ad_row3_col4\" class=\"data row3 col4\" >tegusõna</td>\n",
       "      <td id=\"T_df7ad_row3_col5\" class=\"data row3 col5\" >kindel kõneviis lihtminevik 3. isik ainsus aktiiv jaatav kõne</td>\n",
       "      <td id=\"T_df7ad_row3_col6\" class=\"data row3 col6\" ></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_df7ad_row4_col0\" class=\"data row4 col0\" >iseenesest</td>\n",
       "      <td id=\"T_df7ad_row4_col1\" class=\"data row4 col1\" >iseenesest</td>\n",
       "      <td id=\"T_df7ad_row4_col2\" class=\"data row4 col2\" >iseenesest</td>\n",
       "      <td id=\"T_df7ad_row4_col3\" class=\"data row4 col3\" >0</td>\n",
       "      <td id=\"T_df7ad_row4_col4\" class=\"data row4 col4\" >määrsõna</td>\n",
       "      <td id=\"T_df7ad_row4_col5\" class=\"data row4 col5\" ></td>\n",
       "      <td id=\"T_df7ad_row4_col6\" class=\"data row4 col6\" ></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_df7ad_row5_col0\" class=\"data row5 col0\" >.</td>\n",
       "      <td id=\"T_df7ad_row5_col1\" class=\"data row5 col1\" >.</td>\n",
       "      <td id=\"T_df7ad_row5_col2\" class=\"data row5 col2\" >.</td>\n",
       "      <td id=\"T_df7ad_row5_col3\" class=\"data row5 col3\" ></td>\n",
       "      <td id=\"T_df7ad_row5_col4\" class=\"data row5 col4\" >lausemärk</td>\n",
       "      <td id=\"T_df7ad_row5_col5\" class=\"data row5 col5\" ></td>\n",
       "      <td id=\"T_df7ad_row5_col6\" class=\"data row5 col6\" ></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "Layer(name='morph_analysis_est', attributes=('normaliseeritud_sõne', 'algvorm', 'lõpp', 'sõnaliik', 'vormi_nimetus', 'kliitik'), spans=SL[Span('Aga', [{'normaliseeritud_sõne': 'Aga', 'algvorm': 'aga', 'lõpp': '0', 'sõnaliik': 'sidesõna', 'vormi_nimetus': '', 'kliitik': ''}]),\n",
       "Span('kõik', [{'normaliseeritud_sõne': 'kõik', 'algvorm': 'kõik', 'lõpp': '0', 'sõnaliik': 'asesõna', 'vormi_nimetus': 'mitmus nimetav (nominatiiv)', 'kliitik': ''}, {'normaliseeritud_sõne': 'kõik', 'algvorm': 'kõik', 'lõpp': '0', 'sõnaliik': 'asesõna', 'vormi_nimetus': 'ainsus nimetav (nominatiiv)', 'kliitik': ''}]),\n",
       "Span('juhtus', [{'normaliseeritud_sõne': 'juhtus', 'algvorm': 'juhtuma', 'lõpp': 's', 'sõnaliik': 'tegusõna', 'vormi_nimetus': 'kindel kõneviis lihtminevik 3. isik ainsus aktiiv jaatav kõne', 'kliitik': ''}]),\n",
       "Span('iseenesest', [{'normaliseeritud_sõne': 'iseenesest', 'algvorm': 'iseenesest', 'lõpp': '0', 'sõnaliik': 'määrsõna', 'vormi_nimetus': '', 'kliitik': ''}]),\n",
       "Span('.', [{'normaliseeritud_sõne': '.', 'algvorm': '.', 'lõpp': '', 'sõnaliik': 'lausemärk', 'vormi_nimetus': '', 'kliitik': ''}])])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add a morph layer that has Estonian category names\n",
    "text.tag_layer(['morph_analysis_est'])\n",
    "\n",
    "# Browse the layer\n",
    "text['morph_analysis_est']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, please note that the layer `'morph_analysis_est'` is provided only for educational purposes, and it is not standard in EstNLTK. \n",
    "All the tools building upon morphological analysis are using the layer `'morph_analysis'` .\n",
    "In the following examples, we will also continue with the standard layer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accessing details of the morphological analysis "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`text['morph_analysis']` and `text.morph_analysis` give us the whole layer of morphological analyses. \n",
    "If we are only interested in specific details, e.g. in partofspeechtags or lemmas, we can use attributes to access them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h4>AmbiguousAttributeList (spans)</h4>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>partofspeech</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>J</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td></td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>V</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Z</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "AmbiguousAttributeList([['J'], ['P', 'P'], ['V'], ['D'], ['Z']], ('partofspeech',))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text.partofspeech"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h4>AmbiguousAttributeList (spans)</h4>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lemma</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>aga</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>kõik</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td></td>\n",
       "      <td>kõik</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>juhtuma</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>iseenesest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "AmbiguousAttributeList([['aga'], ['kõik', 'kõik'], ['juhtuma'], ['iseenesest'], ['.']], ('lemma',))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text.lemma"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Resulting `AmbiguousAttributeList` can also be converted to a list:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['aga'], ['kõik', 'kõik'], ['juhtuma'], ['iseenesest'], ['.']]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(text.lemma)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using indexing on `text.morph_analysis`, we can take out analyses of specific words.\n",
    "For instance, let's take out the 2nd word and its lemmas and forms:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "word: kõik\n",
      "lemmas: ['kõik', 'kõik']\n",
      "forms: ['pl n', 'sg n']\n"
     ]
    }
   ],
   "source": [
    "print('word:',   text.morph_analysis[1].text)\n",
    "print('lemmas:', text.morph_analysis[1].lemma)\n",
    "print('forms:',  text.morph_analysis[1].form)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('kõik', 'pl n'), ('kõik', 'sg n')]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# or use zip to combine lemmas and forms of the 2nd word\n",
    "list( zip(text.morph_analysis[1].lemma, text.morph_analysis[1].form) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because 'words' is parent of 'morph_analysis' layer, we can also access analyses through words:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h4>AmbiguousAttributeList (spans)</h4>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lemma</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>aga</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>kõik</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td></td>\n",
       "      <td>kõik</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>juhtuma</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>iseenesest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "AmbiguousAttributeList([['aga'], ['kõik', 'kõik'], ['juhtuma'], ['iseenesest'], ['.']], ('lemma',))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lemmas of all words\n",
    "text.words.lemma"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Taking full advantage of the relations between layers, we can iterate over sentences of `Text`, and then access morphological analyses from words of the sentences:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = Text(\"Olin nägin vaatasin. Ja väga hea oli.\").tag_layer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Sentence:  Olin nägin vaatasin.\n",
      "olema V\n",
      "nägema V\n",
      "vaatama V\n",
      ". Z\n",
      "\n",
      " Sentence:  Ja väga hea oli.\n",
      "ja J\n",
      "väga D\n",
      "hea A\n",
      "olema V\n",
      ". Z\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for sentence in text.sentences:\n",
    "    print(' Sentence: ', sentence.enclosing_text)\n",
    "    for word in sentence:\n",
    "        # Output first lemma and partofspeech of the word\n",
    "        print( word.morph_analysis.lemma[0], word.morph_analysis.partofspeech[0] )\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameters of morphological analysis: disambiguation, guessing..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By default, EstNLTK performs morphological analysis with disambiguation (giving out the analysis that is correct in the context), guessing (if the word is not in the dictionary and cannot be resolved as a compound, it is given a 'guessed' analysis) and proper name analysis. While this kind of output is easy to use because each word has been given an analysis and most words receive only one analysis,  sometimes we want to use the analyser differently. If we want to enhance the recall of the morphological analysis, we can switch off the disambiguation (which, of course, also affects precision). We can also switch off guessing and proper name analysis e.g to verify whether a word exists in Estonian or not. And finally, if we switch on the text-based disambiguation, we will likely get better disambiguation results (especially on proper names), although this may not work on every corpora (e.g. usually works well on news articles, but be careful when applying this on the Internet language)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To change the parameters of morphological analyser, we can use a resolver. \n",
    "Resolver contains information about how to create a layer: what dependency layers are required, and what is the tagger responsible for creating the layer.\n",
    "\n",
    "You can access the default resolver via `layer_resolver` attribute of `Text`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h4>LayerResolver</h4>\n",
       "<br>Default layers: <b>morph_analysis, sentences</b>\n",
       "</br><h4>TaggersRegistry</h4>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>layer</th>\n",
       "      <th>depends_on</th>\n",
       "      <th>tagger_name</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>tokens</td>\n",
       "      <td>[]</td>\n",
       "      <td>TokensTagger</td>\n",
       "      <td>Preprocessing for word segmentation: segments text into tokens.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>compound_tokens</td>\n",
       "      <td>[tokens]</td>\n",
       "      <td>CompoundTokenTagger</td>\n",
       "      <td>Preprocessing for word segmentation: joins tokens into compound tokens.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>words</td>\n",
       "      <td>[tokens, compound_tokens]</td>\n",
       "      <td>WordTagger</td>\n",
       "      <td>Segments text into words.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>sentences</td>\n",
       "      <td>[compound_tokens, words]</td>\n",
       "      <td>SentenceTokenizer</td>\n",
       "      <td>Segments text into sentences.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>paragraphs</td>\n",
       "      <td>[sentences]</td>\n",
       "      <td>ParagraphTokenizer</td>\n",
       "      <td>Segments text into paragraphs.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>morph_analysis</td>\n",
       "      <td>[compound_tokens, words, sentences]</td>\n",
       "      <td>VabamorfTagger</td>\n",
       "      <td>Tags morphological analysis with Vabamorf.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>clauses</td>\n",
       "      <td>[words, sentences, morph_analysis]</td>\n",
       "      <td>ClauseSegmenter</td>\n",
       "      <td>Segments sentences into clauses. (requires Java)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>morph_analysis_est</td>\n",
       "      <td>[morph_analysis]</td>\n",
       "      <td>VabamorfEstCatConverter</td>\n",
       "      <td>Translates category names of Vabamorf's morphological analyses into Estonian (for educational purposes).</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>morph_extended</td>\n",
       "      <td>[morph_analysis]</td>\n",
       "      <td>MorphExtendedTagger</td>\n",
       "      <td>Converts Vabamorf's morphological analyses to syntax preprocessing (CG3) format.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>gt_morph_analysis</td>\n",
       "      <td>[words, sentences, morph_analysis, clauses]</td>\n",
       "      <td>GTMorphConverter</td>\n",
       "      <td>Converts Vabamorf's morphological analyses to giellatekno's (GT) format.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>ner</td>\n",
       "      <td>[morph_analysis, words, sentences]</td>\n",
       "      <td>NerTagger</td>\n",
       "      <td>Detects named entities: person, location and organization names.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>timexes</td>\n",
       "      <td>[]</td>\n",
       "      <td>TimexTagger</td>\n",
       "      <td>Detects temporal expressions and normalizes to corresponding dates, times, durations and recurrences. (requires Java)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>address_parts</td>\n",
       "      <td>[words]</td>\n",
       "      <td>AddressPartTagger</td>\n",
       "      <td>Preprocessing for address detection.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>addresses</td>\n",
       "      <td>[address_parts]</td>\n",
       "      <td>AddressGrammarTagger</td>\n",
       "      <td>Detects addresses.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>maltparser_conll_morph</td>\n",
       "      <td>[sentences, morph_analysis]</td>\n",
       "      <td>ConllMorphTagger</td>\n",
       "      <td>Preprocessing for MaltParser based syntactic analysis.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>maltparser_syntax</td>\n",
       "      <td>[words, sentences, maltparser_conll_morph]</td>\n",
       "      <td>MaltParserTagger</td>\n",
       "      <td>Tags dependency syntactic analysis with MaltParser. (requires Java)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>verb_chains</td>\n",
       "      <td>[words, sentences, morph_analysis, clauses]</td>\n",
       "      <td>VerbChainDetector</td>\n",
       "      <td>Tags main verbs and their extensions (verb chains) in clauses. (experimental)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>np_chunks</td>\n",
       "      <td>[words, sentences, morph_analysis, maltparser_syntax]</td>\n",
       "      <td>NounPhraseChunker</td>\n",
       "      <td>Tags noun phrase chunks in sentences. (experimental)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "LayerResolver(default_layers=['morph_analysis', 'sentences'])\n",
       "TaggersRegistry\n",
       "layer               depends_on                    tagger_name          description                   \n",
       "=====               ==========                    ===========          ===========                   \n",
       "\n",
       "tokens              []                            TokensTagger         Preprocessing for word        \n",
       "                                                                       segmentation: segments text   \n",
       "                                                                       into tokens.                  \n",
       "\n",
       "compound_tokens     ['tokens']                    CompoundTokenTagger  Preprocessing for word        \n",
       "                                                                       segmentation: joins tokens    \n",
       "                                                                       into compound tokens.         \n",
       "\n",
       "words               ['tokens',                    WordTagger           Segments text into words.     \n",
       "                    'compound_tokens']                                                               \n",
       "\n",
       "sentences           ['compound_tokens', 'words']  SentenceTokenizer    Segments text into            \n",
       "                                                                       sentences.                    \n",
       "\n",
       "paragraphs          ['sentences']                 ParagraphTokenizer   Segments text into            \n",
       "                                                                       paragraphs.                   \n",
       "\n",
       "morph_analysis      ['compound_tokens', 'words',  VabamorfTagger       Tags morphological analysis   \n",
       "                    'sentences']                                       with Vabamorf.                \n",
       "\n",
       "clauses             ['words', 'sentences',        ClauseSegmenter      Segments sentences into       \n",
       "                    'morph_analysis']                                  clauses. (requires Java)      \n",
       "\n",
       "morph_analysis_est  ['morph_analysis']            VabamorfEstCatConve  Translates category names of  \n",
       "                                                  rter                 Vabamorf's morphological      \n",
       "                                                                       analyses into Estonian (for   \n",
       "                                                                       educational purposes).        \n",
       "\n",
       "morph_extended      ['morph_analysis']            MorphExtendedTagger  Converts Vabamorf's           \n",
       "                                                                       morphological analyses to     \n",
       "                                                                       syntax preprocessing (CG3)    \n",
       "                                                                       format.                       \n",
       "\n",
       "gt_morph_analysis   ['words', 'sentences',        GTMorphConverter     Converts Vabamorf's           \n",
       "                    'morph_analysis', 'clauses']                       morphological analyses to     \n",
       "                                                                       giellatekno's (GT) format.    \n",
       "\n",
       "ner                 ['morph_analysis', 'words',   NerTagger            Detects named entities:       \n",
       "                    'sentences']                                       person, location and          \n",
       "                                                                       organization names.           \n",
       "\n",
       "timexes             []                            TimexTagger          Detects temporal expressions  \n",
       "                                                                       and normalizes to             \n",
       "                                                                       corresponding dates, times,   \n",
       "                                                                       durations and recurrences.    \n",
       "                                                                       (requires Java)               \n",
       "\n",
       "address_parts       ['words']                     AddressPartTagger    Preprocessing for address     \n",
       "                                                                       detection.                    \n",
       "\n",
       "addresses           ['address_parts']             AddressGrammarTagge  Detects addresses.            \n",
       "                                                  r                                                  \n",
       "\n",
       "maltparser_conll_m  ['sentences',                 ConllMorphTagger     Preprocessing for MaltParser  \n",
       "orph                'morph_analysis']                                  based syntactic analysis.     \n",
       "\n",
       "maltparser_syntax   ['words', 'sentences',        MaltParserTagger     Tags dependency syntactic     \n",
       "                    'maltparser_conll_morph']                          analysis with MaltParser.     \n",
       "                                                                       (requires Java)               \n",
       "\n",
       "verb_chains         ['words', 'sentences',        VerbChainDetector    Tags main verbs and their     \n",
       "                    'morph_analysis', 'clauses']                       extensions (verb chains) in   \n",
       "                                                                       clauses. (experimental)       \n",
       "\n",
       "np_chunks           ['words', 'sentences',        NounPhraseChunker    Tags noun phrase chunks in    \n",
       "                    'morph_analysis',                                  sentences. (experimental)     \n",
       "                    'maltparser_syntax']                                                             \n"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Text.layer_resolver"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Resolver has method `get_tagger`, which returns the tagger responsible for creating the given layer. \n",
    "We can use it to check the default parameters of morph_analysis:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h4>Tagger</h4>\n",
       "Tags morphological analysis on words. Uses Vabamorf's analyzer and disambiguator.\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>name</th>\n",
       "      <th>output layer</th>\n",
       "      <th>output attributes</th>\n",
       "      <th>input layers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>VabamorfTagger</td>\n",
       "      <td>morph_analysis</td>\n",
       "      <td>('normalized_text', 'lemma', 'root', 'root_tokens', 'ending', 'clitic', 'form', 'partofspeech')</td>\n",
       "      <td>('words', 'sentences', 'compound_tokens')</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<h4>Configuration</h4>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>guess</th>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>propername</th>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>disambiguate</th>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>compound</th>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>phonetic</th>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stem</th>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>slang_lex</th>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>postanalysis_tagger</th>\n",
       "      <td>PostMorphAnalysisTagger(('compound_tokens', 'words', 'morph_analysis')-&gt;morph_analysis)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>use_postanalysis</th>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>analysis_reorderer</th>\n",
       "      <td>MorphAnalysisReorderer(('morph_analysis',)-&gt;morph_analysis)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>use_reorderer</th>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>textbased_disambiguator</th>\n",
       "      <td>CorpusBasedMorphDisambiguator(['words', 'sentences', 'morph_analysis']*-&gt;morph_analysis*)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>predisambiguate</th>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>postdisambiguate</th>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "VabamorfTagger(input_layers=('words', 'sentences', 'compound_tokens'), output_layer=morph_analysis, output_attributes=('normalized_text', 'lemma', 'root', 'root_tokens', 'ending', 'clitic', 'form', 'partofspeech'), guess=True, propername=True, disambiguate=True, compound=True, phonetic=False, stem=False, slang_lex=False, postanalysis_tagger=PostMorphAnalysisTagger(('compound_tokens', 'words', 'morph_analysis')->morph_analysis), use_postanalysis=True, analysis_reorderer=MorphAnalysisReorderer(('morph_analysis',)->morph_analysis), use_reorderer=True, textbased_disambiguator=CorpusBasedMorphDisambiguator(['words', 'sentences', 'morph_analysis']*->morph_analysis*), predisambiguate=False, postdisambiguate=False)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Text.layer_resolver.get_tagger('morph_analysis')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Basic configuration parameters are:\n",
    "\n",
    "* `guess` -- if a word is not in the dictionary and cannot be resolved as a compound, then it's analyses will be guessed;\n",
    "* `propername` -- titlecase words will receive additional guesses for propername analyses;\n",
    "* `disambiguate` -- if there are multiple possible analyses for a word, then only analyses fitting to the context will be picked out. This leaves you only one analysis per word for most words;\n",
    "* `compound` -- roots in analyses will have compound word markers. Normally, you wouldn't need to change this parameter;\n",
    "* `phonetic` -- roots in analyses will have phonetic markers. Normally, you wouldn't need to change this parameter;\n",
    "* `stem` -- roots in analyses will be stems, not lemmas, and there will be _no lemmas_ in the output. For example, verb _'läks'_ will obtain root _'läk'_ (with ending _'s'_) and noun _'vette'_ will obtain root _'ve'_ (with ending _'tt'_). Be very careful with changing this parameter, because most of the downstream taggers (such as named entity recognition and syntactic parsing) _do not work with stem-based morphological analysis_. \n",
    "\n",
    "Other parameters are related to components which enhance the quality of morphological analysis:\n",
    "\n",
    "* Parameter `slang_lex` switches on an extended version of Vabamorf's lexicon, which contains extra entries for analysing most common spoken and slang words, such as _'muideks'_ , _'kodukas'_ , _'mõnsa'_ , _'mersu'_ , _'kippelt'_ .\n",
    "\n",
    "\n",
    "* Parameter `postanalysis_tagger` refers to an internal component of `VabamorfTagger`, which makes post-corrections to morphological analyses. Details are covered in the tutorial [01_morphological_analysis.ipynb](../nlp_pipeline/B_morphology/01_morphological_analysis.ipynb). The component can be enabled/disabled by the flag `use_postanalysis`. \n",
    "\n",
    "\n",
    "* Parameter `analysis_reorderer` refers to an internal component, which re-orders ambiguous analyses by their corpus frequency (based on [Estonian UD corpus](https://github.com/estnltk/estnltk-model-training/tree/main/ud_morph_tools/amb_morph_reordering)). The reordering is applied as a last step, after the disambiguation. Details are covered in the tutorial [03_morph_analysis_reordering.ipynb](../nlp_pipeline/B_morphology/03_morph_analysis_reordering.ipynb). The component can be enabled/disabled by the flag `use_reorderer`. \n",
    "\n",
    "\n",
    "* Parameter `textbased_disambiguator` refers to an internal component, which analyses ambiguities in the whole text in order to make advanced disambiguation decisions. It consists of two sub-steps. First, pre-disambiguation of ambiguous proper name analyses applied before the standard disambiguation (flag `predisambiguate`). Second, post-disambiguation of remaining ambiguous analyses applied after the standard disambiguation (flag `postdisambiguate`). Details are in the tutorial [04_morph_analysis_with_corpus-based_disambiguation.ipynb](../nlp_pipeline/B_morphology/04_morph_analysis_with_corpus-based_disambiguation.ipynb)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The configuration tells us that by default, disambiguation, proper name analysis, compound word analysis, and guessing are all applied during morphological analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A special function `make_resolver` can be used to create a new instance of the default resolver. \n",
    "This function also accepts the configuration parameters of morpohological analysis, so you can create a resolver that has different morpohological analysis settings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from estnltk.default_resolver import make_resolver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a new resolver with different morph_analysis settings\n",
    "resolver = make_resolver(\n",
    "                 disambiguate=True,\n",
    "                 guess=True,\n",
    "                 propername=True,\n",
    "                 phonetic=False,\n",
    "                 compound=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the new resolver, we can write an equivalent code to\n",
    "```python\n",
    "text.tag_layer()\n",
    "```\n",
    "as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = Text(\"Kärbes hulbib mees ja naeris puhub sädelevaid mulle.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h4>Layer</h4>\n",
       "\n",
       "\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>layer name</th>\n",
       "      <th>attributes</th>\n",
       "      <th>parent</th>\n",
       "      <th>enveloping</th>\n",
       "      <th>ambiguous</th>\n",
       "      <th>span count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>morph_analysis</td>\n",
       "      <td>normalized_text, lemma, root, root_tokens, ending, clitic, form, partofspeech</td>\n",
       "      <td>words</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_99911\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th id=\"T_99911_level0_col0\" class=\"col_heading level0 col0\" >text</th>\n",
       "      <th id=\"T_99911_level0_col1\" class=\"col_heading level0 col1\" >normalized_text</th>\n",
       "      <th id=\"T_99911_level0_col2\" class=\"col_heading level0 col2\" >lemma</th>\n",
       "      <th id=\"T_99911_level0_col3\" class=\"col_heading level0 col3\" >root</th>\n",
       "      <th id=\"T_99911_level0_col4\" class=\"col_heading level0 col4\" >root_tokens</th>\n",
       "      <th id=\"T_99911_level0_col5\" class=\"col_heading level0 col5\" >ending</th>\n",
       "      <th id=\"T_99911_level0_col6\" class=\"col_heading level0 col6\" >clitic</th>\n",
       "      <th id=\"T_99911_level0_col7\" class=\"col_heading level0 col7\" >form</th>\n",
       "      <th id=\"T_99911_level0_col8\" class=\"col_heading level0 col8\" >partofspeech</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td id=\"T_99911_row0_col0\" class=\"data row0 col0\" >Kärbes</td>\n",
       "      <td id=\"T_99911_row0_col1\" class=\"data row0 col1\" >Kärbes</td>\n",
       "      <td id=\"T_99911_row0_col2\" class=\"data row0 col2\" >kärbes</td>\n",
       "      <td id=\"T_99911_row0_col3\" class=\"data row0 col3\" >kärbes</td>\n",
       "      <td id=\"T_99911_row0_col4\" class=\"data row0 col4\" >['kärbes']</td>\n",
       "      <td id=\"T_99911_row0_col5\" class=\"data row0 col5\" >0</td>\n",
       "      <td id=\"T_99911_row0_col6\" class=\"data row0 col6\" ></td>\n",
       "      <td id=\"T_99911_row0_col7\" class=\"data row0 col7\" >sg n</td>\n",
       "      <td id=\"T_99911_row0_col8\" class=\"data row0 col8\" >S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_99911_row1_col0\" class=\"data row1 col0\" >hulbib</td>\n",
       "      <td id=\"T_99911_row1_col1\" class=\"data row1 col1\" >hulbib</td>\n",
       "      <td id=\"T_99911_row1_col2\" class=\"data row1 col2\" >hulpima</td>\n",
       "      <td id=\"T_99911_row1_col3\" class=\"data row1 col3\" >hulpi</td>\n",
       "      <td id=\"T_99911_row1_col4\" class=\"data row1 col4\" >['hulpi']</td>\n",
       "      <td id=\"T_99911_row1_col5\" class=\"data row1 col5\" >b</td>\n",
       "      <td id=\"T_99911_row1_col6\" class=\"data row1 col6\" ></td>\n",
       "      <td id=\"T_99911_row1_col7\" class=\"data row1 col7\" >b</td>\n",
       "      <td id=\"T_99911_row1_col8\" class=\"data row1 col8\" >V</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_99911_row2_col0\" class=\"data row2 col0\" >mees</td>\n",
       "      <td id=\"T_99911_row2_col1\" class=\"data row2 col1\" >mees</td>\n",
       "      <td id=\"T_99911_row2_col2\" class=\"data row2 col2\" >mees</td>\n",
       "      <td id=\"T_99911_row2_col3\" class=\"data row2 col3\" >mees</td>\n",
       "      <td id=\"T_99911_row2_col4\" class=\"data row2 col4\" >['mees']</td>\n",
       "      <td id=\"T_99911_row2_col5\" class=\"data row2 col5\" >0</td>\n",
       "      <td id=\"T_99911_row2_col6\" class=\"data row2 col6\" ></td>\n",
       "      <td id=\"T_99911_row2_col7\" class=\"data row2 col7\" >sg n</td>\n",
       "      <td id=\"T_99911_row2_col8\" class=\"data row2 col8\" >S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_99911_row3_col0\" class=\"data row3 col0\" >ja</td>\n",
       "      <td id=\"T_99911_row3_col1\" class=\"data row3 col1\" >ja</td>\n",
       "      <td id=\"T_99911_row3_col2\" class=\"data row3 col2\" >ja</td>\n",
       "      <td id=\"T_99911_row3_col3\" class=\"data row3 col3\" >ja</td>\n",
       "      <td id=\"T_99911_row3_col4\" class=\"data row3 col4\" >['ja']</td>\n",
       "      <td id=\"T_99911_row3_col5\" class=\"data row3 col5\" >0</td>\n",
       "      <td id=\"T_99911_row3_col6\" class=\"data row3 col6\" ></td>\n",
       "      <td id=\"T_99911_row3_col7\" class=\"data row3 col7\" ></td>\n",
       "      <td id=\"T_99911_row3_col8\" class=\"data row3 col8\" >J</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_99911_row4_col0\" class=\"data row4 col0\" >naeris</td>\n",
       "      <td id=\"T_99911_row4_col1\" class=\"data row4 col1\" >naeris</td>\n",
       "      <td id=\"T_99911_row4_col2\" class=\"data row4 col2\" >naerma</td>\n",
       "      <td id=\"T_99911_row4_col3\" class=\"data row4 col3\" >naer</td>\n",
       "      <td id=\"T_99911_row4_col4\" class=\"data row4 col4\" >['naer']</td>\n",
       "      <td id=\"T_99911_row4_col5\" class=\"data row4 col5\" >is</td>\n",
       "      <td id=\"T_99911_row4_col6\" class=\"data row4 col6\" ></td>\n",
       "      <td id=\"T_99911_row4_col7\" class=\"data row4 col7\" >s</td>\n",
       "      <td id=\"T_99911_row4_col8\" class=\"data row4 col8\" >V</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_99911_row5_col0\" class=\"data row5 col0\" >puhub</td>\n",
       "      <td id=\"T_99911_row5_col1\" class=\"data row5 col1\" >puhub</td>\n",
       "      <td id=\"T_99911_row5_col2\" class=\"data row5 col2\" >puhuma</td>\n",
       "      <td id=\"T_99911_row5_col3\" class=\"data row5 col3\" >puhu</td>\n",
       "      <td id=\"T_99911_row5_col4\" class=\"data row5 col4\" >['puhu']</td>\n",
       "      <td id=\"T_99911_row5_col5\" class=\"data row5 col5\" >b</td>\n",
       "      <td id=\"T_99911_row5_col6\" class=\"data row5 col6\" ></td>\n",
       "      <td id=\"T_99911_row5_col7\" class=\"data row5 col7\" >b</td>\n",
       "      <td id=\"T_99911_row5_col8\" class=\"data row5 col8\" >V</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_99911_row6_col0\" class=\"data row6 col0\" >sädelevaid</td>\n",
       "      <td id=\"T_99911_row6_col1\" class=\"data row6 col1\" >sädelevaid</td>\n",
       "      <td id=\"T_99911_row6_col2\" class=\"data row6 col2\" >sädelev</td>\n",
       "      <td id=\"T_99911_row6_col3\" class=\"data row6 col3\" >sädelev</td>\n",
       "      <td id=\"T_99911_row6_col4\" class=\"data row6 col4\" >['sädelev']</td>\n",
       "      <td id=\"T_99911_row6_col5\" class=\"data row6 col5\" >id</td>\n",
       "      <td id=\"T_99911_row6_col6\" class=\"data row6 col6\" ></td>\n",
       "      <td id=\"T_99911_row6_col7\" class=\"data row6 col7\" >pl p</td>\n",
       "      <td id=\"T_99911_row6_col8\" class=\"data row6 col8\" >A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_99911_row7_col0\" class=\"data row7 col0\" >mulle</td>\n",
       "      <td id=\"T_99911_row7_col1\" class=\"data row7 col1\" >mulle</td>\n",
       "      <td id=\"T_99911_row7_col2\" class=\"data row7 col2\" >mina</td>\n",
       "      <td id=\"T_99911_row7_col3\" class=\"data row7 col3\" >mina</td>\n",
       "      <td id=\"T_99911_row7_col4\" class=\"data row7 col4\" >['mina']</td>\n",
       "      <td id=\"T_99911_row7_col5\" class=\"data row7 col5\" >lle</td>\n",
       "      <td id=\"T_99911_row7_col6\" class=\"data row7 col6\" ></td>\n",
       "      <td id=\"T_99911_row7_col7\" class=\"data row7 col7\" >sg all</td>\n",
       "      <td id=\"T_99911_row7_col8\" class=\"data row7 col8\" >P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_99911_row8_col0\" class=\"data row8 col0\" >.</td>\n",
       "      <td id=\"T_99911_row8_col1\" class=\"data row8 col1\" >.</td>\n",
       "      <td id=\"T_99911_row8_col2\" class=\"data row8 col2\" >.</td>\n",
       "      <td id=\"T_99911_row8_col3\" class=\"data row8 col3\" >.</td>\n",
       "      <td id=\"T_99911_row8_col4\" class=\"data row8 col4\" >['.']</td>\n",
       "      <td id=\"T_99911_row8_col5\" class=\"data row8 col5\" ></td>\n",
       "      <td id=\"T_99911_row8_col6\" class=\"data row8 col6\" ></td>\n",
       "      <td id=\"T_99911_row8_col7\" class=\"data row8 col7\" ></td>\n",
       "      <td id=\"T_99911_row8_col8\" class=\"data row8 col8\" >Z</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "Layer(name='morph_analysis', attributes=('normalized_text', 'lemma', 'root', 'root_tokens', 'ending', 'clitic', 'form', 'partofspeech'), spans=SL[Span('Kärbes', [{'normalized_text': 'Kärbes', 'lemma': 'kärbes', 'root': 'kärbes', 'root_tokens': ['kärbes'], 'ending': '0', 'clitic': '', 'form': 'sg n', 'partofspeech': 'S'}]),\n",
       "Span('hulbib', [{'normalized_text': 'hulbib', 'lemma': 'hulpima', 'root': 'hulpi', 'root_tokens': ['hulpi'], 'ending': 'b', 'clitic': '', 'form': 'b', 'partofspeech': 'V'}]),\n",
       "Span('mees', [{'normalized_text': 'mees', 'lemma': 'mees', 'root': 'mees', 'root_tokens': ['mees'], 'ending': '0', 'clitic': '', 'form': 'sg n', 'partofspeech': 'S'}]),\n",
       "Span('ja', [{'normalized_text': 'ja', 'lemma': 'ja', 'root': 'ja', 'root_tokens': ['ja'], 'ending': '0', 'clitic': '', 'form': '', 'partofspeech': 'J'}]),\n",
       "Span('naeris', [{'normalized_text': 'naeris', 'lemma': 'naerma', 'root': 'naer', 'root_tokens': ['naer'], 'ending': 'is', 'clitic': '', 'form': 's', 'partofspeech': 'V'}]),\n",
       "Span('puhub', [{'normalized_text': 'puhub', 'lemma': 'puhuma', 'root': 'puhu', 'root_tokens': ['puhu'], 'ending': 'b', 'clitic': '', 'form': 'b', 'partofspeech': 'V'}]),\n",
       "Span('sädelevaid', [{'normalized_text': 'sädelevaid', 'lemma': 'sädelev', 'root': 'sädelev', 'root_tokens': ['sädelev'], 'ending': 'id', 'clitic': '', 'form': 'pl p', 'partofspeech': 'A'}]),\n",
       "Span('mulle', [{'normalized_text': 'mulle', 'lemma': 'mina', 'root': 'mina', 'root_tokens': ['mina'], 'ending': 'lle', 'clitic': '', 'form': 'sg all', 'partofspeech': 'P'}]),\n",
       "Span('.', [{'normalized_text': '.', 'lemma': '.', 'root': '.', 'root_tokens': ['.'], 'ending': '', 'clitic': '', 'form': '', 'partofspeech': 'Z'}])])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text.tag_layer(resolver=resolver)['morph_analysis']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see from the result, with default morphological analysis, all the words get assigned exactly one analysis, but three of them are not correct. The disambiguator has wrongly deleted the correct analyses this time. \n",
    "\n",
    "*Note that this example sentence is a little out of the ordinary and hence the bad performance of disambiguator. The more 'normal' your text is, the better the results.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we want to change the parameters of morphological analysis, we have to change the default values of the flags to create a customized resolver. For example, to switch off disambiguation, we have to set this value to False:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "resolver2 = make_resolver(\n",
    "                 disambiguate=False,\n",
    "                 guess=True,\n",
    "                 propername=True,\n",
    "                 phonetic=False,\n",
    "                 compound=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The resolver tags only those layers on the text that have not been previously tagged. To see the effect of changed parameters we have to create a new text object or delete the affected layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h4>Layer</h4>\n",
       "\n",
       "\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>layer name</th>\n",
       "      <th>attributes</th>\n",
       "      <th>parent</th>\n",
       "      <th>enveloping</th>\n",
       "      <th>ambiguous</th>\n",
       "      <th>span count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>morph_analysis</td>\n",
       "      <td>normalized_text, lemma, root, root_tokens, ending, clitic, form, partofspeech, _ignore</td>\n",
       "      <td>words</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_86669\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th id=\"T_86669_level0_col0\" class=\"col_heading level0 col0\" >text</th>\n",
       "      <th id=\"T_86669_level0_col1\" class=\"col_heading level0 col1\" >normalized_text</th>\n",
       "      <th id=\"T_86669_level0_col2\" class=\"col_heading level0 col2\" >lemma</th>\n",
       "      <th id=\"T_86669_level0_col3\" class=\"col_heading level0 col3\" >root</th>\n",
       "      <th id=\"T_86669_level0_col4\" class=\"col_heading level0 col4\" >root_tokens</th>\n",
       "      <th id=\"T_86669_level0_col5\" class=\"col_heading level0 col5\" >ending</th>\n",
       "      <th id=\"T_86669_level0_col6\" class=\"col_heading level0 col6\" >clitic</th>\n",
       "      <th id=\"T_86669_level0_col7\" class=\"col_heading level0 col7\" >form</th>\n",
       "      <th id=\"T_86669_level0_col8\" class=\"col_heading level0 col8\" >partofspeech</th>\n",
       "      <th id=\"T_86669_level0_col9\" class=\"col_heading level0 col9\" >_ignore</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td id=\"T_86669_row0_col0\" class=\"data row0 col0\" >Kärbes</td>\n",
       "      <td id=\"T_86669_row0_col1\" class=\"data row0 col1\" >Kärbes</td>\n",
       "      <td id=\"T_86669_row0_col2\" class=\"data row0 col2\" >Kärbe</td>\n",
       "      <td id=\"T_86669_row0_col3\" class=\"data row0 col3\" >Kärbe</td>\n",
       "      <td id=\"T_86669_row0_col4\" class=\"data row0 col4\" >['Kärbe']</td>\n",
       "      <td id=\"T_86669_row0_col5\" class=\"data row0 col5\" >s</td>\n",
       "      <td id=\"T_86669_row0_col6\" class=\"data row0 col6\" ></td>\n",
       "      <td id=\"T_86669_row0_col7\" class=\"data row0 col7\" >sg in</td>\n",
       "      <td id=\"T_86669_row0_col8\" class=\"data row0 col8\" >H</td>\n",
       "      <td id=\"T_86669_row0_col9\" class=\"data row0 col9\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_86669_row1_col0\" class=\"data row1 col0\" ></td>\n",
       "      <td id=\"T_86669_row1_col1\" class=\"data row1 col1\" >Kärbes</td>\n",
       "      <td id=\"T_86669_row1_col2\" class=\"data row1 col2\" >Kärbes</td>\n",
       "      <td id=\"T_86669_row1_col3\" class=\"data row1 col3\" >Kärbes</td>\n",
       "      <td id=\"T_86669_row1_col4\" class=\"data row1 col4\" >['Kärbes']</td>\n",
       "      <td id=\"T_86669_row1_col5\" class=\"data row1 col5\" >0</td>\n",
       "      <td id=\"T_86669_row1_col6\" class=\"data row1 col6\" ></td>\n",
       "      <td id=\"T_86669_row1_col7\" class=\"data row1 col7\" >sg n</td>\n",
       "      <td id=\"T_86669_row1_col8\" class=\"data row1 col8\" >H</td>\n",
       "      <td id=\"T_86669_row1_col9\" class=\"data row1 col9\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_86669_row2_col0\" class=\"data row2 col0\" ></td>\n",
       "      <td id=\"T_86669_row2_col1\" class=\"data row2 col1\" >Kärbes</td>\n",
       "      <td id=\"T_86669_row2_col2\" class=\"data row2 col2\" >kärbes</td>\n",
       "      <td id=\"T_86669_row2_col3\" class=\"data row2 col3\" >kärbes</td>\n",
       "      <td id=\"T_86669_row2_col4\" class=\"data row2 col4\" >['kärbes']</td>\n",
       "      <td id=\"T_86669_row2_col5\" class=\"data row2 col5\" >0</td>\n",
       "      <td id=\"T_86669_row2_col6\" class=\"data row2 col6\" ></td>\n",
       "      <td id=\"T_86669_row2_col7\" class=\"data row2 col7\" >sg n</td>\n",
       "      <td id=\"T_86669_row2_col8\" class=\"data row2 col8\" >S</td>\n",
       "      <td id=\"T_86669_row2_col9\" class=\"data row2 col9\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_86669_row3_col0\" class=\"data row3 col0\" >hulbib</td>\n",
       "      <td id=\"T_86669_row3_col1\" class=\"data row3 col1\" >hulbib</td>\n",
       "      <td id=\"T_86669_row3_col2\" class=\"data row3 col2\" >hulpima</td>\n",
       "      <td id=\"T_86669_row3_col3\" class=\"data row3 col3\" >hulpi</td>\n",
       "      <td id=\"T_86669_row3_col4\" class=\"data row3 col4\" >['hulpi']</td>\n",
       "      <td id=\"T_86669_row3_col5\" class=\"data row3 col5\" >b</td>\n",
       "      <td id=\"T_86669_row3_col6\" class=\"data row3 col6\" ></td>\n",
       "      <td id=\"T_86669_row3_col7\" class=\"data row3 col7\" >b</td>\n",
       "      <td id=\"T_86669_row3_col8\" class=\"data row3 col8\" >V</td>\n",
       "      <td id=\"T_86669_row3_col9\" class=\"data row3 col9\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_86669_row4_col0\" class=\"data row4 col0\" >mees</td>\n",
       "      <td id=\"T_86669_row4_col1\" class=\"data row4 col1\" >mees</td>\n",
       "      <td id=\"T_86669_row4_col2\" class=\"data row4 col2\" >mees</td>\n",
       "      <td id=\"T_86669_row4_col3\" class=\"data row4 col3\" >mees</td>\n",
       "      <td id=\"T_86669_row4_col4\" class=\"data row4 col4\" >['mees']</td>\n",
       "      <td id=\"T_86669_row4_col5\" class=\"data row4 col5\" >0</td>\n",
       "      <td id=\"T_86669_row4_col6\" class=\"data row4 col6\" ></td>\n",
       "      <td id=\"T_86669_row4_col7\" class=\"data row4 col7\" >sg n</td>\n",
       "      <td id=\"T_86669_row4_col8\" class=\"data row4 col8\" >S</td>\n",
       "      <td id=\"T_86669_row4_col9\" class=\"data row4 col9\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_86669_row5_col0\" class=\"data row5 col0\" ></td>\n",
       "      <td id=\"T_86669_row5_col1\" class=\"data row5 col1\" >mees</td>\n",
       "      <td id=\"T_86669_row5_col2\" class=\"data row5 col2\" >mesi</td>\n",
       "      <td id=\"T_86669_row5_col3\" class=\"data row5 col3\" >mesi</td>\n",
       "      <td id=\"T_86669_row5_col4\" class=\"data row5 col4\" >['mesi']</td>\n",
       "      <td id=\"T_86669_row5_col5\" class=\"data row5 col5\" >s</td>\n",
       "      <td id=\"T_86669_row5_col6\" class=\"data row5 col6\" ></td>\n",
       "      <td id=\"T_86669_row5_col7\" class=\"data row5 col7\" >sg in</td>\n",
       "      <td id=\"T_86669_row5_col8\" class=\"data row5 col8\" >S</td>\n",
       "      <td id=\"T_86669_row5_col9\" class=\"data row5 col9\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_86669_row6_col0\" class=\"data row6 col0\" >ja</td>\n",
       "      <td id=\"T_86669_row6_col1\" class=\"data row6 col1\" >ja</td>\n",
       "      <td id=\"T_86669_row6_col2\" class=\"data row6 col2\" >ja</td>\n",
       "      <td id=\"T_86669_row6_col3\" class=\"data row6 col3\" >ja</td>\n",
       "      <td id=\"T_86669_row6_col4\" class=\"data row6 col4\" >['ja']</td>\n",
       "      <td id=\"T_86669_row6_col5\" class=\"data row6 col5\" >0</td>\n",
       "      <td id=\"T_86669_row6_col6\" class=\"data row6 col6\" ></td>\n",
       "      <td id=\"T_86669_row6_col7\" class=\"data row6 col7\" ></td>\n",
       "      <td id=\"T_86669_row6_col8\" class=\"data row6 col8\" >J</td>\n",
       "      <td id=\"T_86669_row6_col9\" class=\"data row6 col9\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_86669_row7_col0\" class=\"data row7 col0\" >naeris</td>\n",
       "      <td id=\"T_86669_row7_col1\" class=\"data row7 col1\" >naeris</td>\n",
       "      <td id=\"T_86669_row7_col2\" class=\"data row7 col2\" >naerma</td>\n",
       "      <td id=\"T_86669_row7_col3\" class=\"data row7 col3\" >naer</td>\n",
       "      <td id=\"T_86669_row7_col4\" class=\"data row7 col4\" >['naer']</td>\n",
       "      <td id=\"T_86669_row7_col5\" class=\"data row7 col5\" >is</td>\n",
       "      <td id=\"T_86669_row7_col6\" class=\"data row7 col6\" ></td>\n",
       "      <td id=\"T_86669_row7_col7\" class=\"data row7 col7\" >s</td>\n",
       "      <td id=\"T_86669_row7_col8\" class=\"data row7 col8\" >V</td>\n",
       "      <td id=\"T_86669_row7_col9\" class=\"data row7 col9\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_86669_row8_col0\" class=\"data row8 col0\" ></td>\n",
       "      <td id=\"T_86669_row8_col1\" class=\"data row8 col1\" >naeris</td>\n",
       "      <td id=\"T_86669_row8_col2\" class=\"data row8 col2\" >naeris</td>\n",
       "      <td id=\"T_86669_row8_col3\" class=\"data row8 col3\" >naeris</td>\n",
       "      <td id=\"T_86669_row8_col4\" class=\"data row8 col4\" >['naeris']</td>\n",
       "      <td id=\"T_86669_row8_col5\" class=\"data row8 col5\" >0</td>\n",
       "      <td id=\"T_86669_row8_col6\" class=\"data row8 col6\" ></td>\n",
       "      <td id=\"T_86669_row8_col7\" class=\"data row8 col7\" >sg n</td>\n",
       "      <td id=\"T_86669_row8_col8\" class=\"data row8 col8\" >S</td>\n",
       "      <td id=\"T_86669_row8_col9\" class=\"data row8 col9\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_86669_row9_col0\" class=\"data row9 col0\" ></td>\n",
       "      <td id=\"T_86669_row9_col1\" class=\"data row9 col1\" >naeris</td>\n",
       "      <td id=\"T_86669_row9_col2\" class=\"data row9 col2\" >naeris</td>\n",
       "      <td id=\"T_86669_row9_col3\" class=\"data row9 col3\" >naeris</td>\n",
       "      <td id=\"T_86669_row9_col4\" class=\"data row9 col4\" >['naeris']</td>\n",
       "      <td id=\"T_86669_row9_col5\" class=\"data row9 col5\" >s</td>\n",
       "      <td id=\"T_86669_row9_col6\" class=\"data row9 col6\" ></td>\n",
       "      <td id=\"T_86669_row9_col7\" class=\"data row9 col7\" >sg in</td>\n",
       "      <td id=\"T_86669_row9_col8\" class=\"data row9 col8\" >S</td>\n",
       "      <td id=\"T_86669_row9_col9\" class=\"data row9 col9\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_86669_row10_col0\" class=\"data row10 col0\" >puhub</td>\n",
       "      <td id=\"T_86669_row10_col1\" class=\"data row10 col1\" >puhub</td>\n",
       "      <td id=\"T_86669_row10_col2\" class=\"data row10 col2\" >puhuma</td>\n",
       "      <td id=\"T_86669_row10_col3\" class=\"data row10 col3\" >puhu</td>\n",
       "      <td id=\"T_86669_row10_col4\" class=\"data row10 col4\" >['puhu']</td>\n",
       "      <td id=\"T_86669_row10_col5\" class=\"data row10 col5\" >b</td>\n",
       "      <td id=\"T_86669_row10_col6\" class=\"data row10 col6\" ></td>\n",
       "      <td id=\"T_86669_row10_col7\" class=\"data row10 col7\" >b</td>\n",
       "      <td id=\"T_86669_row10_col8\" class=\"data row10 col8\" >V</td>\n",
       "      <td id=\"T_86669_row10_col9\" class=\"data row10 col9\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_86669_row11_col0\" class=\"data row11 col0\" >sädelevaid</td>\n",
       "      <td id=\"T_86669_row11_col1\" class=\"data row11 col1\" >sädelevaid</td>\n",
       "      <td id=\"T_86669_row11_col2\" class=\"data row11 col2\" >sädelev</td>\n",
       "      <td id=\"T_86669_row11_col3\" class=\"data row11 col3\" >sädelev</td>\n",
       "      <td id=\"T_86669_row11_col4\" class=\"data row11 col4\" >['sädelev']</td>\n",
       "      <td id=\"T_86669_row11_col5\" class=\"data row11 col5\" >id</td>\n",
       "      <td id=\"T_86669_row11_col6\" class=\"data row11 col6\" ></td>\n",
       "      <td id=\"T_86669_row11_col7\" class=\"data row11 col7\" >pl p</td>\n",
       "      <td id=\"T_86669_row11_col8\" class=\"data row11 col8\" >A</td>\n",
       "      <td id=\"T_86669_row11_col9\" class=\"data row11 col9\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_86669_row12_col0\" class=\"data row12 col0\" >mulle</td>\n",
       "      <td id=\"T_86669_row12_col1\" class=\"data row12 col1\" >mulle</td>\n",
       "      <td id=\"T_86669_row12_col2\" class=\"data row12 col2\" >mull</td>\n",
       "      <td id=\"T_86669_row12_col3\" class=\"data row12 col3\" >mull</td>\n",
       "      <td id=\"T_86669_row12_col4\" class=\"data row12 col4\" >['mull']</td>\n",
       "      <td id=\"T_86669_row12_col5\" class=\"data row12 col5\" >e</td>\n",
       "      <td id=\"T_86669_row12_col6\" class=\"data row12 col6\" ></td>\n",
       "      <td id=\"T_86669_row12_col7\" class=\"data row12 col7\" >pl p</td>\n",
       "      <td id=\"T_86669_row12_col8\" class=\"data row12 col8\" >S</td>\n",
       "      <td id=\"T_86669_row12_col9\" class=\"data row12 col9\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_86669_row13_col0\" class=\"data row13 col0\" ></td>\n",
       "      <td id=\"T_86669_row13_col1\" class=\"data row13 col1\" >mulle</td>\n",
       "      <td id=\"T_86669_row13_col2\" class=\"data row13 col2\" >mina</td>\n",
       "      <td id=\"T_86669_row13_col3\" class=\"data row13 col3\" >mina</td>\n",
       "      <td id=\"T_86669_row13_col4\" class=\"data row13 col4\" >['mina']</td>\n",
       "      <td id=\"T_86669_row13_col5\" class=\"data row13 col5\" >lle</td>\n",
       "      <td id=\"T_86669_row13_col6\" class=\"data row13 col6\" ></td>\n",
       "      <td id=\"T_86669_row13_col7\" class=\"data row13 col7\" >sg all</td>\n",
       "      <td id=\"T_86669_row13_col8\" class=\"data row13 col8\" >P</td>\n",
       "      <td id=\"T_86669_row13_col9\" class=\"data row13 col9\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_86669_row14_col0\" class=\"data row14 col0\" ></td>\n",
       "      <td id=\"T_86669_row14_col1\" class=\"data row14 col1\" >mulle</td>\n",
       "      <td id=\"T_86669_row14_col2\" class=\"data row14 col2\" >mulle</td>\n",
       "      <td id=\"T_86669_row14_col3\" class=\"data row14 col3\" >mulle</td>\n",
       "      <td id=\"T_86669_row14_col4\" class=\"data row14 col4\" >['mulle']</td>\n",
       "      <td id=\"T_86669_row14_col5\" class=\"data row14 col5\" >0</td>\n",
       "      <td id=\"T_86669_row14_col6\" class=\"data row14 col6\" ></td>\n",
       "      <td id=\"T_86669_row14_col7\" class=\"data row14 col7\" >sg n</td>\n",
       "      <td id=\"T_86669_row14_col8\" class=\"data row14 col8\" >S</td>\n",
       "      <td id=\"T_86669_row14_col9\" class=\"data row14 col9\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_86669_row15_col0\" class=\"data row15 col0\" >.</td>\n",
       "      <td id=\"T_86669_row15_col1\" class=\"data row15 col1\" >.</td>\n",
       "      <td id=\"T_86669_row15_col2\" class=\"data row15 col2\" >.</td>\n",
       "      <td id=\"T_86669_row15_col3\" class=\"data row15 col3\" >.</td>\n",
       "      <td id=\"T_86669_row15_col4\" class=\"data row15 col4\" >['.']</td>\n",
       "      <td id=\"T_86669_row15_col5\" class=\"data row15 col5\" ></td>\n",
       "      <td id=\"T_86669_row15_col6\" class=\"data row15 col6\" ></td>\n",
       "      <td id=\"T_86669_row15_col7\" class=\"data row15 col7\" ></td>\n",
       "      <td id=\"T_86669_row15_col8\" class=\"data row15 col8\" >Z</td>\n",
       "      <td id=\"T_86669_row15_col9\" class=\"data row15 col9\" >False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "Layer(name='morph_analysis', attributes=('normalized_text', 'lemma', 'root', 'root_tokens', 'ending', 'clitic', 'form', 'partofspeech', '_ignore'), spans=SL[Span('Kärbes', [{'normalized_text': 'Kärbes', 'lemma': 'Kärbe', 'root': 'Kärbe', 'root_tokens': ['Kärbe'], 'ending': 's', 'clitic': '', 'form': 'sg in', 'partofspeech': 'H', '_ignore': False}, {'normalized_text': 'Kärbes', 'lemma': 'Kärbes', 'root': 'Kärbes', 'root_tokens': ['Kärbes'], 'ending': '0', 'clitic': '', 'form': 'sg n', 'partofspeech': 'H', '_ignore': False}, {'normalized_text': 'Kärbes', 'lemma': 'kärbes', 'root': 'kärbes', 'root_tokens': ['kärbes'], 'ending': '0', 'clitic': '', 'form': 'sg n', 'partofspeech': 'S', '_ignore': False}]),\n",
       "Span('hulbib', [{'normalized_text': 'hulbib', 'lemma': 'hulpima', 'root': 'hulpi', 'root_tokens': ['hulpi'], 'ending': 'b', 'clitic': '', 'form': 'b', 'partofspeech': 'V', '_ignore': False}]),\n",
       "Span('mees', [{'normalized_text': 'mees', 'lemma': 'mees', 'root': 'mees', 'root_tokens': ['mees'], 'ending': '0', 'clitic': '', 'form': 'sg n', 'partofspeech': 'S', '_ignore': False}, {'normalized_text': 'mees', 'lemma': 'mesi', 'root': 'mesi', 'root_tokens': ['mesi'], 'ending': 's', 'clitic': '', 'form': 'sg in', 'partofspeech': 'S', '_ignore': False}]),\n",
       "Span('ja', [{'normalized_text': 'ja', 'lemma': 'ja', 'root': 'ja', 'root_tokens': ['ja'], 'ending': '0', 'clitic': '', 'form': '', 'partofspeech': 'J', '_ignore': False}]),\n",
       "Span('naeris', [{'normalized_text': 'naeris', 'lemma': 'naerma', 'root': 'naer', 'root_tokens': ['naer'], 'ending': 'is', 'clitic': '', 'form': 's', 'partofspeech': 'V', '_ignore': False}, {'normalized_text': 'naeris', 'lemma': 'naeris', 'root': 'naeris', 'root_tokens': ['naeris'], 'ending': '0', 'clitic': '', 'form': 'sg n', 'partofspeech': 'S', '_ignore': False}, {'normalized_text': 'naeris', 'lemma': 'naeris', 'root': 'naeris', 'root_tokens': ['naeris'], 'ending': 's', 'clitic': '', 'form': 'sg in', 'partofspeech': 'S', '_ignore': False}]),\n",
       "Span('puhub', [{'normalized_text': 'puhub', 'lemma': 'puhuma', 'root': 'puhu', 'root_tokens': ['puhu'], 'ending': 'b', 'clitic': '', 'form': 'b', 'partofspeech': 'V', '_ignore': False}]),\n",
       "Span('sädelevaid', [{'normalized_text': 'sädelevaid', 'lemma': 'sädelev', 'root': 'sädelev', 'root_tokens': ['sädelev'], 'ending': 'id', 'clitic': '', 'form': 'pl p', 'partofspeech': 'A', '_ignore': False}]),\n",
       "Span('mulle', [{'normalized_text': 'mulle', 'lemma': 'mull', 'root': 'mull', 'root_tokens': ['mull'], 'ending': 'e', 'clitic': '', 'form': 'pl p', 'partofspeech': 'S', '_ignore': False}, {'normalized_text': 'mulle', 'lemma': 'mina', 'root': 'mina', 'root_tokens': ['mina'], 'ending': 'lle', 'clitic': '', 'form': 'sg all', 'partofspeech': 'P', '_ignore': False}, {'normalized_text': 'mulle', 'lemma': 'mulle', 'root': 'mulle', 'root_tokens': ['mulle'], 'ending': '0', 'clitic': '', 'form': 'sg n', 'partofspeech': 'S', '_ignore': False}]),\n",
       "Span('.', [{'normalized_text': '.', 'lemma': '.', 'root': '.', 'root_tokens': ['.'], 'ending': '', 'clitic': '', 'form': '', 'partofspeech': 'Z', '_ignore': False}])])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text.pop_layer('morph_analysis')  # remove morph_analysis from text \n",
    "text.tag_layer(resolver=resolver2)['morph_analysis']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Note:\n",
    " * If disambiguation is switched off, the layer `morph_analysis` will have one extra attribute named `_ignore`. This is actually an internal attribute that is used to tell the disambiguator which analyses should be ignored. Once the disambiguation will be applied, the attribute will be removed. ( You can use `VabamorfDisambiguator` to perform disambiguation separately, see the details in the tutorial [01_morphological_analysis.ipynb](../nlp_pipeline/B_morphology/01_morphological_analysis.ipynb) );"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Warning:\n",
    " * Changing parameters of morphological analysis also affects the performance of downstream taggers that are depending on the results of morphological analysis (such as named entity recognition and syntactic parsing). To the extent that some taggers become not applicable on the resulting morph_analysis layer. Therefore, if you change parameters of morphological analysis, it is not recommended to use any taggers depending on morph_analysis (or use these taggers only when you know what you are doing);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Unknown words\n",
    "\n",
    "If guessings and disambiguation are switched off ( `guess=False`, `propername=False` and `disambiguate=False` ), then morphological analyser can be used to detect unknown words -- words that are orthographically incorrect, or not common in written language:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h4>Layer</h4>\n",
       "\n",
       "\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>layer name</th>\n",
       "      <th>attributes</th>\n",
       "      <th>parent</th>\n",
       "      <th>enveloping</th>\n",
       "      <th>ambiguous</th>\n",
       "      <th>span count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>morph_analysis</td>\n",
       "      <td>normalized_text, lemma, root, root_tokens, ending, clitic, form, partofspeech, _ignore</td>\n",
       "      <td>words</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<style type=\"text/css\">\n",
       "#T_ac4cf_row1_col1, #T_ac4cf_row1_col2, #T_ac4cf_row1_col3, #T_ac4cf_row1_col4, #T_ac4cf_row1_col5, #T_ac4cf_row1_col6, #T_ac4cf_row1_col7, #T_ac4cf_row1_col8, #T_ac4cf_row6_col1, #T_ac4cf_row6_col2, #T_ac4cf_row6_col3, #T_ac4cf_row6_col4, #T_ac4cf_row6_col5, #T_ac4cf_row6_col6, #T_ac4cf_row6_col7, #T_ac4cf_row6_col8 {\n",
       "  opacity: 20%;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_ac4cf\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th id=\"T_ac4cf_level0_col0\" class=\"col_heading level0 col0\" >text</th>\n",
       "      <th id=\"T_ac4cf_level0_col1\" class=\"col_heading level0 col1\" >normalized_text</th>\n",
       "      <th id=\"T_ac4cf_level0_col2\" class=\"col_heading level0 col2\" >lemma</th>\n",
       "      <th id=\"T_ac4cf_level0_col3\" class=\"col_heading level0 col3\" >root</th>\n",
       "      <th id=\"T_ac4cf_level0_col4\" class=\"col_heading level0 col4\" >root_tokens</th>\n",
       "      <th id=\"T_ac4cf_level0_col5\" class=\"col_heading level0 col5\" >ending</th>\n",
       "      <th id=\"T_ac4cf_level0_col6\" class=\"col_heading level0 col6\" >clitic</th>\n",
       "      <th id=\"T_ac4cf_level0_col7\" class=\"col_heading level0 col7\" >form</th>\n",
       "      <th id=\"T_ac4cf_level0_col8\" class=\"col_heading level0 col8\" >partofspeech</th>\n",
       "      <th id=\"T_ac4cf_level0_col9\" class=\"col_heading level0 col9\" >_ignore</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td id=\"T_ac4cf_row0_col0\" class=\"data row0 col0\" >Ma</td>\n",
       "      <td id=\"T_ac4cf_row0_col1\" class=\"data row0 col1\" >Ma</td>\n",
       "      <td id=\"T_ac4cf_row0_col2\" class=\"data row0 col2\" >mina</td>\n",
       "      <td id=\"T_ac4cf_row0_col3\" class=\"data row0 col3\" >mina</td>\n",
       "      <td id=\"T_ac4cf_row0_col4\" class=\"data row0 col4\" >['mina']</td>\n",
       "      <td id=\"T_ac4cf_row0_col5\" class=\"data row0 col5\" >0</td>\n",
       "      <td id=\"T_ac4cf_row0_col6\" class=\"data row0 col6\" ></td>\n",
       "      <td id=\"T_ac4cf_row0_col7\" class=\"data row0 col7\" >sg n</td>\n",
       "      <td id=\"T_ac4cf_row0_col8\" class=\"data row0 col8\" >P</td>\n",
       "      <td id=\"T_ac4cf_row0_col9\" class=\"data row0 col9\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_ac4cf_row1_col0\" class=\"data row1 col0\" >tahax</td>\n",
       "      <td id=\"T_ac4cf_row1_col1\" class=\"data row1 col1\" >None</td>\n",
       "      <td id=\"T_ac4cf_row1_col2\" class=\"data row1 col2\" >None</td>\n",
       "      <td id=\"T_ac4cf_row1_col3\" class=\"data row1 col3\" >None</td>\n",
       "      <td id=\"T_ac4cf_row1_col4\" class=\"data row1 col4\" >None</td>\n",
       "      <td id=\"T_ac4cf_row1_col5\" class=\"data row1 col5\" >None</td>\n",
       "      <td id=\"T_ac4cf_row1_col6\" class=\"data row1 col6\" >None</td>\n",
       "      <td id=\"T_ac4cf_row1_col7\" class=\"data row1 col7\" >None</td>\n",
       "      <td id=\"T_ac4cf_row1_col8\" class=\"data row1 col8\" >None</td>\n",
       "      <td id=\"T_ac4cf_row1_col9\" class=\"data row1 col9\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_ac4cf_row2_col0\" class=\"data row2 col0\" >minna</td>\n",
       "      <td id=\"T_ac4cf_row2_col1\" class=\"data row2 col1\" >minna</td>\n",
       "      <td id=\"T_ac4cf_row2_col2\" class=\"data row2 col2\" >minema</td>\n",
       "      <td id=\"T_ac4cf_row2_col3\" class=\"data row2 col3\" >mine</td>\n",
       "      <td id=\"T_ac4cf_row2_col4\" class=\"data row2 col4\" >['mine']</td>\n",
       "      <td id=\"T_ac4cf_row2_col5\" class=\"data row2 col5\" >a</td>\n",
       "      <td id=\"T_ac4cf_row2_col6\" class=\"data row2 col6\" ></td>\n",
       "      <td id=\"T_ac4cf_row2_col7\" class=\"data row2 col7\" >da</td>\n",
       "      <td id=\"T_ac4cf_row2_col8\" class=\"data row2 col8\" >V</td>\n",
       "      <td id=\"T_ac4cf_row2_col9\" class=\"data row2 col9\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_ac4cf_row3_col0\" class=\"data row3 col0\" >järve</td>\n",
       "      <td id=\"T_ac4cf_row3_col1\" class=\"data row3 col1\" >järve</td>\n",
       "      <td id=\"T_ac4cf_row3_col2\" class=\"data row3 col2\" >järv</td>\n",
       "      <td id=\"T_ac4cf_row3_col3\" class=\"data row3 col3\" >järv</td>\n",
       "      <td id=\"T_ac4cf_row3_col4\" class=\"data row3 col4\" >['järv']</td>\n",
       "      <td id=\"T_ac4cf_row3_col5\" class=\"data row3 col5\" >0</td>\n",
       "      <td id=\"T_ac4cf_row3_col6\" class=\"data row3 col6\" ></td>\n",
       "      <td id=\"T_ac4cf_row3_col7\" class=\"data row3 col7\" >adt</td>\n",
       "      <td id=\"T_ac4cf_row3_col8\" class=\"data row3 col8\" >S</td>\n",
       "      <td id=\"T_ac4cf_row3_col9\" class=\"data row3 col9\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_ac4cf_row4_col0\" class=\"data row4 col0\" ></td>\n",
       "      <td id=\"T_ac4cf_row4_col1\" class=\"data row4 col1\" >järve</td>\n",
       "      <td id=\"T_ac4cf_row4_col2\" class=\"data row4 col2\" >järv</td>\n",
       "      <td id=\"T_ac4cf_row4_col3\" class=\"data row4 col3\" >järv</td>\n",
       "      <td id=\"T_ac4cf_row4_col4\" class=\"data row4 col4\" >['järv']</td>\n",
       "      <td id=\"T_ac4cf_row4_col5\" class=\"data row4 col5\" >0</td>\n",
       "      <td id=\"T_ac4cf_row4_col6\" class=\"data row4 col6\" ></td>\n",
       "      <td id=\"T_ac4cf_row4_col7\" class=\"data row4 col7\" >sg g</td>\n",
       "      <td id=\"T_ac4cf_row4_col8\" class=\"data row4 col8\" >S</td>\n",
       "      <td id=\"T_ac4cf_row4_col9\" class=\"data row4 col9\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_ac4cf_row5_col0\" class=\"data row5 col0\" ></td>\n",
       "      <td id=\"T_ac4cf_row5_col1\" class=\"data row5 col1\" >järve</td>\n",
       "      <td id=\"T_ac4cf_row5_col2\" class=\"data row5 col2\" >järv</td>\n",
       "      <td id=\"T_ac4cf_row5_col3\" class=\"data row5 col3\" >järv</td>\n",
       "      <td id=\"T_ac4cf_row5_col4\" class=\"data row5 col4\" >['järv']</td>\n",
       "      <td id=\"T_ac4cf_row5_col5\" class=\"data row5 col5\" >0</td>\n",
       "      <td id=\"T_ac4cf_row5_col6\" class=\"data row5 col6\" ></td>\n",
       "      <td id=\"T_ac4cf_row5_col7\" class=\"data row5 col7\" >sg p</td>\n",
       "      <td id=\"T_ac4cf_row5_col8\" class=\"data row5 col8\" >S</td>\n",
       "      <td id=\"T_ac4cf_row5_col9\" class=\"data row5 col9\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_ac4cf_row6_col0\" class=\"data row6 col0\" >ääde</td>\n",
       "      <td id=\"T_ac4cf_row6_col1\" class=\"data row6 col1\" >None</td>\n",
       "      <td id=\"T_ac4cf_row6_col2\" class=\"data row6 col2\" >None</td>\n",
       "      <td id=\"T_ac4cf_row6_col3\" class=\"data row6 col3\" >None</td>\n",
       "      <td id=\"T_ac4cf_row6_col4\" class=\"data row6 col4\" >None</td>\n",
       "      <td id=\"T_ac4cf_row6_col5\" class=\"data row6 col5\" >None</td>\n",
       "      <td id=\"T_ac4cf_row6_col6\" class=\"data row6 col6\" >None</td>\n",
       "      <td id=\"T_ac4cf_row6_col7\" class=\"data row6 col7\" >None</td>\n",
       "      <td id=\"T_ac4cf_row6_col8\" class=\"data row6 col8\" >None</td>\n",
       "      <td id=\"T_ac4cf_row6_col9\" class=\"data row6 col9\" >False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "Layer(name='morph_analysis', attributes=('normalized_text', 'lemma', 'root', 'root_tokens', 'ending', 'clitic', 'form', 'partofspeech', '_ignore'), spans=SL[Span('Ma', [{'normalized_text': 'Ma', 'lemma': 'mina', 'root': 'mina', 'root_tokens': ['mina'], 'ending': '0', 'clitic': '', 'form': 'sg n', 'partofspeech': 'P', '_ignore': False}]),\n",
       "Span('tahax', [{'normalized_text': None, 'lemma': None, 'root': None, 'root_tokens': None, 'ending': None, 'clitic': None, 'form': None, 'partofspeech': None, '_ignore': False}]),\n",
       "Span('minna', [{'normalized_text': 'minna', 'lemma': 'minema', 'root': 'mine', 'root_tokens': ['mine'], 'ending': 'a', 'clitic': '', 'form': 'da', 'partofspeech': 'V', '_ignore': False}]),\n",
       "Span('järve', [{'normalized_text': 'järve', 'lemma': 'järv', 'root': 'järv', 'root_tokens': ['järv'], 'ending': '0', 'clitic': '', 'form': 'adt', 'partofspeech': 'S', '_ignore': False}, {'normalized_text': 'järve', 'lemma': 'järv', 'root': 'järv', 'root_tokens': ['järv'], 'ending': '0', 'clitic': '', 'form': 'sg g', 'partofspeech': 'S', '_ignore': False}, {'normalized_text': 'järve', 'lemma': 'järv', 'root': 'järv', 'root_tokens': ['järv'], 'ending': '0', 'clitic': '', 'form': 'sg p', 'partofspeech': 'S', '_ignore': False}]),\n",
       "Span('ääde', [{'normalized_text': None, 'lemma': None, 'root': None, 'root_tokens': None, 'ending': None, 'clitic': None, 'form': None, 'partofspeech': None, '_ignore': False}])])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from estnltk.default_resolver import make_resolver\n",
    "\n",
    "# Switch off guessing and disambiguation\n",
    "resolver3 = make_resolver(\n",
    "                 disambiguate=False,\n",
    "                 guess=False,\n",
    "                 propername=False,\n",
    "                 phonetic=False,\n",
    "                 compound=True)\n",
    "\n",
    "# Tag morph analysis\n",
    "text = Text(\"Ma tahax minna järve ääde\")\n",
    "text.tag_layer(resolver=resolver3)['morph_analysis']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the previous example, the morphological analysis revealed two unknown words: _'tahax'_ and _'ääde'_. Each unknown still has one analysis, but all attributes of the analysis (lemma, root, ending, partofspeech etc.) are set to `None`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Remarks on morphological analysis:\n",
    " * Switching off guessing ( `guess=False` ) only works if guessing of proper names and disambiguation are also switched off  ( `propername=False` and `disambiguate=False` ). If only `guess=False` is used, then the setting is ignored, and the morphological analysis is performed with the default settings;\n",
    " * Be aware that: \n",
    "    * if `guess` is switched off, then punctuation symbols (such as `'.'`, `'!'`, `'?'`) also do not receive any analyses;\n",
    "    * **(!)** if `guess` and `propername` are switched off, but disambiguation is switched on, then an exception will be raised if there are unknown words and/or punctuation symbols in the text. This is because disambiguation requires that all words have been morphologically analysed; \n",
    "    \n",
    "      Note also that if you catch the exception, and proceed with the processing, then the Text object will still have layer `morph_analysis`. But the layer will be incomplete, as its analyses will be ambiguous and contain gaps in places of unknown words;\n",
    "    * **(!)** if `guess` and `propername` are switched off,  and you switch on the parameter `slang_lex` , then slang words, such as `\"kudas\"` or `\"muideks\"` , still get analyses and appear as \"known words\". So, if you want to detect all non-standard words, you should switch off the parameters `guess` and `propername` and refrain from switching on `slang_lex`;\n",
    " * Reordering ( `use_reorderer=True` ) only works with `disambiguate=True`;\n",
    " * In practice, parameters `compound`, `phonetic` and `stem` rarely need to be changed. So, it is advisable to change these parameters only when you really know, what you are doing ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:purple\"> Examples</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, two simple examples of using EstNLTK basic toolchain for extracting relevant parts of text are presented. Let's use the following short text as our corpus:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"Nagu nimigi reedab, on nurgasaag kõige tõhusam tööriist erinevate puitdetailide lõikamiseks, kus eesmärgiks on saavutada täpne lõikenurk ning oluline on lõikenurga seadistamise võimalus. Näiteks pildiraamide meisterdamisel, kus on oluline, et detailide lõikenurgad oleksid kõik täpselt 45 kraadi. Sellisel juhul on nurgasaag täiuslikuks tööriistaks, sest tagab täpsuse ja lõike korratavuse. Üldiselt on valdav osa nurgasaage seadistatavad 45-kraadise lõikenurga alla vähemalt ühes suunas. Lisaks võimaldavad mõned saed veel ka saetera kaldenurga seadistamist, mis tuleb kasuks keerukamate detailide lõikamisel. Nurgasaag on väga tõhus ka kitsamate, kuni 30 cm laiuste puulaudade või muude puitdetailide ristlõigete tegemiseks ehk järkamiseks, mida tuleb palju ette näiteks puitkonstruktsioonide ehitamisel või ka näiteks terrassilaudade või puitparketi paigaldamisel.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 1: Finding all different nouns from the text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's assume we want to find all different noun lemmas that appear in the text. So, first we have to turn our text into an EstNLTK Text object:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_text = Text(\"Nagu nimigi reedab, on nurgasaag kõige tõhusam tööriist erinevate puitdetailide lõikamiseks, kus eesmärgiks on saavutada täpne lõikenurk ning oluline on lõikenurga seadistamise võimalus. Näiteks pildiraamide meisterdamisel, kus on oluline, et detailide lõikenurgad oleksid kõik täpselt 45 kraadi. Sellisel juhul on nurgasaag täiuslikuks tööriistaks, sest tagab täpsuse ja lõike korratavuse. Üldiselt on valdav osa nurgasaage seadistatavad 45-kraadise lõikenurga alla vähemalt ühes suunas. Lisaks võimaldavad mõned saed veel ka saetera kaldenurga seadistamist, mis tuleb kasuks keerukamate detailide lõikamisel. Nurgasaag on väga tõhus ka kitsamate, kuni 30 cm laiuste puulaudade või muude puitdetailide ristlõigete tegemiseks ehk järkamiseks, mida tuleb palju ette näiteks puitkonstruktsioonide ehitamisel või ka näiteks terrassilaudade või puitparketi paigaldamisel.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td><div align = \"left\">Nagu nimigi reedab, on nurgasaag kõige tõhusam tööriist erinevate puitdetailide lõikamiseks, kus eesmärgiks on saavutada täpne lõikenurk ning oluline on lõikenurga seadistamise võimalus. Näiteks pildiraamide meisterdamisel, kus on oluline, et detailide lõikenurgad oleksid kõik täpselt 45 kraadi. Sellisel juhul on nurgasaag täiuslikuks tööriistaks, sest tagab täpsuse ja lõike korratavuse. Üldiselt on valdav osa nurgasaage seadistatavad 45-kraadise lõikenurga alla vähemalt ühes suunas. Lisaks võimaldavad mõned saed veel ka saetera kaldenurga seadistamist, mis tuleb kasuks keerukamate detailide lõikamisel. Nurgasaag on väga tõhus ka kitsamate, kuni 30 cm laiuste puulaudade või muude puitdetailide ristlõigete tegemiseks ehk järkamiseks, mida tuleb palju ette näiteks puitkonstruktsioonide ehitamisel või ka näiteks terrassilaudade või puitparketi paigaldamisel.</div></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "Text(text='Nagu nimigi reedab, on nurgasaag kõige tõhusam tööriist erinevate puitdetailide lõikamiseks, kus eesmärgiks on saavutada täpne lõikenurk ning oluline on lõikenurga seadistamise võimalus. Näiteks pildiraamide meisterdamisel, kus on oluline, et detailide lõikenurgad oleksid kõik täpselt 45 kraadi. Sellisel juhul on nurgasaag täiuslikuks tööriistaks, sest tagab täpsuse ja lõike korratavuse. Üldiselt on valdav osa nurgasaage seadistatavad 45-kraadise lõikenurga alla vähemalt ühes suunas. Lisaks võimaldavad mõned saed veel ka saetera kaldenurga seadistamist, mis tuleb kasuks keerukamate detailide lõikamisel. Nurgasaag on väga tõhus ka kitsamate, kuni 30 cm laiuste puulaudade või muude puitdetailide ristlõigete tegemiseks ehk järkamiseks, mida tuleb palju ette näiteks puitkonstruktsioonide ehitamisel või ka näiteks terrassilaudade või puitparketi paigaldamisel.')"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we need to let the taggers do their job. Let's use the automatic tag_layer() method for that:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td><div align = \"left\">Nagu nimigi reedab, on nurgasaag kõige tõhusam tööriist erinevate puitdetailide lõikamiseks, kus eesmärgiks on saavutada täpne lõikenurk ning oluline on lõikenurga seadistamise võimalus. Näiteks pildiraamide meisterdamisel, kus on oluline, et detailide lõikenurgad oleksid kõik täpselt 45 kraadi. Sellisel juhul on nurgasaag täiuslikuks tööriistaks, sest tagab täpsuse ja lõike korratavuse. Üldiselt on valdav osa nurgasaage seadistatavad 45-kraadise lõikenurga alla vähemalt ühes suunas. Lisaks võimaldavad mõned saed veel ka saetera kaldenurga seadistamist, mis tuleb kasuks keerukamate detailide lõikamisel. Nurgasaag on väga tõhus ka kitsamate, kuni 30 cm laiuste puulaudade või muude puitdetailide ristlõigete tegemiseks ehk järkamiseks, mida tuleb palju ette näiteks puitkonstruktsioonide ehitamisel või ka näiteks terrassilaudade või puitparketi paigaldamisel.</div></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>layer name</th>\n",
       "      <th>attributes</th>\n",
       "      <th>parent</th>\n",
       "      <th>enveloping</th>\n",
       "      <th>ambiguous</th>\n",
       "      <th>span count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>sentences</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>words</td>\n",
       "      <td>False</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>tokens</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>compound_tokens</td>\n",
       "      <td>type, normalized</td>\n",
       "      <td>None</td>\n",
       "      <td>tokens</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>words</td>\n",
       "      <td>normalized_form</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>morph_analysis</td>\n",
       "      <td>normalized_text, lemma, root, root_tokens, ending, clitic, form, partofspeech</td>\n",
       "      <td>words</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>122</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "Text(text='Nagu nimigi reedab, on nurgasaag kõige tõhusam tööriist erinevate puitdetailide lõikamiseks, kus eesmärgiks on saavutada täpne lõikenurk ning oluline on lõikenurga seadistamise võimalus. Näiteks pildiraamide meisterdamisel, kus on oluline, et detailide lõikenurgad oleksid kõik täpselt 45 kraadi. Sellisel juhul on nurgasaag täiuslikuks tööriistaks, sest tagab täpsuse ja lõike korratavuse. Üldiselt on valdav osa nurgasaage seadistatavad 45-kraadise lõikenurga alla vähemalt ühes suunas. Lisaks võimaldavad mõned saed veel ka saetera kaldenurga seadistamist, mis tuleb kasuks keerukamate detailide lõikamisel. Nurgasaag on väga tõhus ka kitsamate, kuni 30 cm laiuste puulaudade või muude puitdetailide ristlõigete tegemiseks ehk järkamiseks, mida tuleb palju ette näiteks puitkonstruktsioonide ehitamisel või ka näiteks terrassilaudade või puitparketi paigaldamisel.')"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_text.tag_layer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can iterate over the lemmas and part-of-speech tags to extract the lemmas that are tagged as nouns. For this, it's easiest to use the zip function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "noun_lemmas = []\n",
    "for lemma, postag in zip(my_text.lemma, my_text.partofspeech):\n",
    "    if 'S' in postag:\n",
    "        noun_lemmas += lemma"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NB!** Note that both, lemmas and part-of-speech tags for every word are given as a list, that's why we have to check if 'S' is in the postag and we cannot use `append` for adding the lemma to noun_lemmas list without iterating over each word's part-of-speech tags and lemmas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['nimi',\n",
       " 'nurgasaag',\n",
       " 'tööriist',\n",
       " 'puitdetail',\n",
       " 'lõikamine',\n",
       " 'eesmärk',\n",
       " 'lõikenurk',\n",
       " 'lõikenurk',\n",
       " 'seadistamine',\n",
       " 'võimalus',\n",
       " 'näide',\n",
       " 'pildiraam',\n",
       " 'meisterdamine',\n",
       " 'detail',\n",
       " 'lõikenurk',\n",
       " 'kraad',\n",
       " 'juht',\n",
       " 'nurgasaag',\n",
       " 'tööriist',\n",
       " 'täpsus',\n",
       " 'lõige',\n",
       " 'korratavus',\n",
       " 'osa',\n",
       " 'nurgasaag',\n",
       " 'lõikenurk',\n",
       " 'suund',\n",
       " 'lisa',\n",
       " 'saag',\n",
       " 'saetera',\n",
       " 'kaldenurk',\n",
       " 'seadistamine',\n",
       " 'kasu',\n",
       " 'detail',\n",
       " 'lõikamine',\n",
       " 'nurgasaag',\n",
       " 'laius',\n",
       " 'puulaud',\n",
       " 'puitdetail',\n",
       " 'ristlõige',\n",
       " 'tegemine',\n",
       " 'järkamine',\n",
       " 'näide',\n",
       " 'puitkonstruktsioon',\n",
       " 'ehitamine',\n",
       " 'näide',\n",
       " 'terrassilaud',\n",
       " 'puitparkett',\n",
       " 'paigaldamine']"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "noun_lemmas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case, we can easily guess what the specific text was about. If we had a larger corpus, we could make a frequency list and e.g draw some conclusions about topics/word use in a specific publication or variety of language in general."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 2: Finding all sentences that contain an infinitive verb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's assume we want to extract all sentences containing an infinitive verb form from a corpus. Let's use the same text as in the previous example. Therefore, we have already tagged the necessary layers and we can iterate over the forms and extract sentences that we want to study:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Nagu nimigi reedab, on nurgasaag kõige tõhusam tööriist erinevate puitdetailide lõikamiseks, kus eesmärgiks on saavutada täpne lõikenurk ning oluline on lõikenurga seadistamise võimalus.']"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "infinitive_sentences = []\n",
    "for sent in my_text.sentences:\n",
    "    for form in sent.form:\n",
    "        if 'da' in form:\n",
    "            a = sent.enclosing_text\n",
    "            infinitive_sentences.append(a)\n",
    "            break # not to include the same sentence twice)\n",
    "infinitive_sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  <span style=\"color:purple\"> Further details </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Further details about EstNLTK's NLP tools can be found from [nlp pipeline tutorials](../nlp_pipeline)."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
