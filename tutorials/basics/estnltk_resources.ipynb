{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0bccd790",
   "metadata": {},
   "source": [
    "## EstNLTK's resources\n",
    "\n",
    "As of version 1.7.0, EstNLTK contains tools for automatically downloading resources required by taggers and other tools. \n",
    "Resources are usually large (model) files, which are not included in the package and can be downloaded on user's demand. \n",
    "\n",
    "### In a nutshell\n",
    "\n",
    "For manually downloading a resource, use the function `download`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b803831b",
   "metadata": {
    "tags": [
     "nbval-skip"
    ]
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading udpipe_syntax_2021-05-29: 40.9MB [00:00, 79.9MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unpacked resource into subfolder 'udpipe_syntax/models_2021-05-29/' of the resources dir.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from estnltk import download\n",
    "# Download models for UDPipeTagger\n",
    "download('udpipetagger')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef3bb48a",
   "metadata": {},
   "source": [
    "The function returns True if the downloading was successful or if the resource already exists, and False otherwise.\n",
    "\n",
    "You can download a resource either by its alias (like in previous example: 'udpipetagger') or by its specific version name ('udpipe_syntax_2021-05-29' in the previous example).\n",
    "\n",
    "Use `ResourceView` to get an overview about EstNLTK's resources and their download status:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f51a0305",
   "metadata": {
    "tags": [
     "nbval-skip"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h4>ResourceView</h4>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>name</th>\n",
       "      <th>description</th>\n",
       "      <th>license</th>\n",
       "      <th>downloaded</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>collocation_net_2022-06-07</td>\n",
       "      <td>Files needed to use CollocationNet. Files include embeddings obtained from training Latent Dirichlet Allocation (LDA) models on different collocation types and example sentences.  (size: 2.8G)</td>\n",
       "      <td>CC BY-SA 4.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>estbert_from_tartunlp_hf_2022-03-10</td>\n",
       "      <td>Model for BertTagger and BertTransformer. BertTagger outputs token or word level embeddings. BertTransformer outputs sentence and word level embeddings. The original EstBERT model was trained on Estonian National Corpus 2017 by Hasan Tanvir, Claudia Kittask, Kairit Sirts. This version of the model is from huggingface tartuNLP/EstBERT commit e97f62c. More info: https://huggingface.co/tartuNLP/EstBERT  (size: 2.4G)</td>\n",
       "      <td>CC BY 4.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>stanza_syntax_2021-05-29</td>\n",
       "      <td>Models for StanzaSyntaxTagger and StanzaSyntaxEnsembleTagger. StanzaSyntaxTagger operates in three modes: - syntax prediction based on sentences - syntax prediction using morphological features generated by Vabamorf - syntax prediction using extended morphological features. Models for StanzaSyntaxEnsembleTagger are trained using extended morphological features. Corresponding models were trained by Sandra Eiche on Estonian Dependency Treebank with UD syntax annotations. Dependency parsing models and the directory 'ensemble_models' must be located in the root directory defining StanzaSyntaxTagger under the subdirectory stanza_resources/et/depparse. Pretrain model under the subdirectory stanza_resources/et/pretrain. For completeness, the file also includes original Stanford models: - directories pretrain, lemma, pos, tokenize - depparse/stanza_depparse.pt  (size: 1.4G)</td>\n",
       "      <td>CC BY-SA 4.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>maltparser_syntax_2021-05-29</td>\n",
       "      <td>Models for MaltparserTagger. MaltparserTagger operates in three modes: - syntax prediction using morphological features generated by Vabamorf - syntax prediction using extended morphological features. - syntax prediction using extended morphological features processed with VISLCG3 Pipeline. For the first two modes two types of dependency relations can be chosen from - UD or CG. Last mode can only be used for CG-type output. Corresponding models were trained by Claudia Kittask on Estonian Dependency Treebank. Dependency parsing models must be located in the root directory defining MaltparserTagger under the subdirectory java-res/maltparser.  (size: 128M)</td>\n",
       "      <td>CC BY-SA 4.0 + https://www.maltparser.org/license.html</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>udpipe_syntax_2021-05-29</td>\n",
       "      <td>Models for UDPipeTagger. UDPipeTagger operates in three modes: - syntax prediction using morphological features generated by Vabamorf - syntax prediction using extended morphological features. - syntax prediction using extended morphological features processed with VISLCG3 Pipeline. For all modes two types of dependency relations can be chosen from - UD or CG. Corresponding models were trained by Claudia Kittask on Estonian Dependency Treebank.  (size: 39M)</td>\n",
       "      <td>CC BY-SA 4.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>stanza_syntax_2020-11-30</td>\n",
       "      <td>Models for StanzaSyntaxTagger. StanzaSyntaxTagger operates in three modes: - syntax prediction based on sentences - syntax prediction using morphological features generated by Vabamorf - syntax prediction using extended morphological features. Corresponding models were trained by Sandra Eiche on Estonian Dependency Treebank with UD syntax annotations. Pretrain model under the subdirectory stanza_resources/et/pretrain. For completeness, the file also includes original Stanford models: - directories pretrain, lemma, pos, tokenize - depparse/stanza_depparse.pt  (size: 470M)</td>\n",
       "      <td>CC BY-SA 4.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>estbert_2020-10-20</td>\n",
       "      <td>Model for BertTagger and BertTransformer. BertTagger outputs token or word level embeddings. BertTransformer outputs sentence and word level embeddings. Corresponding EstBERT model was trained on Estonian National Corpus 2017 by Hasan Tanvir, Claudia Kittask, Kairit Sirts. When appropriate cite the article: EstBERT: A Pretrained Language-Specific BERT for Estonian https://arxiv.org/abs/2011.04784  (size: 476M)</td>\n",
       "      <td>CC BY 4.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>neural_morph_softmax_emb_cat_sum_2019-08-23</td>\n",
       "      <td>Model for SoftmaxEmbCatSumTagger (NeuralMorphTagger). All neural morphological disambiguation models were trained by Kermo Saarse and Kairit Sirts in June-August 2018 using High Performance Cluster in University of Tartu. Specific requirements: Python 3.7, tensorflow version &lt; 2.0, such as 1.15.5.  (size: 355M)</td>\n",
       "      <td>CC BY-SA 4.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>neural_morph_softmax_emb_tag_sum_2019-08-23</td>\n",
       "      <td>Model for SoftmaxEmbTagSumTagger (NeuralMorphTagger). All neural morphological disambiguation models were trained by Kermo Saarse and Kairit Sirts in June-August 2018 using High Performance Cluster in University of Tartu. Specific requirements: Python 3.7, tensorflow version &lt; 2.0, such as 1.15.5.  (size: 354M)</td>\n",
       "      <td>CC BY-SA 4.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>neural_morph_seq2seq_emb_cat_sum_2019-08-23</td>\n",
       "      <td>Model for Seq2SeqEmbCatSumTagger (NeuralMorphTagger). All neural morphological disambiguation models were trained by Kermo Saarse and Kairit Sirts in June-August 2018 using High Performance Cluster in University of Tartu. Specific requirements: Python 3.7, tensorflow version &lt; 2.0, such as 1.15.5.  (size: 366M)</td>\n",
       "      <td>CC BY-SA 4.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>neural_morph_seq2seq_emb_tag_sum_2019-08-23</td>\n",
       "      <td>Model for Seq2SeqEmbTagSumTagger (NeuralMorphTagger). All neural morphological disambiguation models were trained by Kermo Saarse and Kairit Sirts in June-August 2018 using High Performance Cluster in University of Tartu. Specific requirements: Python 3.7, tensorflow version &lt; 2.0, such as 1.15.5.  (size: 365M)</td>\n",
       "      <td>CC BY-SA 4.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>word2vec_lemmas_cbow_s100_2015-06-21</td>\n",
       "      <td>word2vec lemma-based embeddings model created by Alexander Tkachenko. More info: https://github.com/estnltk/word2vec-models  (size: 174M)</td>\n",
       "      <td>CC BY-SA 4.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>word2vec_lemmas_cbow_s200_2015-06-21</td>\n",
       "      <td>word2vec lemma-based embeddings model created by Alexander Tkachenko. More info: https://github.com/estnltk/word2vec-models  (size: 342M)</td>\n",
       "      <td>CC BY-SA 4.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>word2vec_lemmas_sg_s100_2015-06-21</td>\n",
       "      <td>word2vec lemma-based embeddings model created by Alexander Tkachenko. More info: https://github.com/estnltk/word2vec-models  (size: 174M)</td>\n",
       "      <td>CC BY-SA 4.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>word2vec_lemmas_sg_s200_2015-06-21</td>\n",
       "      <td>word2vec lemma-based embeddings model created by Alexander Tkachenko. More info: https://github.com/estnltk/word2vec-models  (size: 342M)</td>\n",
       "      <td>CC BY-SA 4.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>word2vec_words_cbow_s100_2015-06-21</td>\n",
       "      <td>word2vec word-based embeddings model created by Alexander Tkachenko. More info: https://github.com/estnltk/word2vec-models  (size: 322M)</td>\n",
       "      <td>CC BY-SA 4.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>word2vec_words_cbow_s200_2015-06-21</td>\n",
       "      <td>word2vec word-based embeddings model created by Alexander Tkachenko. More info: https://github.com/estnltk/word2vec-models  (size: 633M)</td>\n",
       "      <td>CC BY-SA 4.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>word2vec_words_sg_s100_2015-06-21</td>\n",
       "      <td>word2vec word-based embeddings model created by Alexander Tkachenko. More info: https://github.com/estnltk/word2vec-models  (size: 322M)</td>\n",
       "      <td>CC BY-SA 4.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>word2vec_words_sg_s200_2015-06-21</td>\n",
       "      <td>word2vec word-based embeddings model created by Alexander Tkachenko. More info: https://github.com/estnltk/word2vec-models  (size: 633M)</td>\n",
       "      <td>CC BY-SA 4.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "ResourceView\n",
       "name                  description                            license                    downloaded  \n",
       "====                  ===========                            =======                    ==========  \n",
       "\n",
       "collocation_net_2022  Files needed to use CollocationNet.    CC BY-SA 4.0               False       \n",
       "-06-07                Files include embeddings obtained                                             \n",
       "                      from training Latent Dirichlet                                                \n",
       "                      Allocation (LDA) models on different                                          \n",
       "                      collocation types and example                                                 \n",
       "                      sentences.  (size: 2.8G)                                                      \n",
       "\n",
       "estbert_from_tartunl  Model for BertTagger and               CC BY 4.0                  False       \n",
       "p_hf_2022-03-10       BertTransformer. BertTagger outputs                                           \n",
       "                      token or word level embeddings.                                               \n",
       "                      BertTransformer outputs sentence and                                          \n",
       "                      word level embeddings. The original                                           \n",
       "                      EstBERT model was trained on Estonian                                         \n",
       "                      National Corpus 2017 by Hasan Tanvir,                                         \n",
       "                      Claudia Kittask, Kairit Sirts. This                                           \n",
       "                      version of the model is from                                                  \n",
       "                      huggingface tartuNLP/EstBERT commit                                           \n",
       "                      e97f62c. More info: https://huggingfa                                         \n",
       "                      ce.co/tartuNLP/EstBERT  (size: 2.4G)                                          \n",
       "\n",
       "stanza_syntax_2021-0  Models for StanzaSyntaxTagger and      CC BY-SA 4.0               False       \n",
       "5-29                  StanzaSyntaxEnsembleTagger.                                                   \n",
       "                      StanzaSyntaxTagger operates in three                                          \n",
       "                      modes: - syntax prediction based on                                           \n",
       "                      sentences - syntax prediction using                                           \n",
       "                      morphological features generated by                                           \n",
       "                      Vabamorf - syntax prediction using                                            \n",
       "                      extended morphological features.                                              \n",
       "                      Models for StanzaSyntaxEnsembleTagger                                         \n",
       "                      are trained using extended                                                    \n",
       "                      morphological features. Corresponding                                         \n",
       "                      models were trained by Sandra Eiche                                           \n",
       "                      on Estonian Dependency Treebank with                                          \n",
       "                      UD syntax annotations. Dependency                                             \n",
       "                      parsing models and the directory                                              \n",
       "                      'ensemble_models' must be located in                                          \n",
       "                      the root directory defining                                                   \n",
       "                      StanzaSyntaxTagger under the                                                  \n",
       "                      subdirectory                                                                  \n",
       "                      stanza_resources/et/depparse.                                                 \n",
       "                      Pretrain model under the subdirectory                                         \n",
       "                      stanza_resources/et/pretrain. For                                             \n",
       "                      completeness, the file also includes                                          \n",
       "                      original Stanford models: -                                                   \n",
       "                      directories pretrain, lemma, pos,                                             \n",
       "                      tokenize -                                                                    \n",
       "                      depparse/stanza_depparse.pt  (size:                                           \n",
       "                      1.4G)                                                                         \n",
       "\n",
       "maltparser_syntax_20  Models for MaltparserTagger.           CC BY-SA 4.0 + https://ww  False       \n",
       "21-05-29              MaltparserTagger operates in three     w.maltparser.org/license.              \n",
       "                      modes: - syntax prediction using       html                                   \n",
       "                      morphological features generated by                                           \n",
       "                      Vabamorf - syntax prediction using                                            \n",
       "                      extended morphological features. -                                            \n",
       "                      syntax prediction using extended                                              \n",
       "                      morphological features processed with                                         \n",
       "                      VISLCG3 Pipeline. For the first two                                           \n",
       "                      modes two types of dependency                                                 \n",
       "                      relations can be chosen from - UD or                                          \n",
       "                      CG. Last mode can only be used for                                            \n",
       "                      CG-type output. Corresponding models                                          \n",
       "                      were trained by Claudia Kittask on                                            \n",
       "                      Estonian Dependency Treebank.                                                 \n",
       "                      Dependency parsing models must be                                             \n",
       "                      located in the root directory                                                 \n",
       "                      defining MaltparserTagger under the                                           \n",
       "                      subdirectory java-res/maltparser.                                             \n",
       "                      (size: 128M)                                                                  \n",
       "\n",
       "udpipe_syntax_2021-0  Models for UDPipeTagger. UDPipeTagger  CC BY-SA 4.0               True        \n",
       "5-29                  operates in three modes: - syntax                                             \n",
       "                      prediction using morphological                                                \n",
       "                      features generated by Vabamorf -                                              \n",
       "                      syntax prediction using extended                                              \n",
       "                      morphological features. - syntax                                              \n",
       "                      prediction using extended                                                     \n",
       "                      morphological features processed with                                         \n",
       "                      VISLCG3 Pipeline. For all modes two                                           \n",
       "                      types of dependency relations can be                                          \n",
       "                      chosen from - UD or CG. Corresponding                                         \n",
       "                      models were trained by Claudia                                                \n",
       "                      Kittask on Estonian Dependency                                                \n",
       "                      Treebank.  (size: 39M)                                                        \n",
       "\n",
       "stanza_syntax_2020-1  Models for StanzaSyntaxTagger.         CC BY-SA 4.0               False       \n",
       "1-30                  StanzaSyntaxTagger operates in three                                          \n",
       "                      modes: - syntax prediction based on                                           \n",
       "                      sentences - syntax prediction using                                           \n",
       "                      morphological features generated by                                           \n",
       "                      Vabamorf - syntax prediction using                                            \n",
       "                      extended morphological features.                                              \n",
       "                      Corresponding models were trained by                                          \n",
       "                      Sandra Eiche on Estonian Dependency                                           \n",
       "                      Treebank with UD syntax annotations.                                          \n",
       "                      Pretrain model under the subdirectory                                         \n",
       "                      stanza_resources/et/pretrain. For                                             \n",
       "                      completeness, the file also includes                                          \n",
       "                      original Stanford models: -                                                   \n",
       "                      directories pretrain, lemma, pos,                                             \n",
       "                      tokenize -                                                                    \n",
       "                      depparse/stanza_depparse.pt  (size:                                           \n",
       "                      470M)                                                                         \n",
       "\n",
       "estbert_2020-10-20    Model for BertTagger and               CC BY 4.0                  False       \n",
       "                      BertTransformer. BertTagger outputs                                           \n",
       "                      token or word level embeddings.                                               \n",
       "                      BertTransformer outputs sentence and                                          \n",
       "                      word level embeddings. Corresponding                                          \n",
       "                      EstBERT model was trained on Estonian                                         \n",
       "                      National Corpus 2017 by Hasan Tanvir,                                         \n",
       "                      Claudia Kittask, Kairit Sirts. When                                           \n",
       "                      appropriate cite the article:                                                 \n",
       "                      EstBERT: A Pretrained Language-                                               \n",
       "                      Specific BERT for Estonian                                                    \n",
       "                      https://arxiv.org/abs/2011.04784                                              \n",
       "                      (size: 476M)                                                                  \n",
       "\n",
       "neural_morph_softmax  Model for SoftmaxEmbCatSumTagger       CC BY-SA 4.0               False       \n",
       "_emb_cat_sum_2019-08  (NeuralMorphTagger). All neural                                               \n",
       "-23                   morphological disambiguation models                                           \n",
       "                      were trained by Kermo Saarse and                                              \n",
       "                      Kairit Sirts in June-August 2018                                              \n",
       "                      using High Performance Cluster in                                             \n",
       "                      University of Tartu. Specific                                                 \n",
       "                      requirements: Python 3.7, tensorflow                                          \n",
       "                      version < 2.0, such as 1.15.5.                                                \n",
       "                      (size: 355M)                                                                  \n",
       "\n",
       "neural_morph_softmax  Model for SoftmaxEmbTagSumTagger       CC BY-SA 4.0               False       \n",
       "_emb_tag_sum_2019-08  (NeuralMorphTagger). All neural                                               \n",
       "-23                   morphological disambiguation models                                           \n",
       "                      were trained by Kermo Saarse and                                              \n",
       "                      Kairit Sirts in June-August 2018                                              \n",
       "                      using High Performance Cluster in                                             \n",
       "                      University of Tartu. Specific                                                 \n",
       "                      requirements: Python 3.7, tensorflow                                          \n",
       "                      version < 2.0, such as 1.15.5.                                                \n",
       "                      (size: 354M)                                                                  \n",
       "\n",
       "neural_morph_seq2seq  Model for Seq2SeqEmbCatSumTagger       CC BY-SA 4.0               False       \n",
       "_emb_cat_sum_2019-08  (NeuralMorphTagger). All neural                                               \n",
       "-23                   morphological disambiguation models                                           \n",
       "                      were trained by Kermo Saarse and                                              \n",
       "                      Kairit Sirts in June-August 2018                                              \n",
       "                      using High Performance Cluster in                                             \n",
       "                      University of Tartu. Specific                                                 \n",
       "                      requirements: Python 3.7, tensorflow                                          \n",
       "                      version < 2.0, such as 1.15.5.                                                \n",
       "                      (size: 366M)                                                                  \n",
       "\n",
       "neural_morph_seq2seq  Model for Seq2SeqEmbTagSumTagger       CC BY-SA 4.0               False       \n",
       "_emb_tag_sum_2019-08  (NeuralMorphTagger). All neural                                               \n",
       "-23                   morphological disambiguation models                                           \n",
       "                      were trained by Kermo Saarse and                                              \n",
       "                      Kairit Sirts in June-August 2018                                              \n",
       "                      using High Performance Cluster in                                             \n",
       "                      University of Tartu. Specific                                                 \n",
       "                      requirements: Python 3.7, tensorflow                                          \n",
       "                      version < 2.0, such as 1.15.5.                                                \n",
       "                      (size: 365M)                                                                  \n",
       "\n",
       "word2vec_lemmas_cbow  word2vec lemma-based embeddings model  CC BY-SA 4.0               False       \n",
       "_s100_2015-06-21      created by Alexander Tkachenko. More                                          \n",
       "                      info:                                                                         \n",
       "                      https://github.com/estnltk/word2vec-                                          \n",
       "                      models  (size: 174M)                                                          \n",
       "\n",
       "word2vec_lemmas_cbow  word2vec lemma-based embeddings model  CC BY-SA 4.0               False       \n",
       "_s200_2015-06-21      created by Alexander Tkachenko. More                                          \n",
       "                      info:                                                                         \n",
       "                      https://github.com/estnltk/word2vec-                                          \n",
       "                      models  (size: 342M)                                                          \n",
       "\n",
       "word2vec_lemmas_sg_s  word2vec lemma-based embeddings model  CC BY-SA 4.0               False       \n",
       "100_2015-06-21        created by Alexander Tkachenko. More                                          \n",
       "                      info:                                                                         \n",
       "                      https://github.com/estnltk/word2vec-                                          \n",
       "                      models  (size: 174M)                                                          \n",
       "\n",
       "word2vec_lemmas_sg_s  word2vec lemma-based embeddings model  CC BY-SA 4.0               False       \n",
       "200_2015-06-21        created by Alexander Tkachenko. More                                          \n",
       "                      info:                                                                         \n",
       "                      https://github.com/estnltk/word2vec-                                          \n",
       "                      models  (size: 342M)                                                          \n",
       "\n",
       "word2vec_words_cbow_  word2vec word-based embeddings model   CC BY-SA 4.0               False       \n",
       "s100_2015-06-21       created by Alexander Tkachenko. More                                          \n",
       "                      info:                                                                         \n",
       "                      https://github.com/estnltk/word2vec-                                          \n",
       "                      models  (size: 322M)                                                          \n",
       "\n",
       "word2vec_words_cbow_  word2vec word-based embeddings model   CC BY-SA 4.0               False       \n",
       "s200_2015-06-21       created by Alexander Tkachenko. More                                          \n",
       "                      info:                                                                         \n",
       "                      https://github.com/estnltk/word2vec-                                          \n",
       "                      models  (size: 633M)                                                          \n",
       "\n",
       "word2vec_words_sg_s1  word2vec word-based embeddings model   CC BY-SA 4.0               False       \n",
       "00_2015-06-21         created by Alexander Tkachenko. More                                          \n",
       "                      info:                                                                         \n",
       "                      https://github.com/estnltk/word2vec-                                          \n",
       "                      models  (size: 322M)                                                          \n",
       "\n",
       "word2vec_words_sg_s2  word2vec word-based embeddings model   CC BY-SA 4.0               False       \n",
       "00_2015-06-21         created by Alexander Tkachenko. More                                          \n",
       "                      info:                                                                         \n",
       "                      https://github.com/estnltk/word2vec-                                          \n",
       "                      models  (size: 633M)                                                          \n"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from estnltk import ResourceView\n",
    "ResourceView()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa1dff90",
   "metadata": {},
   "source": [
    "The information in `ResourceView` table is based on the resources index json file: https://github.com/estnltk/estnltk_resources.\n",
    "The index file gives detailed information about each resource, such as resource description, size, url, license, and unpacking path relative to the resources directory."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "941976a5",
   "metadata": {},
   "source": [
    "**Downloading all resources.** By default, only one version -- the latest version -- of the resource will be downloaded, even if there are multiple resources available.\n",
    "However, if you set `only_latest=False`, then all resources with the given alias will be downloaded:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5489da0a",
   "metadata": {
    "tags": [
     "nbval-skip"
    ]
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading word2vec_lemmas_sg_s100_2015-06-21: 169MB [00:01, 86.0MB/s] \n",
      "Downloading word2vec_lemmas_sg_s200_2015-06-21: 333MB [00:04, 76.7MB/s] \n",
      "Downloading word2vec_words_sg_s100_2015-06-21: 313MB [00:03, 88.7MB/s] \n",
      "Downloading word2vec_words_sg_s200_2015-06-21: 616MB [00:09, 68.4MB/s] \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Download all word2vec skip-gram models (alias: 'word2vec_sg')\n",
    "download('word2vec_sg', only_latest=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78c101b5",
   "metadata": {},
   "source": [
    "Use `ResourceView` to see which resources have been downloaded:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3c1be2d1",
   "metadata": {
    "tags": [
     "nbval-skip"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h4>ResourceView</h4>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>name</th>\n",
       "      <th>description</th>\n",
       "      <th>license</th>\n",
       "      <th>downloaded</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>udpipe_syntax_2021-05-29</td>\n",
       "      <td>Models for UDPipeTagger. UDPipeTagger operates in three modes: - syntax prediction using morphological features generated by Vabamorf - syntax prediction using extended morphological features. - syntax prediction using extended morphological features processed with VISLCG3 Pipeline. For all modes two types of dependency relations can be chosen from - UD or CG. Corresponding models were trained by Claudia Kittask on Estonian Dependency Treebank.  (size: 39M)</td>\n",
       "      <td>CC BY-SA 4.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>word2vec_lemmas_sg_s100_2015-06-21</td>\n",
       "      <td>word2vec lemma-based embeddings model created by Alexander Tkachenko. More info: https://github.com/estnltk/word2vec-models  (size: 174M)</td>\n",
       "      <td>CC BY-SA 4.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>word2vec_lemmas_sg_s200_2015-06-21</td>\n",
       "      <td>word2vec lemma-based embeddings model created by Alexander Tkachenko. More info: https://github.com/estnltk/word2vec-models  (size: 342M)</td>\n",
       "      <td>CC BY-SA 4.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>word2vec_words_sg_s100_2015-06-21</td>\n",
       "      <td>word2vec word-based embeddings model created by Alexander Tkachenko. More info: https://github.com/estnltk/word2vec-models  (size: 322M)</td>\n",
       "      <td>CC BY-SA 4.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>word2vec_words_sg_s200_2015-06-21</td>\n",
       "      <td>word2vec word-based embeddings model created by Alexander Tkachenko. More info: https://github.com/estnltk/word2vec-models  (size: 633M)</td>\n",
       "      <td>CC BY-SA 4.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "ResourceView\n",
       "name                  description                            license                    downloaded  \n",
       "====                  ===========                            =======                    ==========  \n",
       "\n",
       "udpipe_syntax_2021-0  Models for UDPipeTagger. UDPipeTagger  CC BY-SA 4.0               True        \n",
       "5-29                  operates in three modes: - syntax                                             \n",
       "                      prediction using morphological                                                \n",
       "                      features generated by Vabamorf -                                              \n",
       "                      syntax prediction using extended                                              \n",
       "                      morphological features. - syntax                                              \n",
       "                      prediction using extended                                                     \n",
       "                      morphological features processed with                                         \n",
       "                      VISLCG3 Pipeline. For all modes two                                           \n",
       "                      types of dependency relations can be                                          \n",
       "                      chosen from - UD or CG. Corresponding                                         \n",
       "                      models were trained by Claudia                                                \n",
       "                      Kittask on Estonian Dependency                                                \n",
       "                      Treebank.  (size: 39M)                                                        \n",
       "\n",
       "word2vec_lemmas_sg_s  word2vec lemma-based embeddings model  CC BY-SA 4.0               True        \n",
       "100_2015-06-21        created by Alexander Tkachenko. More                                          \n",
       "                      info:                                                                         \n",
       "                      https://github.com/estnltk/word2vec-                                          \n",
       "                      models  (size: 174M)                                                          \n",
       "\n",
       "word2vec_lemmas_sg_s  word2vec lemma-based embeddings model  CC BY-SA 4.0               True        \n",
       "200_2015-06-21        created by Alexander Tkachenko. More                                          \n",
       "                      info:                                                                         \n",
       "                      https://github.com/estnltk/word2vec-                                          \n",
       "                      models  (size: 342M)                                                          \n",
       "\n",
       "word2vec_words_sg_s1  word2vec word-based embeddings model   CC BY-SA 4.0               True        \n",
       "00_2015-06-21         created by Alexander Tkachenko. More                                          \n",
       "                      info:                                                                         \n",
       "                      https://github.com/estnltk/word2vec-                                          \n",
       "                      models  (size: 322M)                                                          \n",
       "\n",
       "word2vec_words_sg_s2  word2vec word-based embeddings model   CC BY-SA 4.0               True        \n",
       "00_2015-06-21         created by Alexander Tkachenko. More                                          \n",
       "                      info:                                                                         \n",
       "                      https://github.com/estnltk/word2vec-                                          \n",
       "                      models  (size: 633M)                                                          \n"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Browse only downloaded resources\n",
    "ResourceView(downloaded=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eee6321f",
   "metadata": {},
   "source": [
    "### Where to find downloaded resources?\n",
    "\n",
    "EstNLTK provides function `get_resource_paths`, which returns a list of all paths to downloaded resources associated with the given name or alias:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4f6d5d8b",
   "metadata": {
    "tags": [
     "nbval-skip"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['C:\\\\Programmid\\\\Miniconda3\\\\envs\\\\py39_devel\\\\lib\\\\site-packages\\\\estnltk-1.7.0-py3.9-win-amd64.egg\\\\estnltk\\\\estnltk_resources\\\\udpipe_syntax\\\\models_2021-05-29\\\\']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from estnltk import get_resource_paths\n",
    "# Get paths to downloaded UDPipeTagger's models\n",
    "get_resource_paths('udpipetagger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "76dbf1ca",
   "metadata": {
    "tags": [
     "nbval-skip"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['C:\\\\Programmid\\\\Miniconda3\\\\envs\\\\py39_devel\\\\lib\\\\site-packages\\\\estnltk-1.7.0-py3.9-win-amd64.egg\\\\estnltk\\\\estnltk_resources\\\\word2vec\\\\embeddings_2015-06-21\\\\lemmas.sg.s100.w2v.bin',\n",
       " 'C:\\\\Programmid\\\\Miniconda3\\\\envs\\\\py39_devel\\\\lib\\\\site-packages\\\\estnltk-1.7.0-py3.9-win-amd64.egg\\\\estnltk\\\\estnltk_resources\\\\word2vec\\\\embeddings_2015-06-21\\\\lemmas.sg.s200.w2v.bin',\n",
       " 'C:\\\\Programmid\\\\Miniconda3\\\\envs\\\\py39_devel\\\\lib\\\\site-packages\\\\estnltk-1.7.0-py3.9-win-amd64.egg\\\\estnltk\\\\estnltk_resources\\\\word2vec\\\\embeddings_2015-06-21\\\\words.sg.s100.w2v.bin',\n",
       " 'C:\\\\Programmid\\\\Miniconda3\\\\envs\\\\py39_devel\\\\lib\\\\site-packages\\\\estnltk-1.7.0-py3.9-win-amd64.egg\\\\estnltk\\\\estnltk_resources\\\\word2vec\\\\embeddings_2015-06-21\\\\words.sg.s200.w2v.bin']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get paths to downloaded word2vec skip-gram models\n",
    "get_resource_paths('word2vec_sg')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e34a377",
   "metadata": {},
   "source": [
    "The function returns an empty list if the resource has not been downloaded yet (or if there is no such resource):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cc31a7b1",
   "metadata": {
    "tags": [
     "nbval-skip"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get paths to downloaded stanzatagger's models\n",
    "get_resource_paths('stanzatagger')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e979baf5",
   "metadata": {},
   "source": [
    "If there are multiple versions of the resource, then versions are _sorted by resource dates_ : the latest resources come first in the list.\n",
    "\n",
    "You can request only a single resource (the latest resource) by setting `only_latest=True`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a7dfc395",
   "metadata": {
    "tags": [
     "nbval-skip"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Programmid\\\\Miniconda3\\\\envs\\\\py39_devel\\\\lib\\\\site-packages\\\\estnltk-1.7.0-py3.9-win-amd64.egg\\\\estnltk\\\\estnltk_resources\\\\word2vec\\\\embeddings_2015-06-21\\\\lemmas.sg.s100.w2v.bin'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_resource_paths('word2vec_sg', only_latest=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8461597b",
   "metadata": {},
   "source": [
    "Note that this returns a string instead of a list. \n",
    "And if the requested resource is missing, `None` value will be returned."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e33146d1",
   "metadata": {},
   "source": [
    "### Where is the resources directory and how to change it?\n",
    "\n",
    "By default, EstNLTK attempts to download resources into sub directory `estnltk_resources` inside the installation directory of the `estnltk` package.\n",
    "If that fails (e.g. due to insufficient permissions), then EstNLTK creates sub directory `estnltk_resources` into [user's home directory](https://docs.python.org/3/library/pathlib.html#pathlib.Path.home) and stores resources there. \n",
    "\n",
    "If you want to force your own resources location, then you can set system environment variable ESTNLTK_RESOURCES to a full path of the new resources directory.\n",
    "Note that this must be an existing directory where writing is permitted.\n",
    "Naturally, the environment variable should be set _before_ downloading any resources."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b412781d",
   "metadata": {},
   "source": [
    "### Removing resources\n",
    "\n",
    "Use the function `delete_resource` to remove a downloaded resource:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1d589d70",
   "metadata": {
    "tags": [
     "nbval-skip"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from estnltk.resource_utils import delete_resource\n",
    "delete_resource('word2vec_words_sg_s100_2015-06-21')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62d65dc0",
   "metadata": {},
   "source": [
    "The function returns True in case of a successful deletion. \n",
    "Note that resources can be deleted only by their specific names, not by their aliases.\n",
    "E.g. `delete_resource('word2vec_sg')` would not have worked in the previous example."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf1d93fd",
   "metadata": {},
   "source": [
    "### Integrating automatic resource downloading ( for developers )\n",
    "\n",
    "If you are creating a tagger that needs some of external / downloadable resources, then you can use the function `get_resource_paths` with the autodownload option.\n",
    "\n",
    "Namely, if you set `download_missing=True` and the requested resource has not been downloaded yet, then the user will be prompted with a question asking for a permission to download the missing resource. \n",
    "If the user gives the permission, then the resource will be downloaded automatically and it's path will be returned as a result:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "342e064a",
   "metadata": {
    "tags": [
     "nbval-skip"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This requires downloading resource 'word2vec_words_sg_s100_2015-06-21' (size: 322M). Proceed with downloading? [Y/n] Y\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading word2vec_words_sg_s100_2015-06-21: 313MB [00:04, 72.9MB/s] \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'C:\\\\Programmid\\\\Miniconda3\\\\envs\\\\py39_devel\\\\lib\\\\site-packages\\\\estnltk-1.7.0-py3.9-win-amd64.egg\\\\estnltk\\\\estnltk_resources\\\\word2vec\\\\embeddings_2015-06-21\\\\words.sg.s100.w2v.bin'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from estnltk.downloader import get_resource_paths\n",
    "get_resource_paths('word2vec_words_sg_s100_2015-06-21', only_latest=True, download_missing=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d943c81e",
   "metadata": {},
   "source": [
    "So, you can use `get_resource_paths` in the constructor of a tagger to get the path to a required resource regardless its download state: if the resource is missing, it will be downloaded automatically (if user permits it)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
