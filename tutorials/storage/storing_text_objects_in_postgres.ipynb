{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Storing of `Text` objects in a PostgreSQL database"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This tutorial demonstrates how to store and query EstNLTK `Text` objects in a PostgreSQL database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from estnltk import Text, logger\n",
    "from estnltk.taggers import VabamorfTagger, WordTagger\n",
    "from estnltk.storage.postgres import PostgresStorage, create_schema, delete_schema\n",
    "from estnltk.storage.postgres import LayerQuery, SubstringQuery, IndexQuery, MetadataQuery"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Access to the database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:storage.py:41: connecting to host: 'localhost', port: '5432', dbname: 'test_db', user: 'postgres'\n",
      "INFO:storage.py:58: schema: 'my_schema', temporary: False, role: 'postgres'\n"
     ]
    }
   ],
   "source": [
    "storage = PostgresStorage(host=None,\n",
    "                          port=None,\n",
    "                          dbname='test_db',\n",
    "                          user=None,\n",
    "                          password=None,\n",
    "                          pgpass_file='~/.pgpass',\n",
    "                          schema='my_schema',\n",
    "                          role=None,\n",
    "                          temporary=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If any of the parameters `host`, `port`, `dbname`, `user` or `password` is `None` then the missing values are searced from the `pgpass_file`. The first line of the file that matches the given arguments is used to connect to an existing PostgreSQL database.\n",
    "\n",
    "File line format:\n",
    "\n",
    "    host:port:dbname:user:password\n",
    " \n",
    "Example file contents:\n",
    "\n",
    "    # host:port:dbname:user:password\n",
    "    localhost:5432:test_db:username:password\n",
    "    example.com:5432:*:exampleuser:kj3dno34"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create schema\n",
    "\n",
    "Probably the schema is already set up in the database. If not and you have enough privileges, you can create one:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "create_schema(storage)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create collections\n",
    "\n",
    "Now, new collections can be created and displayed. Collection stores `Text` objects in the database and provides a read/write API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:collection.py:92: new empty collection 'my_first_collection' created\n",
      "INFO:collection.py:92: new empty collection 'my_second_collection' created\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<b>PostgresStorage</b><br/>\n",
       "user=postgres password=xxx dbname=test_db host=localhost port=5432 schema=my_schema<br/>temporary=False<br/>\n",
       "collection count: 2\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>rows</th>\n",
       "      <th>total_size</th>\n",
       "      <th>comment</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>collection</th>\n",
       "      <th>version</th>\n",
       "      <th>relations</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">my_first_collection</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">2.0</th>\n",
       "      <th></th>\n",
       "      <td>0</td>\n",
       "      <td>32 kB</td>\n",
       "      <td>first demo collection</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>structure</th>\n",
       "      <td>0</td>\n",
       "      <td>16 kB</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">my_second_collection</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">2.0</th>\n",
       "      <th></th>\n",
       "      <td>0</td>\n",
       "      <td>32 kB</td>\n",
       "      <td>second demo collection</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>structure</th>\n",
       "      <td>0</td>\n",
       "      <td>16 kB</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<estnltk.storage.postgres.storage.PostgresStorage at 0x2ac7406b790>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "storage['my_first_collection'].create('first demo collection')\n",
    "storage['my_second_collection'].create('second demo collection')\n",
    "storage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The collection names as a list of strings is also available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['my_first_collection', 'my_second_collection']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "storage.collections"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Derive and display a collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<b>PgCollection</b><br/><b>name:</b> my_first_collection<br/><b>storage:</b> PostgresStorage(user=postgres password=xxx dbname=test_db host=localhost port=5432 schema=my_schema temporary=False)<br/><b>count objects:</b> 0<br/><b>Metadata</b><br/>This collection has no metadata.<br/><b>Layers</b><br/>unknown"
      ],
      "text/plain": [
       "<estnltk.storage.postgres.collection.PgCollection at 0x2ac6abbf700>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collection = storage['my_first_collection']\n",
    "collection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Delete collections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "del storage['my_first_collection']\n",
    "# or\n",
    "storage['my_second_collection'].delete()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and the storage is empty again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<b>PostgresStorage</b><br/>\n",
       "user=postgres password=xxx dbname=test_db host=localhost port=5432 schema=my_schema<br/>temporary=False<br/>\n",
       "collection count: 0\n",
       "<br/>This storage has no collections."
      ],
      "text/plain": [
       "<estnltk.storage.postgres.storage.PostgresStorage at 0x2ac7406b790>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "storage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add texts\n",
    "\n",
    "Let's create a new collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:collection.py:92: new empty collection 'my_collection' created\n"
     ]
    }
   ],
   "source": [
    "collection = storage[\"my_collection\"].create(description='demo collection', meta={'author': 'str'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and add some data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:collection_text_object_inserter.py:107: inserted 3 texts into the collection 'my_collection'\n"
     ]
    }
   ],
   "source": [
    "with collection.insert() as collection_insert:\n",
    "    text1 = Text('Ööbik laulab.').tag_layer(['morph_analysis'])\n",
    "    text1.meta['author'] = 'Kõivupuu'\n",
    "    collection_insert(text1, meta_data=text1.meta)\n",
    "\n",
    "    text2 = Text('Öökull ei laula.').tag_layer(['morph_analysis'])\n",
    "    text2.meta['author'] = 'Niinepuu'\n",
    "    key2 = collection_insert(text2, meta_data=text2.meta)\n",
    "    \n",
    "    text3 = Text('Karu magab.').tag_layer(['morph_analysis'])\n",
    "    text3.meta['author'] = 'Niinemets'\n",
    "    key3 = collection_insert(text3, meta_data=text3.meta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All inserted `Text` objects must have the same layers.\n",
    "\n",
    "You can see what's inside"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<b>PgCollection</b><br/><b>name:</b> my_collection<br/><b>storage:</b> PostgresStorage(user=postgres password=xxx dbname=test_db host=localhost port=5432 schema=my_schema temporary=False)<br/><b>count objects:</b> 3<br/><b>Metadata</b><br/><table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>data type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>author</th>\n",
       "      <td>text</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><b>Layers</b><table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>layer_type</th>\n",
       "      <th>attributes</th>\n",
       "      <th>ambiguous</th>\n",
       "      <th>parent</th>\n",
       "      <th>enveloping</th>\n",
       "      <th>meta</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>words</th>\n",
       "      <td>attached</td>\n",
       "      <td>(normalized_form,)</td>\n",
       "      <td>True</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>compound_tokens</th>\n",
       "      <td>attached</td>\n",
       "      <td>(type, normalized)</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>tokens</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sentences</th>\n",
       "      <td>attached</td>\n",
       "      <td>()</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>words</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>morph_analysis</th>\n",
       "      <td>attached</td>\n",
       "      <td>(normalized_text, lemma, root, root_tokens, ending, clitic, form, partofspeech)</td>\n",
       "      <td>True</td>\n",
       "      <td>words</td>\n",
       "      <td>None</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tokens</th>\n",
       "      <td>attached</td>\n",
       "      <td>()</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<estnltk.storage.postgres.collection.PgCollection at 0x2ac7406b0a0>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The layers inserted with the `Text` objects are stored in the same database table with the `Text` object and are called **attached** layers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create layers\n",
    "\n",
    "The `create_layer` method creates a new layer for every `Text` object in the collection. These layers are stored in separate database files and are called **detached** layers. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:collection.py:634: collection: 'my_collection'\n",
      "INFO:collection.py:653: preparing to create a new layer: 'detached_morph_1'\n",
      "INFO:collection.py:685: inserting data into the 'detached_morph_1' layer table\n",
      "INFO:collection_detached_layer_inserter.py:70: inserted 3 detached 'detached_morph_1' layers into the collection 'my_collection'\n",
      "INFO:collection.py:719: layer created: 'detached_morph_1'\n",
      "INFO:collection.py:634: collection: 'my_collection'\n",
      "INFO:collection.py:653: preparing to create a new layer: 'detached_morph_2'\n",
      "INFO:collection.py:685: inserting data into the 'detached_morph_2' layer table\n",
      "INFO:collection_detached_layer_inserter.py:70: inserted 3 detached 'detached_morph_2' layers into the collection 'my_collection'\n",
      "INFO:collection.py:719: layer created: 'detached_morph_2'\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<b>PgCollection</b><br/><b>name:</b> my_collection<br/><b>storage:</b> PostgresStorage(user=postgres password=xxx dbname=test_db host=localhost port=5432 schema=my_schema temporary=False)<br/><b>count objects:</b> 3<br/><b>Metadata</b><br/><table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>data type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>author</th>\n",
       "      <td>text</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><b>Layers</b><table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>layer_type</th>\n",
       "      <th>attributes</th>\n",
       "      <th>ambiguous</th>\n",
       "      <th>parent</th>\n",
       "      <th>enveloping</th>\n",
       "      <th>meta</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>words</th>\n",
       "      <td>attached</td>\n",
       "      <td>(normalized_form,)</td>\n",
       "      <td>True</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>compound_tokens</th>\n",
       "      <td>attached</td>\n",
       "      <td>(type, normalized)</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>tokens</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sentences</th>\n",
       "      <td>attached</td>\n",
       "      <td>()</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>words</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>morph_analysis</th>\n",
       "      <td>attached</td>\n",
       "      <td>(normalized_text, lemma, root, root_tokens, ending, clitic, form, partofspeech)</td>\n",
       "      <td>True</td>\n",
       "      <td>words</td>\n",
       "      <td>None</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tokens</th>\n",
       "      <td>attached</td>\n",
       "      <td>()</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>detached_morph_1</th>\n",
       "      <td>detached</td>\n",
       "      <td>(normalized_text, lemma, root, root_tokens, ending, clitic, form, partofspeech, _ignore)</td>\n",
       "      <td>True</td>\n",
       "      <td>words</td>\n",
       "      <td>None</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>detached_morph_2</th>\n",
       "      <td>detached</td>\n",
       "      <td>(normalized_text, lemma, root, root_tokens, ending, clitic, form, partofspeech, _ignore)</td>\n",
       "      <td>True</td>\n",
       "      <td>words</td>\n",
       "      <td>None</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<estnltk.storage.postgres.collection.PgCollection at 0x2ac7406b0a0>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer_1 = 'detached_morph_1'\n",
    "layer_2 = 'detached_morph_2'\n",
    "\n",
    "tagger = VabamorfTagger(disambiguate=False, output_layer=layer_1)\n",
    "collection.create_layer(tagger=tagger)\n",
    "\n",
    "tagger = VabamorfTagger(disambiguate=False, output_layer=layer_2)\n",
    "collection.create_layer(tagger=tagger)\n",
    "\n",
    "collection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: after you have added a detached layer to the collection, you can no longer add new `Text` objects to it. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>\n",
    "<div class=\"alert alert-block alert-warning\">\n",
    "<h4><i>Size limits on text and layer insertion</i></h4> \n",
    "<p>Be aware that database columns have size limits. If you insert large <code>Text</code>-s and/or many layers (especially richly annotated morphological or syntactic layers), you may end up exceeding those limits. This is indicated by the following error message:\n",
    "<pre>\n",
    "psycopg2.errors.ProgramLimitExceeded: total size of jsonb array elements exceeds the maximum of 268435455 bytes\n",
    "</pre>\n",
    "Unfortunately, this limit cannot be changed in the database configuration. \n",
    "To bypass the situation, you can split the large <code>Text</code> into smaller <code>Text</code> objects and insert small texts separately. For more details about splitting, see the functions <code>extract_sections</code> and <code>split_by</code>: <a href=\"https://github.com/estnltk/estnltk/blob/version_1.6/tutorials/system/layer_operations.ipynb\">https://github.com/estnltk/estnltk/blob/version_1.6/tutorials/system/layer_operations.ipynb</a>. A recommendation is to consider splitting if the size of the (raw) text exceeds 1 MB. \n",
    "\n",
    "</p>\n",
    "</div>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Delayed and parallel layer creation\n",
    "\n",
    "Sometimes you want to add a new detached layer to the collection, but without filling it with data right away. \n",
    "Then you can use the `add_layer` method to add a layer template to the collection. \n",
    "You can use collection's `add_layer` method in combination with tagger's `get_layer_template` method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:collection.py:791: detached layer 'paragraphs' created from template\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<b>PgCollection</b><br/><b>name:</b> my_collection<br/><b>storage:</b> PostgresStorage(user=postgres password=xxx dbname=test_db host=localhost port=5432 schema=my_schema temporary=False)<br/><b>count objects:</b> 3<br/><b>Metadata</b><br/><table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>data type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>author</th>\n",
       "      <td>text</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><b>Layers</b><table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>layer_type</th>\n",
       "      <th>attributes</th>\n",
       "      <th>ambiguous</th>\n",
       "      <th>parent</th>\n",
       "      <th>enveloping</th>\n",
       "      <th>meta</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>words</th>\n",
       "      <td>attached</td>\n",
       "      <td>(normalized_form,)</td>\n",
       "      <td>True</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>compound_tokens</th>\n",
       "      <td>attached</td>\n",
       "      <td>(type, normalized)</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>tokens</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sentences</th>\n",
       "      <td>attached</td>\n",
       "      <td>()</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>words</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>morph_analysis</th>\n",
       "      <td>attached</td>\n",
       "      <td>(normalized_text, lemma, root, root_tokens, ending, clitic, form, partofspeech)</td>\n",
       "      <td>True</td>\n",
       "      <td>words</td>\n",
       "      <td>None</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tokens</th>\n",
       "      <td>attached</td>\n",
       "      <td>()</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>detached_morph_1</th>\n",
       "      <td>detached</td>\n",
       "      <td>(normalized_text, lemma, root, root_tokens, ending, clitic, form, partofspeech, _ignore)</td>\n",
       "      <td>True</td>\n",
       "      <td>words</td>\n",
       "      <td>None</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>detached_morph_2</th>\n",
       "      <td>detached</td>\n",
       "      <td>(normalized_text, lemma, root, root_tokens, ending, clitic, form, partofspeech, _ignore)</td>\n",
       "      <td>True</td>\n",
       "      <td>words</td>\n",
       "      <td>None</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>paragraphs</th>\n",
       "      <td>detached</td>\n",
       "      <td>()</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>sentences</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<estnltk.storage.postgres.collection.PgCollection at 0x2ac7406b0a0>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from estnltk.taggers import ParagraphTokenizer\n",
    "\n",
    "paragraph_tokenizer = ParagraphTokenizer()\n",
    "collection.add_layer( layer_template=paragraph_tokenizer.get_layer_template() )\n",
    "\n",
    "collection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To fill in the newly created layer, you can use `collection.create_layer()` with `mode='append'`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:collection.py:634: collection: 'my_collection'\n",
      "INFO:collection.py:642: appending existing layer: 'paragraphs'\n",
      "INFO:collection.py:685: inserting data into the 'paragraphs' layer table\n",
      "INFO:collection_detached_layer_inserter.py:70: inserted 3 detached 'paragraphs' layers into the collection 'my_collection'\n",
      "INFO:collection.py:719: layer created: 'paragraphs'\n"
     ]
    }
   ],
   "source": [
    "collection.create_layer(tagger=paragraph_tokenizer, mode='append')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternatively, you can also launch several layer creators in parallel, so that they create layers for non-overlapping blocks of texts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:collection.py:998: layer deleted: 'paragraphs'\n"
     ]
    }
   ],
   "source": [
    "# Remove layer\n",
    "collection.delete_layer( paragraph_tokenizer.output_layer )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:collection.py:791: detached layer 'paragraphs' created from template\n"
     ]
    }
   ],
   "source": [
    "# Add the template layer once more\n",
    "collection.add_layer( layer_template=paragraph_tokenizer.get_layer_template() )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, you can use `collection.create_layer_block()` to apply the tagger only on a block of collection's texts, where the block is defined by method's input parameter `(module, remainder)`. As a result, only texts with `text_id % module = remainder` will be tagged:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:collection.py:829: inserting data into the 'paragraphs' layer table block (2, 0)\n",
      "INFO:collection_detached_layer_inserter.py:70: inserted 2 detached 'paragraphs' layers into the collection 'my_collection'\n",
      "INFO:collection.py:862: block (2, 0) of 'paragraphs' layer created\n"
     ]
    }
   ],
   "source": [
    "# Tag the first block\n",
    "collection.create_layer_block( paragraph_tokenizer, (2, 0) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:collection.py:829: inserting data into the 'paragraphs' layer table block (2, 1)\n",
      "INFO:collection_detached_layer_inserter.py:70: inserted 1 detached 'paragraphs' layers into the collection 'my_collection'\n",
      "INFO:collection.py:862: block (2, 1) of 'paragraphs' layer created\n"
     ]
    }
   ],
   "source": [
    "# Tag the second block\n",
    "collection.create_layer_block( paragraph_tokenizer, (2, 1) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: if you use `collection.create_layer_block()` with `mode='append'`, then the method will continue creating an existing block, tagging only untagged texts inside the block."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Iterate collection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Number of `Text` objects in the collection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(collection)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Don't list the collection elements if the collection is large."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Text(text='Ööbik laulab.'),\n",
       " Text(text='Öökull ei laula.'),\n",
       " Text(text='Karu magab.')]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(collection)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Collection yields `Text` objects with selected layers. The selected layers are by default the attached layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['words', 'compound_tokens', 'sentences', 'morph_analysis', 'tokens']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collection.selected_layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dependencies are included automatically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['words', 'detached_morph_1']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collection.selected_layers = [layer_1]\n",
    "collection.selected_layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The indexes start from `0`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td><div align = \"left\">Ööbik laulab.</div></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<h4>Metadata</h4>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>author</td>\n",
       "      <td>Kõivupuu</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>layer name</th>\n",
       "      <th>attributes</th>\n",
       "      <th>parent</th>\n",
       "      <th>enveloping</th>\n",
       "      <th>ambiguous</th>\n",
       "      <th>span count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>words</td>\n",
       "      <td>normalized_form</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>detached_morph_1</td>\n",
       "      <td>normalized_text, lemma, root, root_tokens, ending, clitic, form, partofspeech, _ignore</td>\n",
       "      <td>words</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "Text(text='Ööbik laulab.')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collection[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, you can iterate over the whole collection using the `select()` method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Text(text='Ööbik laulab.')\n",
      "1 Text(text='Öökull ei laula.')\n",
      "2 Text(text='Karu magab.')\n"
     ]
    }
   ],
   "source": [
    "for text_id, text_obj in collection.select():\n",
    "    print(text_id, text_obj)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the collection has metadata columns (i.e. `meta` argument was specified while creating the collection), then `collection_meta` argument can be used to select the metadata along with the index and `Text` object:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Text(text='Ööbik laulab.') {'author': 'Kõivupuu'}\n",
      "1 Text(text='Öökull ei laula.') {'author': 'Niinepuu'}\n",
      "2 Text(text='Karu magab.') {'author': 'Niinemets'}\n"
     ]
    }
   ],
   "source": [
    "for text_id, text_obj, text_meta in collection.select( collection_meta=['author'] ):\n",
    "    print(text_id, text_obj, text_meta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Search collection\n",
    "\n",
    "EstNLTK provides different types of queries to search `Text` objects from the collection."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`IndexQuery` can be used to search for a particular entry by index:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1, Text(text='Öökull ei laula.'))]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(collection.select( query=IndexQuery( [1] ) ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`MetadataQuery` can be used to search for `Text` objects with specific metadata. By default, collection's metadata columns will be searched:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Text(text='Öökull ei laula.') {'author': 'Niinepuu'}\n"
     ]
    }
   ],
   "source": [
    "q = MetadataQuery( {'author': 'Niinepuu'} )\n",
    "for key, txt, meta in collection.select( query=q, collection_meta=['author'] ):\n",
    "    print(key, txt, meta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternatively, if you use `MetadataQuery` with `meta_type='TEXT'`, then the query searches for metadata inside `Text` objects (the `meta` field):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 Text(text='Karu magab.') {'author': 'Niinemets'}\n"
     ]
    }
   ],
   "source": [
    "q = MetadataQuery( {'author': 'Niinemets'}, meta_type='TEXT' )\n",
    "for key, txt in collection.select( query=q ):\n",
    "    print(key, txt, txt.meta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`SubstringQuery` finds all `Text` objects that have the given substring in their raw text:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Text(text='Ööbik laulab.')\n",
      "1 Text(text='Öökull ei laula.')\n"
     ]
    }
   ],
   "source": [
    "q = SubstringQuery('laula')\n",
    "for key, txt in collection.select(query=q):\n",
    "    print(key, txt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`LayerQuery` can be used to search texts by the attribute values in layers.\n",
    "\n",
    "Find texts that contain lemma `laulma` in the attached `morph_analysis` layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Text(text='Ööbik laulab.')\n",
      "1 Text(text='Öökull ei laula.')\n"
     ]
    }
   ],
   "source": [
    "q = LayerQuery('morph_analysis', lemma='laulma')\n",
    "for key, txt in collection.select(query=q):\n",
    "    print(key, txt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also search for multiple layer attributes.\n",
    "\n",
    "Find texts that contain a span in the detached `detached_morph_1` layer with partofspeech `V` and form `b` ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Text(text='Ööbik laulab.')\n",
      "2 Text(text='Karu magab.')\n"
     ]
    }
   ],
   "source": [
    "q = LayerQuery(layer_name=layer_1, partofspeech='V', form='b')\n",
    "\n",
    "for key, text in collection.select(query=q):\n",
    "    print(key, text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find texts that contain a span in the attached `morph_analysis` layer with lemma `laulma` and form `b`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Text(text='Ööbik laulab.')\n"
     ]
    }
   ],
   "source": [
    "q = LayerQuery('morph_analysis', lemma='laulma', form='b')\n",
    "\n",
    "for key, txt in collection.select(query=q):\n",
    "    print(key, txt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combined conditions with OR and AND operators"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can use `|` (\"OR\"), and `&` (\"AND\") operators to create composite queries."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find texts that contain a span in the `morph_analysis` layer with lemma `ööbik` **or** lemma `öökull`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Text(text='Ööbik laulab.')\n",
      "1 Text(text='Öökull ei laula.')\n"
     ]
    }
   ],
   "source": [
    "q = LayerQuery('morph_analysis', lemma='ööbik') | \\\n",
    "    LayerQuery('morph_analysis', lemma='öökull')\n",
    "\n",
    "for key, txt in collection.select(query=q):\n",
    "    print(key, txt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find texts that contain a span in the `detached_morph_2` layer with lemma `ööbik` **and** lemma `öökull`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "q = LayerQuery(layer_2, lemma='ööbik') & \\\n",
    "    LayerQuery(layer_2, lemma='öökull')\n",
    "for key, txt in collection.select(query=q):\n",
    "    print(key, txt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No such text."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find texts that contain a span in the `detached_morph_2` layer with lemma `ööbik` **and** another span with partofspeech `V` and form `b`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Text(text='Ööbik laulab.')\n"
     ]
    }
   ],
   "source": [
    "q = LayerQuery(layer_name=layer_2, lemma='ööbik') & \\\n",
    "    LayerQuery(layer_name=layer_2, partofspeech='V', form='b')\n",
    "\n",
    "for key, text in collection.select(query=q):\n",
    "    print(key, text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find texts that contain a span in the `morph_analysis` layer with lemma `laulma` **and** another span with lemma `ööbik` **or** `öökull`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Text(text='Ööbik laulab.')\n",
      "1 Text(text='Öökull ei laula.')\n"
     ]
    }
   ],
   "source": [
    "q = (LayerQuery('morph_analysis', lemma='ööbik') | LayerQuery('morph_analysis', lemma='öökull')) & \\\n",
    "     LayerQuery('morph_analysis', lemma='laulma')\n",
    "for key, txt in collection.select(query=q):\n",
    "    print(key, txt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Naturally, we can also combine layer queries over different layers. \n",
    "\n",
    "Find texts with lemma `ööbik` **or** `öökull` in the `detached_morph_1` layer **and** lemma `laulma` in the `detached_morph_2` layer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Text(text='Ööbik laulab.')\n",
      "1 Text(text='Öökull ei laula.')\n"
     ]
    }
   ],
   "source": [
    "q = (LayerQuery(layer_1, lemma='ööbik') | LayerQuery(layer_1, lemma='öökull')) & \\\n",
    "     LayerQuery(layer_2, lemma='laulma')\n",
    "\n",
    "for key, text in collection.select(query=q):\n",
    "    print(key, text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we can also combine different types of queries.\n",
    "\n",
    "Find texts with lemma `ööbik` in the `detached_morph_2` layer **or** with metadata entry `'author': 'Niinemets'`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Text(text='Öökull ei laula.')\n",
      "2 Text(text='Karu magab.')\n"
     ]
    }
   ],
   "source": [
    "q = LayerQuery(layer_2, lemma='öökull') | \\\n",
    "    MetadataQuery({'author': 'Niinemets'}, meta_type='TEXT')\n",
    "\n",
    "for key, text in collection.select(query=q):\n",
    "    print(key, text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Queries over blocks of texts (parallelization)\n",
    "\n",
    "You can use `BlockQuery` to make queries over non-overlapping subsets (blocks) of the collection. \n",
    "This can be useful for query parallelization: you can launch several parallel query jobs on the collection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from estnltk.storage.postgres import BlockQuery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "q = LayerQuery('morph_analysis', lemma='ööbik') | \\\n",
    "    LayerQuery('morph_analysis', lemma='öökull')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can add `BlockQuery` constraint to the query. The block of documents is defined by the input parameter `(module, remainder)`, which instructs to select only texts with `text_id % module = remainder`. So, if we want to cover the whole collection with 2 queries, we add a `BlockQuery` with  `module=2` and `remainder=0` to the first query and a `BlockQuery` with  `module=2` and `remainder=1` to the second query:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Text(text='Ööbik laulab.')\n"
     ]
    }
   ],
   "source": [
    "# Search the first block\n",
    "for key, txt in collection.select(query=q & BlockQuery(2, 0)):\n",
    "    print(key, txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Text(text='Öökull ei laula.')\n"
     ]
    }
   ],
   "source": [
    "# Search the second block\n",
    "for key, txt in collection.select(query=q & BlockQuery(2, 1)):\n",
    "    print(key, txt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Delete collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "collection.delete()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Indexing layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:collection.py:92: new empty collection 'collection_with_layers' created\n",
      "INFO:collection_text_object_inserter.py:107: inserted 2 texts into the collection 'collection_with_layers'\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<b>PgCollection</b><br/><b>name:</b> collection_with_layers<br/><b>storage:</b> PostgresStorage(user=postgres password=xxx dbname=test_db host=localhost port=5432 schema=my_schema temporary=False)<br/><b>count objects:</b> 2<br/><b>Metadata</b><br/>This collection has no metadata.<br/><b>Layers</b><table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>layer_type</th>\n",
       "      <th>attributes</th>\n",
       "      <th>ambiguous</th>\n",
       "      <th>parent</th>\n",
       "      <th>enveloping</th>\n",
       "      <th>meta</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>sentences</th>\n",
       "      <td>attached</td>\n",
       "      <td>()</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>words</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tokens</th>\n",
       "      <td>attached</td>\n",
       "      <td>()</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>words</th>\n",
       "      <td>attached</td>\n",
       "      <td>(normalized_form,)</td>\n",
       "      <td>True</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>compound_tokens</th>\n",
       "      <td>attached</td>\n",
       "      <td>(type, normalized)</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>tokens</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<estnltk.storage.postgres.collection.PgCollection at 0x2ac74eccaf0>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collection = storage.get_collection('collection_with_layers')\n",
    "collection.create()\n",
    "\n",
    "with collection.insert() as collection_insert:\n",
    "    collection_insert(Text('See on esimene lause.').tag_layer([\"sentences\"]))\n",
    "    collection_insert(Text('See on teine lause.').tag_layer([\"sentences\"]))\n",
    "\n",
    "collection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ngram index enables to index ngrams in layer attributes.\n",
    "For example, a bigram index on an attribute with values `['see', 'on', 'esimene', 'lause']` will contain pairs *'see-on'*, *'on-esimene'*, *'esimene-lause'*.\n",
    "Indices of a higher order are also supported.\n",
    "\n",
    "To build an ngram index, provide an argument *ngram_index* when creating a new layer.\n",
    "The following code creates a bi-gram index on an attribute *lemma* for a newly created layer *indexed_layer*:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:collection.py:634: collection: 'collection_with_layers'\n",
      "INFO:collection.py:653: preparing to create a new layer: 'indexed_layer'\n",
      "INFO:collection.py:685: inserting data into the 'indexed_layer' layer table\n",
      "INFO:collection_detached_layer_inserter.py:70: inserted 2 detached 'indexed_layer' layers into the collection 'collection_with_layers'\n",
      "INFO:collection.py:719: layer created: 'indexed_layer'\n"
     ]
    }
   ],
   "source": [
    "indexed_layer = 'indexed_layer'\n",
    "tagger = VabamorfTagger(disambiguate=False, output_layer=indexed_layer)\n",
    "\n",
    "collection.create_layer(tagger=tagger, ngram_index={\"lemma\": 2})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To search an ngram index, use `LayerNgramQuery` query:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Search entries containing lemma bigram 'see-olema':"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Text(text='See on esimene lause.')\n",
      "1 Text(text='See on teine lause.')\n"
     ]
    }
   ],
   "source": [
    "from estnltk.storage.postgres import LayerNgramQuery\n",
    "\n",
    "q = LayerNgramQuery( { indexed_layer: {\n",
    "        \"lemma\": [(\"see\", \"olema\")]\n",
    "    }})\n",
    "for key, text in collection.select(query=q):\n",
    "    print(key, text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Search 'teine-lause' OR 'olema-esimene':"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Text(text='See on esimene lause.')\n",
      "1 Text(text='See on teine lause.')\n"
     ]
    }
   ],
   "source": [
    "q = LayerNgramQuery( { indexed_layer: {\n",
    "        \"lemma\":  [(\"teine\", \"lause\"), (\"olema\", \"esimene\")]\n",
    "    }})\n",
    "for key, text in collection.select(query=q):\n",
    "    print(key, text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Search 'see-olema' AND 'olema-esimene':"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Text(text='See on esimene lause.')\n"
     ]
    }
   ],
   "source": [
    "q = LayerNgramQuery( { indexed_layer: {\n",
    "        \"lemma\":  [[(\"see\", \"olema\"), (\"olema\", \"esimene\")]]\n",
    "    }})\n",
    "for key, text in collection.select(query=q):\n",
    "    print(key, text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<b>PgCollection</b><br/><b>name:</b> collection_with_layers<br/><b>storage:</b> PostgresStorage(user=postgres password=xxx dbname=test_db host=localhost port=5432 schema=my_schema temporary=False)<br/><b>count objects:</b> 2<br/><b>Metadata</b><br/>This collection has no metadata.<br/><b>Layers</b><table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>layer_type</th>\n",
       "      <th>attributes</th>\n",
       "      <th>ambiguous</th>\n",
       "      <th>parent</th>\n",
       "      <th>enveloping</th>\n",
       "      <th>meta</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>sentences</th>\n",
       "      <td>attached</td>\n",
       "      <td>()</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>words</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tokens</th>\n",
       "      <td>attached</td>\n",
       "      <td>()</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>words</th>\n",
       "      <td>attached</td>\n",
       "      <td>(normalized_form,)</td>\n",
       "      <td>True</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>compound_tokens</th>\n",
       "      <td>attached</td>\n",
       "      <td>(type, normalized)</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>tokens</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>indexed_layer</th>\n",
       "      <td>detached</td>\n",
       "      <td>(normalized_text, lemma, root, root_tokens, ending, clitic, form, partofspeech, _ignore)</td>\n",
       "      <td>True</td>\n",
       "      <td>words</td>\n",
       "      <td>None</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<estnltk.storage.postgres.collection.PgCollection at 0x2ac74eccaf0>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Delete layer\n",
    "\n",
    "Only detched layers can be deleted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<b>PgCollection</b><br/><b>name:</b> collection_with_layers<br/><b>storage:</b> PostgresStorage(user=postgres password=xxx dbname=test_db host=localhost port=5432 schema=my_schema temporary=False)<br/><b>count objects:</b> 2<br/><b>Metadata</b><br/>This collection has no metadata.<br/><b>Layers</b><table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>layer_type</th>\n",
       "      <th>attributes</th>\n",
       "      <th>ambiguous</th>\n",
       "      <th>parent</th>\n",
       "      <th>enveloping</th>\n",
       "      <th>meta</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>sentences</th>\n",
       "      <td>attached</td>\n",
       "      <td>()</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>words</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tokens</th>\n",
       "      <td>attached</td>\n",
       "      <td>()</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>words</th>\n",
       "      <td>attached</td>\n",
       "      <td>(normalized_form,)</td>\n",
       "      <td>True</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>compound_tokens</th>\n",
       "      <td>attached</td>\n",
       "      <td>(type, normalized)</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>tokens</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>indexed_layer</th>\n",
       "      <td>detached</td>\n",
       "      <td>(normalized_text, lemma, root, root_tokens, ending, clitic, form, partofspeech, _ignore)</td>\n",
       "      <td>True</td>\n",
       "      <td>words</td>\n",
       "      <td>None</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<estnltk.storage.postgres.collection.PgCollection at 0x2ac74eccaf0>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The only detached layer in this collection is the layer `indexed_layer`. Let's delete it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:collection.py:998: layer deleted: 'indexed_layer'\n"
     ]
    }
   ],
   "source": [
    "collection.delete_layer('indexed_layer')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally delete the collection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "collection.delete()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `PgSubCollection`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:collection.py:92: new empty collection 'my_collection' created\n",
      "INFO:collection_text_object_inserter.py:107: inserted 5 texts into the collection 'my_collection'\n"
     ]
    }
   ],
   "source": [
    "collection = storage.get_collection('my_collection')\n",
    "collection.create()\n",
    "\n",
    "texts = ['Esimene tekst.', 'Teine tekst.', 'Kolmas tekst.', 'Neljas tekst.', 'Viies tekst.']\n",
    "\n",
    "with collection.insert() as collection_insert:\n",
    "    for t in texts:\n",
    "        collection_insert(Text(t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:collection.py:634: collection: 'my_collection'\n",
      "INFO:collection.py:653: preparing to create a new layer: 'tokens'\n",
      "INFO:collection.py:685: inserting data into the 'tokens' layer table\n",
      "INFO:collection_detached_layer_inserter.py:70: inserted 5 detached 'tokens' layers into the collection 'my_collection'\n",
      "INFO:collection.py:719: layer created: 'tokens'\n"
     ]
    }
   ],
   "source": [
    "from estnltk.taggers import TokensTagger\n",
    "\n",
    "tokens_tagger = TokensTagger()\n",
    "\n",
    "collection.create_layer(tagger=tokens_tagger)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `select` method returns a `PgSubCollection` object that provides read-only access to a subset of the collection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PgSubCollection(collection: 'my_collection', selected_layers=[], meta_attributes=(), progressbar=None, return_index=True)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collection.select(query=None,\n",
    "                  layers=None,  # Sequence[str] \n",
    "                  collection_meta=None,  # Sequence[str] \n",
    "                  progressbar=None,  # str\n",
    "                  return_index=True,  # bool\n",
    "                  itersize= 10\n",
    "                  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e4db5e5d35254ffaae2bbddb12473977",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?doc/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, Text(text='Esimene tekst.'))\n",
      "(1, Text(text='Teine tekst.'))\n",
      "(2, Text(text='Kolmas tekst.'))\n",
      "(3, Text(text='Neljas tekst.'))\n",
      "(4, Text(text='Viies tekst.'))\n"
     ]
    }
   ],
   "source": [
    "for text in collection.select(progressbar='notebook', return_index=True):\n",
    "    print(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also directly access first and last texts of the `PgSubCollection`. The `head` method selects only first `N` texts from the subset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, Text(text='Esimene tekst.'))\n",
      "(1, Text(text='Teine tekst.'))\n",
      "(2, Text(text='Kolmas tekst.'))\n"
     ]
    }
   ],
   "source": [
    "# Select first 3 texts\n",
    "for text in collection.select().head( 3 ):\n",
    "    print(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And the `tail` method selects last `N` texts:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, Text(text='Neljas tekst.'))\n",
      "(4, Text(text='Viies tekst.'))\n"
     ]
    }
   ],
   "source": [
    "# Select only last 2 texts\n",
    "for text in collection.select().tail( 2 ):\n",
    "    print(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get detached layer without `Text` object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PgSubCollectionLayer(collection: 'my_collection', detached_layer='tokens', progressbar=None, return_index=False)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "detached_layers = collection.select(return_index=False).detached_layer('tokens')\n",
    "detached_layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h4>Layer</h4>\n",
       "\n",
       "No Text object.\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>layer name</th>\n",
       "      <th>attributes</th>\n",
       "      <th>parent</th>\n",
       "      <th>enveloping</th>\n",
       "      <th>ambiguous</th>\n",
       "      <th>span count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>tokens</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "Layer(name='tokens', attributes=(), spans=SL[Span(None, [{}]),\n",
       "Span(None, [{}]),\n",
       "Span(None, [{}])])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(detached_layers))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Working with fragments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:collection.py:92: new empty collection 'collection_with_fragments' created\n",
      "INFO:collection_text_object_inserter.py:107: inserted 2 texts into the collection 'collection_with_fragments'\n",
      "INFO:collection.py:514: collection: 'collection_with_fragments'\n",
      "INFO:collection_detached_layer_inserter.py:70: inserted 2 detached 'fragmented_morph' layers into the collection 'collection_with_fragments'\n",
      "INFO:collection.py:561: fragmented layer created: 'fragmented_morph'\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<b>PgCollection</b><br/><b>name:</b> collection_with_fragments<br/><b>storage:</b> PostgresStorage(user=postgres password=xxx dbname=test_db host=localhost port=5432 schema=my_schema temporary=False)<br/><b>count objects:</b> 2<br/><b>Metadata</b><br/>This collection has no metadata.<br/><b>Layers</b><table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>layer_type</th>\n",
       "      <th>attributes</th>\n",
       "      <th>ambiguous</th>\n",
       "      <th>parent</th>\n",
       "      <th>enveloping</th>\n",
       "      <th>meta</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>words</th>\n",
       "      <td>attached</td>\n",
       "      <td>(normalized_form,)</td>\n",
       "      <td>True</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>compound_tokens</th>\n",
       "      <td>attached</td>\n",
       "      <td>(type, normalized)</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>tokens</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sentences</th>\n",
       "      <td>attached</td>\n",
       "      <td>()</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>words</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>morph_analysis</th>\n",
       "      <td>attached</td>\n",
       "      <td>(normalized_text, lemma, root, root_tokens, ending, clitic, form, partofspeech)</td>\n",
       "      <td>True</td>\n",
       "      <td>words</td>\n",
       "      <td>None</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tokens</th>\n",
       "      <td>attached</td>\n",
       "      <td>()</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fragmented_morph</th>\n",
       "      <td>fragmented</td>\n",
       "      <td>(normalized_text, lemma, root, root_tokens, ending, clitic, form, partofspeech, _ignore)</td>\n",
       "      <td>True</td>\n",
       "      <td>words</td>\n",
       "      <td>None</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<estnltk.storage.postgres.collection.PgCollection at 0x2ac74efe190>"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collection = storage[\"collection_with_fragments\"].create(description='demo collection')\n",
    "\n",
    "with collection.insert() as collection_insert:\n",
    "    text1 = Text('Ööbik laulab.').tag_layer(['morph_analysis'])\n",
    "    collection_insert(text1)\n",
    "\n",
    "    text2 = Text('Öökull ei laula.').tag_layer(['morph_analysis'])\n",
    "    key2 = collection_insert(text2)\n",
    "\n",
    "    \n",
    "def fragmenter(layer):\n",
    "    return [layer]\n",
    "\n",
    "\n",
    "tagger = VabamorfTagger(disambiguate=False, output_layer='fragmented_morph')\n",
    "\n",
    "collection.create_fragmented_layer(tagger=tagger, fragmenter=fragmenter)\n",
    "\n",
    "collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:collection.py:92: new empty collection 'fragment_test' created\n",
      "INFO:collection_text_object_inserter.py:107: inserted 2 texts into the collection 'fragment_test'\n",
      "INFO:collection.py:634: collection: 'fragment_test'\n",
      "INFO:collection.py:653: preparing to create a new layer: 'layer_fragment_1'\n",
      "INFO:collection.py:685: inserting data into the 'layer_fragment_1' layer table\n",
      "INFO:collection_detached_layer_inserter.py:70: inserted 2 detached 'layer_fragment_1' layers into the collection 'fragment_test'\n",
      "INFO:collection.py:719: layer created: 'layer_fragment_1'\n"
     ]
    }
   ],
   "source": [
    "from estnltk.storage.postgres import RowMapperRecord\n",
    "\n",
    "table_name = 'fragment_test'\n",
    "collection = storage.get_collection(table_name)\n",
    "collection.create()\n",
    "\n",
    "with collection.insert() as collection_insert:\n",
    "    text1 = Text('see on esimene lause').tag_layer([\"sentences\"])\n",
    "    collection_insert(text1)\n",
    "    text2 = Text('see on teine lause').tag_layer([\"sentences\"])\n",
    "    collection_insert(text2)\n",
    "\n",
    "layer_fragment_name = \"layer_fragment_1\"\n",
    "tagger = VabamorfTagger(disambiguate=False, output_layer=layer_fragment_name)\n",
    "\n",
    "collection.create_layer(tagger=tagger)\n",
    "\n",
    "fragment_name = \"fragment_1\"\n",
    "\n",
    "def row_mapper(row):\n",
    "        parent_id, layer = row\n",
    "        return [{'fragment': layer, 'parent_id': parent_id},\n",
    "                {'fragment': layer, 'parent_id': parent_id}]\n",
    "\n",
    "collection.create_fragment(fragment_name,\n",
    "                    data_iterator=collection.select().fragmented_layer(name=layer_fragment_name),\n",
    "                    row_mapper=row_mapper,\n",
    "                    create_index=False,\n",
    "                    ngram_index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<b>PgCollection</b><br/><b>name:</b> fragment_test<br/><b>storage:</b> PostgresStorage(user=postgres password=xxx dbname=test_db host=localhost port=5432 schema=my_schema temporary=False)<br/><b>count objects:</b> 2<br/><b>Metadata</b><br/>This collection has no metadata.<br/><b>Layers</b><table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>layer_type</th>\n",
       "      <th>attributes</th>\n",
       "      <th>ambiguous</th>\n",
       "      <th>parent</th>\n",
       "      <th>enveloping</th>\n",
       "      <th>meta</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>sentences</th>\n",
       "      <td>attached</td>\n",
       "      <td>()</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>words</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tokens</th>\n",
       "      <td>attached</td>\n",
       "      <td>()</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>words</th>\n",
       "      <td>attached</td>\n",
       "      <td>(normalized_form,)</td>\n",
       "      <td>True</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>compound_tokens</th>\n",
       "      <td>attached</td>\n",
       "      <td>(type, normalized)</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>tokens</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>layer_fragment_1</th>\n",
       "      <td>detached</td>\n",
       "      <td>(normalized_text, lemma, root, root_tokens, ending, clitic, form, partofspeech, _ignore)</td>\n",
       "      <td>True</td>\n",
       "      <td>words</td>\n",
       "      <td>None</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<estnltk.storage.postgres.collection.PgCollection at 0x2ac74eccdc0>"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "collection.delete()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "delete_schema(storage)\n",
    "storage.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
