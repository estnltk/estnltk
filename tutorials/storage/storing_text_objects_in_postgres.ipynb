{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Storing of `Text` objects in a PostgreSQL database"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This tutorial demonstrates how to store and query EstNLTK `Text` objects in a PostgreSQL database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from estnltk import Text, logger\n",
    "from estnltk.taggers import VabamorfTagger, WordTagger, CompoundTokenTagger\n",
    "from estnltk.storage.postgres import PostgresStorage, create_schema, delete_schema\n",
    "from estnltk.storage.postgres import LayerQuery, SubstringQuery, IndexQuery, MetadataQuery"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Access to the database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:storage.py:41: connecting to host: 'localhost', port: '5432', dbname: 'test_db', user: 'postgres'\n",
      "INFO:storage.py:58: schema: 'my_schema', temporary: False, role: 'postgres'\n"
     ]
    }
   ],
   "source": [
    "storage = PostgresStorage(host=None,\n",
    "                          port=None,\n",
    "                          dbname='test_db',\n",
    "                          user=None,\n",
    "                          password=None,\n",
    "                          pgpass_file='~/.pgpass',\n",
    "                          schema='my_schema',\n",
    "                          role=None,\n",
    "                          temporary=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If any of the parameters `host`, `port`, `dbname`, `user` or `password` is `None` then the missing values are searced from the `pgpass_file`. The first line of the file that matches the given arguments is used to connect to an existing PostgreSQL database.\n",
    "\n",
    "File line format:\n",
    "\n",
    "    host:port:dbname:user:password\n",
    " \n",
    "Example file contents:\n",
    "\n",
    "    # host:port:dbname:user:password\n",
    "    localhost:5432:test_db:username:password\n",
    "    example.com:5432:*:exampleuser:kj3dno34"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create schema\n",
    "\n",
    "Probably the schema is already set up in the database. If not and you have enough privileges, you can create one:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "create_schema(storage)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create collections\n",
    "\n",
    "Now, new collections can be created and displayed. Collection stores `Text` objects in the database and provides a read/write API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:collection.py:94: new empty collection 'my_first_collection' created\n",
      "INFO:collection.py:94: new empty collection 'my_second_collection' created\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<b>PostgresStorage</b><br/>\n",
       "user=postgres password=xxx dbname=test_db host=localhost port=5432 schema=my_schema<br/>temporary=False<br/>\n",
       "collection count: 2\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>rows</th>\n",
       "      <th>total_size</th>\n",
       "      <th>comment</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>collection</th>\n",
       "      <th>version</th>\n",
       "      <th>relations</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">my_first_collection</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">3.0</th>\n",
       "      <th></th>\n",
       "      <td>0</td>\n",
       "      <td>32 kB</td>\n",
       "      <td>first demo collection</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>structure</th>\n",
       "      <td>0</td>\n",
       "      <td>16 kB</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">my_second_collection</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">3.0</th>\n",
       "      <th></th>\n",
       "      <td>0</td>\n",
       "      <td>32 kB</td>\n",
       "      <td>second demo collection</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>structure</th>\n",
       "      <td>0</td>\n",
       "      <td>16 kB</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<estnltk.storage.postgres.storage.PostgresStorage at 0x1b3b5707880>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "storage['my_first_collection'].create('first demo collection')\n",
    "storage['my_second_collection'].create('second demo collection')\n",
    "storage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The collection names as a list of strings is also available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['my_first_collection', 'my_second_collection']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "storage.collections"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Derive and display a collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<b>PgCollection</b><br/><b>name:</b> my_first_collection<br/><b>storage:</b> PostgresStorage(user=postgres password=xxx dbname=test_db host=localhost port=5432 schema=my_schema temporary=False)<br/><b>count objects:</b> 0<br/><b>Metadata</b><br/>This collection has no metadata.<br/><b>Layers</b><br/>unknown"
      ],
      "text/plain": [
       "<estnltk.storage.postgres.collection.PgCollection at 0x1b3b5734df0>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collection = storage['my_first_collection']\n",
    "collection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Delete collections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "del storage['my_first_collection']\n",
    "# or\n",
    "storage['my_second_collection'].delete()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and the storage is empty again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<b>PostgresStorage</b><br/>\n",
       "user=postgres password=xxx dbname=test_db host=localhost port=5432 schema=my_schema<br/>temporary=False<br/>\n",
       "collection count: 0\n",
       "<br/>This storage has no collections."
      ],
      "text/plain": [
       "<estnltk.storage.postgres.storage.PostgresStorage at 0x1b3b5707880>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "storage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add texts\n",
    "\n",
    "Let's create a new collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:collection.py:94: new empty collection 'my_collection' created\n"
     ]
    }
   ],
   "source": [
    "collection = storage[\"my_collection\"].create(description='demo collection', meta={'author': 'str'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and add some data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:collection_text_object_inserter.py:107: inserted 4 texts into the collection 'my_collection'\n"
     ]
    }
   ],
   "source": [
    "with collection.insert() as collection_insert:\n",
    "    text1 = Text('Ööbik laulab.').tag_layer('morph_analysis')\n",
    "    text1.meta['author'] = 'Kõivupuu'\n",
    "    collection_insert(text1, meta_data=text1.meta)\n",
    "\n",
    "    text2 = Text('Öökull ei laula.').tag_layer('morph_analysis')\n",
    "    text2.meta['author'] = 'Niinepuu'\n",
    "    key2 = collection_insert(text2, meta_data=text2.meta)\n",
    "    \n",
    "    text3 = Text('Karu magab.').tag_layer('morph_analysis')\n",
    "    text3.meta['author'] = 'Niinemets'\n",
    "    key3 = collection_insert(text3, meta_data=text3.meta)\n",
    "    \n",
    "    text4 = Text('Vana-Karu lõi trummi.').tag_layer('morph_analysis')\n",
    "    text4.meta['author'] = 'Musumets'\n",
    "    key4 = collection_insert(text4, meta_data=text4.meta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All inserted `Text` objects must have the same layers.\n",
    "\n",
    "You can see what's inside"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<b>PgCollection</b><br/><b>name:</b> my_collection<br/><b>storage:</b> PostgresStorage(user=postgres password=xxx dbname=test_db host=localhost port=5432 schema=my_schema temporary=False)<br/><b>count objects:</b> 4<br/><b>Metadata</b><br/><table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>data type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>author</th>\n",
       "      <td>text</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><b>Layers</b><table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>layer_type</th>\n",
       "      <th>attributes</th>\n",
       "      <th>ambiguous</th>\n",
       "      <th>sparse</th>\n",
       "      <th>parent</th>\n",
       "      <th>enveloping</th>\n",
       "      <th>meta</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>tokens</th>\n",
       "      <td>attached</td>\n",
       "      <td>()</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>compound_tokens</th>\n",
       "      <td>attached</td>\n",
       "      <td>(type, normalized)</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>tokens</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sentences</th>\n",
       "      <td>attached</td>\n",
       "      <td>()</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>words</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>morph_analysis</th>\n",
       "      <td>attached</td>\n",
       "      <td>(normalized_text, lemma, root, root_tokens, ending, clitic, form, partofspeech)</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>words</td>\n",
       "      <td>None</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>words</th>\n",
       "      <td>attached</td>\n",
       "      <td>(normalized_form,)</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<estnltk.storage.postgres.collection.PgCollection at 0x1b3b5798100>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The layers inserted with the `Text` objects are stored in the same database table with the `Text` object and are called **attached** layers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create layers\n",
    "\n",
    "The `create_layer` method creates a new layer for every `Text` object in the collection. These layers are stored in separate database files and are called **detached** layers. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:collection.py:696: collection: 'my_collection'\n",
      "INFO:collection.py:715: preparing to create a new layer: 'detached_morph_1'\n",
      "INFO:collection.py:747: inserting data into the 'detached_morph_1' layer table\n",
      "INFO:collection_detached_layer_inserter.py:86: inserted 4 detached 'detached_morph_1' layers into the collection 'my_collection'\n",
      "INFO:collection.py:782: layer created: 'detached_morph_1'\n",
      "INFO:collection.py:696: collection: 'my_collection'\n",
      "INFO:collection.py:715: preparing to create a new layer: 'detached_morph_2'\n",
      "INFO:collection.py:747: inserting data into the 'detached_morph_2' layer table\n",
      "INFO:collection_detached_layer_inserter.py:86: inserted 4 detached 'detached_morph_2' layers into the collection 'my_collection'\n",
      "INFO:collection.py:782: layer created: 'detached_morph_2'\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<b>PgCollection</b><br/><b>name:</b> my_collection<br/><b>storage:</b> PostgresStorage(user=postgres password=xxx dbname=test_db host=localhost port=5432 schema=my_schema temporary=False)<br/><b>count objects:</b> 4<br/><b>Metadata</b><br/><table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>data type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>author</th>\n",
       "      <td>text</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><b>Layers</b><table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>layer_type</th>\n",
       "      <th>attributes</th>\n",
       "      <th>ambiguous</th>\n",
       "      <th>sparse</th>\n",
       "      <th>parent</th>\n",
       "      <th>enveloping</th>\n",
       "      <th>meta</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>tokens</th>\n",
       "      <td>attached</td>\n",
       "      <td>()</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>compound_tokens</th>\n",
       "      <td>attached</td>\n",
       "      <td>(type, normalized)</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>tokens</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sentences</th>\n",
       "      <td>attached</td>\n",
       "      <td>()</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>words</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>morph_analysis</th>\n",
       "      <td>attached</td>\n",
       "      <td>(normalized_text, lemma, root, root_tokens, ending, clitic, form, partofspeech)</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>words</td>\n",
       "      <td>None</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>words</th>\n",
       "      <td>attached</td>\n",
       "      <td>(normalized_form,)</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>detached_morph_1</th>\n",
       "      <td>detached</td>\n",
       "      <td>(normalized_text, lemma, root, root_tokens, ending, clitic, form, partofspeech, _ignore)</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>words</td>\n",
       "      <td>None</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>detached_morph_2</th>\n",
       "      <td>detached</td>\n",
       "      <td>(normalized_text, lemma, root, root_tokens, ending, clitic, form, partofspeech, _ignore)</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>words</td>\n",
       "      <td>None</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<estnltk.storage.postgres.collection.PgCollection at 0x1b3b5798100>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer_1 = 'detached_morph_1'\n",
    "layer_2 = 'detached_morph_2'\n",
    "\n",
    "tagger = VabamorfTagger(disambiguate=False, output_layer=layer_1)\n",
    "collection.create_layer(tagger=tagger)\n",
    "\n",
    "tagger = VabamorfTagger(disambiguate=False, output_layer=layer_2)\n",
    "collection.create_layer(tagger=tagger)\n",
    "\n",
    "collection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: after you have added a detached layer to the collection, you can no longer add new `Text` objects to it. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>\n",
    "<div class=\"alert alert-block alert-warning\">\n",
    "<h4><i>Size limits on text and layer insertion</i></h4> \n",
    "<p>Be aware that database columns have size limits. If you insert large <code>Text</code>-s and/or many layers (especially richly annotated morphological or syntactic layers), you may end up exceeding those limits. This is indicated by the following error message:\n",
    "<pre>\n",
    "psycopg2.errors.ProgramLimitExceeded: total size of jsonb array elements exceeds the maximum of 268435455 bytes\n",
    "</pre>\n",
    "Unfortunately, this limit cannot be changed in the database configuration. \n",
    "To bypass the situation, you can split the large <code>Text</code> into smaller <code>Text</code> objects and insert small texts separately. For more details about splitting, see the functions <code>extract_sections</code> and <code>split_by</code>: <a href=\"https://github.com/estnltk/estnltk/blob/version_1.6/tutorials/system/layer_operations.ipynb\">https://github.com/estnltk/estnltk/blob/version_1.6/tutorials/system/layer_operations.ipynb</a>. A recommendation is to consider splitting if the size of the (raw) text exceeds 1 MB. \n",
    "\n",
    "</p>\n",
    "</div>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Delayed and parallel layer creation\n",
    "\n",
    "Sometimes you want to add a new detached layer to the collection, but without filling it with data right away. \n",
    "Then you can use the `add_layer` method to add a layer template to the collection. \n",
    "You can use collection's `add_layer` method in combination with tagger's `get_layer_template` method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:collection.py:867: detached layer 'paragraphs' created from template\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<b>PgCollection</b><br/><b>name:</b> my_collection<br/><b>storage:</b> PostgresStorage(user=postgres password=xxx dbname=test_db host=localhost port=5432 schema=my_schema temporary=False)<br/><b>count objects:</b> 4<br/><b>Metadata</b><br/><table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>data type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>author</th>\n",
       "      <td>text</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><b>Layers</b><table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>layer_type</th>\n",
       "      <th>attributes</th>\n",
       "      <th>ambiguous</th>\n",
       "      <th>sparse</th>\n",
       "      <th>parent</th>\n",
       "      <th>enveloping</th>\n",
       "      <th>meta</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>tokens</th>\n",
       "      <td>attached</td>\n",
       "      <td>()</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>compound_tokens</th>\n",
       "      <td>attached</td>\n",
       "      <td>(type, normalized)</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>tokens</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sentences</th>\n",
       "      <td>attached</td>\n",
       "      <td>()</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>words</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>morph_analysis</th>\n",
       "      <td>attached</td>\n",
       "      <td>(normalized_text, lemma, root, root_tokens, ending, clitic, form, partofspeech)</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>words</td>\n",
       "      <td>None</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>words</th>\n",
       "      <td>attached</td>\n",
       "      <td>(normalized_form,)</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>detached_morph_1</th>\n",
       "      <td>detached</td>\n",
       "      <td>(normalized_text, lemma, root, root_tokens, ending, clitic, form, partofspeech, _ignore)</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>words</td>\n",
       "      <td>None</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>detached_morph_2</th>\n",
       "      <td>detached</td>\n",
       "      <td>(normalized_text, lemma, root, root_tokens, ending, clitic, form, partofspeech, _ignore)</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>words</td>\n",
       "      <td>None</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>paragraphs</th>\n",
       "      <td>detached</td>\n",
       "      <td>()</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>sentences</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<estnltk.storage.postgres.collection.PgCollection at 0x1b3b5798100>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from estnltk.taggers import ParagraphTokenizer\n",
    "\n",
    "paragraph_tokenizer = ParagraphTokenizer()\n",
    "collection.add_layer( layer_template=paragraph_tokenizer.get_layer_template() )\n",
    "\n",
    "collection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To fill in the newly created layer, you can use `collection.create_layer()` with `mode='append'`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:collection.py:696: collection: 'my_collection'\n",
      "INFO:collection.py:704: appending existing layer: 'paragraphs'\n",
      "INFO:collection.py:747: inserting data into the 'paragraphs' layer table\n",
      "INFO:collection_detached_layer_inserter.py:86: inserted 4 detached 'paragraphs' layers into the collection 'my_collection'\n",
      "INFO:collection.py:782: layer created: 'paragraphs'\n"
     ]
    }
   ],
   "source": [
    "collection.create_layer(tagger=paragraph_tokenizer, mode='append')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternatively, you can also launch several layer creators in parallel, so that they create layers for non-overlapping blocks of texts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:collection.py:1097: layer deleted: 'paragraphs'\n"
     ]
    }
   ],
   "source": [
    "# Remove layer\n",
    "collection.delete_layer( paragraph_tokenizer.output_layer )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:collection.py:867: detached layer 'paragraphs' created from template\n"
     ]
    }
   ],
   "source": [
    "# Add the template layer once more\n",
    "collection.add_layer( layer_template=paragraph_tokenizer.get_layer_template() )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, you can use `collection.create_layer_block()` to apply the tagger only on a block of collection's texts, where the block is defined by method's input parameter `(module, remainder)`. As a result, only texts with `text_id % module == remainder` will be tagged. \n",
    "If you are using parallel processing, it is recommended to create a new database connection for each block-creating process, like in the examples below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:storage.py:41: connecting to host: 'localhost', port: '5432', dbname: 'test_db', user: 'postgres'\n",
      "INFO:storage.py:58: schema: 'my_schema', temporary: False, role: 'postgres'\n",
      "INFO:collection.py:911: inserting data into the 'paragraphs' layer table block (2, 0)\n",
      "INFO:collection_detached_layer_inserter.py:86: inserted 2 detached 'paragraphs' layers into the collection 'my_collection'\n",
      "INFO:collection.py:985: block (2, 0) of 'paragraphs' layer created\n"
     ]
    }
   ],
   "source": [
    "# In case of parallel processing: Open a new connection to the database & collection\n",
    "storage_a = PostgresStorage( dbname='test_db', pgpass_file='~/.pgpass', schema='my_schema' )\n",
    "collection_a = storage_a[\"my_collection\"]\n",
    "# Tag the first block\n",
    "collection_a.create_layer_block( paragraph_tokenizer, (2, 0) )\n",
    "# Close the connection\n",
    "storage_a.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:storage.py:41: connecting to host: 'localhost', port: '5432', dbname: 'test_db', user: 'postgres'\n",
      "INFO:storage.py:58: schema: 'my_schema', temporary: False, role: 'postgres'\n",
      "INFO:collection.py:911: inserting data into the 'paragraphs' layer table block (2, 1)\n",
      "INFO:collection_detached_layer_inserter.py:86: inserted 2 detached 'paragraphs' layers into the collection 'my_collection'\n",
      "INFO:collection.py:985: block (2, 1) of 'paragraphs' layer created\n"
     ]
    }
   ],
   "source": [
    "# In case of parallel processing: Open a new connection to the database & collection\n",
    "storage_b = PostgresStorage( dbname='test_db', pgpass_file='~/.pgpass', schema='my_schema' )\n",
    "collection_b = storage_b[\"my_collection\"]\n",
    "# Tag the second block\n",
    "collection_b.create_layer_block( paragraph_tokenizer, (2, 1) )\n",
    "# Close the connection\n",
    "storage_b.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: if you use `collection.create_layer_block()` with `mode='append'`, then the method will continue creating an existing block, tagging only untagged texts inside the block."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sparse layers\n",
    "\n",
    "Detached layers can be _sparse_, which means that empty layers are not stored in the layer table. \n",
    "This saves up the storage, and queries can also be faster over sparse layers.\n",
    "\n",
    "You can use the parameter `sparse=True` to create a sparse layer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:collection.py:696: collection: 'my_collection'\n",
      "INFO:collection.py:715: preparing to create a new layer: 'compound_tokens_sparse'\n",
      "INFO:collection.py:747: inserting data into the 'compound_tokens_sparse' layer table\n",
      "INFO:collection_detached_layer_inserter.py:82: inserted 1 detached 'compound_tokens_sparse' layers into the collection 'my_collection', skipped 3 empty layers\n",
      "INFO:collection.py:782: layer created: 'compound_tokens_sparse'\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<b>PgCollection</b><br/><b>name:</b> my_collection<br/><b>storage:</b> PostgresStorage(user=postgres password=xxx dbname=test_db host=localhost port=5432 schema=my_schema temporary=False)<br/><b>count objects:</b> 4<br/><b>Metadata</b><br/><table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>data type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>author</th>\n",
       "      <td>text</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><b>Layers</b><table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>layer_type</th>\n",
       "      <th>attributes</th>\n",
       "      <th>ambiguous</th>\n",
       "      <th>sparse</th>\n",
       "      <th>parent</th>\n",
       "      <th>enveloping</th>\n",
       "      <th>meta</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>tokens</th>\n",
       "      <td>attached</td>\n",
       "      <td>()</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>compound_tokens</th>\n",
       "      <td>attached</td>\n",
       "      <td>(type, normalized)</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>tokens</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sentences</th>\n",
       "      <td>attached</td>\n",
       "      <td>()</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>words</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>morph_analysis</th>\n",
       "      <td>attached</td>\n",
       "      <td>(normalized_text, lemma, root, root_tokens, ending, clitic, form, partofspeech)</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>words</td>\n",
       "      <td>None</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>words</th>\n",
       "      <td>attached</td>\n",
       "      <td>(normalized_form,)</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>detached_morph_1</th>\n",
       "      <td>detached</td>\n",
       "      <td>(normalized_text, lemma, root, root_tokens, ending, clitic, form, partofspeech, _ignore)</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>words</td>\n",
       "      <td>None</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>detached_morph_2</th>\n",
       "      <td>detached</td>\n",
       "      <td>(normalized_text, lemma, root, root_tokens, ending, clitic, form, partofspeech, _ignore)</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>words</td>\n",
       "      <td>None</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>paragraphs</th>\n",
       "      <td>detached</td>\n",
       "      <td>()</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>sentences</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>compound_tokens_sparse</th>\n",
       "      <td>detached</td>\n",
       "      <td>(type, normalized)</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>None</td>\n",
       "      <td>tokens</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<estnltk.storage.postgres.collection.PgCollection at 0x1b3b5798100>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create tagger for sparse 'compound_tokens' layer\n",
    "compound_token_tagger = CompoundTokenTagger(output_layer='compound_tokens_sparse')\n",
    "\n",
    "# Tag sparse layer\n",
    "collection.create_layer(tagger=compound_token_tagger, sparse=True)\n",
    "\n",
    "# Check results\n",
    "collection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The parameter `sparse=True` can also be passed to `collection.add_layer()` method."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Iterate collection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Number of `Text` objects in the collection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(collection)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Don't list the collection elements if the collection is large."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Text(text='Ööbik laulab.'),\n",
       " Text(text='Öökull ei laula.'),\n",
       " Text(text='Karu magab.'),\n",
       " Text(text='Vana-Karu lõi trummi.')]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(collection)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Collection yields `Text` objects with selected layers. The selected layers are by default the attached layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tokens', 'compound_tokens', 'sentences', 'morph_analysis', 'words']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collection.selected_layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dependencies are included automatically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['words', 'detached_morph_1']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collection.selected_layers = [layer_1]\n",
    "collection.selected_layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The indexes start from `0`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td><div align = \"left\">Ööbik laulab.</div></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<h4>Metadata</h4>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>author</td>\n",
       "      <td>Kõivupuu</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>layer name</th>\n",
       "      <th>attributes</th>\n",
       "      <th>parent</th>\n",
       "      <th>enveloping</th>\n",
       "      <th>ambiguous</th>\n",
       "      <th>span count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>words</td>\n",
       "      <td>normalized_form</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>detached_morph_1</td>\n",
       "      <td>normalized_text, lemma, root, root_tokens, ending, clitic, form, partofspeech, _ignore</td>\n",
       "      <td>words</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "Text(text='Ööbik laulab.')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collection[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, you can iterate over the whole collection using the `select()` method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Text(text='Ööbik laulab.')\n",
      "1 Text(text='Öökull ei laula.')\n",
      "2 Text(text='Karu magab.')\n",
      "3 Text(text='Vana-Karu lõi trummi.')\n"
     ]
    }
   ],
   "source": [
    "for text_id, text_obj in collection.select():\n",
    "    print(text_id, text_obj)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the collection has metadata columns (i.e. `meta` argument was specified while creating the collection), then `collection_meta` argument can be used to select the metadata along with the index and `Text` object:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Text(text='Ööbik laulab.') {'author': 'Kõivupuu'}\n",
      "1 Text(text='Öökull ei laula.') {'author': 'Niinepuu'}\n",
      "2 Text(text='Karu magab.') {'author': 'Niinemets'}\n",
      "3 Text(text='Vana-Karu lõi trummi.') {'author': 'Musumets'}\n"
     ]
    }
   ],
   "source": [
    "for text_id, text_obj, text_meta in collection.select( collection_meta=['author'] ):\n",
    "    print(text_id, text_obj, text_meta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Search collection\n",
    "\n",
    "EstNLTK provides different types of queries to search `Text` objects from the collection."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`IndexQuery` can be used to search for a particular entry by index:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1, Text(text='Öökull ei laula.'))]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(collection.select( query=IndexQuery( [1] ) ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`MetadataQuery` can be used to search for `Text` objects with specific metadata. By default, collection's metadata columns will be searched:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Text(text='Öökull ei laula.') {'author': 'Niinepuu'}\n"
     ]
    }
   ],
   "source": [
    "q = MetadataQuery( {'author': 'Niinepuu'} )\n",
    "for key, txt, meta in collection.select( query=q, collection_meta=['author'] ):\n",
    "    print(key, txt, meta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternatively, if you use `MetadataQuery` with `meta_type='TEXT'`, then the query searches for metadata inside `Text` objects (the `meta` field):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 Text(text='Karu magab.') {'author': 'Niinemets'}\n"
     ]
    }
   ],
   "source": [
    "q = MetadataQuery( {'author': 'Niinemets'}, meta_type='TEXT' )\n",
    "for key, txt in collection.select( query=q ):\n",
    "    print(key, txt, txt.meta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`SubstringQuery` finds all `Text` objects that have the given substring in their raw text:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Text(text='Ööbik laulab.')\n",
      "1 Text(text='Öökull ei laula.')\n"
     ]
    }
   ],
   "source": [
    "q = SubstringQuery('laula')\n",
    "for key, txt in collection.select(query=q):\n",
    "    print(key, txt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`LayerQuery` can be used to search texts by the attribute values in layers.\n",
    "\n",
    "Find texts that contain lemma `laulma` in the attached `morph_analysis` layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Text(text='Ööbik laulab.')\n",
      "1 Text(text='Öökull ei laula.')\n"
     ]
    }
   ],
   "source": [
    "q = LayerQuery('morph_analysis', lemma='laulma')\n",
    "for key, txt in collection.select(query=q):\n",
    "    print(key, txt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also search for multiple layer attributes.\n",
    "\n",
    "Find texts that contain a span in the detached `detached_morph_1` layer with partofspeech `V` and form `b` ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Text(text='Ööbik laulab.')\n",
      "2 Text(text='Karu magab.')\n"
     ]
    }
   ],
   "source": [
    "q = LayerQuery(layer_name=layer_1, partofspeech='V', form='b')\n",
    "\n",
    "for key, text in collection.select(query=q):\n",
    "    print(key, text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find texts that contain a span in the attached `morph_analysis` layer with lemma `laulma` and form `b`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Text(text='Ööbik laulab.')\n"
     ]
    }
   ],
   "source": [
    "q = LayerQuery('morph_analysis', lemma='laulma', form='b')\n",
    "\n",
    "for key, txt in collection.select(query=q):\n",
    "    print(key, txt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combined conditions with OR and AND operators"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can use `|` (\"OR\"), and `&` (\"AND\") operators to create composite queries."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find texts that contain a span in the `morph_analysis` layer with lemma `ööbik` **or** lemma `öökull`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Text(text='Ööbik laulab.')\n",
      "1 Text(text='Öökull ei laula.')\n"
     ]
    }
   ],
   "source": [
    "q = LayerQuery('morph_analysis', lemma='ööbik') | \\\n",
    "    LayerQuery('morph_analysis', lemma='öökull')\n",
    "\n",
    "for key, txt in collection.select(query=q):\n",
    "    print(key, txt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find texts that contain a span in the `detached_morph_2` layer with lemma `ööbik` **and** lemma `öökull`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "q = LayerQuery(layer_2, lemma='ööbik') & \\\n",
    "    LayerQuery(layer_2, lemma='öökull')\n",
    "for key, txt in collection.select(query=q):\n",
    "    print(key, txt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No such text."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find texts that contain a span in the `detached_morph_2` layer with lemma `ööbik` **and** another span with partofspeech `V` and form `b`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Text(text='Ööbik laulab.')\n"
     ]
    }
   ],
   "source": [
    "q = LayerQuery(layer_name=layer_2, lemma='ööbik') & \\\n",
    "    LayerQuery(layer_name=layer_2, partofspeech='V', form='b')\n",
    "\n",
    "for key, text in collection.select(query=q):\n",
    "    print(key, text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find texts that contain a span in the `morph_analysis` layer with lemma `laulma` **and** another span with lemma `ööbik` **or** `öökull`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Text(text='Ööbik laulab.')\n",
      "1 Text(text='Öökull ei laula.')\n"
     ]
    }
   ],
   "source": [
    "q = (LayerQuery('morph_analysis', lemma='ööbik') | LayerQuery('morph_analysis', lemma='öökull')) & \\\n",
    "     LayerQuery('morph_analysis', lemma='laulma')\n",
    "for key, txt in collection.select(query=q):\n",
    "    print(key, txt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Naturally, we can also combine layer queries over different layers. \n",
    "\n",
    "Find texts with lemma `ööbik` **or** `öökull` in the `detached_morph_1` layer **and** lemma `laulma` in the `detached_morph_2` layer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Text(text='Ööbik laulab.')\n",
      "1 Text(text='Öökull ei laula.')\n"
     ]
    }
   ],
   "source": [
    "q = (LayerQuery(layer_1, lemma='ööbik') | LayerQuery(layer_1, lemma='öökull')) & \\\n",
    "     LayerQuery(layer_2, lemma='laulma')\n",
    "\n",
    "for key, text in collection.select(query=q):\n",
    "    print(key, text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we can also combine different types of queries.\n",
    "\n",
    "Find texts with lemma `ööbik` in the `detached_morph_2` layer **or** with metadata entry `'author': 'Niinemets'`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Text(text='Öökull ei laula.')\n",
      "2 Text(text='Karu magab.')\n"
     ]
    }
   ],
   "source": [
    "q = LayerQuery(layer_2, lemma='öökull') | \\\n",
    "    MetadataQuery({'author': 'Niinemets'}, meta_type='TEXT')\n",
    "\n",
    "for key, text in collection.select(query=q):\n",
    "    print(key, text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Queries over blocks of texts (parallelization)\n",
    "\n",
    "You can use `BlockQuery` to make queries over non-overlapping subsets (blocks) of the collection. \n",
    "This can be useful for query parallelization: you can launch several parallel query jobs on the collection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from estnltk.storage.postgres import BlockQuery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "q = LayerQuery('morph_analysis', lemma='ööbik') | \\\n",
    "    LayerQuery('morph_analysis', lemma='öökull')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can add `BlockQuery` constraint to the query. The block of documents is defined by the input parameter `(module, remainder)`, which instructs to select only texts with `text_id % module == remainder`. So, if we want to cover the whole collection with 2 queries, we add `BlockQuery(module=2, remainder=0)` to the first query and `BlockQuery(module=2, remainder=1)` to the second query.\n",
    "For parallel querying, it is recommended to create a new database connection for each block query, like in the examples below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:storage.py:41: connecting to host: 'localhost', port: '5432', dbname: 'test_db', user: 'postgres'\n",
      "INFO:storage.py:58: schema: 'my_schema', temporary: False, role: 'postgres'\n",
      "0 Text(text='Ööbik laulab.')\n"
     ]
    }
   ],
   "source": [
    "# In case of parallel processing: Open a new connection to the database & collection\n",
    "storage_a = PostgresStorage( dbname='test_db', pgpass_file='~/.pgpass', schema='my_schema' )\n",
    "collection_a = storage_a[\"my_collection\"]\n",
    "# Search the first block\n",
    "for key, txt in collection_a.select(query=q & BlockQuery(2, 0)):\n",
    "    print(key, txt)\n",
    "# Close the connection\n",
    "storage_a.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:storage.py:41: connecting to host: 'localhost', port: '5432', dbname: 'test_db', user: 'postgres'\n",
      "INFO:storage.py:58: schema: 'my_schema', temporary: False, role: 'postgres'\n",
      "1 Text(text='Öökull ei laula.')\n"
     ]
    }
   ],
   "source": [
    "# In case of parallel processing: Open a new connection to the database & collection\n",
    "storage_b = PostgresStorage( dbname='test_db', pgpass_file='~/.pgpass', schema='my_schema' )\n",
    "collection_b = storage_b[\"my_collection\"]\n",
    "# Search the second block\n",
    "for key, txt in collection_b.select(query=q & BlockQuery(2, 1)):\n",
    "    print(key, txt)\n",
    "# Close the connection\n",
    "storage_b.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Queries over sparse layers\n",
    "\n",
    "By default, iteration over sparse layers works as the default iteration, yielding all texts (that match the selection query):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Text(text='Ööbik laulab.') | compound_tokens_sparse length: 0\n",
      "1 Text(text='Öökull ei laula.') | compound_tokens_sparse length: 0\n",
      "2 Text(text='Karu magab.') | compound_tokens_sparse length: 0\n",
      "3 Text(text='Vana-Karu lõi trummi.') | compound_tokens_sparse length: 1\n"
     ]
    }
   ],
   "source": [
    "# Iterate over collection by selecting a sparse layer (default)\n",
    "for key, text in collection.select(layers=['compound_tokens_sparse']):\n",
    "    print(key, text, '| compound_tokens_sparse length:', len(text['compound_tokens_sparse']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, you can use `keep_all_texts=False` to constrain the query to yield only those texts that have non-empty sparse layers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 Text(text='Vana-Karu lõi trummi.') | compound_tokens_sparse length: 1\n"
     ]
    }
   ],
   "source": [
    "# Iterate over collection by selecting texts with non-empty sparse layers\n",
    "for key, text in collection.select(layers=['compound_tokens_sparse'], keep_all_texts=False):\n",
    "    print(key, text, '| compound_tokens_sparse length:', len(text['compound_tokens_sparse']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that if you have multiple sparse layers selected, then the query yields an intersection of non-empty sparse layers: only texts that have all the selected sparse layers non-empty will be yield."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a sparse layer from a selection\n",
    "\n",
    "Esentially, `collection.select(...)` yields a read-only subcollection of texts from the collection (see `PgSubCollection` below). \n",
    "This subcollection can be used as a basis for creating a new sparse layer that covers only texts from that subcollection. \n",
    "You can use `collection.select(...).create_layer(tagger)` to tag a sparse layer over the selection:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:collection.py:696: collection: 'my_collection'\n",
      "INFO:collection.py:715: preparing to create a new layer: 'paragraphs_sparse'\n",
      "INFO:collection.py:747: inserting data into the 'paragraphs_sparse' layer table\n",
      "INFO:collection_detached_layer_inserter.py:86: inserted 2 detached 'paragraphs_sparse' layers into the collection 'my_collection'\n",
      "INFO:collection.py:782: layer created: 'paragraphs_sparse'\n"
     ]
    }
   ],
   "source": [
    "# Create tagger for sparse 'paragraphs' layer\n",
    "paragraph_tokenizer = ParagraphTokenizer(output_layer='paragraphs_sparse')\n",
    "\n",
    "# Annotate only a subselection of texts with 'paragraphs'\n",
    "collection.select(query=IndexQuery([0, 1])).create_layer(paragraph_tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In a similar manner, you can use `collection.select(...).create_layer_block(tagger, block)` to tag a block over the selection. However, remember to create the layer table beforehand via `collection.add_layer(layer_template=tagger.get_layer_template(), sparse=True)`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the default iteration over the sparse layer still yields all text objects:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Text(text='Ööbik laulab.') | paragraphs_sparse length: 1\n",
      "1 Text(text='Öökull ei laula.') | paragraphs_sparse length: 1\n",
      "2 Text(text='Karu magab.') | paragraphs_sparse length: 0\n",
      "3 Text(text='Vana-Karu lõi trummi.') | paragraphs_sparse length: 0\n"
     ]
    }
   ],
   "source": [
    "# Browse results: iterate over collection by selecting a sparse layer\n",
    "for key, text in collection.select(layers=['paragraphs_sparse']):\n",
    "    print(key, text, '| paragraphs_sparse length:', len(text['paragraphs_sparse']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And `keep_all_texts=False` can be used to constrain the query to texts with non-empty sparse layers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Text(text='Ööbik laulab.') | paragraphs_sparse length: 1\n",
      "1 Text(text='Öökull ei laula.') | paragraphs_sparse length: 1\n"
     ]
    }
   ],
   "source": [
    "for key, text in collection.select(layers=['paragraphs_sparse'], keep_all_texts=False):\n",
    "    print(key, text, '| paragraphs_sparse length:', len(text['paragraphs_sparse']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we're done with these examples. Delete the collection:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "collection.delete()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Indexing layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a new collection:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:collection.py:94: new empty collection 'collection_with_layers' created\n",
      "INFO:collection_text_object_inserter.py:107: inserted 2 texts into the collection 'collection_with_layers'\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<b>PgCollection</b><br/><b>name:</b> collection_with_layers<br/><b>storage:</b> PostgresStorage(user=postgres password=xxx dbname=test_db host=localhost port=5432 schema=my_schema temporary=False)<br/><b>count objects:</b> 2<br/><b>Metadata</b><br/>This collection has no metadata.<br/><b>Layers</b><table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>layer_type</th>\n",
       "      <th>attributes</th>\n",
       "      <th>ambiguous</th>\n",
       "      <th>sparse</th>\n",
       "      <th>parent</th>\n",
       "      <th>enveloping</th>\n",
       "      <th>meta</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>sentences</th>\n",
       "      <td>attached</td>\n",
       "      <td>()</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>words</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tokens</th>\n",
       "      <td>attached</td>\n",
       "      <td>()</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>compound_tokens</th>\n",
       "      <td>attached</td>\n",
       "      <td>(type, normalized)</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>tokens</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>words</th>\n",
       "      <td>attached</td>\n",
       "      <td>(normalized_form,)</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<estnltk.storage.postgres.collection.PgCollection at 0x1b3b694c790>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collection = storage.get_collection('collection_with_layers')\n",
    "collection.create()\n",
    "\n",
    "with collection.insert() as collection_insert:\n",
    "    collection_insert(Text('See on esimene lause.').tag_layer([\"sentences\"]))\n",
    "    collection_insert(Text('See on teine lause.').tag_layer([\"sentences\"]))\n",
    "\n",
    "collection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ngram index enables to index ngrams in layer attributes.\n",
    "For example, a bigram index on an attribute with values `['see', 'on', 'esimene', 'lause']` will contain pairs *'see-on'*, *'on-esimene'*, *'esimene-lause'*.\n",
    "Indices of a higher order are also supported.\n",
    "\n",
    "To build an ngram index, provide an argument *ngram_index* when creating a new layer.\n",
    "The following code creates a bi-gram index on an attribute *lemma* for a newly created layer *indexed_layer*:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:collection.py:696: collection: 'collection_with_layers'\n",
      "INFO:collection.py:715: preparing to create a new layer: 'indexed_layer'\n",
      "INFO:collection.py:747: inserting data into the 'indexed_layer' layer table\n",
      "INFO:collection_detached_layer_inserter.py:86: inserted 2 detached 'indexed_layer' layers into the collection 'collection_with_layers'\n",
      "INFO:collection.py:782: layer created: 'indexed_layer'\n"
     ]
    }
   ],
   "source": [
    "indexed_layer = 'indexed_layer'\n",
    "tagger = VabamorfTagger(disambiguate=False, output_layer=indexed_layer)\n",
    "\n",
    "collection.create_layer(tagger=tagger, ngram_index={\"lemma\": 2})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To search an ngram index, use `LayerNgramQuery` query:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Search entries containing lemma bigram 'see-olema':"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Text(text='See on esimene lause.')\n",
      "1 Text(text='See on teine lause.')\n"
     ]
    }
   ],
   "source": [
    "from estnltk.storage.postgres import LayerNgramQuery\n",
    "\n",
    "q = LayerNgramQuery( { indexed_layer: {\n",
    "        \"lemma\": [(\"see\", \"olema\")]\n",
    "    }})\n",
    "for key, text in collection.select(query=q):\n",
    "    print(key, text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Search 'teine-lause' OR 'olema-esimene':"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Text(text='See on esimene lause.')\n",
      "1 Text(text='See on teine lause.')\n"
     ]
    }
   ],
   "source": [
    "q = LayerNgramQuery( { indexed_layer: {\n",
    "        \"lemma\":  [(\"teine\", \"lause\"), (\"olema\", \"esimene\")]\n",
    "    }})\n",
    "for key, text in collection.select(query=q):\n",
    "    print(key, text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Search 'see-olema' AND 'olema-esimene':"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Text(text='See on esimene lause.')\n"
     ]
    }
   ],
   "source": [
    "q = LayerNgramQuery( { indexed_layer: {\n",
    "        \"lemma\":  [[(\"see\", \"olema\"), (\"olema\", \"esimene\")]]\n",
    "    }})\n",
    "for key, text in collection.select(query=q):\n",
    "    print(key, text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<b>PgCollection</b><br/><b>name:</b> collection_with_layers<br/><b>storage:</b> PostgresStorage(user=postgres password=xxx dbname=test_db host=localhost port=5432 schema=my_schema temporary=False)<br/><b>count objects:</b> 2<br/><b>Metadata</b><br/>This collection has no metadata.<br/><b>Layers</b><table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>layer_type</th>\n",
       "      <th>attributes</th>\n",
       "      <th>ambiguous</th>\n",
       "      <th>sparse</th>\n",
       "      <th>parent</th>\n",
       "      <th>enveloping</th>\n",
       "      <th>meta</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>sentences</th>\n",
       "      <td>attached</td>\n",
       "      <td>()</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>words</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tokens</th>\n",
       "      <td>attached</td>\n",
       "      <td>()</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>compound_tokens</th>\n",
       "      <td>attached</td>\n",
       "      <td>(type, normalized)</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>tokens</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>words</th>\n",
       "      <td>attached</td>\n",
       "      <td>(normalized_form,)</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>indexed_layer</th>\n",
       "      <td>detached</td>\n",
       "      <td>(normalized_text, lemma, root, root_tokens, ending, clitic, form, partofspeech, _ignore)</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>words</td>\n",
       "      <td>None</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<estnltk.storage.postgres.collection.PgCollection at 0x1b3b694c790>"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Delete layer\n",
    "\n",
    "Only detched layers can be deleted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<b>PgCollection</b><br/><b>name:</b> collection_with_layers<br/><b>storage:</b> PostgresStorage(user=postgres password=xxx dbname=test_db host=localhost port=5432 schema=my_schema temporary=False)<br/><b>count objects:</b> 2<br/><b>Metadata</b><br/>This collection has no metadata.<br/><b>Layers</b><table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>layer_type</th>\n",
       "      <th>attributes</th>\n",
       "      <th>ambiguous</th>\n",
       "      <th>sparse</th>\n",
       "      <th>parent</th>\n",
       "      <th>enveloping</th>\n",
       "      <th>meta</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>sentences</th>\n",
       "      <td>attached</td>\n",
       "      <td>()</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>words</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tokens</th>\n",
       "      <td>attached</td>\n",
       "      <td>()</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>compound_tokens</th>\n",
       "      <td>attached</td>\n",
       "      <td>(type, normalized)</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>tokens</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>words</th>\n",
       "      <td>attached</td>\n",
       "      <td>(normalized_form,)</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>indexed_layer</th>\n",
       "      <td>detached</td>\n",
       "      <td>(normalized_text, lemma, root, root_tokens, ending, clitic, form, partofspeech, _ignore)</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>words</td>\n",
       "      <td>None</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<estnltk.storage.postgres.collection.PgCollection at 0x1b3b694c790>"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The only detached layer in this collection is the layer `indexed_layer`. Let's delete it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:collection.py:1097: layer deleted: 'indexed_layer'\n"
     ]
    }
   ],
   "source": [
    "collection.delete_layer('indexed_layer')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally delete the collection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "collection.delete()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `PgSubCollection`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:collection.py:94: new empty collection 'my_collection' created\n",
      "INFO:collection_text_object_inserter.py:107: inserted 5 texts into the collection 'my_collection'\n"
     ]
    }
   ],
   "source": [
    "collection = storage.get_collection('my_collection')\n",
    "collection.create()\n",
    "\n",
    "texts = ['Esimene tekst.', 'Teine tekst.', 'Kolmas tekst.', 'Neljas tekst.', 'Viies tekst.']\n",
    "\n",
    "with collection.insert() as collection_insert:\n",
    "    for t in texts:\n",
    "        collection_insert(Text(t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:collection.py:696: collection: 'my_collection'\n",
      "INFO:collection.py:715: preparing to create a new layer: 'tokens'\n",
      "INFO:collection.py:747: inserting data into the 'tokens' layer table\n",
      "INFO:collection_detached_layer_inserter.py:86: inserted 5 detached 'tokens' layers into the collection 'my_collection'\n",
      "INFO:collection.py:782: layer created: 'tokens'\n"
     ]
    }
   ],
   "source": [
    "from estnltk.taggers import TokensTagger\n",
    "\n",
    "tokens_tagger = TokensTagger()\n",
    "\n",
    "collection.create_layer(tagger=tokens_tagger)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `select` method returns a `PgSubCollection` object that provides read-only access to a subset of the collection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PgSubCollection(collection: 'my_collection', selected_layers=[], meta_attributes=(), progressbar=None, return_index=True)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collection.select(query=None,\n",
    "                  layers=None,  # Sequence[str] \n",
    "                  collection_meta=None,  # Sequence[str] \n",
    "                  progressbar=None,  # str\n",
    "                  return_index=True,  # bool\n",
    "                  itersize= 10\n",
    "                  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8167ebdb6c304efda0c23b54d12093f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?doc/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, Text(text='Esimene tekst.'))\n",
      "(1, Text(text='Teine tekst.'))\n",
      "(2, Text(text='Kolmas tekst.'))\n",
      "(3, Text(text='Neljas tekst.'))\n",
      "(4, Text(text='Viies tekst.'))\n"
     ]
    }
   ],
   "source": [
    "for text in collection.select(progressbar='notebook', return_index=True):\n",
    "    print(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also directly access first and last texts of the `PgSubCollection`. The `head` method selects only first `N` texts from the subset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, Text(text='Esimene tekst.'))\n",
      "(1, Text(text='Teine tekst.'))\n",
      "(2, Text(text='Kolmas tekst.'))\n"
     ]
    }
   ],
   "source": [
    "# Select first 3 texts\n",
    "for text in collection.select().head( 3 ):\n",
    "    print(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And the `tail` method selects last `N` texts:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, Text(text='Neljas tekst.'))\n",
      "(4, Text(text='Viies tekst.'))\n"
     ]
    }
   ],
   "source": [
    "# Select only last 2 texts\n",
    "for text in collection.select().tail( 2 ):\n",
    "    print(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get detached layer without `Text` object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PgSubCollectionLayer(collection: 'my_collection', detached_layer='tokens', progressbar=None, return_index=False, skip_empty=False)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "detached_layers = collection.select(return_index=False).detached_layer('tokens')\n",
    "detached_layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h4>Layer</h4>\n",
       "\n",
       "No Text object.\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>layer name</th>\n",
       "      <th>attributes</th>\n",
       "      <th>parent</th>\n",
       "      <th>enveloping</th>\n",
       "      <th>ambiguous</th>\n",
       "      <th>span count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>tokens</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "Layer(name='tokens', attributes=(), spans=SL[Span(None, [{}]),\n",
       "Span(None, [{}]),\n",
       "Span(None, [{}])])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(detached_layers))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Working with fragments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:collection.py:94: new empty collection 'collection_with_fragments' created\n",
      "INFO:collection_text_object_inserter.py:107: inserted 2 texts into the collection 'collection_with_fragments'\n",
      "INFO:collection.py:566: collection: 'collection_with_fragments'\n",
      "INFO:collection_detached_layer_inserter.py:86: inserted 2 detached 'fragmented_morph' layers into the collection 'collection_with_fragments'\n",
      "INFO:collection.py:614: fragmented layer created: 'fragmented_morph'\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<b>PgCollection</b><br/><b>name:</b> collection_with_fragments<br/><b>storage:</b> PostgresStorage(user=postgres password=xxx dbname=test_db host=localhost port=5432 schema=my_schema temporary=False)<br/><b>count objects:</b> 2<br/><b>Metadata</b><br/>This collection has no metadata.<br/><b>Layers</b><table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>layer_type</th>\n",
       "      <th>attributes</th>\n",
       "      <th>ambiguous</th>\n",
       "      <th>sparse</th>\n",
       "      <th>parent</th>\n",
       "      <th>enveloping</th>\n",
       "      <th>meta</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>tokens</th>\n",
       "      <td>attached</td>\n",
       "      <td>()</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>compound_tokens</th>\n",
       "      <td>attached</td>\n",
       "      <td>(type, normalized)</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>tokens</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sentences</th>\n",
       "      <td>attached</td>\n",
       "      <td>()</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>words</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>morph_analysis</th>\n",
       "      <td>attached</td>\n",
       "      <td>(normalized_text, lemma, root, root_tokens, ending, clitic, form, partofspeech)</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>words</td>\n",
       "      <td>None</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>words</th>\n",
       "      <td>attached</td>\n",
       "      <td>(normalized_form,)</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fragmented_morph</th>\n",
       "      <td>fragmented</td>\n",
       "      <td>(normalized_text, lemma, root, root_tokens, ending, clitic, form, partofspeech, _ignore)</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>words</td>\n",
       "      <td>None</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<estnltk.storage.postgres.collection.PgCollection at 0x1b3b6a6a400>"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collection = storage[\"collection_with_fragments\"].create(description='demo collection')\n",
    "\n",
    "with collection.insert() as collection_insert:\n",
    "    text1 = Text('Ööbik laulab.').tag_layer(['morph_analysis'])\n",
    "    collection_insert(text1)\n",
    "\n",
    "    text2 = Text('Öökull ei laula.').tag_layer(['morph_analysis'])\n",
    "    key2 = collection_insert(text2)\n",
    "\n",
    "    \n",
    "def fragmenter(layer):\n",
    "    return [layer]\n",
    "\n",
    "\n",
    "tagger = VabamorfTagger(disambiguate=False, output_layer='fragmented_morph')\n",
    "\n",
    "collection.create_fragmented_layer(tagger=tagger, fragmenter=fragmenter)\n",
    "\n",
    "collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:collection.py:94: new empty collection 'fragment_test' created\n",
      "INFO:collection_text_object_inserter.py:107: inserted 2 texts into the collection 'fragment_test'\n",
      "INFO:collection.py:696: collection: 'fragment_test'\n",
      "INFO:collection.py:715: preparing to create a new layer: 'layer_fragment_1'\n",
      "INFO:collection.py:747: inserting data into the 'layer_fragment_1' layer table\n",
      "INFO:collection_detached_layer_inserter.py:86: inserted 2 detached 'layer_fragment_1' layers into the collection 'fragment_test'\n",
      "INFO:collection.py:782: layer created: 'layer_fragment_1'\n"
     ]
    }
   ],
   "source": [
    "from estnltk.storage.postgres import RowMapperRecord\n",
    "\n",
    "table_name = 'fragment_test'\n",
    "collection = storage.get_collection(table_name)\n",
    "collection.create()\n",
    "\n",
    "with collection.insert() as collection_insert:\n",
    "    text1 = Text('see on esimene lause').tag_layer([\"sentences\"])\n",
    "    collection_insert(text1)\n",
    "    text2 = Text('see on teine lause').tag_layer([\"sentences\"])\n",
    "    collection_insert(text2)\n",
    "\n",
    "layer_fragment_name = \"layer_fragment_1\"\n",
    "tagger = VabamorfTagger(disambiguate=False, output_layer=layer_fragment_name)\n",
    "\n",
    "collection.create_layer(tagger=tagger)\n",
    "\n",
    "fragment_name = \"fragment_1\"\n",
    "\n",
    "def row_mapper(row):\n",
    "        parent_id, layer = row\n",
    "        return [{'fragment': layer, 'parent_id': parent_id},\n",
    "                {'fragment': layer, 'parent_id': parent_id}]\n",
    "\n",
    "collection.create_fragment(fragment_name,\n",
    "                    data_iterator=collection.select().fragmented_layer(name=layer_fragment_name),\n",
    "                    row_mapper=row_mapper,\n",
    "                    create_index=False,\n",
    "                    ngram_index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<b>PgCollection</b><br/><b>name:</b> fragment_test<br/><b>storage:</b> PostgresStorage(user=postgres password=xxx dbname=test_db host=localhost port=5432 schema=my_schema temporary=False)<br/><b>count objects:</b> 2<br/><b>Metadata</b><br/>This collection has no metadata.<br/><b>Layers</b><table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>layer_type</th>\n",
       "      <th>attributes</th>\n",
       "      <th>ambiguous</th>\n",
       "      <th>sparse</th>\n",
       "      <th>parent</th>\n",
       "      <th>enveloping</th>\n",
       "      <th>meta</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>sentences</th>\n",
       "      <td>attached</td>\n",
       "      <td>()</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>words</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tokens</th>\n",
       "      <td>attached</td>\n",
       "      <td>()</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>compound_tokens</th>\n",
       "      <td>attached</td>\n",
       "      <td>(type, normalized)</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>tokens</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>words</th>\n",
       "      <td>attached</td>\n",
       "      <td>(normalized_form,)</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>layer_fragment_1</th>\n",
       "      <td>detached</td>\n",
       "      <td>(normalized_text, lemma, root, root_tokens, ending, clitic, form, partofspeech, _ignore)</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>words</td>\n",
       "      <td>None</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<estnltk.storage.postgres.collection.PgCollection at 0x1b3b667e580>"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "collection.delete()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "delete_schema(storage)\n",
    "storage.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
