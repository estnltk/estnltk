{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2b00e97f-54de-4358-a5cd-2ac37ace4d94",
   "metadata": {},
   "source": [
    "# How to systematically build a decorator for rule taggers \n",
    "\n",
    "The logic of all rule taggers is the same: \n",
    "1. Rules are used to extract potential matches.\n",
    "2. A matching rule assigns a set of initial attributes to each match. \n",
    "3. Conflict resolver strategy is used to deal with overlapping patterns.\n",
    "4. Global or rule-specific decorator is used to update attribute values or filter out spurious macthes\n",
    "\n",
    "In this notebook, we show how to systematically develop decorators. \n",
    "The latter can be quite error prone as its input structure is complex and it is hard to test its behaviour.\n",
    "As a concrete example, we are developing a decorator for PhraseTagger that should match proper names from the list specified by lemma tuples.\n",
    "We can refine this extraction strategy by requiring that words in the match have matching cases. \n",
    "For that we need to access the morphogical annotations and check their consistency.\n",
    "To demonstrate attribute derivation, we also convert proper names to their normal form in the nominal case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a4624021-3c64-495d-94b1-ce776b955862",
   "metadata": {},
   "outputs": [],
   "source": [
    "from estnltk import Text\n",
    "from estnltk.taggers.system.rule_taggers import Ruleset \n",
    "from estnltk.taggers.system.rule_taggers import StaticExtractionRule \n",
    "from estnltk.taggers.system.rule_taggers import DynamicExtractionRule\n",
    "from estnltk.taggers import PhraseTagger"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8615901-dd8e-40f2-bea8-69479a6f2646",
   "metadata": {},
   "source": [
    "## I. Define initial set of extraction rules \n",
    "\n",
    "We need initail ruleset to proceed with development.\n",
    "This ruleset does not have to be complete as long as it creates enough matches in test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6411f24b-be3e-46d0-9eed-d6d7ef726b6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "extraction_rules = Ruleset([\n",
    "    StaticExtractionRule(pattern=('aadu','must'), attributes = {'entity_type': 'PER', 'profession': 'politician', 'age': 63}),\n",
    "    StaticExtractionRule(pattern=('euroopa','liit'), attributes = {'entity_type': 'ORG'})\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e78b3c1-dc9b-44fe-b16b-ff3185fcedce",
   "metadata": {},
   "source": [
    "## II. Define the initil test data\n",
    "The aim here is to define a set of revealing example sentences which contain true and false matches.\n",
    "The list here does not have to be complete. \n",
    "We need enough examples to carve out main code paths in the decorator.\n",
    "We also need to add morph analysis layer to these texts, otherwise we cannot check for consistency. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5f89e8f4-b5e8-43ee-9a7f-c52aabea1227",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h4>Layer</h4>\n",
       "\n",
       "\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>layer name</th>\n",
       "      <th>attributes</th>\n",
       "      <th>parent</th>\n",
       "      <th>enveloping</th>\n",
       "      <th>ambiguous</th>\n",
       "      <th>span count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>morph_analysis</td>\n",
       "      <td>normalized_text, lemma, root, root_tokens, ending, clitic, form, partofspeech</td>\n",
       "      <td>words</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>text</th>\n",
       "      <th>normalized_text</th>\n",
       "      <th>lemma</th>\n",
       "      <th>root</th>\n",
       "      <th>root_tokens</th>\n",
       "      <th>ending</th>\n",
       "      <th>clitic</th>\n",
       "      <th>form</th>\n",
       "      <th>partofspeech</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>Täna</td>\n",
       "      <td>Täna</td>\n",
       "      <td>täna</td>\n",
       "      <td>täna</td>\n",
       "      <td>['täna']</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>räägime</td>\n",
       "      <td>räägime</td>\n",
       "      <td>rääkima</td>\n",
       "      <td>rääki</td>\n",
       "      <td>['rääki']</td>\n",
       "      <td>me</td>\n",
       "      <td></td>\n",
       "      <td>me</td>\n",
       "      <td>V</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Aadu</td>\n",
       "      <td>Aadu</td>\n",
       "      <td>Aadu</td>\n",
       "      <td>Aadu</td>\n",
       "      <td>['Aadu']</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>sg n</td>\n",
       "      <td>H</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Mustast</td>\n",
       "      <td>Mustast</td>\n",
       "      <td>must</td>\n",
       "      <td>must</td>\n",
       "      <td>['must']</td>\n",
       "      <td>st</td>\n",
       "      <td></td>\n",
       "      <td>sg el</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>ja</td>\n",
       "      <td>ja</td>\n",
       "      <td>ja</td>\n",
       "      <td>ja</td>\n",
       "      <td>['ja']</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>J</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Euroopa</td>\n",
       "      <td>Euroopa</td>\n",
       "      <td>Euroopa</td>\n",
       "      <td>Euroopa</td>\n",
       "      <td>['Euroopa']</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>sg g</td>\n",
       "      <td>H</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Liidust</td>\n",
       "      <td>Liidust</td>\n",
       "      <td>Liidu</td>\n",
       "      <td>Liidu</td>\n",
       "      <td>['Liidu']</td>\n",
       "      <td>st</td>\n",
       "      <td></td>\n",
       "      <td>sg el</td>\n",
       "      <td>H</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td></td>\n",
       "      <td>Liidust</td>\n",
       "      <td>Liidud</td>\n",
       "      <td>Liidud</td>\n",
       "      <td>['Liidud']</td>\n",
       "      <td>st</td>\n",
       "      <td></td>\n",
       "      <td>sg el</td>\n",
       "      <td>H</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td></td>\n",
       "      <td>Liidust</td>\n",
       "      <td>Liit</td>\n",
       "      <td>Liit</td>\n",
       "      <td>['Liit']</td>\n",
       "      <td>st</td>\n",
       "      <td></td>\n",
       "      <td>sg el</td>\n",
       "      <td>H</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>['.']</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Z</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "Layer(name='morph_analysis', attributes=('normalized_text', 'lemma', 'root', 'root_tokens', 'ending', 'clitic', 'form', 'partofspeech'), spans=SL[Span('Täna', [{'normalized_text': 'Täna', 'lemma': 'täna', 'root': 'täna', 'root_tokens': ['täna'], 'ending': '0', 'clitic': '', 'form': '', 'partofspeech': 'D'}]),\n",
       "Span('räägime', [{'normalized_text': 'räägime', 'lemma': 'rääkima', 'root': 'rääki', 'root_tokens': ['rääki'], 'ending': 'me', 'clitic': '', 'form': 'me', 'partofspeech': 'V'}]),\n",
       "Span('Aadu', [{'normalized_text': 'Aadu', 'lemma': 'Aadu', 'root': 'Aadu', 'root_tokens': ['Aadu'], 'ending': '0', 'clitic': '', 'form': 'sg n', 'partofspeech': 'H'}]),\n",
       "Span('Mustast', [{'normalized_text': 'Mustast', 'lemma': 'must', 'root': 'must', 'root_tokens': ['must'], 'ending': 'st', 'clitic': '', 'form': 'sg el', 'partofspeech': 'A'}]),\n",
       "Span('ja', [{'normalized_text': 'ja', 'lemma': 'ja', 'root': 'ja', 'root_tokens': ['ja'], 'ending': '0', 'clitic': '', 'form': '', 'partofspeech': 'J'}]),\n",
       "Span('Euroopa', [{'normalized_text': 'Euroopa', 'lemma': 'Euroopa', 'root': 'Euroopa', 'root_tokens': ['Euroopa'], 'ending': '0', 'clitic': '', 'form': 'sg g', 'partofspeech': 'H'}]),\n",
       "Span('Liidust', [{'normalized_text': 'Liidust', 'lemma': 'Liidu', 'root': 'Liidu', 'root_tokens': ['Liidu'], 'ending': 'st', 'clitic': '', 'form': 'sg el', 'partofspeech': 'H'}, {'normalized_text': 'Liidust', 'lemma': 'Liidud', 'root': 'Liidud', 'root_tokens': ['Liidud'], 'ending': 'st', 'clitic': '', 'form': 'sg el', 'partofspeech': 'H'}, {'normalized_text': 'Liidust', 'lemma': 'Liit', 'root': 'Liit', 'root_tokens': ['Liit'], 'ending': 'st', 'clitic': '', 'form': 'sg el', 'partofspeech': 'H'}]),\n",
       "Span('.', [{'normalized_text': '.', 'lemma': '.', 'root': '.', 'root_tokens': ['.'], 'ending': '', 'clitic': '', 'form': '', 'partofspeech': 'Z'}])])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h4>Layer</h4>\n",
       "\n",
       "\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>layer name</th>\n",
       "      <th>attributes</th>\n",
       "      <th>parent</th>\n",
       "      <th>enveloping</th>\n",
       "      <th>ambiguous</th>\n",
       "      <th>span count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>morph_analysis</td>\n",
       "      <td>normalized_text, lemma, root, root_tokens, ending, clitic, form, partofspeech</td>\n",
       "      <td>words</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>text</th>\n",
       "      <th>normalized_text</th>\n",
       "      <th>lemma</th>\n",
       "      <th>root</th>\n",
       "      <th>root_tokens</th>\n",
       "      <th>ending</th>\n",
       "      <th>clitic</th>\n",
       "      <th>form</th>\n",
       "      <th>partofspeech</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>Eile</td>\n",
       "      <td>Eile</td>\n",
       "      <td>eile</td>\n",
       "      <td>eile</td>\n",
       "      <td>['eile']</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>rääkisime</td>\n",
       "      <td>rääkisime</td>\n",
       "      <td>rääkima</td>\n",
       "      <td>rääki</td>\n",
       "      <td>['rääki']</td>\n",
       "      <td>sime</td>\n",
       "      <td></td>\n",
       "      <td>sime</td>\n",
       "      <td>V</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Aadule</td>\n",
       "      <td>Aadule</td>\n",
       "      <td>Aadu</td>\n",
       "      <td>Aadu</td>\n",
       "      <td>['Aadu']</td>\n",
       "      <td>le</td>\n",
       "      <td></td>\n",
       "      <td>sg all</td>\n",
       "      <td>H</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>musta</td>\n",
       "      <td>musta</td>\n",
       "      <td>must</td>\n",
       "      <td>must</td>\n",
       "      <td>['must']</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>sg g</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>kaabu</td>\n",
       "      <td>kaabu</td>\n",
       "      <td>kaabu</td>\n",
       "      <td>kaabu</td>\n",
       "      <td>['kaabu']</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>sg g</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>kinkimisest</td>\n",
       "      <td>kinkimisest</td>\n",
       "      <td>kinkimine</td>\n",
       "      <td>kinkimine</td>\n",
       "      <td>['kinkimine']</td>\n",
       "      <td>st</td>\n",
       "      <td></td>\n",
       "      <td>sg el</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>ja</td>\n",
       "      <td>ja</td>\n",
       "      <td>ja</td>\n",
       "      <td>ja</td>\n",
       "      <td>['ja']</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>J</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Euroopas</td>\n",
       "      <td>Euroopas</td>\n",
       "      <td>Euroopa</td>\n",
       "      <td>Euroopa</td>\n",
       "      <td>['Euroopa']</td>\n",
       "      <td>s</td>\n",
       "      <td></td>\n",
       "      <td>sg in</td>\n",
       "      <td>H</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>liidu</td>\n",
       "      <td>liidu</td>\n",
       "      <td>liit</td>\n",
       "      <td>liit</td>\n",
       "      <td>['liit']</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>sg g</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>sõlmimisest</td>\n",
       "      <td>sõlmimisest</td>\n",
       "      <td>sõlmimine</td>\n",
       "      <td>sõlmimine</td>\n",
       "      <td>['sõlmimine']</td>\n",
       "      <td>st</td>\n",
       "      <td></td>\n",
       "      <td>sg el</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>['.']</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Z</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "Layer(name='morph_analysis', attributes=('normalized_text', 'lemma', 'root', 'root_tokens', 'ending', 'clitic', 'form', 'partofspeech'), spans=SL[Span('Eile', [{'normalized_text': 'Eile', 'lemma': 'eile', 'root': 'eile', 'root_tokens': ['eile'], 'ending': '0', 'clitic': '', 'form': '', 'partofspeech': 'D'}]),\n",
       "Span('rääkisime', [{'normalized_text': 'rääkisime', 'lemma': 'rääkima', 'root': 'rääki', 'root_tokens': ['rääki'], 'ending': 'sime', 'clitic': '', 'form': 'sime', 'partofspeech': 'V'}]),\n",
       "Span('Aadule', [{'normalized_text': 'Aadule', 'lemma': 'Aadu', 'root': 'Aadu', 'root_tokens': ['Aadu'], 'ending': 'le', 'clitic': '', 'form': 'sg all', 'partofspeech': 'H'}]),\n",
       "Span('musta', [{'normalized_text': 'musta', 'lemma': 'must', 'root': 'must', 'root_tokens': ['must'], 'ending': '0', 'clitic': '', 'form': 'sg g', 'partofspeech': 'A'}]),\n",
       "Span('kaabu', [{'normalized_text': 'kaabu', 'lemma': 'kaabu', 'root': 'kaabu', 'root_tokens': ['kaabu'], 'ending': '0', 'clitic': '', 'form': 'sg g', 'partofspeech': 'S'}]),\n",
       "Span('kinkimisest', [{'normalized_text': 'kinkimisest', 'lemma': 'kinkimine', 'root': 'kinkimine', 'root_tokens': ['kinkimine'], 'ending': 'st', 'clitic': '', 'form': 'sg el', 'partofspeech': 'S'}]),\n",
       "Span('ja', [{'normalized_text': 'ja', 'lemma': 'ja', 'root': 'ja', 'root_tokens': ['ja'], 'ending': '0', 'clitic': '', 'form': '', 'partofspeech': 'J'}]),\n",
       "Span('Euroopas', [{'normalized_text': 'Euroopas', 'lemma': 'Euroopa', 'root': 'Euroopa', 'root_tokens': ['Euroopa'], 'ending': 's', 'clitic': '', 'form': 'sg in', 'partofspeech': 'H'}]),\n",
       "Span('liidu', [{'normalized_text': 'liidu', 'lemma': 'liit', 'root': 'liit', 'root_tokens': ['liit'], 'ending': '0', 'clitic': '', 'form': 'sg g', 'partofspeech': 'S'}]),\n",
       "Span('sõlmimisest', [{'normalized_text': 'sõlmimisest', 'lemma': 'sõlmimine', 'root': 'sõlmimine', 'root_tokens': ['sõlmimine'], 'ending': 'st', 'clitic': '', 'form': 'sg el', 'partofspeech': 'S'}]),\n",
       "Span('.', [{'normalized_text': '.', 'lemma': '.', 'root': '.', 'root_tokens': ['.'], 'ending': '', 'clitic': '', 'form': '', 'partofspeech': 'Z'}])])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "text1 = Text('Täna räägime Aadu Mustast ja Euroopa Liidust.')\n",
    "text2 = Text('Eile rääkisime Aadule musta kaabu kinkimisest ja Euroopas liidu sõlmimisest.')\n",
    "\n",
    "text1.tag_layer('morph_analysis')\n",
    "text2.tag_layer('morph_analysis')\n",
    "\n",
    "display(text1['morph_analysis'])\n",
    "display(text2['morph_analysis'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02666848-750d-47ab-979c-b7ed1f40ab70",
   "metadata": {},
   "source": [
    "## III. Extract initial matches for the decorator \n",
    "\n",
    "The decorator is a function that matches the following template \n",
    "\n",
    "```python\n",
    "def decorator(text: Text, base_span: BaseSpan, annotations: Dict[str, Any]) -> Optional[Dict[str, Any]]\n",
    "```\n",
    "\n",
    "where \n",
    "* the input `text` gives a full access to the text object that is tagged  \n",
    "* the input `base_span` is the current match to be decorated\n",
    "* the input `annotations` contains the initial set of attributes for the match\n",
    "\n",
    "The function should return `None` if the match is a false positive and updated dictionary for real matches.\n",
    "It is safe to modify existing annotations.\n",
    "\n",
    "**Shortcut for decorator development:**\n",
    "In principle, one can define decorator function in one go without running it on real data, but this a mentally difficult and error-prone way to develop complex logic. It is far more simpler to extract all inputs on which the decorator is applied on test data and use that as the input for the decorator. \n",
    "\n",
    "For that we need to define the initial phrase tagger and use the following method to get the list which will be processed by the decorator:\n",
    "\n",
    "\n",
    "```python\n",
    "def extract_matches(self, raw_text: str, layers: Dict[str, Layer]) --> List[Tuple[EnvelopingBaseSpan, str, Any]]\n",
    "```\n",
    "\n",
    "where `raw_text` is underlying `Text.text` field in the `Text` object.  Note that the output list will be processed by a conflict resolver if this is provided as an argument during the initialisation of the phase tagger. Hence, you can also test the behaviour of conflict resolvers on the same input. \n",
    "For standard conflict resolving strategies `KEEP_MAXIMAL` and `KEEP_MINIMAL` the corresponding resolvers can be imported as follows:\n",
    "\n",
    "```python\n",
    "from estnltk.taggers.system.rule_taggers.helper_methods.helper_methods import keep_maximal_matches\n",
    "from estnltk.taggers.system.rule_taggers.helper_methods.helper_methods import keep_minimal_matches\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "72a19407-e0cf-48e5-9c35-282e734b9562",
   "metadata": {},
   "outputs": [],
   "source": [
    "from estnltk.taggers.system.rule_taggers.helper_methods.helper_methods import keep_maximal_matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "95bbe809-a061-43c9-9f70-55a2bfad2b31",
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_tagger = PhraseTagger(\n",
    "    output_layer='entities',\n",
    "    input_layer='morph_analysis',\n",
    "    input_attribute='lemma', \n",
    "    ruleset=extraction_rules,\n",
    "    output_attributes=('match', 'entity_type', 'profession', 'age'),\n",
    "    conflict_resolver='KEEP_MAXIMAL',\n",
    "    ignore_case=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6a7f7df9-3552-4039-b9be-02e5db2ec4eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_text = text1.text\n",
    "layers = {'morph_analysis': text1['morph_analysis']}\n",
    "output = initial_tagger.extract_annotations(raw_text, layers)\n",
    "filtered_output = keep_maximal_matches(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a3d6930-044d-4d93-87d2-dca1e12b40c5",
   "metadata": {},
   "source": [
    "##  IV. Decorator development \n",
    "\n",
    "Let us start with the first input from the extraction output to nail the overall structure of the decorator.\n",
    "For that we need to collect base spans and corresponding annotations given by static rules. \n",
    "To get going, we just define the corresponding annotation by ourselves by knowing that the first match corresponds to Aadu Must. \n",
    "\n",
    "Note that the necessary input span is the first element in the tuple corresponding to the first match and the initial annotation also contains the phrase under the key `initial_tagger.self.phrase_attribute` which is `phrase` currently. This key can be renamed to anything else by specifying the input `phrase_attribute` during the initialisation of the tagger. The third element in the input tuple corresponds to the phrase attribute.   \n",
    "\n",
    "**TODO:** Update this when we have corrected the errors in the tagger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3088af69-1547-41e1-a1ef-4904f2886ce9",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_text = text1\n",
    "input_span = output[0][0]\n",
    "input_annotation = {'phrase': output[0][2], 'entity_type': 'PER', 'profession': 'politician', 'age': 63}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b9b3d794-4807-4d74-ba87-05f3761524b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Match as compound span: EnvelopingBaseSpan((ElementaryBaseSpan(13, 17), ElementaryBaseSpan(18, 25)))\n",
      "Match phrase as a list of words: ('aadu', 'must')\n",
      "The first word of the match: ElementaryBaseSpan(13, 17)\n",
      "Number of morphanalysis of the first word: 1\n",
      "Morphological forms of the first word: ['sg n']\n"
     ]
    }
   ],
   "source": [
    "def decorator_that_prints_some_relevant_information(text, span, annotation):\n",
    "    print(f\"Match as compound span: {span}\")\n",
    "    print(f\"Match phrase as a list of words: {annotation['phrase']}\")\n",
    "    print(f\"The first word of the match: {span[0]}\")\n",
    "    print(f\"Number of morphanalysis of the first word: {len(text['morph_analysis'].get(span[0]).annotations)}\")\n",
    "    print(f\"Morphological forms of the first word: {text['morph_analysis'].get(span[0])['form']}\")\n",
    "\n",
    "decorator_that_prints_some_relevant_information(input_text, input_span, input_annotation)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98af5adf-af7e-4b99-afe7-f97ae042db07",
   "metadata": {},
   "source": [
    "Lets now build a decorator that analyses the consistency of morphological forms of the matched phrase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f35af060-fe8a-4610-bc78-95dfdd389586",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'phrase': ('aadu', 'must'),\n",
       " 'entity_type': 'PER',\n",
       " 'profession': 'politician',\n",
       " 'age': 63,\n",
       " 'normal_form': 'Aadu must'}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def morphological_consistency_checker(text, span, annotation):\n",
    "    # Check full names\n",
    "    if len(input_span) == 2 and annotation['entity_type'] == 'PER':\n",
    "        word_1 = text['morph_analysis'].get(span[0])\n",
    "        word_2 = text['morph_analysis'].get(span[1])\n",
    "\n",
    "        # The first word in the name must be in nominative\n",
    "        if 'sg n' not in word_1['form'] and 'pg n' not in word_1['form']:\n",
    "            return None\n",
    "        \n",
    "        # For simplicity lets assume that the first analysis is correct \n",
    "        annotation['normal_form'] = f\"{word_1['lemma'][0]} {word_2['lemma'][0]}\"\n",
    "        return annotation\n",
    "        \n",
    "morphological_consistency_checker(input_text, input_span, input_annotation)        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfaeca98-379d-4fc3-9c83-a2d2a22f93f7",
   "metadata": {},
   "source": [
    "This seems to work now for the first input lets check how it works over all inputs.\n",
    "For that we need to convert all matches into decorator inputs and run the decorator over all of them.\n",
    "We use function `get_decorator_inputs` for that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4a7128a3-4db6-46b2-81ec-19da692e4f1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: move this method into PhraseTagger and generalize\n",
    "def get_decorator_inputs(tagger, text, match_list):\n",
    "    output = [None] * len(match_list)\n",
    "    for i, (base_span, _, phrase) in enumerate(match_list):\n",
    "        static_rulelist = tagger.static_ruleset_map.get(phrase, None)\n",
    "        for group, priority, annotation in static_rulelist:\n",
    "            annotation = annotation.copy()\n",
    "            annotation[tagger.phrase_attribute] = phrase\n",
    "        if tagger.group_attribute:\n",
    "            annotation[self.group_attribute] = group\n",
    "        if tagger.priority_attribute:\n",
    "            annotation[self.priority_attribute] = priority\n",
    "        if tagger.pattern_attribute:\n",
    "            annotation[self.pattern_attribute] = phrase\n",
    "        output[i] = (text, base_span, annotation)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "68ff49b4-0b86-45ac-ad1e-e910abab96a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input no: 0\n",
      "Input pattern: aadu must\n",
      "Output: {'entity_type': 'PER', 'profession': 'politician', 'age': 63, 'phrase': ('aadu', 'must'), 'normal_form': 'Aadu must'}\n",
      "\n",
      "Input no: 1\n",
      "Input pattern: euroopa liit\n",
      "Output: None\n",
      "\n"
     ]
    }
   ],
   "source": [
    "decorator_inputs = get_decorator_inputs(initial_tagger, text1, output)\n",
    "for i, (text, span, annotation) in enumerate(decorator_inputs):\n",
    "    print(f\"Input no: {i}\")\n",
    "    print(f\"Input pattern: {' '.join(annotation['phrase'])}\")\n",
    "    print(f\"Output: {morphological_consistency_checker(text, span, annotation)}\")\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e07ce55a-5441-411e-b744-7a4284676972",
   "metadata": {},
   "source": [
    "**Observation:** The decorator fails to handle the phrase Euroopa Liit which is expected as we did not specify how to handle organisations. Lets refine the decorator to get rid of this error. Here we can use the list of decorator inputs to define a new target input.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "98df1901-137a-4c2c-a508-b98ed178ddd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_text = decorator_inputs[1][0]\n",
    "input_span = decorator_inputs[1][1]\n",
    "input_annotation = decorator_inputs[1][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e62a664e-ac42-43bb-adb4-4e092f7a6a54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'entity_type': 'ORG',\n",
       " 'phrase': ('euroopa', 'liit'),\n",
       " 'normal_form': 'Euroopa Liidu'}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def morphological_consistency_checker(text, span, annotation):\n",
    "    # Check full names\n",
    "    if len(input_span) == 2 and annotation['entity_type'] == 'PER':\n",
    "        word_1 = text['morph_analysis'].get(span[0])\n",
    "        word_2 = text['morph_analysis'].get(span[1])\n",
    "\n",
    "        # The first word in the name must be in nominative\n",
    "        if 'sg n' not in word_1['form'] and 'pg n' not in word_1['form']:\n",
    "            return None\n",
    "        \n",
    "        # For simplicity lets assume that the first analysis is correct \n",
    "        annotation['normal_form'] = f\"{word_1['lemma'][0]} {word_2['lemma'][0]}\"\n",
    "        return annotation\n",
    "    # Check organisation names\n",
    "    elif len(input_span) == 2 and annotation['entity_type'] == 'ORG':\n",
    "        word_1 = text['morph_analysis'].get(span[0])\n",
    "        word_2 = text['morph_analysis'].get(span[1])\n",
    "\n",
    "        # The first word in the name must be in genitive\n",
    "        if 'sg g' not in word_1['form'] and 'pg g' not in word_1['form']:\n",
    "            return None\n",
    "        \n",
    "        # For simplicity lets assume that the first analysis is correct \n",
    "        annotation['normal_form'] = f\"{word_1['lemma'][0]} {word_2['lemma'][0]}\"\n",
    "        return annotation\n",
    "        \n",
    "morphological_consistency_checker(input_text, input_span, input_annotation)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20d24d6f-918b-476c-9572-52df3167d0a7",
   "metadata": {},
   "source": [
    "The consistency check is fine but the normal form is incorrect. We are not going to correct this as a better option is to define the normal form as an attribute in the static rule.\n",
    "Let us now define the new tagger and see how it works on test texts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9607194a-2c4d-499f-869f-50dae271966e",
   "metadata": {},
   "outputs": [],
   "source": [
    "updated_tagger = PhraseTagger(\n",
    "    output_layer='entities',\n",
    "    input_layer='morph_analysis',\n",
    "    input_attribute='lemma', \n",
    "    ruleset=extraction_rules,\n",
    "    output_attributes=('match', 'entity_type', 'profession', 'age'),\n",
    "    decorator=morphological_consistency_checker,\n",
    "    conflict_resolver='KEEP_MAXIMAL',\n",
    "    ignore_case=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "98ee68a9-492c-425e-bf7c-18ad91d12504",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h4>Layer</h4>\n",
       "\n",
       "\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>layer name</th>\n",
       "      <th>attributes</th>\n",
       "      <th>parent</th>\n",
       "      <th>enveloping</th>\n",
       "      <th>ambiguous</th>\n",
       "      <th>span count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>entities</td>\n",
       "      <td>match, entity_type, profession, age</td>\n",
       "      <td>None</td>\n",
       "      <td>morph_analysis</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>text</th>\n",
       "      <th>match</th>\n",
       "      <th>entity_type</th>\n",
       "      <th>profession</th>\n",
       "      <th>age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>['Aadu', 'Mustast']</td>\n",
       "      <td>None</td>\n",
       "      <td>PER</td>\n",
       "      <td>politician</td>\n",
       "      <td>63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>['Euroopa', 'Liidust']</td>\n",
       "      <td>None</td>\n",
       "      <td>ORG</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "Layer(name='entities', attributes=('match', 'entity_type', 'profession', 'age'), spans=SL[EnvelopingSpan(['Aadu', 'Mustast'], [{'match': None, 'entity_type': 'PER', 'profession': 'politician', 'age': 63}]),\n",
       "EnvelopingSpan(['Euroopa', 'Liidust'], [{'match': None, 'entity_type': 'ORG', 'profession': None, 'age': None}])])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h4>Layer</h4>\n",
       "\n",
       "\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>layer name</th>\n",
       "      <th>attributes</th>\n",
       "      <th>parent</th>\n",
       "      <th>enveloping</th>\n",
       "      <th>ambiguous</th>\n",
       "      <th>span count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>entities</td>\n",
       "      <td>match, entity_type, profession, age</td>\n",
       "      <td>None</td>\n",
       "      <td>morph_analysis</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>text</th>\n",
       "      <th>match</th>\n",
       "      <th>entity_type</th>\n",
       "      <th>profession</th>\n",
       "      <th>age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "Layer(name='entities', attributes=('match', 'entity_type', 'profession', 'age'), spans=SL[])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if 'entities' in text1.layers:\n",
    "    text1.pop_layer('entities')\n",
    "display(updated_tagger(text1)['entities'])\n",
    "\n",
    "if 'entities' in text2.layers:\n",
    "    text2.pop_layer('entities')\n",
    "display(updated_tagger(text2)['entities'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "234f9332-ad13-4e16-826e-069a6985a220",
   "metadata": {},
   "source": [
    "As it seems to work we do not have to tweak the decorator further. \n",
    "However, we should now define test cases to fix the intended behaviour.    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6e9e71f-7368-4b50-9a71-3b177d2e9c4a",
   "metadata": {},
   "source": [
    "## V. Development of regression tests\n",
    "\n",
    "The simplest way to fix the desired behaviour is to define a function that we can check with `pytest`. There are now two options for that. First, we can write tests for the decorator. Second, we can test the behaviour of the entire tagger. Both options are useful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "526815a5-1f11-4a76-9bd8-c957b4d36e9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def test_morphological_consistency_checker():\n",
    "    \n",
    "    tagger = PhraseTagger(\n",
    "        output_layer='entities',\n",
    "        input_layer='morph_analysis',\n",
    "        input_attribute='lemma', \n",
    "        ruleset=extraction_rules,\n",
    "        output_attributes=('match', 'entity_type', 'profession', 'age'),\n",
    "        decorator=morphological_consistency_checker,\n",
    "        conflict_resolver='KEEP_MAXIMAL',\n",
    "        ignore_case=True)\n",
    "\n",
    "    # The first test text\n",
    "    text = Text('Täna räägime Aadu Mustast ja Euroopa Liidust.').tag_layer('morph_analysis')\n",
    "    raw_text = text.text\n",
    "    layers = {'morph_analysis': text1['morph_analysis']}\n",
    "    output = initial_tagger.extract_annotations(raw_text, layers)\n",
    "    filtered_output = keep_maximal_matches(output)\n",
    "    decorator_inputs = get_decorator_inputs(tagger, text1, output)\n",
    "\n",
    "    decorator_inputs = get_decorator_inputs(initial_tagger, text, output)\n",
    "    result = morphological_consistency_checker(*decorator_inputs[0])\n",
    "    target = {'entity_type': 'PER', 'profession': 'politician', 'age': 63, 'phrase': ('aadu', 'must'), 'normal_form': 'Aadu must'}\n",
    "    assert result == target\n",
    "\n",
    "    result = morphological_consistency_checker(*decorator_inputs[1])\n",
    "    target = {'entity_type': 'ORG', 'phrase': ('euroopa', 'liit'), 'normal_form': 'Euroopa Liidu'}\n",
    "    assert result == target\n",
    "    \n",
    "    # The second test text\n",
    "    text = Text('Eile rääkisime Aadule musta kaabu kinkimisest ja Euroopas liidu sõlmimisest.').tag_layer('morph_analysis')\n",
    "    raw_text = text.text\n",
    "    layers = {'morph_analysis': text2['morph_analysis']}\n",
    "    output = initial_tagger.extract_annotations(raw_text, layers)\n",
    "    filtered_output = keep_maximal_matches(output)\n",
    "    decorator_inputs = get_decorator_inputs(tagger, text, output)\n",
    "\n",
    "    result = morphological_consistency_checker(*decorator_inputs[0])\n",
    "    assert result is None\n",
    "    \n",
    "    result = morphological_consistency_checker(*decorator_inputs[1])\n",
    "    assert result is None\n",
    "\n",
    "    return True\n",
    "\n",
    "test_morphological_consistency_checker()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9b0299d6-4477-4d75-8a4f-4cc12827c82e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_final_tagger():\n",
    "    \n",
    "    tagger = PhraseTagger(\n",
    "        output_layer='entities',\n",
    "        input_layer='morph_analysis',\n",
    "        input_attribute='lemma', \n",
    "        ruleset=extraction_rules,\n",
    "        output_attributes=('match', 'entity_type', 'profession', 'age'),\n",
    "        decorator=morphological_consistency_checker,\n",
    "        conflict_resolver='KEEP_MAXIMAL',\n",
    "        ignore_case=True)\n",
    "\n",
    "    # The first test text\n",
    "    text = tagger(Text('Täna räägime Aadu Mustast ja Euroopa Liidust.').tag_layer('morph_analysis'))\n",
    "    assert len(text['entities']) == 2\n",
    "    assert text['entities'][0].text == ['Aadu', 'Mustast']\n",
    "    assert text['entities'][1].text == ['Euroopa', 'Liidust']\n",
    "\n",
    "    # The second test text    \n",
    "    text = tagger(Text('Eile rääkisime Aadule musta kaabu kinkimisest ja Euroopas liidu sõlmimisest.').tag_layer('morph_analysis'))\n",
    "    assert len(text['entities']) == 0\n",
    "\n",
    "    return True "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd85f50a-3af7-4311-9dfc-f4613944db90",
   "metadata": {},
   "source": [
    "**Final comments:** These tests are naive, since the mix data with code. \n",
    "It is much more wiser to build a separate test suite that reads inputs and desired outputs from text files.\n",
    "For taggers the corresponding framework is implemented in `estnltk_core.taggers.tagger_tester` module."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
