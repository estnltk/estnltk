{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Restoring tokenization of a pretokenized text\n",
    "\n",
    "There may be situations where you want to use the simplest tokenization (split words by whitespaces only), or load a pretokenized text in a way that the original tokenization is preserved. \n",
    "This tutorial shows how to do it in EstNLTK.\n",
    "\n",
    "**Note**: EstNLTK's tokenization is configurable, and in some situations it is more convenient to change tokenization rules instead of forcing whitespace tokenization. \n",
    "For details, see the tokenization tutorials in [nlp_pipeline/A_text_segmentation](../nlp_pipeline/A_text_segmentation)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Whitespace tokenization for words\n",
    "\n",
    "Use can use `WhiteSpaceTokensTagger` to split the text into `tokens` by whitespaces.\n",
    "After that, you should also use `PretokenizedTextCompoundTokensTagger` to create an empty `compound_tokens` layer, or otherwise, the default `CompoundTokensTagger` would still join some of the whitespace-sparated tokens into words.\n",
    "Finally, you can tag the `words` layer as usual:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Text that needs to be tokenized by whitespaces\n",
    "from estnltk import Text\n",
    "text=Text('29.04-21.05 täheldati muutust vanuserühmas 25-32 ja/või 55-64 aastat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h4>Layer</h4>\n",
       "\n",
       "\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>layer name</th>\n",
       "      <th>attributes</th>\n",
       "      <th>parent</th>\n",
       "      <th>enveloping</th>\n",
       "      <th>ambiguous</th>\n",
       "      <th>span count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>words</td>\n",
       "      <td>normalized_form</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>text</th>\n",
       "      <th>normalized_form</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>29.04-21.05</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>täheldati</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>muutust</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>vanuserühmas</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25-32</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>ja/või</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>55-64</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>aastat</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "Layer(name='words', attributes=('normalized_form',), spans=SL[Span('29.04-21.05', [{'normalized_form': None}]),\n",
       "Span('täheldati', [{'normalized_form': None}]),\n",
       "Span('muutust', [{'normalized_form': None}]),\n",
       "Span('vanuserühmas', [{'normalized_form': None}]),\n",
       "Span('25-32', [{'normalized_form': None}]),\n",
       "Span('ja/või', [{'normalized_form': None}]),\n",
       "Span('55-64', [{'normalized_form': None}]),\n",
       "Span('aastat', [{'normalized_form': None}])])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from estnltk.taggers import WhiteSpaceTokensTagger\n",
    "from estnltk.taggers import PretokenizedTextCompoundTokensTagger\n",
    "\n",
    "# Initialize tools for white space tokenization\n",
    "tokens_tagger = WhiteSpaceTokensTagger()\n",
    "compound_tokens_tagger = PretokenizedTextCompoundTokensTagger()\n",
    "\n",
    "# Perform word tokenization\n",
    "tokens_tagger.tag(text)\n",
    "compound_tokens_tagger.tag(text)\n",
    "text.tag_layer('words') # join tokens and compound_tokens layers\n",
    "\n",
    "# Browse results\n",
    "text.words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Be aware:** EstNLTK's analysis tools assume that punctuation (esp. sentence ending punctuation) is separated from word tokens. \n",
    "The whitespace tokenization shown above does not separate punctuation from words and thus, the quality of downstream analysis (sentence tokenization, morphological analysis etc.) likely suffers because of that.\n",
    "Apply it carefully."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Restoring a pre-tokenized text\n",
    "\n",
    "A more advanced use case is loading a pre-tokenized text. For instance, if the original text has manually corrected word and sentence tokenization, you may want to preserve the correct annotations instead of automatically creating new ones (which may introduce some errors)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to restore a pretokenized text, you should artificially reconstruct the text -- join tokens by whitespaces and sentences by newlines -- and then use `WhiteSpaceTokensTagger`, `PretokenizedTextCompoundTokensTagger`, and a modified `SentenceTokenizer` to restore the layers `'tokens'`, `'compound_tokens'`, `'words'`, and `'sentences'`. Follows a brief example on how to do it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example of a pretokenized text\n",
    "pretokenized_text = '''\n",
    "<s>\n",
    "Maa\n",
    "suurima\n",
    "vulkaani\n",
    "Mauna Loa\n",
    "kõrgus\n",
    "on\n",
    "8742\n",
    "meetrit\n",
    "mõõdetuna\n",
    "Vaikse\n",
    "ookeani\n",
    "põhjal\n",
    "asuvalt\n",
    "jalamilt\n",
    ".\n",
    "</s>\n",
    "<s>\n",
    "Mauna Loa\n",
    "jalam\n",
    "mahuks\n",
    "parajasti\n",
    "Olympus\n",
    "Mons'i\n",
    "kaldeerasse\n",
    "!\n",
    "</s>\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) collect raw words, and multiword expressions\n",
    "raw_words = []\n",
    "multiword_expressions = []\n",
    "raw_tokens = pretokenized_text.split('\\n')\n",
    "for raw_token in raw_tokens:\n",
    "    if raw_token not in ['<s>', '</s>']:  # Skip sentence boundary tags\n",
    "        raw_words.append(raw_token)\n",
    "        if ' ' in raw_token:\n",
    "            multiword_expressions.append(raw_token)\n",
    "    elif raw_token == '</s>':\n",
    "        raw_words[-1] += '\\n'  # newline == sentence ending\n",
    "        \n",
    "# 2) reconstruct the text\n",
    "text_str = ' '.join(raw_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3) create estnltk's text\n",
    "from estnltk import Text\n",
    "text = Text(text_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can restore the original tokenization annotation. First, let's split the text into tokens by whitespaces:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td><div align = \"left\"> Maa suurima vulkaani Mauna Loa kõrgus on 8742 meetrit mõõdetuna Vaikse ookeani põhjal asuvalt jalamilt .</br> Mauna Loa jalam mahuks parajasti Olympus Mons&#x27;i kaldeerasse !</br> </div></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>layer name</th>\n",
       "      <th>attributes</th>\n",
       "      <th>parent</th>\n",
       "      <th>enveloping</th>\n",
       "      <th>ambiguous</th>\n",
       "      <th>span count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>tokens</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "Text(text=\" Maa suurima vulkaani Mauna Loa kõrgus on 8742 meetrit mõõdetuna Vaikse ookeani põhjal asuvalt jalamilt .\\n Mauna Loa jalam mahuks parajasti Olympus Mons'i kaldeerasse !\\n \")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from estnltk.taggers import WhiteSpaceTokensTagger\n",
    "tokens_tagger = WhiteSpaceTokensTagger()\n",
    "tokens_tagger.tag(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we can use `PretokenizedTextCompoundTokensTagger` to restore the multiword (multitoken) expressions from the original text:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td><div align = \"left\"> Maa suurima vulkaani Mauna Loa kõrgus on 8742 meetrit mõõdetuna Vaikse ookeani põhjal asuvalt jalamilt .</br> Mauna Loa jalam mahuks parajasti Olympus Mons&#x27;i kaldeerasse !</br> </div></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>layer name</th>\n",
       "      <th>attributes</th>\n",
       "      <th>parent</th>\n",
       "      <th>enveloping</th>\n",
       "      <th>ambiguous</th>\n",
       "      <th>span count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>tokens</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>compound_tokens</td>\n",
       "      <td>type, normalized</td>\n",
       "      <td>None</td>\n",
       "      <td>tokens</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "Text(text=\" Maa suurima vulkaani Mauna Loa kõrgus on 8742 meetrit mõõdetuna Vaikse ookeani põhjal asuvalt jalamilt .\\n Mauna Loa jalam mahuks parajasti Olympus Mons'i kaldeerasse !\\n \")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 4) convert multiword expressions to the form of lists of lists of strings\n",
    "multiword_expressions = [mw.split() for mw in multiword_expressions]\n",
    "\n",
    "# 5) restore the original compound tokens\n",
    "from estnltk.taggers import PretokenizedTextCompoundTokensTagger\n",
    "compound_tokens_tagger = PretokenizedTextCompoundTokensTagger( multiword_units = multiword_expressions )\n",
    "compound_tokens_tagger.tag(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* _Notes on_ `PretokenizedTextCompoundTokensTagger`: \n",
    "  \n",
    "   * multiword expressions passed to the `PretokenizedTextCompoundTokensTagger` must be exactly in the same order as they appear in the text;\n",
    "\n",
    "   * if the original text does not have any multiword expressions or compound tokens, you still need to create the `'compound_tokens'` layer, because it is a prerequisite to the `'words'` layer. So, you should initialize `PretokenizedTextCompoundTokensTagger` with zero input parameters, so that it will create an empty `'compound_tokens'` layer;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we use the default words tagger to create the 'words' layer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td><div align = \"left\"> Maa suurima vulkaani Mauna Loa kõrgus on 8742 meetrit mõõdetuna Vaikse ookeani põhjal asuvalt jalamilt .</br> Mauna Loa jalam mahuks parajasti Olympus Mons&#x27;i kaldeerasse !</br> </div></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>layer name</th>\n",
       "      <th>attributes</th>\n",
       "      <th>parent</th>\n",
       "      <th>enveloping</th>\n",
       "      <th>ambiguous</th>\n",
       "      <th>span count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>tokens</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>compound_tokens</td>\n",
       "      <td>type, normalized</td>\n",
       "      <td>None</td>\n",
       "      <td>tokens</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>words</td>\n",
       "      <td>normalized_form</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "Text(text=\" Maa suurima vulkaani Mauna Loa kõrgus on 8742 meetrit mõõdetuna Vaikse ookeani põhjal asuvalt jalamilt .\\n Mauna Loa jalam mahuks parajasti Olympus Mons'i kaldeerasse !\\n \")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 6) add words layer\n",
    "text.tag_layer(['words'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we create a customized sentence tagger that will split sentences by newlines only:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td><div align = \"left\"> Maa suurima vulkaani Mauna Loa kõrgus on 8742 meetrit mõõdetuna Vaikse ookeani põhjal asuvalt jalamilt .</br> Mauna Loa jalam mahuks parajasti Olympus Mons&#x27;i kaldeerasse !</br> </div></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>layer name</th>\n",
       "      <th>attributes</th>\n",
       "      <th>parent</th>\n",
       "      <th>enveloping</th>\n",
       "      <th>ambiguous</th>\n",
       "      <th>span count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>sentences</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>words</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>tokens</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>compound_tokens</td>\n",
       "      <td>type, normalized</td>\n",
       "      <td>None</td>\n",
       "      <td>tokens</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>words</td>\n",
       "      <td>normalized_form</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "Text(text=\" Maa suurima vulkaani Mauna Loa kõrgus on 8742 meetrit mõõdetuna Vaikse ookeani põhjal asuvalt jalamilt .\\n Mauna Loa jalam mahuks parajasti Olympus Mons'i kaldeerasse !\\n \")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 7) create a sentence tokenizer that only splits sentences in places of new lines\n",
    "from estnltk.taggers import SentenceTokenizer\n",
    "from nltk.tokenize.simple import LineTokenizer\n",
    "newline_sentence_tokenizer = SentenceTokenizer( base_sentence_tokenizer=LineTokenizer() )\n",
    "\n",
    "# 8) split text into sentences by newlines\n",
    "newline_sentence_tokenizer.tag(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Results -- the original tokenization is successfully restored in the `Text` object:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h4>Layer</h4>\n",
       "\n",
       "\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>layer name</th>\n",
       "      <th>attributes</th>\n",
       "      <th>parent</th>\n",
       "      <th>enveloping</th>\n",
       "      <th>ambiguous</th>\n",
       "      <th>span count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>words</td>\n",
       "      <td>normalized_form</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>text</th>\n",
       "      <th>normalized_form</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>Maa</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>suurima</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>vulkaani</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Mauna Loa</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>kõrgus</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>on</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8742</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>meetrit</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>mõõdetuna</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Vaikse</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>ookeani</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>põhjal</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>asuvalt</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>jalamilt</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>.</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Mauna Loa</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>jalam</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>mahuks</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>parajasti</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Olympus</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Mons'i</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>kaldeerasse</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>!</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "Layer(name='words', attributes=('normalized_form',), spans=SL[Span('Maa', [{'normalized_form': None}]),\n",
       "Span('suurima', [{'normalized_form': None}]),\n",
       "Span('vulkaani', [{'normalized_form': None}]),\n",
       "Span('Mauna Loa', [{'normalized_form': None}]),\n",
       "Span('kõrgus', [{'normalized_form': None}]),\n",
       "Span('on', [{'normalized_form': None}]),\n",
       "Span('8742', [{'normalized_form': None}]),\n",
       "Span('meetrit', [{'normalized_form': None}]),\n",
       "Span('mõõdetuna', [{'normalized_form': None}]),\n",
       "Span('Vaikse', [{'normalized_form': None}]),\n",
       "Span('ookeani', [{'normalized_form': None}]),\n",
       "Span('põhjal', [{'normalized_form': None}]),\n",
       "Span('asuvalt', [{'normalized_form': None}]),\n",
       "Span('jalamilt', [{'normalized_form': None}]),\n",
       "Span('.', [{'normalized_form': None}]),\n",
       "Span('Mauna Loa', [{'normalized_form': None}]),\n",
       "Span('jalam', [{'normalized_form': None}]),\n",
       "Span('mahuks', [{'normalized_form': None}]),\n",
       "Span('parajasti', [{'normalized_form': None}]),\n",
       "Span('Olympus', [{'normalized_form': None}]),\n",
       "Span(\"Mons'i\", [{'normalized_form': None}]),\n",
       "Span('kaldeerasse', [{'normalized_form': None}]),\n",
       "Span('!', [{'normalized_form': None}])])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text.words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h4>Layer</h4>\n",
       "\n",
       "\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>layer name</th>\n",
       "      <th>attributes</th>\n",
       "      <th>parent</th>\n",
       "      <th>enveloping</th>\n",
       "      <th>ambiguous</th>\n",
       "      <th>span count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>sentences</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>words</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>['Maa', 'suurima', 'vulkaani', 'Mauna Loa', 'kõrgus', 'on', '8742', 'meetrit', ' ..., type: &lt;class 'list'&gt;, length: 15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>['Mauna Loa', 'jalam', 'mahuks', 'parajasti', 'Olympus', \"Mons'i\", 'kaldeerasse', '!']</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "Layer(name='sentences', attributes=(), spans=SL[EnvelopingSpan(['Maa', 'suurima', 'vulkaani', 'Mauna Loa', 'kõrgus', 'on', '8742', 'meetrit', 'mõõdetuna', 'Vaikse', 'ookeani', 'põhjal', 'asuvalt', 'jalamilt', '.'], [{}]),\n",
       "EnvelopingSpan(['Mauna Loa', 'jalam', 'mahuks', 'parajasti', 'Olympus', \"Mons'i\", 'kaldeerasse', '!'], [{}])])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text.sentences"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
