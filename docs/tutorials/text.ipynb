{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Working with text\n",
    "=================\n",
    "\n",
    "In this tutorial, we start with Estnltk basics and introduce you to the\n",
    "**Text** class. We will take the class apart to bits and\n",
    "pieces and put it back together to give a good overview, what it can do\n",
    "for you and how can you work with it.\n",
    "\n",
    "Getting started\n",
    "---------------\n",
    "\n",
    "One of the most important classes in Estnltk is **Text**,\n",
    "which is essentally the main interface for doing everything Estnltk is\n",
    "capable of. It is actually a subclass of standard `dict` class in Python\n",
    "and stores all data relevant to the text in this form:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'text': 'Tere maailm!'}\n"
     ]
    }
   ],
   "source": [
    "from estnltk import Text\n",
    "\n",
    "text = Text('Tere maailm!')\n",
    "print (repr(text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can use **Text** instances the same way as you would\n",
    "use a typical `dict` object in Python:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tere maailm!\n"
     ]
    }
   ],
   "source": [
    "print (text['text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Naturally, you can initiate a new instance from a dictionary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "text2 = Text({'text': 'Tere maailm!'})\n",
    "print (text == text2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the **Text** class is essentially a dictionary, it has\n",
    "a number of **advantages**:\n",
    "\n",
    "-   via JSON serialization, it is easy to store texts in databases, pass\n",
    "    it easily around with HTTP GET/PUT commands,\n",
    "-   simple to inspect and debug,\n",
    "-   simple to extend and add new layers of annotations.\n",
    "\n",
    "Main disadvantage is that the dictionary can get quite verbose, so space\n",
    "can be an issue when storing large corpora with many layers of\n",
    "annotations.\n",
    "\n",
    "### Layers\n",
    "\n",
    "A **Text** instance can have different types of layers\n",
    "that hold annotations or denote special regions of the text. For\n",
    "instance, `words` layer defines the word tokens, `named_entities` layer\n",
    "denotes the positions of named entities etc.\n",
    "\n",
    "There are two types of layers:\n",
    "\n",
    "1.  **simple** layer has elements that only span a single region *such\n",
    "    as words, sentences*.\n",
    "2.  **multi** layer has elements that can span several regions. For\n",
    "    example, sentence *\"Kõrred, millel on toitunud viljasääse vastsed,\n",
    "    jäävad õhukeseks.\"* has two clauses:\n",
    "    \n",
    "    a.  *\"Kõrred jäävad õhukeseks\"*,\n",
    "\n",
    "    b.  *\", millel on toitunud viljasääse vastsed, \"* .\n",
    "    \n",
    "    Clause *a* spans multiple regions in the original text."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Both types of layers require each layer element to define `start` and\n",
    "`end` attributes. Simple layer elements define `start` and `end` as\n",
    "integers of the range containing the element. Multi layer elements\n",
    "similarily define `start` and `end` attributes, but these are lists of\n",
    "respective start and end positions of the element.\n",
    "\n",
    "Simple layer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'end': 6, 'start': 0, 'text': 'Kõrred'},\n",
       " {'end': 7, 'start': 6, 'text': ','},\n",
       " {'end': 14, 'start': 8, 'text': 'millel'},\n",
       " {'end': 17, 'start': 15, 'text': 'on'},\n",
       " {'end': 26, 'start': 18, 'text': 'toitunud'},\n",
       " {'end': 37, 'start': 27, 'text': 'viljasääse'},\n",
       " {'end': 45, 'start': 38, 'text': 'vastsed'},\n",
       " {'end': 46, 'start': 45, 'text': ','},\n",
       " {'end': 53, 'start': 47, 'text': 'jäävad'},\n",
       " {'end': 63, 'start': 54, 'text': 'õhukeseks'},\n",
       " {'end': 64, 'start': 63, 'text': '.'}]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from estnltk import Text\n",
    "text = Text('Kõrred, millel on toitunud viljasääse vastsed, jäävad õhukeseks.')\n",
    "text.tokenize_words()\n",
    "text['words']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each word has a `start` and `end` attribute that tells, where the word\n",
    "is located in the text. In case of multi layers, we see slightly\n",
    "different result:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'end': [6, 64], 'start': [0, 47]}, {'end': [46], 'start': [6]}]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text.tag_clauses()\n",
    "text['clauses']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that first clause has two spans in the text. Although the second\n",
    "clause has only one span, it is also defined as a multi layer element.\n",
    "Estnltk uses *either* **simple** or **multi** type for a single layer.\n",
    "However, nothing stops you from mixing these two, if you wish.\n",
    "\n",
    "In next sections, we discuss typical NLP operations you can do with\n",
    "Estnltk and also explain, how the results are stored in the dictionary\n",
    "underneath the **Text** instances."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tokenization\n",
    "------------\n",
    "\n",
    "One of the most basic tasks of any NLP pipeline is text and sentence\n",
    "tokenization. The **Text** class has methods\n",
    "**tokenize\\_paragraphs()**,\n",
    "**tokenize\\_sentences()** and\n",
    "**tokenize\\_words()**, which you can call to do this\n",
    "explicitly. However, there are also properties\n",
    "**word\\_texts**,\n",
    "**sentence\\_texts** and\n",
    "**paragraph\\_texts** that do this automatically when\n",
    "you use them and also give you the texts of tokenized words or\n",
    "sentences:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Üle', 'oja', 'mäele', ',', 'läbi', 'oru', 'jõele', '.', 'Ämber', 'läks', 'ümber', '.']\n"
     ]
    }
   ],
   "source": [
    "from estnltk import Text\n",
    "\n",
    "text = Text('Üle oja mäele, läbi oru jõele. Ämber läks ümber.')\n",
    "print (text.word_texts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order for the tokenization to happen, **Text** instance\n",
    "applies the default tokenizer in background and updates the text data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'paragraphs': [{'end': 48, 'start': 0}],\n",
      " 'sentences': [{'end': 30, 'start': 0}, {'end': 48, 'start': 31}],\n",
      " 'text': 'Üle oja mäele, läbi oru jõele. Ämber läks ümber.',\n",
      " 'words': [{'end': 3, 'start': 0, 'text': 'Üle'},\n",
      "           {'end': 7, 'start': 4, 'text': 'oja'},\n",
      "           {'end': 13, 'start': 8, 'text': 'mäele'},\n",
      "           {'end': 14, 'start': 13, 'text': ','},\n",
      "           {'end': 19, 'start': 15, 'text': 'läbi'},\n",
      "           {'end': 23, 'start': 20, 'text': 'oru'},\n",
      "           {'end': 29, 'start': 24, 'text': 'jõele'},\n",
      "           {'end': 30, 'start': 29, 'text': '.'},\n",
      "           {'end': 36, 'start': 31, 'text': 'Ämber'},\n",
      "           {'end': 41, 'start': 37, 'text': 'läks'},\n",
      "           {'end': 47, 'start': 42, 'text': 'ümber'},\n",
      "           {'end': 48, 'start': 47, 'text': '.'}]}\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "pprint (text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, there is now a `words` element in the dictionary, which\n",
    "is a list of dictionaries denoting `start` and `end` positions of the\n",
    "respective words. You also see `sentences` and `paragraphs` elements,\n",
    "because sentence and paragraph tokenization is a prerequisite before\n",
    "word tokenization and Estnltk did this automatically on your behalf.\n",
    "\n",
    "The **word\\_texts** property does basically the same\n",
    "as the following snippet:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Üle', 'oja', 'mäele', ',', 'läbi', 'oru', 'jõele', '.', 'Ämber', 'läks', 'ümber', '.']\n"
     ]
    }
   ],
   "source": [
    "text = Text('Üle oja mäele, läbi oru jõele. Ämber läks ümber.')\n",
    "text.tokenize_words() # this method applies text tokenization\n",
    "print ([text['text'][word['start']:word['end']] for word in text['words']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Only difference is that by using **word\\_texts**\n",
    "property twice does not perform tokenization twice. Second call would\n",
    "use the `start` and `end` attributes already stored in the\n",
    "**Text** instance.\n",
    "\n",
    "The default word tokenizer is a modification of\n",
    "[WordPunctTokenizer](http://www.nltk.org/api/nltk.tokenize.html#nltk.tokenize.regexp.WordPunctTokenizer)\n",
    ":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Tere', 'maailm', '!']\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize.regexp import WordPunctTokenizer\n",
    "tok = WordPunctTokenizer()\n",
    "print (tok.tokenize('Tere maailm!'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also, the default sentence tokenizer comes from NLTK:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Esimene lause.', 'Teine lause?']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk.data\n",
    "tok = nltk.data.load('tokenizers/punkt/estonian.pickle')\n",
    "tok.tokenize('Esimene lause. Teine lause?')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to plug in custom tokenization functionality, you need to\n",
    "implement interface defined by NLTK\n",
    "[StringTokenizer](http://www.nltk.org/api/nltk.tokenize.html#nltk.tokenize.api.StringTokenizer)\n",
    "and supply them as keyword arguments when initiating\n",
    "**Text** objects. Of course, all other NLTK tokenizers\n",
    "follow this interface:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Hmm,', 'lausemärgid', 'jäävad', 'sõnade', 'külge.', 'Ja', 'laused', 'tuvastatakse', 'praegu', 'reavahetuste', 'järgi']\n",
      "['Hmm, lausemärgid jäävad sõnade külge. Ja laused', 'tuvastatakse praegu', 'reavahetuste järgi']\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize.regexp import WhitespaceTokenizer\n",
    "from nltk.tokenize.simple import LineTokenizer\n",
    "\n",
    "kwargs = {\n",
    "    \"word_tokenizer\": WhitespaceTokenizer(),\n",
    "    \"sentence_tokenizer\": LineTokenizer()\n",
    "}\n",
    "\n",
    "plain = '''Hmm, lausemärgid jäävad sõnade külge. Ja laused\n",
    "tuvastatakse praegu\n",
    "\n",
    "reavahetuste järgi'''\n",
    "\n",
    "text = Text(plain, **kwargs)\n",
    "print (text.word_texts)\n",
    "print (text.sentence_texts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After both word and sentence tokenization, a **Text**\n",
    "instance looks like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'paragraphs': [{'end': 67, 'start': 0}, {'end': 87, 'start': 69}],\n",
       " 'sentences': [{'end': 47, 'start': 0},\n",
       "  {'end': 67, 'start': 48},\n",
       "  {'end': 87, 'start': 69}],\n",
       " 'text': 'Hmm, lausemärgid jäävad sõnade külge. Ja laused\\ntuvastatakse praegu\\n\\nreavahetuste järgi',\n",
       " 'words': [{'end': 4, 'start': 0, 'text': 'Hmm,'},\n",
       "  {'end': 16, 'start': 5, 'text': 'lausemärgid'},\n",
       "  {'end': 23, 'start': 17, 'text': 'jäävad'},\n",
       "  {'end': 30, 'start': 24, 'text': 'sõnade'},\n",
       "  {'end': 37, 'start': 31, 'text': 'külge.'},\n",
       "  {'end': 40, 'start': 38, 'text': 'Ja'},\n",
       "  {'end': 47, 'start': 41, 'text': 'laused'},\n",
       "  {'end': 60, 'start': 48, 'text': 'tuvastatakse'},\n",
       "  {'end': 67, 'start': 61, 'text': 'praegu'},\n",
       "  {'end': 81, 'start': 69, 'text': 'reavahetuste'},\n",
       "  {'end': 87, 'start': 82, 'text': 'järgi'}]}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the full list of tokenization related properties of\n",
    "**Text**:\n",
    "\n",
    "-   **text** - the text string itself\n",
    "-   **words** - list of word dictionaries\n",
    "-   **word\\_texts** - word texts\n",
    "-   **word\\_starts** - word start positions\n",
    "-   **word\\_ends** - word end positions\n",
    "-   **word\\_spans** - word (start, end) position\n",
    "    tuples\n",
    "-   **sentence\\_texts** - list of sentence\n",
    "    dictionaries\n",
    "-   **sentence\\_texts** - list of sentence texts\n",
    "-   **sentence\\_starts** - sentence start positions\n",
    "-   **sentence\\_ends** - sentence end positions\n",
    "-   **sentence\\_spans** - sentence (start, end)\n",
    "    position pairs\n",
    "-   **paragraph\\_texts** - paragraph texts\n",
    "-   **paragraph\\_starts** - paragraph start positions\n",
    "-   **paragraph\\_ends** - paragraph end positions\n",
    "-   **paragraph\\_spans** - paragraph (start, end)\n",
    "    position pairs\n",
    "\n",
    "Example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Esimene lause. Teine lause'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from estnltk import Text\n",
    "\n",
    "text = Text('Esimene lause. Teine lause')\n",
    "\n",
    "text.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'end': 7, 'start': 0, 'text': 'Esimene'},\n",
       " {'end': 13, 'start': 8, 'text': 'lause'},\n",
       " {'end': 14, 'start': 13, 'text': '.'},\n",
       " {'end': 20, 'start': 15, 'text': 'Teine'},\n",
       " {'end': 26, 'start': 21, 'text': 'lause'}]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text.words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Esimene', 'lause', '.', 'Teine', 'lause']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text.word_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 8, 13, 15, 21]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text.word_starts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[7, 13, 14, 20, 26]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text.word_ends"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 7), (8, 13), (13, 14), (15, 20), (21, 26)]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text.word_spans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'end': 14, 'start': 0}, {'end': 26, 'start': 15}]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text.sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Esimene lause.', 'Teine lause']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text.sentence_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 15]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text.sentence_starts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[14, 26]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text.sentence_ends"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 14), (15, 26)]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text.sentence_spans"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that if a dictionary already has `words`, `sentences` or\n",
    "`paragraphs` elements (or any other element that we introduce later),\n",
    "accessing these elements in a newly initialized **Text**\n",
    "object does not require recomputing them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Esimene', 'lause', '.', 'Teine', 'lause', '.']\n"
     ]
    }
   ],
   "source": [
    "text = Text({'paragraphs': [{'end': 27, 'start': 0}],\n",
    "             'sentences': [{'end': 14, 'start': 0}, {'end': 27, 'start': 15}],\n",
    "             'text': 'Esimene lause. Teine lause.',\n",
    "             'words': [{'end': 7, 'start': 0, 'text': 'Esimene'},\n",
    "                       {'end': 13, 'start': 8, 'text': 'lause'},\n",
    "                       {'end': 14, 'start': 13, 'text': '.'},\n",
    "                       {'end': 20, 'start': 15, 'text': 'Teine'},\n",
    "                       {'end': 26, 'start': 21, 'text': 'lause'},\n",
    "                       {'end': 27, 'start': 26, 'text': '.'}]}\n",
    ")\n",
    "\n",
    "print (text.word_texts) # tokenization is already done, just extract words using the positions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should also remember this, when you have defined custom tokenizers.\n",
    "In such cases you can force retokenization by calling\n",
    "**tokenize\\_words()**,\n",
    "**tokenize\\_sentences()** or\n",
    "**tokenize\\_words()**.\n",
    "\n",
    "> **note**\n",
    ">\n",
    "> Things to remember!\n",
    ">\n",
    "> 1.  `words`, `sentences` and `paragraphs` are **simple** layers.\n",
    "> 2.  use properties to access the tokenized word/sentence texts and\n",
    ">     avoid **tokenize\\_words()**,\n",
    ">     **tokenize\\_sentences()** or\n",
    ">     **tokenize\\_paragraphs()**, unless you have a\n",
    ">     meaningful reason to use them (for example, preparing documents\n",
    ">     for indexing in a database).\n",
    "\n",
    "Morphological analysis\n",
    "----------------------\n",
    "\n",
    "In linguistics, morphology is the identification, analysis, and\n",
    "description of the structure of a given language's morphemes and other\n",
    "linguistic units, such as root words, lemmas, suffixes, parts of speech\n",
    "etc. Estnltk wraps [Vabamorf](https://github.com/Filosoft/vabamorf)\n",
    "morphological analyzer, which can do both morphological analysis and\n",
    "synthesis.\n",
    "\n",
    "Esnltk **Text** class properties for extracting\n",
    "morphological information:\n",
    "\n",
    "-   **analysis** - raw analysis data.\n",
    "-   **roots** - root forms of words.\n",
    "-   **root\\_tokens** - for compound words, all the\n",
    "    tokens the root is made of.\n",
    "-   **lemmas** - dictionary (canonical) word forms.\n",
    "-   **forms** - word form expressing the case,\n",
    "    plurality, voice etc.\n",
    "-   **endings** - word inflective suffixes.\n",
    "-   **postags** - part-of-speech (POS) tags (word\n",
    "    types).\n",
    "-   **postag\\_descriptions** - Estonian descriptions\n",
    "    for POS tags.\n",
    "-   **descriptions** - Estonian descriptions for\n",
    "    forms.\n",
    "\n",
    "These properties call **tag\\_analysis()** method in\n",
    "background, which also call **tokenize\\_paragraphs()**,\n",
    "**tokenize\\_sentences()** and\n",
    "**tokenize\\_words()** as word tokenization is required\n",
    "in order add morphological analysis. Morphological analysis adds extra\n",
    "information to `words` layer, which we'll explain in following sections.\n",
    "\n",
    "See [postag\\_table](http://estnltk.github.io/estnltk/1.4/tutorials/morf_tables.html#postag-table), [nounform\\_table](http://estnltk.github.io/estnltk/1.4/tutorials/morf_tables.html#nounform-table) and [verbform\\_table](http://estnltk.github.io/estnltk/1.4/tutorials/morf_tables.html#verbform-table) for more detailed\n",
    "information about various analysis tags.\n",
    "\n",
    "### Property aggregation\n",
    "\n",
    "Before we continue with morphological analysis, we introduce a way to\n",
    "put together various information in a simple way. Often you want to\n",
    "extract various information, such as words, lemmas, postags and put them\n",
    "together such that you could easily access all of them. Estnltk has\n",
    "**ZipBuilder** class, which can compile together\n",
    "properties you need and then format them in various ways. First, you can\n",
    "initiate the builder on a Text object by calling\n",
    "**get** attribute and then chain together the\n",
    "attributes you wish to have. Last step is telling the format you want\n",
    "the data to appear.\n",
    "get <item_1> <item_2> ... <item_n> as <format>\n",
    "You can think of this process as building a sentence: **get `<item_1> <item_2> ... <item_n> as <format>`**. Output formats include\n",
    "Pandas\n",
    "[DataFrame](http://pandas.pydata.org/pandas-docs/dev/generated/pandas.DataFrame.html):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word_texts</th>\n",
       "      <th>postags</th>\n",
       "      <th>postag_descriptions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Usjas</td>\n",
       "      <td>A</td>\n",
       "      <td>omadussõna algvõrre</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>kaslane</td>\n",
       "      <td>S</td>\n",
       "      <td>nimisõna</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ründas</td>\n",
       "      <td>V</td>\n",
       "      <td>tegusõna</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>künklikul</td>\n",
       "      <td>A</td>\n",
       "      <td>omadussõna algvõrre</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>maastikul</td>\n",
       "      <td>S</td>\n",
       "      <td>nimisõna</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>tünjat</td>\n",
       "      <td>A</td>\n",
       "      <td>omadussõna algvõrre</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Tallinnfilmi</td>\n",
       "      <td>H</td>\n",
       "      <td>pärisnimi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>režissööri</td>\n",
       "      <td>S</td>\n",
       "      <td>nimisõna</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     word_texts postags  postag_descriptions\n",
       "0         Usjas       A  omadussõna algvõrre\n",
       "1       kaslane       S             nimisõna\n",
       "2        ründas       V             tegusõna\n",
       "3     künklikul       A  omadussõna algvõrre\n",
       "4     maastikul       S             nimisõna\n",
       "5        tünjat       A  omadussõna algvõrre\n",
       "6  Tallinnfilmi       H            pärisnimi\n",
       "7    režissööri       S             nimisõna"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from estnltk import Text\n",
    "text = Text('Usjas kaslane ründas künklikul maastikul tünjat Tallinnfilmi režissööri')\n",
    "text.get.word_texts.postags.postag_descriptions.as_dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A list of tuples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Usjas', 'A', 'omadussõna algvõrre'),\n",
       " ('kaslane', 'S', 'nimisõna'),\n",
       " ('ründas', 'V', 'tegusõna'),\n",
       " ('künklikul', 'A', 'omadussõna algvõrre'),\n",
       " ('maastikul', 'S', 'nimisõna'),\n",
       " ('tünjat', 'A', 'omadussõna algvõrre'),\n",
       " ('Tallinnfilmi', 'H', 'pärisnimi'),\n",
       " ('režissööri', 'S', 'nimisõna')]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(text.get.word_texts.postags.postag_descriptions.as_zip)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A list of lists:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Usjas',\n",
       "  'kaslane',\n",
       "  'ründas',\n",
       "  'künklikul',\n",
       "  'maastikul',\n",
       "  'tünjat',\n",
       "  'Tallinnfilmi',\n",
       "  'režissööri'],\n",
       " ['A', 'S', 'V', 'A', 'S', 'A', 'H', 'S'],\n",
       " ['omadussõna algvõrre',\n",
       "  'nimisõna',\n",
       "  'tegusõna',\n",
       "  'omadussõna algvõrre',\n",
       "  'nimisõna',\n",
       "  'omadussõna algvõrre',\n",
       "  'pärisnimi',\n",
       "  'nimisõna']]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text.get.word_texts.postags.postag_descriptions.as_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A dictionary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'postag_descriptions': ['omadussõna algvõrre',\n",
       "  'nimisõna',\n",
       "  'tegusõna',\n",
       "  'omadussõna algvõrre',\n",
       "  'nimisõna',\n",
       "  'omadussõna algvõrre',\n",
       "  'pärisnimi',\n",
       "  'nimisõna'],\n",
       " 'postags': ['A', 'S', 'V', 'A', 'S', 'A', 'H', 'S'],\n",
       " 'word_texts': ['Usjas',\n",
       "  'kaslane',\n",
       "  'ründas',\n",
       "  'künklikul',\n",
       "  'maastikul',\n",
       "  'tünjat',\n",
       "  'Tallinnfilmi',\n",
       "  'režissööri']}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text.get.word_texts.postags.postag_descriptions.as_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All the properties can be given also as a list, which can be convinient\n",
    "in some situations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word_texts</th>\n",
       "      <th>postags</th>\n",
       "      <th>postag_descriptions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Usjas</td>\n",
       "      <td>A</td>\n",
       "      <td>omadussõna algvõrre</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>kaslane</td>\n",
       "      <td>S</td>\n",
       "      <td>nimisõna</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ründas</td>\n",
       "      <td>V</td>\n",
       "      <td>tegusõna</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>künklikul</td>\n",
       "      <td>A</td>\n",
       "      <td>omadussõna algvõrre</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>maastikul</td>\n",
       "      <td>S</td>\n",
       "      <td>nimisõna</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>tünjat</td>\n",
       "      <td>A</td>\n",
       "      <td>omadussõna algvõrre</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Tallinnfilmi</td>\n",
       "      <td>H</td>\n",
       "      <td>pärisnimi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>režissööri</td>\n",
       "      <td>S</td>\n",
       "      <td>nimisõna</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     word_texts postags  postag_descriptions\n",
       "0         Usjas       A  omadussõna algvõrre\n",
       "1       kaslane       S             nimisõna\n",
       "2        ründas       V             tegusõna\n",
       "3     künklikul       A  omadussõna algvõrre\n",
       "4     maastikul       S             nimisõna\n",
       "5        tünjat       A  omadussõna algvõrre\n",
       "6  Tallinnfilmi       H            pärisnimi\n",
       "7    režissööri       S             nimisõna"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text.get(['word_texts', 'postags', 'postag_descriptions']).as_dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "> **Note**\n",
    ">\n",
    "> Estnltk does not stop the programmer doing wrong things\n",
    ">\n",
    "> You can chain together any **Text** property, but only\n",
    "> thing you must take care of is that all the properties act on same\n",
    "> layer/unit data. So, when you mix sentence and word properties, you\n",
    "> get either an error or malformed output."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### Word analysis\n",
    "\n",
    "Morphological analysis is performed with method\n",
    "**tag\\_analysis()** and is invoked by accessing any\n",
    "property requiring this. In such case, also methods\n",
    "**tokenize\\_paragraphs()**,\n",
    "**tokenize\\_sentences()** and\n",
    "**tokenize\\_words()** are called as word and sentence\n",
    "tokenization is required in order add morphological analysis.\n",
    "Morphological analysis adds extra information to `words` layer, which\n",
    "we'll explain below.\n",
    "\n",
    "After doing morphological analysis, ideally only one unambiguous\n",
    "dictionary containing all the raw data is generated. However, sometimes\n",
    "the disambiguator cannot really eliminate all ambiguity and you get\n",
    "multiple analysis variants:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'paragraphs': [{'end': 7, 'start': 0}],\n",
       " 'sentences': [{'end': 7, 'start': 0}],\n",
       " 'text': 'mõeldud',\n",
       " 'words': [{'analysis': [{'clitic': '',\n",
       "     'ending': '0',\n",
       "     'form': '',\n",
       "     'lemma': 'mõeldud',\n",
       "     'partofspeech': 'A',\n",
       "     'root': 'mõel=dud',\n",
       "     'root_tokens': ['mõeldud']},\n",
       "    {'clitic': '',\n",
       "     'ending': '0',\n",
       "     'form': 'sg n',\n",
       "     'lemma': 'mõeldud',\n",
       "     'partofspeech': 'A',\n",
       "     'root': 'mõel=dud',\n",
       "     'root_tokens': ['mõeldud']},\n",
       "    {'clitic': '',\n",
       "     'ending': 'd',\n",
       "     'form': 'pl n',\n",
       "     'lemma': 'mõeldud',\n",
       "     'partofspeech': 'A',\n",
       "     'root': 'mõel=dud',\n",
       "     'root_tokens': ['mõeldud']},\n",
       "    {'clitic': '',\n",
       "     'ending': 'dud',\n",
       "     'form': 'tud',\n",
       "     'lemma': 'mõtlema',\n",
       "     'partofspeech': 'V',\n",
       "     'root': 'mõtle',\n",
       "     'root_tokens': ['mõtle']}],\n",
       "   'end': 7,\n",
       "   'start': 0,\n",
       "   'text': 'mõeldud'}]}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from estnltk import Text\n",
    "text = Text('mõeldud')\n",
    "text.tag_analysis()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The word *mõeldud* has quite a lot ambiguity as it can be interpreted\n",
    "either as a *verb* or *adjective*. Adjective version itself can be\n",
    "though of as singular or plural and with different suffixes.\n",
    "\n",
    "This ambiguity also affects how properties work. In this case, there are\n",
    "two lemmas and when accessing **lemmas** property,\n",
    "estnltk displays both unique cases, sorted alphabetically and separated\n",
    "by a pipe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['mõeldud|mõtlema']\n",
      "['A|V']\n"
     ]
    }
   ],
   "source": [
    "print (text.lemmas)\n",
    "print (text.postags)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we have already seen that morphological data is added to word level\n",
    "dictionary under element `analysis`. Let's also look at a single\n",
    "analysis dictionary element for word \"raudteejaamadelgi\":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[{'clitic': 'gi',\n",
       "   'ending': 'del',\n",
       "   'form': 'pl ad',\n",
       "   'lemma': 'raudteejaam',\n",
       "   'partofspeech': 'S',\n",
       "   'root': 'raud_tee_jaam',\n",
       "   'root_tokens': ['raud', 'tee', 'jaam']}]]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Text('raudteejaamadelgi').analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'clitic': 'gi',\n",
       " 'ending': 'del',\n",
       " 'form': 'pl ad',\n",
       " 'lemma': 'raudteejaam',\n",
       " 'partofspeech': 'S',\n",
       " 'root': 'raud_tee_jaam',\n",
       " 'root_tokens': ['raud', 'tee', 'jaam']}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{'clitic': 'gi',                         # In Estonian, -gi and -ki suffixes\n",
    " 'ending': 'del',                        # word suffix without clitic\n",
    " 'form': 'pl ad',                        # word form, in this case plural and adessive (alalütlev) case\n",
    " 'lemma': 'raudteejaam',                 # the dictionary form of the word\n",
    " 'partofspeech': 'S',                    # POS tag, in this case substantive\n",
    " 'root': 'raud_tee_jaam',                # root form (same as lemma, but verbs do not have -ma suffix)\n",
    "                                         # also has compound word markers and optional phonetic markers\n",
    " 'root_tokens': ['raud', 'tee', 'jaam']} # for compund word roots, a list of simple roots the compound is made of"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Human-readable descriptions\n",
    "\n",
    "**Text** class has properties\n",
    "**postag\\_descriptions** and\n",
    "**descriptions**, which give Estonian descriptions\n",
    "respectively to POS tags and word forms:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word_texts</th>\n",
       "      <th>postags</th>\n",
       "      <th>postag_descriptions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Usjas</td>\n",
       "      <td>A</td>\n",
       "      <td>omadussõna algvõrre</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>kaslane</td>\n",
       "      <td>S</td>\n",
       "      <td>nimisõna</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ründas</td>\n",
       "      <td>V</td>\n",
       "      <td>tegusõna</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>künklikul</td>\n",
       "      <td>A</td>\n",
       "      <td>omadussõna algvõrre</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>maastikul</td>\n",
       "      <td>S</td>\n",
       "      <td>nimisõna</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>tünjat</td>\n",
       "      <td>A</td>\n",
       "      <td>omadussõna algvõrre</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Tallinnfilmi</td>\n",
       "      <td>H</td>\n",
       "      <td>pärisnimi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>režissööri</td>\n",
       "      <td>S</td>\n",
       "      <td>nimisõna</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     word_texts postags  postag_descriptions\n",
       "0         Usjas       A  omadussõna algvõrre\n",
       "1       kaslane       S             nimisõna\n",
       "2        ründas       V             tegusõna\n",
       "3     künklikul       A  omadussõna algvõrre\n",
       "4     maastikul       S             nimisõna\n",
       "5        tünjat       A  omadussõna algvõrre\n",
       "6  Tallinnfilmi       H            pärisnimi\n",
       "7    režissööri       S             nimisõna"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from estnltk import Text\n",
    "text = Text('Usjas kaslane ründas künklikul maastikul tünjat Tallinnfilmi režissööri')\n",
    "\n",
    "text.get.word_texts.postags.postag_descriptions.as_dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word_texts</th>\n",
       "      <th>forms</th>\n",
       "      <th>descriptions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Usjas</td>\n",
       "      <td>sg n</td>\n",
       "      <td>ainsus nimetav (nominatiiv)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>kaslane</td>\n",
       "      <td>sg n</td>\n",
       "      <td>ainsus nimetav (nominatiiv)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ründas</td>\n",
       "      <td>s</td>\n",
       "      <td>kindel kõneviis lihtminevik 3. isik ainsus akt...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>künklikul</td>\n",
       "      <td>sg ad</td>\n",
       "      <td>ainsus alalütlev (adessiiv)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>maastikul</td>\n",
       "      <td>sg ad</td>\n",
       "      <td>ainsus alalütlev (adessiiv)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>tünjat</td>\n",
       "      <td>sg p</td>\n",
       "      <td>ainsus osastav (partitiiv)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Tallinnfilmi</td>\n",
       "      <td>sg g</td>\n",
       "      <td>ainsus omastav (genitiiv)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>režissööri</td>\n",
       "      <td>sg p</td>\n",
       "      <td>ainsus osastav (partitiiv)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     word_texts  forms                                       descriptions\n",
       "0         Usjas   sg n                        ainsus nimetav (nominatiiv)\n",
       "1       kaslane   sg n                        ainsus nimetav (nominatiiv)\n",
       "2        ründas      s  kindel kõneviis lihtminevik 3. isik ainsus akt...\n",
       "3     künklikul  sg ad                        ainsus alalütlev (adessiiv)\n",
       "4     maastikul  sg ad                        ainsus alalütlev (adessiiv)\n",
       "5        tünjat   sg p                         ainsus osastav (partitiiv)\n",
       "6  Tallinnfilmi   sg g                          ainsus omastav (genitiiv)\n",
       "7    režissööri   sg p                         ainsus osastav (partitiiv)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text.get.word_texts.forms.descriptions.as_dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also, see [nounform\\_table](http://estnltk.github.io/estnltk/1.4/tutorials/morf_tables.html#nounform-table), [verbform\\_table](http://estnltk.github.io/estnltk/1.4/tutorials/morf_tables.html#verbform-table) and [postag\\_table](http://estnltk.github.io/estnltk/1.4/tutorials/morf_tables.html#postag-table) that\n",
    "contains detailed information with examples about the morphological\n",
    "attributes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis options & phonetic information\n",
    "\n",
    "By default, estnltk does not add phonetic information to analyzed word\n",
    "roots, but this functionality can be changed. Here are all the options\n",
    "that can be given to the **Text** class that will affect\n",
    "the analysis results:\n",
    "\n",
    "* disambiguate: boolean (default: True)\n",
    "\n",
    "     * Disambiguate the output and remove incosistent analyses.\n",
    "    \n",
    "    \n",
    "* guess: boolean (default: True)\n",
    "\n",
    "    * Use guessing in case of unknown words\n",
    "\n",
    "    **NB!** In order to switch guessing off, disambiguation and proper\n",
    "    name analysis have to be set to False as well.  \n",
    "    \n",
    "    \n",
    "* propername: boolean (default: True)\n",
    "\n",
    "   * Perform additional analysis of proper names.\n",
    "   \n",
    "\n",
    "* compound: boolean (default: True)\n",
    "\n",
    "   * Add compound word markers to root forms.\n",
    "   \n",
    "\n",
    "* phonetic: boolean (default: False)\n",
    "\n",
    "   * Add phonetic information to root forms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['t?os]in~k<ond', 'p<al]k', 's<aa', 'oma', 'p<alk']\n"
     ]
    }
   ],
   "source": [
    "from estnltk import Text\n",
    "print (Text('tosinkond palki sai oma palga', phonetic=True, compound=False).roots)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See [phonetic_markers](http://estnltk.github.io/estnltk/1.4/tutorials/morf_tables.html#phonetic-markers) for more information. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Note**\n",
    ">\n",
    "> Things to remember about morphological analysis!\n",
    ">\n",
    "> 1.  Morphological analysis is stored in `analysis` attribute of each\n",
    ">     word.\n",
    "> 2.  Morphological analysis is in `words` layer.\n",
    "> 3.  Use **ZipBuilder** class simplify data retrieval.\n",
    "> 4.  If you write something that needs better performance, access the\n",
    ">     **Text** directly as a dictionary, because when\n",
    ">     using properties, one loop per property is executed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Giellatekno (gt) tagset\n",
    "-------------------------\n",
    "\n",
    "Giellatekno (gt) morphological analysis tagset is an alternative tagset that can be used instead of the default (Filosoft's) tagset. Note that all tools relying on the morphological analysis (e.g. clause segmenter, temporal expression tagger, or verb chain detector) assume that the default tagset is used, thus they won't work with the gt tagset.\n",
    "\n",
    "<!-- (http://www.filosoft.ee/html_morf_et/morfoutinfo.html) -->\n",
    "\n",
    "Estnltk has function **convert_text()**, which can be used to convert morphological analyses in *Text* object from Filosoft's morphological categories to Giellatekno's categories:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word_texts</th>\n",
       "      <th>postags</th>\n",
       "      <th>forms</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Rändur</td>\n",
       "      <td>S</td>\n",
       "      <td>Sg Nom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>võttis</td>\n",
       "      <td>V</td>\n",
       "      <td>Pers Prt Ind Sg 3 Aff</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>seljakotist</td>\n",
       "      <td>S</td>\n",
       "      <td>Sg Ela</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>vilepilli</td>\n",
       "      <td>S</td>\n",
       "      <td>Sg Par</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ja</td>\n",
       "      <td>J</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>tõstis</td>\n",
       "      <td>V</td>\n",
       "      <td>Pers Prt Ind Sg 3 Aff</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>huultele</td>\n",
       "      <td>S</td>\n",
       "      <td>Pl All</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>.</td>\n",
       "      <td>Z</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    word_texts postags                  forms\n",
       "0       Rändur       S                 Sg Nom\n",
       "1       võttis       V  Pers Prt Ind Sg 3 Aff\n",
       "2  seljakotist       S                 Sg Ela\n",
       "3    vilepilli       S                 Sg Par\n",
       "4           ja       J                       \n",
       "5       tõstis       V  Pers Prt Ind Sg 3 Aff\n",
       "6     huultele       S                 Pl All\n",
       "7            .       Z                       "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from estnltk.converters.gt_conversion import convert_text\n",
    "from estnltk import Text\n",
    "\n",
    "text = Text('Rändur võttis seljakotist vilepilli ja tõstis huultele.')\n",
    "\n",
    "# Tag analysis in the text (using Filosoft's morphological categories)\n",
    "text.tag_analysis()\n",
    "\n",
    "# Convert analyses into gt format\n",
    "text = Text( convert_text(text) )\n",
    "\n",
    "text.get.word_texts.postags.forms.as_dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that if **convert_text()** is applied to a *Text* object, it overwrites the old layer containing words and their morphological analyses (``\"words\"``) with the new one, which has the same structure (words and analyses), but different categories, and different numbers of analyses.\n",
    "\n",
    "**(!) Important!** If you need to apply other tools on the *Text* (e.g. named entity recognizer, or clause segmenter), you should keep the ``\"words\"`` layer as it is (i.e. with Filosoft's morphological categories), and store the gt analyses into a new layer. Alternatively, you can apply **convert_text()** at the very end of the processing, after all morphology-dependent tools have been applied already.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the parameter **layer_name** is passed to the function **convert_text()**, gt analyses will be stored into a separate layer, and the original layer ``\"words\"`` will remain as it is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from estnltk.converters.gt_conversion import convert_text\n",
    "from estnltk import Text\n",
    "\n",
    "text2 = Text('Rändur haaras vile')\n",
    "\n",
    "# Tag analysis in the text (using Filosoft's morphological categories)\n",
    "text2.tag_analysis()\n",
    "\n",
    "# Convert analyses to gt format and store into the layer 'words2'\n",
    "text2 = Text( convert_text(text2, layer_name='words2') )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[{'clitic': '',\n",
       "   'ending': '0',\n",
       "   'form': 'sg n',\n",
       "   'lemma': 'rändur',\n",
       "   'partofspeech': 'S',\n",
       "   'root': 'rändur',\n",
       "   'root_tokens': ['rändur']}],\n",
       " [{'clitic': '',\n",
       "   'ending': 's',\n",
       "   'form': 's',\n",
       "   'lemma': 'haarama',\n",
       "   'partofspeech': 'V',\n",
       "   'root': 'haara',\n",
       "   'root_tokens': ['haara']}],\n",
       " [{'clitic': '',\n",
       "   'ending': '0',\n",
       "   'form': 'sg n',\n",
       "   'lemma': 'vile',\n",
       "   'partofspeech': 'S',\n",
       "   'root': 'vile',\n",
       "   'root_tokens': ['vile']}]]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Analyses with Filosoft's categories\n",
    "text2.analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'analysis': [{'clitic': '',\n",
       "    'ending': '0',\n",
       "    'form': 'Sg Nom',\n",
       "    'lemma': 'rändur',\n",
       "    'partofspeech': 'S',\n",
       "    'root': 'rändur',\n",
       "    'root_tokens': ['rändur']}],\n",
       "  'end': 6,\n",
       "  'start': 0,\n",
       "  'text': 'Rändur'},\n",
       " {'analysis': [{'clitic': '',\n",
       "    'ending': 's',\n",
       "    'form': 'Pers Prt Ind Sg 3 Aff',\n",
       "    'lemma': 'haarama',\n",
       "    'partofspeech': 'V',\n",
       "    'root': 'haara',\n",
       "    'root_tokens': ['haara']}],\n",
       "  'end': 13,\n",
       "  'start': 7,\n",
       "  'text': 'haaras'},\n",
       " {'analysis': [{'clitic': '',\n",
       "    'ending': '0',\n",
       "    'form': 'Sg Nom',\n",
       "    'lemma': 'vile',\n",
       "    'partofspeech': 'S',\n",
       "    'root': 'vile',\n",
       "    'root_tokens': ['vile']}],\n",
       "  'end': 18,\n",
       "  'start': 14,\n",
       "  'text': 'vile'}]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Analyses with GT categories\n",
    "text2['words2']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Morphological synthesis\n",
    "-----------------------\n",
    "\n",
    "The reverse operation of morphological analysis is synthesis. That is,\n",
    "given the dictionary form of the word and some options, generating all\n",
    "possible inflections that match given criteria.\n",
    "\n",
    "Estnltk has function **synthesize()**, which\n",
    "accepts these parameters:\n",
    "\n",
    "1.  word dictionary form (lemma).\n",
    "2.  word form (see [nounform\\_table](http://estnltk.github.io/estnltk/1.4/tutorials/morf_tables.html#nounform-table) and [verbform\\_table](http://estnltk.github.io/estnltk/1.4/tutorials/morf_tables.html#verbform-table)).\n",
    "3.  *(optional)* POS tag (see [postag\\_table](http://estnltk.github.io/estnltk/1.4/tutorials/morf_tables.html#postag-table)).\n",
    "4.  *(optional)* hint, essentially a prefix filter.\n",
    "\n",
    "Let's generate plural genitive forms for lemma \"palk\" (in English a\n",
    "*paycheck* and a *log*):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['palkade', 'palkide']"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from estnltk import synthesize\n",
    "synthesize('palk', 'pl g')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can hint the synthesizer so that it outputs only inflections that\n",
    "match prefix *palka*:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['palkade']"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "synthesize('palk', 'pl g', hint='palka')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For fun, here is some demo code for synthesizing all forms of any given\n",
    "noun (See [nounform\\_table](http://estnltk.github.io/estnltk/1.4/tutorials/morf_tables.html#nounform-table)):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from estnltk import synthesize\n",
    "import pandas\n",
    "\n",
    "cases = [\n",
    "    ('n', 'nimetav'),\n",
    "    ('g', 'omastav'),\n",
    "    ('p', 'osastav'),\n",
    "    ('ill', 'sisseütlev'),\n",
    "    ('in', 'seesütlev'),\n",
    "    ('el', 'seestütlev'),\n",
    "    ('all', 'alaleütlev'),\n",
    "    ('ad', 'alalütlev'),\n",
    "    ('abl', 'alaltütlev'),\n",
    "    ('tr', 'saav'),\n",
    "    ('ter', 'rajav'),\n",
    "    ('es', 'olev'),\n",
    "    ('ab', 'ilmaütlev'),\n",
    "    ('kom', 'kaasaütlev')]\n",
    "\n",
    "def synthesize_all(word):\n",
    "    case_rows = []\n",
    "    sing_rows = []\n",
    "    plur_rows = []\n",
    "    for case, name in cases:\n",
    "        case_rows.append(name)\n",
    "        sing_rows.append(', '.join(synthesize(word, 'sg ' + case, 'S')))\n",
    "        plur_rows.append(', '.join(synthesize(word, 'pl ' + case, 'S')))\n",
    "    return pandas.DataFrame({'case': case_rows, 'singular': sing_rows, 'plural': plur_rows}, columns=['case', 'singular', 'plural'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>case</th>\n",
       "      <th>singular</th>\n",
       "      <th>plural</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>nimetav</td>\n",
       "      <td>kuusk</td>\n",
       "      <td>kuused</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>omastav</td>\n",
       "      <td>kuuse</td>\n",
       "      <td>kuuskede</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>osastav</td>\n",
       "      <td>kuuske</td>\n",
       "      <td>kuuski, kuuskesid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sisseütlev</td>\n",
       "      <td>kuusesse</td>\n",
       "      <td>kuuskedesse</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>seesütlev</td>\n",
       "      <td>kuuses</td>\n",
       "      <td>kuuskedes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>seestütlev</td>\n",
       "      <td>kuusest</td>\n",
       "      <td>kuuskedest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>alaleütlev</td>\n",
       "      <td>kuusele</td>\n",
       "      <td>kuuskedele</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>alalütlev</td>\n",
       "      <td>kuusel</td>\n",
       "      <td>kuuskedel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>alaltütlev</td>\n",
       "      <td>kuuselt</td>\n",
       "      <td>kuuskedelt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>saav</td>\n",
       "      <td>kuuseks</td>\n",
       "      <td>kuuskedeks</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>rajav</td>\n",
       "      <td>kuuseni</td>\n",
       "      <td>kuuskedeni</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>olev</td>\n",
       "      <td>kuusena</td>\n",
       "      <td>kuuskedena</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>ilmaütlev</td>\n",
       "      <td>kuuseta</td>\n",
       "      <td>kuuskedeta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>kaasaütlev</td>\n",
       "      <td>kuusega</td>\n",
       "      <td>kuuskedega</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          case  singular             plural\n",
       "0      nimetav     kuusk             kuused\n",
       "1      omastav     kuuse           kuuskede\n",
       "2      osastav    kuuske  kuuski, kuuskesid\n",
       "3   sisseütlev  kuusesse        kuuskedesse\n",
       "4    seesütlev    kuuses          kuuskedes\n",
       "5   seestütlev   kuusest         kuuskedest\n",
       "6   alaleütlev   kuusele         kuuskedele\n",
       "7    alalütlev    kuusel          kuuskedel\n",
       "8   alaltütlev   kuuselt         kuuskedelt\n",
       "9         saav   kuuseks         kuuskedeks\n",
       "10       rajav   kuuseni         kuuskedeni\n",
       "11        olev   kuusena         kuuskedena\n",
       "12   ilmaütlev   kuuseta         kuuskedeta\n",
       "13  kaasaütlev   kuusega         kuuskedega"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "synthesize_all('kuusk')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try something funny as well:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>case</th>\n",
       "      <th>singular</th>\n",
       "      <th>plural</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>nimetav</td>\n",
       "      <td>luuslang-lendur</td>\n",
       "      <td>luuslang-lendurid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>omastav</td>\n",
       "      <td>luuslang-lenduri</td>\n",
       "      <td>luuslang-lendurite</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>osastav</td>\n",
       "      <td>luuslang-lendurit</td>\n",
       "      <td>luuslang-lendureid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sisseütlev</td>\n",
       "      <td>luuslang-lendurisse</td>\n",
       "      <td>luuslang-lendureisse, luuslang-lenduritesse</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>seesütlev</td>\n",
       "      <td>luuslang-lenduris</td>\n",
       "      <td>luuslang-lendureis, luuslang-lendurites</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>seestütlev</td>\n",
       "      <td>luuslang-lendurist</td>\n",
       "      <td>luuslang-lendureist, luuslang-lenduritest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>alaleütlev</td>\n",
       "      <td>luuslang-lendurile</td>\n",
       "      <td>luuslang-lendureile, luuslang-lenduritele</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>alalütlev</td>\n",
       "      <td>luuslang-lenduril</td>\n",
       "      <td>luuslang-lendureil, luuslang-lenduritel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>alaltütlev</td>\n",
       "      <td>luuslang-lendurilt</td>\n",
       "      <td>luuslang-lendureilt, luuslang-lenduritelt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>saav</td>\n",
       "      <td>luuslang-lenduriks</td>\n",
       "      <td>luuslang-lendureiks, luuslang-lenduriteks</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>rajav</td>\n",
       "      <td>luuslang-lendurini</td>\n",
       "      <td>luuslang-lendureini, luuslang-lenduriteni</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>olev</td>\n",
       "      <td>luuslang-lendurina</td>\n",
       "      <td>luuslang-lendureina, luuslang-lenduritena</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>ilmaütlev</td>\n",
       "      <td>luuslang-lendurita</td>\n",
       "      <td>luuslang-lenduriteta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>kaasaütlev</td>\n",
       "      <td>luuslang-lenduriga</td>\n",
       "      <td>luuslang-lenduritega</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          case             singular  \\\n",
       "0      nimetav      luuslang-lendur   \n",
       "1      omastav     luuslang-lenduri   \n",
       "2      osastav    luuslang-lendurit   \n",
       "3   sisseütlev  luuslang-lendurisse   \n",
       "4    seesütlev    luuslang-lenduris   \n",
       "5   seestütlev   luuslang-lendurist   \n",
       "6   alaleütlev   luuslang-lendurile   \n",
       "7    alalütlev    luuslang-lenduril   \n",
       "8   alaltütlev   luuslang-lendurilt   \n",
       "9         saav   luuslang-lenduriks   \n",
       "10       rajav   luuslang-lendurini   \n",
       "11        olev   luuslang-lendurina   \n",
       "12   ilmaütlev   luuslang-lendurita   \n",
       "13  kaasaütlev   luuslang-lenduriga   \n",
       "\n",
       "                                         plural  \n",
       "0                             luuslang-lendurid  \n",
       "1                            luuslang-lendurite  \n",
       "2                            luuslang-lendureid  \n",
       "3   luuslang-lendureisse, luuslang-lenduritesse  \n",
       "4       luuslang-lendureis, luuslang-lendurites  \n",
       "5     luuslang-lendureist, luuslang-lenduritest  \n",
       "6     luuslang-lendureile, luuslang-lenduritele  \n",
       "7       luuslang-lendureil, luuslang-lenduritel  \n",
       "8     luuslang-lendureilt, luuslang-lenduritelt  \n",
       "9     luuslang-lendureiks, luuslang-lenduriteks  \n",
       "10    luuslang-lendureini, luuslang-lenduriteni  \n",
       "11    luuslang-lendureina, luuslang-lenduritena  \n",
       "12                         luuslang-lenduriteta  \n",
       "13                         luuslang-lenduritega  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "synthesize_all('luuslang-lendur')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Correcting spelling\n",
    "-------------------\n",
    "\n",
    "Many applications can benefit from spellcheck functionality, which flags\n",
    "incorrect words and also provides suggestions. Estnltk Text class has\n",
    "properties **spelling**, that tells which words are\n",
    "correctly spelled and **spelling\\_suggestions**,\n",
    "which lists suggestions for incorrect words:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word_texts</th>\n",
       "      <th>spelling</th>\n",
       "      <th>spelling_suggestions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Vikastes</td>\n",
       "      <td>False</td>\n",
       "      <td>[Vigastes, Vihastes]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>lausetes</td>\n",
       "      <td>True</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>on</td>\n",
       "      <td>True</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>trügivigasid</td>\n",
       "      <td>False</td>\n",
       "      <td>[trükivigasid]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>!</td>\n",
       "      <td>True</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     word_texts spelling  spelling_suggestions\n",
       "0      Vikastes    False  [Vigastes, Vihastes]\n",
       "1      lausetes     True                    []\n",
       "2            on     True                    []\n",
       "3  trügivigasid    False        [trükivigasid]\n",
       "4             !     True                    []"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from estnltk import Text\n",
    "text = Text('Vikastes lausetes on trügivigasid!')\n",
    "\n",
    "text.get.word_texts.spelling.spelling_suggestions.as_dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is also **spellcheck\\_results** that\n",
    "gives both spelling and suggestions together. This is more efficient\n",
    "than calling **spelling** and\n",
    "**spelling\\_suggestions** separately:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'spelling': False,\n",
       "  'suggestions': ['Vigastes', 'Vihastes'],\n",
       "  'text': 'Vikastes'},\n",
       " {'spelling': True, 'suggestions': [], 'text': 'lausetes'},\n",
       " {'spelling': True, 'suggestions': [], 'text': 'on'},\n",
       " {'spelling': False, 'suggestions': ['trükivigasid'], 'text': 'trügivigasid'},\n",
       " {'spelling': True, 'suggestions': [], 'text': '!'}]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text.spellcheck_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lastly, there is function **fix\\_spelling()** that\n",
    "replaces incorrect words with first suggestion in the list. It is very\n",
    "naive, but it may be handy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vigastes lausetes on trükivigasid!\n"
     ]
    }
   ],
   "source": [
    "print(text.fix_spelling())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Detecting invalid characters\n",
    "----------------------------\n",
    "\n",
    "Often, during preprocessing of text files, we wish to check if the files\n",
    "satisfy certain assumptions. One such possible requirement is check if\n",
    "the files contain characters that can be handled by our application. For\n",
    "example, an application assuming Estonian input might not work with\n",
    "Cyrillic characters. In such cases, it is necessary to detect invalid\n",
    "input.\n",
    "\n",
    "### Predefined alphabets\n",
    "\n",
    "Estnltk has predefined alphabets for Estonian and Russian, that can be\n",
    "combined with various punctuation and whitespace:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from estnltk import EST_ALPHA, RUS_ALPHA, DIGITS, WHITESPACE, PUNCTUATION, ESTONIAN, RUSSIAN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Estonian alphabet (EST\\_ALPHA):**\n",
    "\n",
    "`abcdefghijklmnoprsšzžtuvwõäöüxyzABCDEFGHIJKLMNOPRSŠZŽTUVWÕÄÖÜXYZ`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Russian alphabet (RUS\\_ALPHA):**\n",
    "\n",
    "`абвгдеёжзийклмнопрстуфхцчшщъыьэюяАБВГДЕЁЖЗИЙКЛМНОПРСТУФХЦЧШЩЪЫЬЭЮЯ`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Standard punctuation (PUNCTUATION):**\n",
    "\n",
    "```!\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~–```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Digits:**\n",
    "\n",
    "`0123456789`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Whitespace:**\n",
    "\n",
    "`' \\t\\n\\r\\x0b\\x0c'`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Estonian combined with punctuation and whitespace:**\n",
    "\n",
    "```'abcdefghijklmnoprsšzžtuvwõäöüxyzABCDEFGHIJKLMNOPRSŠZŽTUVWÕÄÖÜXYZ0123456789 \\t\\n\\r\\x0b\\x0c!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~–'```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Russian combined with punctuation and whitespace:**\n",
    "\n",
    "```'абвгдеёжзийклмнопрстуфхцчшщъыьэюяАБВГДЕЁЖЗИЙКЛМНОПРСТУФХЦЧШЩЪЫЬЭЮЯ0123456789 \\t\\n\\r\\x0b\\x0c!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~–'```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Detecting characters\n",
    "\n",
    "By default, Estnltk assumes Estonian alphabet with whitespace and\n",
    "punctuation, but you can supply **TextCleaner**\n",
    "instances with other dictionaries to a Text instance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from estnltk import Text, TextCleaner, RUSSIAN\n",
    "td_ru = TextCleaner(RUSSIAN)\n",
    "\n",
    "et_plain = 'Segan suhkrut malbelt tassis, kus nii armsalt aurab tee.'\n",
    "ru_plain = 'Дождь, звонкой пеленой наполнил небо майский дождь.'\n",
    "\n",
    "et_correct = Text(et_plain)\n",
    "et_invalid = Text(ru_plain)\n",
    "ru_correct = Text(ru_plain, text_cleaner=td_ru)\n",
    "ru_invalid = Text(et_plain, text_cleaner=td_ru)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you can use **is\\_valid()** method to check if the\n",
    "text contains only characters defined in the alphabet:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "et_correct.is_valid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "et_invalid.is_valid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ru_correct.is_valid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ru_invalid.is_valid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In addition to checking just for correctness, we might want to get the\n",
    "list of invalid characters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "¶ō\n"
     ]
    }
   ],
   "source": [
    "from estnltk import Text\n",
    "\n",
    "text = Text('Esmaspäeval (27.04) liikus madalrōhkkond Pōhjalahelt Soome kohale.¶')\n",
    "print (text.invalid_characters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Surprisingly, in addition to `¶` we also see character `ō` as invalid.\n",
    "Well, the reason is that is not the correct `õ`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **note**\n",
    ">\n",
    "> Different Unicode characters\n",
    ">\n",
    "> -   ō latin small letter o with macron (U+014D)\n",
    "> -   õ latin small letter o with tilde (U+00F5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is really hard to distinguish the difference visually, but in case we\n",
    "are indexing the text, we fail to find it via search later if we assume\n",
    "it used correct character `õ`.\n",
    "\n",
    "So, let's replace the wrong `ō` and remove other invalid characters\n",
    "using method **clean()**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Esmaspäeval (27.04) liikus madalrõhkkond Põhjalahelt Soome kohale.\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "text = text.replace('ō', 'õ').clean()\n",
    "print (text)\n",
    "print (text.is_valid())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Searching, replacing and splitting\n",
    "----------------------------------\n",
    "\n",
    "Estnltk **Text** class mimics the behaviour of some string\n",
    "functions for convenience: **capitalize()**,\n",
    "**count()**, **endswith()**,\n",
    "**find()**, **index()**,\n",
    "**isalnum()**, **isalpha()**,\n",
    "**isdigit()**, **islower()**,\n",
    "**isspace()**, **istitle()**,\n",
    "**isupper()**, **lower()**,\n",
    "**lstrip()**, **replace()**,\n",
    "**rfind()**, **rindex()**,\n",
    "**rstrip()**, **startswith()**,\n",
    "**strip()**.\n",
    "\n",
    "However, if the method modifies the string, such as\n",
    "**strip()**, the method returns a new\n",
    "**Text** instance, invalidating all computed attributes\n",
    "such as the start and end positions as a result of tokenization. These\n",
    "attributes won't be copied to the resulting string. However, all the\n",
    "original keyword arguments are passed to the new copy. It is recommended\n",
    "to use these methods in case the text does not have any layers.\n",
    "\n",
    "Here is an example showing few of these methods at work:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tere estnltk!\n"
     ]
    }
   ],
   "source": [
    "from estnltk import Text\n",
    "\n",
    "text = Text('        TERE MAAILM  ').strip().capitalize().replace('maailm', 'estnltk!')\n",
    "print (text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting by layers\n",
    "\n",
    "A more important concept is splitting text into smaller pieces in order\n",
    "to work with them independently. For example, we might want to process\n",
    "the text one sentence at a time. Estnltk has\n",
    "**split\\_by()** method, that takes one parameter: the\n",
    "layer defining the splits:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'paragraphs': [],\n",
      " 'sentences': [{'end': 14, 'start': 0}],\n",
      " 'text': 'Esimene lause.'}\n",
      "{'paragraphs': [],\n",
      " 'sentences': [{'end': 12, 'start': 0}],\n",
      " 'text': 'Teine lause.'}\n",
      "{'paragraphs': [],\n",
      " 'sentences': [{'end': 13, 'start': 0}],\n",
      " 'text': 'Kolmas lause.'}\n"
     ]
    }
   ],
   "source": [
    "from estnltk import Text\n",
    "from pprint import pprint\n",
    "text = Text('Esimene lause. Teine lause. Kolmas lause.')\n",
    "for sentence in text.split_by('sentences'):\n",
    "    pprint(sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An example with **multi** layer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kõrred jäävad õhukeseks.\n",
      ", millel on toitunud viljasääse vastsed,\n"
     ]
    }
   ],
   "source": [
    "from estnltk import Text\n",
    "\n",
    "text = Text('Kõrred, millel on toitunud viljasääse vastsed, jäävad õhukeseks.')\n",
    "for clause in text.split_by('clauses'):\n",
    "    print (clause)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **note**\n",
    ">\n",
    "> Things to remember!\n",
    ">\n",
    "> 1.  The resulting sentences are also **Text** instances.\n",
    "> 2.  **Simple** layer elements that do not belong entirely to a single\n",
    ">     split, **are discarded**!\n",
    "> 3.  **Multi** layer element regions that do not belong entirely to a\n",
    ">     single split, **are discarded**!\n",
    "> 4.  **Multi** layer elements will end up in several splits, if spans\n",
    ">     of the element are distributed in several splits.\n",
    "> 5.  Start and end positions defining the layer element locations are\n",
    ">     modified so they align with the split they are moved into.\n",
    "> 6.  Splitting only deals with `start` and `end` attributes of layer\n",
    ">     elements. Other attributes are not modified and are copied as they\n",
    ">     are.\n",
    "> 7.  **Multi** layer split texts are by default separated with a space\n",
    ">     character ' '."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting with regular expressions\n",
    "\n",
    "Sometimes it can be useful to split the text using regular expressions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'text': 'Pidage meeles, et '}, {'text': ', muidu tuleb pahandus!'}]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from estnltk import Text\n",
    "text = Text('Pidage meeles, et <red font>teete kodused tööd kõik ära</red font>, muidu tuleb pahandus!')\n",
    "text.split_by_regex('<red font>.*?</red font>')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By default, the matched regions are discarded and used as separators.\n",
    "This can be changed by using `gaps=False` argument that reverses the\n",
    "behaviour:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'text': '<red font>teete kodused tööd kõik ära</red font>'}]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text.split_by_regex('<red font>.*?</red font>', gaps=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dividing elements by layers\n",
    "\n",
    "In addition to splitting, we use a term *dividing* if we actually do not\n",
    "want **Text** instances as the result. Instead, we may\n",
    "just want to access the words, one sentence at a time, having the\n",
    "reference to the original instance. Estnltk has\n",
    "**divide()** method, that takes two parameters: the\n",
    "element to divide into bins, the element that defines the bins:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from estnltk import Text\n",
    "\n",
    "text = Text('Esimene lause. Teine lause.')\n",
    "for sentence in text.divide('words', 'sentences'):\n",
    "    for word in sentence:\n",
    "        word['new_attribute'] = 'Estnltk greets the word ' + word['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'paragraphs': [{'end': 27, 'start': 0}],\n",
       " 'sentences': [{'end': 14, 'start': 0}, {'end': 27, 'start': 15}],\n",
       " 'text': 'Esimene lause. Teine lause.',\n",
       " 'words': [{'end': 7,\n",
       "   'new_attribute': 'Estnltk greets the word Esimene',\n",
       "   'start': 0,\n",
       "   'text': 'Esimene'},\n",
       "  {'end': 13,\n",
       "   'new_attribute': 'Estnltk greets the word lause',\n",
       "   'start': 8,\n",
       "   'text': 'lause'},\n",
       "  {'end': 14,\n",
       "   'new_attribute': 'Estnltk greets the word .',\n",
       "   'start': 13,\n",
       "   'text': '.'},\n",
       "  {'end': 20,\n",
       "   'new_attribute': 'Estnltk greets the word Teine',\n",
       "   'start': 15,\n",
       "   'text': 'Teine'},\n",
       "  {'end': 26,\n",
       "   'new_attribute': 'Estnltk greets the word lause',\n",
       "   'start': 21,\n",
       "   'text': 'lause'},\n",
       "  {'end': 27,\n",
       "   'new_attribute': 'Estnltk greets the word .',\n",
       "   'start': 26,\n",
       "   'text': '.'}]}"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **divide()** method is useful for\n",
    "\n",
    "1.  adding new attributes to existing elements/layers in the text\n",
    "2.  keeping the original start and end positions when"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **note**\n",
    ">\n",
    "> Nota bene!\n",
    ">\n",
    "> The original references are lost in elements having `start` and `end`\n",
    "> positions in **multi layer format**. The reason is that multi layer\n",
    "> elements can span regions that end up in different splits/divisions,\n",
    "> thus invalidating the `start` and `end` attributes. Updating the\n",
    "> invalidated attributes requires modifying them, which we cannot do as\n",
    "> this would also modify the original element. Thus, instead a copy is\n",
    "> made of the element, the attributes are updated, and the element is\n",
    "> returned."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Temporal expression (TIMEX) tagging\n",
    "-----------------------------------\n",
    "\n",
    "Temporal expressions tagger identifies temporal expressions (timexes) in\n",
    "text and normalizes these expressions, providing corresponding\n",
    "calendrical dates and times. The current version of the temporal\n",
    "expressions tagger is tuned for processing news texts (so the quality of\n",
    "the analysis may be suboptimal in other domains). The program outputs an\n",
    "annotation in a format similar to TimeML's TIMEX3 (more detailed\n",
    "description can be found in [annotation\n",
    "guidelines](https://github.com/soras/Ajavt/blob/master/doc/margendusformaat_et.pdf?raw=true),\n",
    "which are currently only in Estonian).\n",
    "\n",
    "The **Text** class has property\n",
    "**timexes**, which returns a list of time expressions\n",
    "found in the text:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from estnltk import Text\n",
    "from pprint import pprint\n",
    "\n",
    "text = Text('Järgmisel kolmapäeval, kõige hiljemalt kell 18.00 algab viiepäevane koosolek, mida korraldatakse igal aastal')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output is a list of four dictionaries, each representing an timex\n",
    "found in text:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'end': 21,\n",
      "  'id': 0,\n",
      "  'start': 0,\n",
      "  'temporal_function': True,\n",
      "  'text': 'Järgmisel kolmapäeval',\n",
      "  'tid': 't1',\n",
      "  'type': 'DATE',\n",
      "  'value': '2016-11-23'},\n",
      " {'anchor_id': 0,\n",
      "  'anchor_tid': 't1',\n",
      "  'end': 49,\n",
      "  'id': 1,\n",
      "  'start': 39,\n",
      "  'temporal_function': True,\n",
      "  'text': 'kell 18. 00',\n",
      "  'tid': 't2',\n",
      "  'type': 'TIME',\n",
      "  'value': '2016-11-23T18:00'},\n",
      " {'end': 67,\n",
      "  'id': 2,\n",
      "  'start': 56,\n",
      "  'temporal_function': False,\n",
      "  'text': 'viiepäevane',\n",
      "  'tid': 't3',\n",
      "  'type': 'DURATION',\n",
      "  'value': 'P5D'},\n",
      " {'end': 108,\n",
      "  'id': 3,\n",
      "  'quant': 'EVERY',\n",
      "  'start': 97,\n",
      "  'temporal_function': True,\n",
      "  'text': 'igal aastal',\n",
      "  'tid': 't4',\n",
      "  'type': 'SET',\n",
      "  'value': 'P1Y'}]\n"
     ]
    }
   ],
   "source": [
    "pprint(text.timexes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are a number of mandatory attributes present in the dictionaries:\n",
    "\n",
    "-   **start, end** - the expression start and end positions in the text.\n",
    "\n",
    "\n",
    "-   **tid** - TimeML format *id* of the expression.\n",
    "\n",
    "\n",
    "-   **id** - the zero-based *id* of the expressions, matches the\n",
    "    position of the respective dictionary in the resulting list.\n",
    "    \n",
    "    \n",
    "-   **type** - following the TimeML specification, four types of temporal expressions are distinguished:\n",
    "\n",
    "   -   *DATE expressions*, e.g. *järgmisel kolmapäeval* (*on next\n",
    "        Wednesday*)\n",
    "   -    *TIME expressions*, e.g. *kell 18.00* (*at 18 o’clock*)\n",
    "   -      *DURATIONs*, e.g. *viis päeva* (*five days*)\n",
    "    -   *SETs of times*, e.g. *igal aastal* (*on every year*)\n",
    "    \n",
    "    \n",
    "- **temporal\\_function** - boolean value indicating whether the semantics of the expression are relative to the context.\n",
    "  -  For DATE and TIME expressions:\n",
    "\n",
    "     -   *True* indicates that the expression is relative and semantics have been computed by heuristics;\n",
    "     -   *False* indicates that the expression is absolute and semantics haven't been computed by heuristics;\n",
    "\n",
    "  -   For DURATION expressions, *temporal\\_function* is mostly\n",
    "        *False*, except for vague durations;\n",
    "  -   For SET expressions, *temporal\\_function* is always *True*;    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **value** is a mandatory attribute containing the semantics and has\n",
    "four possible formats:\n",
    "\n",
    "1. Date and time **yyyy-mm-ddThh:mm**\n",
    "   -   *yyyy* - year (4 digits)\n",
    "   -   *mm* - month (01-12)\n",
    "   -   *dd* - day (01-31)\n",
    "\n",
    "2. Week-based **yyyy-Wnn-wdThh:mm**\n",
    "   -   *nn* - the week of the year (01-53)\n",
    "   -   *wd* - day of the week (1-7, where 1 denotes Monday).\n",
    "\n",
    "3.  Time based **Thh:mm**\n",
    "\n",
    "4.  Time span **Pn1Yn2Mn3Wn4DTn5Hn6M**\n",
    "\n",
    "       ni denotes a value and Y (year), M (month), W (week), D (day), H\n",
    "    (hours), M (minutes) denotes respective time granularity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Formats (1) and (2) are used with DATE, TIME and SET types. Format (1)\n",
    "is always preferred if both (1) and (2) can be used. Format (3) is used\n",
    "in cases it is impossible to extract the date. Format (4) is used is\n",
    "used in time span expressions.\n",
    "\n",
    "In addition, there are dedicated markers for special time notions:\n",
    "\n",
    "1. Different times of the day\n",
    "\n",
    "   -   *MO* - morning - hommik\n",
    "   -   *AF* - afternoon - pärastlõuna\n",
    "   -   *EV* - evening - õhtu\n",
    "   -   *NI* - night - öö\n",
    "   -   *DT* - daytime - päevane aeg\n",
    "   \n",
    "2.  Weekends/workdays\n",
    "\n",
    "   -   *WD* - workday - tööpäev\n",
    "   -   *WE* - weekend - nädalalõpp \n",
    "    \n",
    "3.  Seasons\n",
    "\n",
    "   -   *SP* - spring - kevad\n",
    "   -   *SU* - summer - suvi\n",
    "   -   *FA* - fall - sügis\n",
    "   -   *WI* - winter - talv  \n",
    "\n",
    "4. Quarters\n",
    "\n",
    "   -   *Q1, Q2, Q3, Q4*\n",
    "   -   *QX* - unknown/unspecified quarter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Document creation date\n",
    "\n",
    "Relative temporal expressions often depend on document creation date,\n",
    "which can be supplied as `creation_date` parameter. If no\n",
    "`creation_date` argument is passed, it is set as the date the code is\n",
    "run (June 8, 2015 in the example):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'end': 4,\n",
       "  'id': 0,\n",
       "  'start': 0,\n",
       "  'temporal_function': True,\n",
       "  'text': 'Täna',\n",
       "  'tid': 't1',\n",
       "  'type': 'DATE',\n",
       "  'value': '2016-11-14'}]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from estnltk import Text\n",
    "Text('Täna on ilus ilm').timexes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, when passing `creation_date=datetime.datetime(1986, 12, 21)`, we see that word \"today\" (*täna*) refers to to December 21, 1986:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'end': 4,\n",
       "  'id': 0,\n",
       "  'start': 0,\n",
       "  'temporal_function': True,\n",
       "  'text': 'Täna',\n",
       "  'tid': 't1',\n",
       "  'type': 'DATE',\n",
       "  'value': '1986-12-21'}]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import datetime\n",
    "Text('Täna on ilus ilm', creation_date=datetime.datetime(1986, 12, 21)).timexes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TIMEX examples\n",
    "\n",
    "Here are some examples of temporal expressions and fields that the\n",
    "tagger can extract. The document creation date is fixed to Dec 21, 1986\n",
    "in the examples below. See [annotation\n",
    "guidelines](https://github.com/soras/Ajavt/blob/master/doc/margendusformaat_et.pdf?raw=true)\n",
    "for more detailed explanations.\n",
    "\n",
    "|  Example      |      Temporal expression     |       Type    |   Value       |       Modifier |\n",
    "|  --------------|-----------------------------|----------------|---------------|---------------|\n",
    "|  Järgmisel reedel | Järgmisel reedel          |      DATE     |  1986-12-26   |               |\n",
    "|  2004\\. aastal  | 2004\\. aastal           |        DATE     |  2004            |   |\n",
    " | esmaspäeva hommikul |  esmaspäeva hommikul       |      TIME   |    1986-12-15TMO   |         |   \n",
    "|  järgmisel reedel kell 14.00  | järgmisel reedel kell 14. 00   | TIME  |     1986-12-26T14:00   |  |\n",
    "|  neljapäeviti  |neljapäeviti             |       SET     |   XXXX-WXX-XX       |     |\n",
    "|  hommikuti  |   hommikuti        |               SET    |    XXXX-XX-XXTMO      |   |\n",
    "|  selle kuu alguses    |   selle kuu alguses      |         DATE    |   1986-12      |      START  |\n",
    "|  1990ndate lõpus   |  1990ndate lõpus        |         DATE     |  199        |        END|\n",
    " | VI sajandist e.m.a   |   VI sajandist e.m.a      |        DATE  |     BC05  |          |    \n",
    " | kolm tundi   |       kolm tundi             |         DURATION |  PT3H  |      |        \n",
    " | viis kuud   |   viis kuud               |        DURATION |  P5M        |    |     \n",
    " | kaks minutit  |  kaks minutit           |         DURATION |  PT2M        |      |  \n",
    " | teisipäeviti  | teisipäeviti            |        SET    |    XXXX-WXX-XX       |  | \n",
    " | kolm päeva igas kuus  | kolm päeva       |               DURATION  | P3D   |   |       \n",
    " | kolm päeva igas kuus  |  igas kuus        |               SET     |   P1M      |     |      \n",
    "|  hiljuti          |         hiljuti | DATE    |   PAST\\_REF    |      | \n",
    " | tulevikus         |        tulevikus       |                DATE   |    FUTURE\\_REF        || \n",
    "|  2009\\. aasta alguses    |  2009\\. aasta alguses    |        DATE  |     2009     |          START|\n",
    " | juuni alguseks 2007. aastal           |   juuni alguseks     |     DATE   |    1986-06      |      START | \n",
    " | juuni alguseks 2007. aastal          |              2007\\. aastal        |   DATE    |   2007      |    |      \n",
    " | 2009\\. aasta esimesel poolel   |     2009\\. aasta esimesel poolel  |  DATE |  2009         |  FIRST\\_HALF|\n",
    "|  umbes 4 aastat       |     umbes 4 aastat         |         DURATION  | P4Y          |      APPROX| \n",
    "|  peaaegu 4 aastat    |      peaaegu 4 aastat         |       DURATION |  P4Y        |        LESS\\_THAN | \n",
    "|  12-15 märts 2009     |     12-  |  DATE   |    2009-03-12    |     | \n",
    "|  12-15 märts 2009     |     15 märts 2009    |               DATE  |     2009-03-15    |     | \n",
    "|  12-15 märts 2009    |             DURATION   | PXXD     |          ||\n",
    "|  eelmise kuu lõpus     |    eelmise kuu lõpus        |       DATE  |     1986-11      |      END|\n",
    "|  2004\\. aasta suvel    |    2004\\. aasta suvel        |      DATE   |    2004-SU     |       | \n",
    " | Detsembris oli keskmine temperatuur kaks korda madalam kui kuu aega varem |  Detsembris | DATE  |  1986-12 |  |          \n",
    " | Detsembris oli keskmine temperatuur kaks korda madalam kui kuu aega varem | kuu aega varem  |DATE  | 1986-11 | |          \n",
    " | neljapäeval, 17. juunil|   neljapäeval , 17. juunil   |     DATE   |    1986-06-17   |      | \n",
    " | täna, 100 aastat tagasi |  täna |  DATE   |    1986-12-21    |     | \n",
    " | täna, 100 aastat tagasi  | 100 aastat tagasi      |         DATE   |    1886   |       |      \n",
    " | neljapäeva öösel vastu reedet       |   neljapäeva öösel vastu reedet |  TIME  |   1986-12-19TNI |   |   \n",
    " | viimase aasta jooksul |    viimase aasta jooksul     |      DURATION  | P1Y    |       |    \n",
    " | viimase aasta jooksul     |       DATE     |  1985      |        |  |\n",
    "|  viimase kolme aasta jooksul      |                  viimase kolme aasta jooksul  |   DURATION  | P3Y    |   |         \n",
    "|  viimase kolme aasta jooksul  |    DATE     |  1983    |      |  |    \n",
    "|  aastaid tagasi     |       aastaid tagasi     |             DATE    |   PAST\\_REF   |    |    \n",
    "|  aastate pärast     |       aastate pärast     |             DATE    |   FUTURE\\_REF   |     | | \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tagging clauses\n",
    "---------------\n",
    "\n",
    "### Basic usage\n",
    "\n",
    "A simple sentence, also called an independent clause, typically contains\n",
    "a finite verb, and expresses a complete thought. However, natural\n",
    "language sentences can also be long and complex, consisting of two or\n",
    "more clauses joined together. The clause structure can be made even more\n",
    "complex due to embedded clauses, which divide their parent clauses into\n",
    "two halves:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from estnltk import Text\n",
    "text = Text('Mees, keda seal kohtasime, oli tuttav ja teretas meid.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The clause annotations define embedded clauses and clause boundaries.\n",
    "Additionally, each word in a sentence is associated with a clause index:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word_texts</th>\n",
       "      <th>clause_indices</th>\n",
       "      <th>clause_annotations</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Mees</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>,</td>\n",
       "      <td>1</td>\n",
       "      <td>embedded_clause_start</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>keda</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>seal</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>kohtasime</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>,</td>\n",
       "      <td>1</td>\n",
       "      <td>embedded_clause_end</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>oli</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>tuttav</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>ja</td>\n",
       "      <td>0</td>\n",
       "      <td>clause_boundary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>teretas</td>\n",
       "      <td>2</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>meid</td>\n",
       "      <td>2</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>.</td>\n",
       "      <td>2</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   word_texts  clause_indices     clause_annotations\n",
       "0        Mees               0                   None\n",
       "1           ,               1  embedded_clause_start\n",
       "2        keda               1                   None\n",
       "3        seal               1                   None\n",
       "4   kohtasime               1                   None\n",
       "5           ,               1    embedded_clause_end\n",
       "6         oli               0                   None\n",
       "7      tuttav               0                   None\n",
       "8          ja               0        clause_boundary\n",
       "9     teretas               2                   None\n",
       "10       meid               2                   None\n",
       "11          .               2                   None"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text.get.word_texts.clause_indices.clause_annotations.as_dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clause annotation information is stored in `words` layer as\n",
    "`clause_index` and `clause_annotation` attributes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'analysis': [{'clitic': '',\n",
       "    'ending': '0',\n",
       "    'form': 'sg n',\n",
       "    'lemma': 'mees',\n",
       "    'partofspeech': 'S',\n",
       "    'root': 'mees',\n",
       "    'root_tokens': ['mees']}],\n",
       "  'clause_index': 0,\n",
       "  'end': 4,\n",
       "  'start': 0,\n",
       "  'text': 'Mees'},\n",
       " {'analysis': [{'clitic': '',\n",
       "    'ending': '',\n",
       "    'form': '',\n",
       "    'lemma': ',',\n",
       "    'partofspeech': 'Z',\n",
       "    'root': ',',\n",
       "    'root_tokens': [',']}],\n",
       "  'clause_annotation': 'embedded_clause_start',\n",
       "  'clause_index': 1,\n",
       "  'end': 5,\n",
       "  'start': 4,\n",
       "  'text': ','},\n",
       " {'analysis': [{'clitic': '',\n",
       "    'ending': 'da',\n",
       "    'form': 'pl p',\n",
       "    'lemma': 'kes',\n",
       "    'partofspeech': 'P',\n",
       "    'root': 'kes',\n",
       "    'root_tokens': ['kes']},\n",
       "   {'clitic': '',\n",
       "    'ending': 'da',\n",
       "    'form': 'sg p',\n",
       "    'lemma': 'kes',\n",
       "    'partofspeech': 'P',\n",
       "    'root': 'kes',\n",
       "    'root_tokens': ['kes']}],\n",
       "  'clause_index': 1,\n",
       "  'end': 10,\n",
       "  'start': 6,\n",
       "  'text': 'keda'},\n",
       " {'analysis': [{'clitic': '',\n",
       "    'ending': '0',\n",
       "    'form': '',\n",
       "    'lemma': 'seal',\n",
       "    'partofspeech': 'D',\n",
       "    'root': 'seal',\n",
       "    'root_tokens': ['seal']}],\n",
       "  'clause_index': 1,\n",
       "  'end': 15,\n",
       "  'start': 11,\n",
       "  'text': 'seal'},\n",
       " {'analysis': [{'clitic': '',\n",
       "    'ending': 'sime',\n",
       "    'form': 'sime',\n",
       "    'lemma': 'kohtama',\n",
       "    'partofspeech': 'V',\n",
       "    'root': 'kohta',\n",
       "    'root_tokens': ['kohta']}],\n",
       "  'clause_index': 1,\n",
       "  'end': 25,\n",
       "  'start': 16,\n",
       "  'text': 'kohtasime'},\n",
       " {'analysis': [{'clitic': '',\n",
       "    'ending': '',\n",
       "    'form': '',\n",
       "    'lemma': ',',\n",
       "    'partofspeech': 'Z',\n",
       "    'root': ',',\n",
       "    'root_tokens': [',']}],\n",
       "  'clause_annotation': 'embedded_clause_end',\n",
       "  'clause_index': 1,\n",
       "  'end': 26,\n",
       "  'start': 25,\n",
       "  'text': ','},\n",
       " {'analysis': [{'clitic': '',\n",
       "    'ending': 'i',\n",
       "    'form': 's',\n",
       "    'lemma': 'olema',\n",
       "    'partofspeech': 'V',\n",
       "    'root': 'ole',\n",
       "    'root_tokens': ['ole']}],\n",
       "  'clause_index': 0,\n",
       "  'end': 30,\n",
       "  'start': 27,\n",
       "  'text': 'oli'},\n",
       " {'analysis': [{'clitic': '',\n",
       "    'ending': '0',\n",
       "    'form': 'sg n',\n",
       "    'lemma': 'tuttav',\n",
       "    'partofspeech': 'A',\n",
       "    'root': 'tuttav',\n",
       "    'root_tokens': ['tuttav']}],\n",
       "  'clause_index': 0,\n",
       "  'end': 37,\n",
       "  'start': 31,\n",
       "  'text': 'tuttav'},\n",
       " {'analysis': [{'clitic': '',\n",
       "    'ending': '0',\n",
       "    'form': '',\n",
       "    'lemma': 'ja',\n",
       "    'partofspeech': 'J',\n",
       "    'root': 'ja',\n",
       "    'root_tokens': ['ja']}],\n",
       "  'clause_annotation': 'clause_boundary',\n",
       "  'clause_index': 0,\n",
       "  'end': 40,\n",
       "  'start': 38,\n",
       "  'text': 'ja'},\n",
       " {'analysis': [{'clitic': '',\n",
       "    'ending': 's',\n",
       "    'form': 's',\n",
       "    'lemma': 'teretama',\n",
       "    'partofspeech': 'V',\n",
       "    'root': 'tereta',\n",
       "    'root_tokens': ['tereta']}],\n",
       "  'clause_index': 2,\n",
       "  'end': 48,\n",
       "  'start': 41,\n",
       "  'text': 'teretas'},\n",
       " {'analysis': [{'clitic': '',\n",
       "    'ending': 'd',\n",
       "    'form': 'pl p',\n",
       "    'lemma': 'mina',\n",
       "    'partofspeech': 'P',\n",
       "    'root': 'mina',\n",
       "    'root_tokens': ['mina']}],\n",
       "  'clause_index': 2,\n",
       "  'end': 53,\n",
       "  'start': 49,\n",
       "  'text': 'meid'},\n",
       " {'analysis': [{'clitic': '',\n",
       "    'ending': '',\n",
       "    'form': '',\n",
       "    'lemma': '.',\n",
       "    'partofspeech': 'Z',\n",
       "    'root': '.',\n",
       "    'root_tokens': ['.']}],\n",
       "  'clause_index': 2,\n",
       "  'end': 54,\n",
       "  'start': 53,\n",
       "  'text': '.'}]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text.words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clause indices and annotations can be explicitly tagged with method\n",
    "**tag\\_clause\\_annotations()**.\n",
    "\n",
    "Property **clause\\_texts()** can be used to see the\n",
    "full clauses themselves:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Mees oli tuttav ja', ', keda seal kohtasime,', 'teretas meid.']"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text.clause_texts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Method **tag\\_clauses()** can be used create a special\n",
    "`clauses` multilayer, that lists character-level indices of start and\n",
    "end positions of clause regions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'end': [4, 40], 'start': [0, 27]},\n",
       " {'end': [26], 'start': [4]},\n",
       " {'end': [54], 'start': [41]}]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text.tag_clauses()\n",
    "text['clauses']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It might be useful to process each clause of the sentence independently:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mees oli tuttav ja\n",
      ", keda seal kohtasime,\n",
      "teretas meid.\n"
     ]
    }
   ],
   "source": [
    "for clause in text.split_by('clauses'):\n",
    "    print (clause.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The 'ignore\\_missing\\_commas' mode\n",
    "\n",
    "Because commas are important clause delimiters in Estonian, the quality\n",
    "of the clause segmentation may suffer due to accidentially missing\n",
    "commas in the input text. To address this issue, the clause segmenter\n",
    "can be initialized in a mode in which the program tries to be less\n",
    "sensitive to missing commas while detecting clause boundaries.\n",
    "\n",
    "Example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keegi teine ka siin ju kirjutas\n",
      "et ütles\n",
      "et saab ise asjadele järgi minna\n",
      "aga vastust seepeale ei tulnudki.\n"
     ]
    }
   ],
   "source": [
    "from estnltk import ClauseSegmenter\n",
    "from estnltk import Text\n",
    "\n",
    "segmenter = ClauseSegmenter( ignore_missing_commas=True )\n",
    "text = Text('Keegi teine ka siin ju kirjutas et ütles et saab ise asjadele järgi minna aga vastust seepeale ei tulnudki.', clause_segmenter = segmenter)\n",
    "\n",
    "for clause in text.split_by('clauses'):\n",
    "    print (clause.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that this mode is experimental and compared to the basic mode, it\n",
    "may introduce additional incorrect clause boundaries, although it also\n",
    "improves clause boundary detection in texts with (a lot of) missing\n",
    "commas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verb chain tagging\n",
    "------------------\n",
    "\n",
    "Verb chain tagger identifies main verbs (predicates) in clauses. The\n",
    "current version of the program aims to detect following verb chain\n",
    "constructions:\n",
    "\n",
    "-   basic main verbs:\n",
    "    -   (affirmative) single non-*olema* main verbs (example: Pidevalt\n",
    "        **uurivad** asjade seisu ka hollandlased);\n",
    "    -   (affirmative) single *olema* main verbs (e.g. Raha **on** alati\n",
    "        vähe) and two word *olema* verb chains (**Oleme** sellist kino\n",
    "        ennegi **näinud**);\n",
    "    -   negated main verbs: *ei/ära/pole/ega* + verb (e.g. Helistasin\n",
    "        korraks Carmenile, kuid ta **ei vastanud.**);\n",
    "-   verb chain extensions:\n",
    "    -   verb + verb : the chain is extended with an infinite verb if the\n",
    "        last verb of the chain subcategorizes for it, e.g. the verb\n",
    "        *kutsuma* is extended with *ma*-verb arguments (for example:\n",
    "        Kevadpäike **kutsub** mind **suusatama**) and the verb *püüdma*\n",
    "        is extended with *da*-verb arguments (Aita **ei püüdnudki**\n",
    "        Leenat **mõista**);\n",
    "    -   verb + nom/adv + verb : the last verb of the chain is extended\n",
    "        with nominal/adverb arguments which subcategorize for an\n",
    "        infinite verb, e.g. the verb *otsima* forms a multiword unit\n",
    "        with the nominal *võimalust* which, in turn, takes infinite\n",
    "        *da*-verb as an argument (for example: Seepärast **otsisimegi\n",
    "        võimalust** kusagilt mõned ilvesed **hankida**);\n",
    "\n",
    "Verb chains are stored as a simple layer named `verb_chains`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'analysis_ids': [[0], [0], [0]],\n",
       "  'clause_index': 0,\n",
       "  'end': [8, 16, 29],\n",
       "  'mood': 'condit',\n",
       "  'morph': ['V_ks', 'V_nud', 'V_ma'],\n",
       "  'other_verbs': False,\n",
       "  'pattern': ['ole', 'verb', 'verb'],\n",
       "  'phrase': [1, 2, 4],\n",
       "  'pol': 'POS',\n",
       "  'roots': ['ole', 'pida', 'mine'],\n",
       "  'start': [3, 9, 23],\n",
       "  'tense': 'past',\n",
       "  'voice': 'personal'},\n",
       " {'analysis_ids': [[0], [3]],\n",
       "  'clause_index': 1,\n",
       "  'end': [37, 44],\n",
       "  'mood': 'indic',\n",
       "  'morph': ['V_neg', 'V_nud'],\n",
       "  'other_verbs': False,\n",
       "  'pattern': ['ei', 'verb'],\n",
       "  'phrase': [7, 8],\n",
       "  'pol': 'NEG',\n",
       "  'roots': ['ei', 'mine'],\n",
       "  'start': [35, 38],\n",
       "  'tense': 'imperfect',\n",
       "  'voice': 'personal'}]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from estnltk import Text\n",
    "text = Text('Ta oleks pidanud sinna minema, aga ei läinud.')\n",
    "text.verb_chains"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Following is a brief description of the attributes:\n",
    "\n",
    "-   `analysis_ids` - the indices of analysis ids of the words in the\n",
    "    phrase of this chain.\n",
    "-   `clause_index` - the clause id this chain was tagged in.\n",
    "-   `mood` - mood of the finite verb. Possible values: *'indic'*\n",
    "    (indicative), *'imper'* (imperative), *'condit'* (conditional),\n",
    "    *'quotat'* (quotative) or *'??'* (undetermined);\n",
    "-   `morph` - for each word in the chain, lists its morphological\n",
    "    features: part of speech tag and form (in one string, separated by\n",
    "    '\\_', and multiple variants of the pos/form are separated by '/');\n",
    "-   `other_verbs` - boolean, marks whether there are other verbs in the\n",
    "    context, which can be potentially added to the verb chain; if\n",
    "    `True`,then it is uncertain whether the chain is complete or not;\n",
    "-   `pattern` - the general pattern of the chain: for each word in the\n",
    "    chain, lists whether it is *'ega'*, *'ei'*, *'ära'*, *'pole'*,\n",
    "    *'ole'*, *'&'* (conjunction: ja/ning/ega/või), *'verb'* (verb\n",
    "    different than *'ole'*) or *'nom/adv'* (nominal/adverb);\n",
    "-   `phrase` - the word indices of the sentence that make up the verb\n",
    "    chain phrase.\n",
    "-   `pol` - grammatical polarity of the finite verb. Possible values:\n",
    "    *'POS'*, *'NEG'* or *'??'*. *'NEG'* means that the chain begins with\n",
    "    a negation word *ei/pole/ega/ära*; *'??'* is reserved for cases\n",
    "    where it is uncertain whether *ära* forms a negated verb chain or\n",
    "    not;\n",
    "-   `roots` - for each word in the chain, lists its corresponding 'root'\n",
    "    value from the morphological analysis;\n",
    "-   `tense` - tense of the finite verb. Possible values depend on the\n",
    "    mood value. Tenses of indicative: *'present'*, *'imperfect'*,\n",
    "    *'perfect'*, *'pluperfect'*; tense of imperative: *'present'*;\n",
    "    tenses of conditional and quotative: *'present'* and *'past'*.\n",
    "    Additionally, the tense may remain undetermined (*'??'*).\n",
    "-   `voice` - voice of the finite verb. Possible values: *'personal'*,\n",
    "    *'impersonal'*, *'??'* (undetermined).\n",
    "\n",
    "Note that the words in the verb chain (in `phrase`, `pattern`, `morph`\n",
    "and `roots`) are ordered by the order of the grammatical relations - the\n",
    "order which may not coincide with the word order in text. The first word\n",
    "is the finite verb (main verb) of the clause (except in case of the\n",
    "negation constructions, where the first word is typically a negation\n",
    "word), and each following word is governed by the previous word in the\n",
    "chain. An exception: the chain may end with a conjunction of two\n",
    "infinite verbs (general pattern *verb & verb*), in this case, both\n",
    "infinite verbs can be considered as being governed by the preceding word\n",
    "in the chain.\n",
    "\n",
    "Attributes `start` and `end` contain start and end positions for each\n",
    "token in the phrase, and these token positions are listed in the\n",
    "ascending order, regardless the order of the grammatical relations.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Estonian wordnet\n",
    "----------------\n",
    "\n",
    "Estonian WordNet API provides means to query Estonian WordNet. WordNet\n",
    "is a network of synsets, in which synsets are collections of synonymous\n",
    "words and are connected to other synsets via relations. For example, the\n",
    "synset which contains the word \"koer\" (\"dog\") has a generalisation via\n",
    "hypernymy relation in the form of synset which contains the word\n",
    "\"koerlane\" (\"canine\").\n",
    "\n",
    "Estonian WordNet contains synsets with different types of\n",
    "part-of-speech: *adverbs, adjectives, verbs* and *nouns*.\n",
    "\n",
    "  Part of speech   API equivalent\n",
    "  ---------------- ----------------\n",
    "  Adverb           wn.ADV\n",
    "  Adjective        wn.ADJ\n",
    "  Noun             wn.NOUN\n",
    "  Verb             wn.VERB\n",
    "\n",
    "Given API is on most parts in conformance with NLTK WordNet's API\n",
    "(<http://www.nltk.org/howto/wordnet.html>). However, there are some\n",
    "differences due to different structure of the WordNets.\n",
    "\n",
    "-   Lemma classes' relations return empty sets. Reason: In Estonian\n",
    "    WordNet relations are only between synsets.\n",
    "-   No verb frames. Reason: No information on verb frames.\n",
    "-   Only path, Leacock-Chodorow and Wu-Palmer similarities. No\n",
    "    information on Information Content.\n",
    "\n",
    "Existing relations:\n",
    "\n",
    "*antonym, be\\_in\\_state, belongs\\_to\\_class, causes, fuzzynym,\n",
    "has\\_holo\\_location, has\\_holo\\_madeof, has\\_holo\\_member,\n",
    "has\\_holo\\_part, has\\_holo\\_portion, has\\_holonym, has\\_hyperonym,\n",
    "has\\_hyponym, has\\_instance, has\\_mero\\_location, has\\_mero\\_madeof,\n",
    "has\\_mero\\_member, has\\_mero\\_part, has\\_mero\\_portion, has\\_meronym,\n",
    "has\\_subevent, has\\_xpos\\_hyperonym, has\\_xpos\\_hyponym, involved,\n",
    "involved\\_agent, involved\\_instrument, involved\\_location,\n",
    "involved\\_patient, involved\\_target\\_direction, is\\_caused\\_by,\n",
    "is\\_subevent\\_of, near\\_antonym, near\\_synonym, role, role\\_agent,\n",
    "role\\_instrument, role\\_location, role\\_patient,\n",
    "role\\_target\\_direction, state\\_of, xpos\\_fuzzynym, xpos\\_near\\_antonym,\n",
    "xpos\\_near\\_synonym .*\n",
    "\n",
    "### Wordnet API\n",
    "\n",
    "Before anything else, let's import the module:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from estnltk.wordnet import wn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The most common use for the API is to query synsets. Synsets can be\n",
    "queried in several ways. The easiest way is to query all the synsets\n",
    "which match some conditions. For that we can either use:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"Synset('korraldama.v.07')\",\n",
       " \"Synset('korraldamine.n.03')\",\n",
       " \"Synset('küsima.v.02')\",\n",
       " \"Synset('küsimine.n.02')\",\n",
       " \"Synset('mõjutama.v.01')\",\n",
       " \"Synset('mõjutamine.n.02')\",\n",
       " \"Synset('lubama.v.01')\",\n",
       " \"Synset('lubamine.n.01')\",\n",
       " \"Synset('üksmeelel olema.v.01')\",\n",
       " \"Synset('informeerima.v.01')\",\n",
       " \"Synset('informeerimine.n.02')\",\n",
       " \"Synset('selgitama.v.01')\",\n",
       " \"Synset('selgitamine.n.02')\",\n",
       " \"Synset('väljendama.v.03')\",\n",
       " \"Synset('väljendamine.n.04')\",\n",
       " \"Synset('rääkima.v.04')\",\n",
       " \"Synset('avaldama.v.04')\",\n",
       " \"Synset('avaldamine.n.02')\",\n",
       " \"Synset('mõtlema.v.02')\",\n",
       " \"Synset('mõtlemine.n.02')\",\n",
       " \"Synset('häälitsema.v.01')\",\n",
       " \"Synset('valimistulemus.n.01')\",\n",
       " \"Synset('kirjutama.v.02')\",\n",
       " \"Synset('kirjutamine.n.02')\",\n",
       " \"Synset('sisse kandma.v.01')\",\n",
       " \"Synset('registreerimine.n.02')\",\n",
       " \"Synset('väljendama.v.01')\",\n",
       " \"Synset('väljendamine.n.06')\",\n",
       " \"Synset('mängima.v.01')\",\n",
       " \"Synset('mängimine.n.01')\",\n",
       " \"Synset('loobuma.v.02')\",\n",
       " \"Synset('loobumine.n.02')\",\n",
       " \"Synset('võitlema.v.01')\",\n",
       " \"Synset('võitlemine.n.01')\",\n",
       " \"Synset('ründama.v.01')\",\n",
       " \"Synset('ründamine.n.02')\",\n",
       " \"Synset('toituma.v.01')\",\n",
       " \"Synset('rakendama.v.01')\",\n",
       " \"Synset('rakendamine.n.01')\",\n",
       " \"Synset('hankima.v.02')\",\n",
       " \"Synset('hankimine.n.02')\",\n",
       " \"Synset('kokku puutuma.v.01')\",\n",
       " \"Synset('külgnemine.n.01')\",\n",
       " \"Synset('puutuma.v.02')\",\n",
       " \"Synset('võtma.v.01')\",\n",
       " \"Synset('võtmine.n.02')\",\n",
       " \"Synset('põrkama.v.01')\",\n",
       " \"Synset('põrkamine.n.02')\",\n",
       " \"Synset('katma.v.02')\",\n",
       " \"Synset('katmine.n.02')\",\n",
       " \"Synset('sulgema.v.01')\",\n",
       " \"Synset('sulgemine.n.03')\",\n",
       " \"Synset('ühendama.v.01')\",\n",
       " \"Synset('ühendamine.n.02')\",\n",
       " \"Synset('viima.v.02')\",\n",
       " \"Synset('viimine.n.02')\",\n",
       " \"Synset('viskama.v.02')\",\n",
       " \"Synset('viskamine.n.02')\",\n",
       " \"Synset('puhastama.v.01')\",\n",
       " \"Synset('puhastamine.n.02')\",\n",
       " \"Synset('lahutama.v.01')\",\n",
       " \"Synset('lahutamine.n.01')\",\n",
       " \"Synset('looma.v.02')\",\n",
       " \"Synset('loomine.n.03')\",\n",
       " \"Synset('looma.v.05')\",\n",
       " \"Synset('loomine.n.04')\",\n",
       " \"Synset('tegema.v.06')\",\n",
       " \"Synset('tegemine.n.04')\",\n",
       " \"Synset('vormima.v.01')\",\n",
       " \"Synset('vormimine.n.01')\",\n",
       " \"Synset('kaunistama.v.01')\",\n",
       " \"Synset('kaunistamine.n.02')\",\n",
       " \"Synset('kujutama.v.01')\",\n",
       " \"Synset('kujutamine.n.02')\",\n",
       " \"Synset('seletama.v.01')\",\n",
       " \"Synset('seletamine.n.03')\",\n",
       " \"Synset('sooritama.v.04')\",\n",
       " \"Synset('sooritamine.n.02')\",\n",
       " \"Synset('ihaldama.v.01')\",\n",
       " \"Synset('ihaldamine.n.01')\",\n",
       " \"Synset('liikuma.v.03')\",\n",
       " \"Synset('liikuma.v.02')\",\n",
       " \"Synset('liikumine.n.06')\",\n",
       " \"Synset('lahkuma.v.03')\",\n",
       " \"Synset('lahkumine.n.03')\",\n",
       " \"Synset('liigutama.v.02')\",\n",
       " \"Synset('liigutamine.n.03')\",\n",
       " \"Synset('käima.v.01')\",\n",
       " \"Synset('käimine.n.01')\",\n",
       " \"Synset('sõitma.v.02')\",\n",
       " \"Synset('sõitmine.n.02')\",\n",
       " \"Synset('laskuma.v.01')\",\n",
       " \"Synset('laskumine.n.02')\",\n",
       " \"Synset('juhtima.v.03')\",\n",
       " \"Synset('juhtimine.n.02')\",\n",
       " \"Synset('saabuma.v.03')\",\n",
       " \"Synset('saabumine.n.02')\",\n",
       " \"Synset('sisenema.v.01')\",\n",
       " \"Synset('sisenemine.n.01')\",\n",
       " \"Synset('mööda minema.v.01')\",\n",
       " \"Synset('möödumine.n.01')\",\n",
       " \"Synset('kogema.v.02')\",\n",
       " \"Synset('kogemine.n.02')\",\n",
       " \"Synset('vaatama.v.02')\",\n",
       " \"Synset('vaatamine.n.04')\",\n",
       " \"Synset('näima.v.01')\",\n",
       " \"Synset('näimine.n.01')\",\n",
       " \"Synset('kõlama.v.02')\",\n",
       " \"Synset('kõlamine.n.01')\",\n",
       " \"Synset('kinkima.v.01')\",\n",
       " \"Synset('kinkimine.n.02')\",\n",
       " \"Synset('olema.v.09')\",\n",
       " \"Synset('olemine.n.03')\",\n",
       " \"Synset('omama.v.02')\",\n",
       " \"Synset('omamine.n.02')\",\n",
       " \"Synset('omandama.v.02')\",\n",
       " \"Synset('omandamine.n.04')\",\n",
       " \"Synset('maksma.v.02')\",\n",
       " \"Synset('maksmine.n.02')\",\n",
       " \"Synset('kaotama.v.01')\",\n",
       " \"Synset('kaotamine.n.03')\",\n",
       " \"Synset('kahju kannatama.v.01')\",\n",
       " \"Synset('tekitama.v.02')\",\n",
       " \"Synset('tekitamine.n.05')\",\n",
       " \"Synset('varustama.v.02')\",\n",
       " \"Synset('varustamine.n.02')\",\n",
       " \"Synset('varustama.v.01')\",\n",
       " \"Synset('varustamine.n.03')\",\n",
       " \"Synset('tegutsema.v.03')\",\n",
       " \"Synset('tegutsemine.n.02')\",\n",
       " \"Synset('vaeva nägema.v.01')\",\n",
       " \"Synset('pingutamine.n.01')\",\n",
       " \"Synset('hoolitsema.v.02')\",\n",
       " \"Synset('hoolitsemine.n.02')\",\n",
       " \"Synset('juhtima.v.02')\",\n",
       " \"Synset('juhtimine.n.03')\",\n",
       " \"Synset('määrama.v.04')\",\n",
       " \"Synset('määramine.n.03')\",\n",
       " \"Synset('kontrollima.v.01')\",\n",
       " \"Synset('kontrollimine.n.02')\",\n",
       " \"Synset('püüdma.v.02')\",\n",
       " \"Synset('püüdmine.n.03')\",\n",
       " \"Synset('abistama.v.02')\",\n",
       " \"Synset('abistamine.n.03')\",\n",
       " \"Synset('sooritama.v.03')\",\n",
       " \"Synset('sooritamine.n.03')\",\n",
       " \"Synset('petma.v.01')\",\n",
       " \"Synset('petmine.n.02')\",\n",
       " \"Synset('olema.v.08')\",\n",
       " \"Synset('lõppema.v.02')\",\n",
       " \"Synset('lõppemine.n.01')\",\n",
       " \"Synset('ootama.v.02')\",\n",
       " \"Synset('ootamine.n.02')\",\n",
       " \"Synset('olema.v.07')\",\n",
       " \"Synset('olemine.n.05')\",\n",
       " \"Synset('sobima.v.04')\",\n",
       " \"Synset('sobimine.n.02')\",\n",
       " \"Synset('võrdne olema.v.01')\",\n",
       " \"Synset('võrdumine.n.01')\",\n",
       " \"Synset('juurde kuuluma.v.01')\",\n",
       " \"Synset('lõpetama.v.03')\",\n",
       " \"Synset('lõpetamine.n.03')\",\n",
       " \"Synset('hoidma.v.02')\",\n",
       " \"Synset('hoidmine.n.02')\",\n",
       " \"Synset('jätkama.v.02')\",\n",
       " \"Synset('jätkamine.n.01')\",\n",
       " \"Synset('veetma.v.01')\",\n",
       " \"Synset('veetmine.n.01')\",\n",
       " \"Synset('võima.v.01')\",\n",
       " \"Synset('müüma.v.01')\",\n",
       " \"Synset('müümine.n.02')\",\n",
       " \"Synset('alla tulema.v.01')\",\n",
       " \"Synset('sadamine.n.01')\",\n",
       " \"Synset('korrastama.v.03')\",\n",
       " \"Synset('sugemine.n.01')\",\n",
       " \"Synset('vigastama.v.01')\",\n",
       " \"Synset('haavamine.n.01')\",\n",
       " \"Synset('hoolitsema.v.01')\",\n",
       " \"Synset('muutuma.v.01')\",\n",
       " \"Synset('muutumine.n.02')\",\n",
       " \"Synset('jääma.v.01')\",\n",
       " \"Synset('jäämine.n.02')\",\n",
       " \"Synset('kujundama.v.02')\",\n",
       " \"Synset('kujundamine.n.02')\",\n",
       " \"Synset('jääma.v.04')\",\n",
       " \"Synset('jäämine.n.03')\",\n",
       " \"Synset('vähenema.v.02')\",\n",
       " \"Synset('vähenemine.n.02')\",\n",
       " \"Synset('kasvama.v.04')\",\n",
       " \"Synset('kasvamine.n.03')\",\n",
       " \"Synset('kõrvaldama.v.01')\",\n",
       " \"Synset('kõrvaldamine.n.02')\",\n",
       " \"Synset('halvenema.v.01')\",\n",
       " \"Synset('halvenemine.n.02')\",\n",
       " \"Synset('parandama.v.02')\",\n",
       " \"Synset('parandamine.n.03')\",\n",
       " \"Synset('kahjustuma.v.02')\",\n",
       " \"Synset('kahjustumine.n.01')\",\n",
       " \"Synset('murduma.v.01')\",\n",
       " \"Synset('murdumine.n.01')\",\n",
       " \"Synset('käituma.v.01')\",\n",
       " \"Synset('käitumine.n.02')\",\n",
       " \"Synset('juhtuma.v.03')\",\n",
       " \"Synset('juhtumine.n.01')\",\n",
       " \"Synset('jätkama.v.01')\",\n",
       " \"Synset('jätkamine.n.02')\",\n",
       " \"Synset('lõpetama.v.02')\",\n",
       " \"Synset('lõpetamine.n.04')\",\n",
       " \"Synset('katkestama.v.01')\",\n",
       " \"Synset('katkestamine.n.03')\",\n",
       " \"Synset('vähendama.v.01')\",\n",
       " \"Synset('vähendamine.n.02')\",\n",
       " \"Synset('täitma.v.01')\",\n",
       " \"Synset('täitmine.n.04')\",\n",
       " \"Synset('märkima.v.01')\",\n",
       " \"Synset('märkimine.n.01')\",\n",
       " \"Synset('teadma.v.01')\",\n",
       " \"Synset('teadmine.n.03')\",\n",
       " \"Synset('meelde tulema.v.01')\",\n",
       " \"Synset('meenumine.n.01')\",\n",
       " \"Synset('meelde tuletama.v.01')\",\n",
       " \"Synset('meenutamine.n.02')\",\n",
       " \"Synset('mõtlema.v.01')\",\n",
       " \"Synset('tuvastama.v.01')\",\n",
       " \"Synset('tuvastamine.n.02')\",\n",
       " \"Synset('otsustama.v.03')\",\n",
       " \"Synset('otsustamine.n.02')\",\n",
       " \"Synset('valima.v.01')\",\n",
       " \"Synset('valimine.n.02')\",\n",
       " \"Synset('arvama.v.02')\",\n",
       " \"Synset('arvamine.n.01')\",\n",
       " \"Synset('arvama.v.05')\",\n",
       " \"Synset('otsustama.v.02')\",\n",
       " \"Synset('otsustamine.n.03')\",\n",
       " \"Synset('kindlaks määrama.v.01')\",\n",
       " \"Synset('fikseerimine.n.02')\",\n",
       " \"Synset('kavandama.v.01')\",\n",
       " \"Synset('kavandamine.n.02')\",\n",
       " \"Synset('ootama.v.01')\",\n",
       " \"Synset('ootamine.n.03')\",\n",
       " \"Synset('ettevõtmine.n.01')\",\n",
       " \"Synset('seks.n.01')\",\n",
       " \"Synset('tootmine.n.01')\",\n",
       " \"Synset('kunst.n.02')\",\n",
       " \"Synset('toit.n.03')\",\n",
       " \"Synset('võitlus.n.01')\",\n",
       " \"Synset('rünnak.n.01')\",\n",
       " \"Synset('asi.n.04')\",\n",
       " \"Synset('menetlus.n.02')\",\n",
       " \"Synset('rühmategevus.n.01')\",\n",
       " \"Synset('karistus.n.01')\",\n",
       " \"Synset('löök.n.02')\",\n",
       " \"Synset('artikkel.n.01')\",\n",
       " \"Synset('abi.n.01')\",\n",
       " \"Synset('järglane.n.01')\",\n",
       " \"Synset('mikroorganism.n.01')\",\n",
       " \"Synset('teadmine.n.01')\",\n",
       " \"Synset('lind.n.01')\",\n",
       " \"Synset('motiiv.n.01')\",\n",
       " \"Synset('tunne.n.02')\",\n",
       " \"Synset('koht.n.04')\",\n",
       " \"Synset('imetaja.n.01')\",\n",
       " \"Synset('vorm.n.01')\",\n",
       " \"Synset('selgrootu.n.01')\",\n",
       " \"Synset('mollusk.n.01')\",\n",
       " \"Synset('aeg.n.02')\",\n",
       " \"Synset('koer.n.01')\",\n",
       " \"Synset('ruum.n.03')\",\n",
       " \"Synset('olend.n.01')\",\n",
       " \"Synset('putukas.n.01')\",\n",
       " \"Synset('seisund.n.03')\",\n",
       " \"Synset('sündmus.n.02')\",\n",
       " \"Synset('vastne.n.01')\",\n",
       " \"Synset('hobune.n.01')\",\n",
       " \"Synset('hominiid.n.01')\",\n",
       " \"Synset('kala.n.01')\",\n",
       " \"Synset('asi.n.03')\",\n",
       " \"Synset('üksus.n.01')\",\n",
       " \"Synset('kontor.n.01')\",\n",
       " \"Synset('töökoht.n.02')\",\n",
       " \"Synset('olmerajatis.n.01')\",\n",
       " \"Synset('tegu.n.03')\",\n",
       " \"Synset('riie.n.02')\",\n",
       " \"Synset('nõu.n.01')\",\n",
       " \"Synset('transpordivahend.n.01')\",\n",
       " \"Synset('kate.n.02')\",\n",
       " \"Synset('looming.n.01')\",\n",
       " \"Synset('riistapuu.n.01')\",\n",
       " \"Synset('mõjuaine.n.01')\",\n",
       " \"Synset('varustus.n.01')\",\n",
       " \"Synset('mööbliese.n.01')\",\n",
       " \"Synset('grupp.n.02')\",\n",
       " \"Synset('vahend.n.02')\",\n",
       " \"Synset('mehhanism.n.01')\",\n",
       " \"Synset('arstim.n.02')\",\n",
       " \"Synset('ravimisviis.n.01')\",\n",
       " \"Synset('ava.n.02')\",\n",
       " \"Synset('dekoratsioon.n.01')\",\n",
       " \"Synset('ornament.n.01')\",\n",
       " \"Synset('tee.n.04')\",\n",
       " \"Synset('mänguasi.n.01')\",\n",
       " \"Synset('omand.n.02')\",\n",
       " \"Synset('ehitatu.n.01')\",\n",
       " \"Synset('süsteem.n.04')\",\n",
       " \"Synset('õhusõiduk.n.01')\",\n",
       " \"Synset('aparaat.n.01')\",\n",
       " \"Synset('kott.n.01')\",\n",
       " \"Synset('barjäär.n.01')\",\n",
       " \"Synset('paat.n.01')\",\n",
       " \"Synset('köide.n.01')\",\n",
       " \"Synset('pudel.n.01')\",\n",
       " \"Synset('omadus.n.02')\",\n",
       " \"Synset('auto.n.01')\",\n",
       " \"Synset('kaart.n.01')\",\n",
       " \"Synset('tool.n.01')\",\n",
       " \"Synset('riided.n.01')\",\n",
       " \"Synset('rõivas.n.01')\",\n",
       " \"Synset('kaup.n.01')\",\n",
       " \"Synset('komponent.n.01')\",\n",
       " \"Synset('kujutamine.n.01')\",\n",
       " \"Synset('kujutis.n.01')\",\n",
       " \"Synset('seos.n.02')\",\n",
       " \"Synset('niit.n.02')\",\n",
       " \"Synset('aed.n.01')\",\n",
       " \"Synset('mootor.n.01')\",\n",
       " \"Synset('kaevand.n.01')\",\n",
       " \"Synset('pind.n.03')\",\n",
       " \"Synset('pind.n.02')\",\n",
       " \"Synset('pool.n.02')\",\n",
       " \"Synset('kinnitusvahend.n.01')\",\n",
       " \"Synset('peakate.n.01')\",\n",
       " \"Synset('hulk.n.03')\",\n",
       " \"Synset('valgustus.n.02')\",\n",
       " \"Synset('kiht.n.02')\",\n",
       " \"Synset('tuba.n.01')\",\n",
       " \"Synset('maja.n.01')\",\n",
       " \"Synset('masin.n.01')\",\n",
       " \"Synset('mõõteriist.n.01')\",\n",
       " \"Synset('pill.n.01')\",\n",
       " \"Synset('polster.n.01')\",\n",
       " \"Synset('osa.n.04')\",\n",
       " \"Synset('fenomen.n.01')\",\n",
       " \"Synset('läbikäik.n.01')\",\n",
       " \"Synset('pilt.n.01')\",\n",
       " \"Synset('kilp.n.01')\",\n",
       " \"Synset('käsitöökoda.n.01')\",\n",
       " \"Synset('teivas.n.01')\",\n",
       " \"Synset('kepp.n.01')\",\n",
       " \"Synset('toodang.n.02')\",\n",
       " \"Synset('töö.n.04')\",\n",
       " \"Synset('saavutus.n.01')\",\n",
       " \"Synset('rakk.n.01')\",\n",
       " \"Synset('kunstiteos.n.01')\",\n",
       " \"Synset('tee.n.03')\",\n",
       " \"Synset('plaat.n.01')\",\n",
       " \"Synset('laev.n.01')\",\n",
       " \"Synset('pood.n.01')\",\n",
       " \"Synset('riba.n.01')\",\n",
       " \"Synset('tugi.n.01')\",\n",
       " \"Synset('alus.n.02')\",\n",
       " \"Synset('laud.n.01')\",\n",
       " \"Synset('tööriist.n.01')\",\n",
       " \"Synset('tegu.n.02')\",\n",
       " \"Synset('toru.n.01')\",\n",
       " \"Synset('sõiduk.n.01')\",\n",
       " \"Synset('laev.n.02')\",\n",
       " \"Synset('relv.n.01')\",\n",
       " \"Synset('iseloomujoon.n.01')\",\n",
       " \"Synset('välimus.n.01')\",\n",
       " \"Synset('põhijoon.n.01')\",\n",
       " \"Synset('käitumine.n.01')\",\n",
       " \"Synset('omadus.n.01')\",\n",
       " \"Synset('viis.n.03')\",\n",
       " \"Synset('värv.n.01')\",\n",
       " \"Synset('distants.n.01')\",\n",
       " \"Synset('mõõde.n.01')\",\n",
       " \"Synset('aste.n.02')\",\n",
       " \"Synset('arv.n.01')\",\n",
       " \"Synset('väärtus.n.01')\",\n",
       " \"Synset('õigus.n.01')\",\n",
       " \"Synset('võimelisus.n.01')\",\n",
       " \"Synset('keha.n.02')\",\n",
       " \"Synset('nahk.n.01')\",\n",
       " \"Synset('kaotus.n.01')\",\n",
       " \"Synset('trakt.n.01')\",\n",
       " \"Synset('habe.n.01')\",\n",
       " \"Synset('kude.n.01')\",\n",
       " \"Synset('luu.n.01')\",\n",
       " \"Synset('muskel.n.01')\",\n",
       " \"Synset('organ.n.02')\",\n",
       " \"Synset('eritis.n.01')\",\n",
       " \"Synset('hormoon.n.01')\",\n",
       " \"Synset('veresoon.n.01')\",\n",
       " \"Synset('veen.n.01')\",\n",
       " \"Synset('eksitus.n.01')\",\n",
       " \"Synset('kile.n.01')\",\n",
       " \"Synset('võime.n.01')\",\n",
       " \"Synset('osavus.n.01')\",\n",
       " \"Synset('võimetus.n.01')\",\n",
       " \"Synset('meel.n.02')\",\n",
       " \"Synset('taju.n.01')\",\n",
       " \"Synset('meetod.n.02')\",\n",
       " \"Synset('süsteem.n.03')\",\n",
       " \"Synset('tunnetusprotsess.n.01')\",\n",
       " \"Synset('aisting.n.01')\",\n",
       " \"Synset('struktuur.n.01')\",\n",
       " \"Synset('korraldus.n.03')\",\n",
       " \"Synset('liigitamine.n.01')\",\n",
       " \"Synset('teadmised.n.01')\",\n",
       " \"Synset('idee.n.01')\",\n",
       " \"Synset('käsitus.n.01')\",\n",
       " \"Synset('tüüp.n.01')\",\n",
       " \"Synset('kogus.n.01')\",\n",
       " \"Synset('kava.n.01')\",\n",
       " \"Synset('õpetus.n.01')\",\n",
       " \"Synset('usk.n.01')\",\n",
       " \"Synset('siht.n.03')\",\n",
       " \"Synset('teooria.n.01')\",\n",
       " \"Synset('ainevaldkond.n.01')\",\n",
       " \"Synset('teadus.n.01')\",\n",
       " \"Synset('bioloogia.n.01')\",\n",
       " \"Synset('meditsiin.n.01')\",\n",
       " \"Synset('füüsika.n.01')\",\n",
       " \"Synset('hoiak.n.01')\",\n",
       " \"Synset('kalduvus.n.01')\",\n",
       " \"Synset('tõuge.n.01')\",\n",
       " \"Synset('suhtlus.n.02')\",\n",
       " \"Synset('teade.n.02')\",\n",
       " \"Synset('paberileht.n.01')\",\n",
       " \"Synset('keel.n.03')\",\n",
       " \"Synset('sõna.n.01')\",\n",
       " \"Synset('nimi.n.01')\",\n",
       " \"Synset('tiitel.n.01')\",\n",
       " \"Synset('kirjutis.n.01')\",\n",
       " \"Synset('luuletus.n.01')\",\n",
       " \"Synset('tekst.n.01')\",\n",
       " \"Synset('raamat.n.01')\",\n",
       " \"Synset('käsiraamat.n.01')\",\n",
       " \"Synset('nimekiri.n.02')\",\n",
       " \"Synset('arvutiprogramm.n.01')\",\n",
       " \"Synset('sõnum.n.01')\",\n",
       " \"Synset('näitamine.n.01')\",\n",
       " \"Synset('kiri.n.01')\",\n",
       " \"Synset('informatsioon.n.01')\",\n",
       " \"Synset('poliitika.n.01')\",\n",
       " \"Synset('avaldus.n.02')\",\n",
       " \"Synset('deklaratsioon.n.01')\",\n",
       " \"Synset('signaal.n.01')\",\n",
       " \"Synset('tundemärk.n.01')\",\n",
       " \"Synset('sümbol.n.01')\",\n",
       " \"Synset('tähis.n.01')\",\n",
       " \"Synset('täht.n.02')\",\n",
       " \"Synset('kirjatäht.n.01')\",\n",
       " \"Synset('embleem.n.01')\",\n",
       " \"Synset('kokkupuude.n.01')\",\n",
       " \"Synset('põhjus.n.01')\",\n",
       " \"Synset('keel.n.02')\",\n",
       " \"Synset('suhtlus.n.01')\",\n",
       " \"Synset('kompositsioon.n.01')\",\n",
       " \"Synset('laul.n.01')\",\n",
       " \"Synset('väljendusstiil.n.01')\",\n",
       " \"Synset('retooriline vahend.n.01')\",\n",
       " \"Synset('jutt.n.01')\",\n",
       " \"Synset('keel.n.01')\",\n",
       " \"Synset('hääl.n.02')\",\n",
       " \"Synset('käsk.n.01')\",\n",
       " \"Synset('palve.n.02')\",\n",
       " \"Synset('juhtum.n.01')\",\n",
       " \"Synset('muutus.n.01')\",\n",
       " \"Synset('halb õnn.n.01')\",\n",
       " \"Synset('liikumine.n.03')\",\n",
       " \"Synset('kasv.n.02')\",\n",
       " \"Synset('heli.n.01')\",\n",
       " \"Synset('võistlus.n.01')\",\n",
       " \"Synset('emotsioon.n.01')\",\n",
       " \"Synset('iha.n.01')\",\n",
       " \"Synset('nauding.n.01')\",\n",
       " \"Synset('tuju.n.01')\",\n",
       " \"Synset('toit.n.02')\",\n",
       " \"Synset('portsjon.n.01')\",\n",
       " \"Synset('toit.n.01')\",\n",
       " \"Synset('kondiitritoode.n.02')\",\n",
       " \"Synset('kompvek.n.01')\",\n",
       " \"Synset('magustoit.n.01')\",\n",
       " \"Synset('pagaritoode.n.01')\",\n",
       " \"Synset('kondiitritoode.n.01')\",\n",
       " \"Synset('kook.n.01')\",\n",
       " \"Synset('liha.n.01')\",\n",
       " \"Synset('jahutoode.n.01')\",\n",
       " \"Synset('söödav vili.n.01')\",\n",
       " \"Synset('köögivili.n.01')\",\n",
       " \"Synset('maitseaine.n.01')\",\n",
       " \"Synset('valik.n.01')\",\n",
       " \"Synset('kaste.n.01')\",\n",
       " \"Synset('piimatoode.n.01')\",\n",
       " \"Synset('juust.n.01')\",\n",
       " \"Synset('jook.n.01')\",\n",
       " \"Synset('vein.n.01')\",\n",
       " \"Synset('korraldus.n.01')\",\n",
       " \"Synset('inimkond.n.01')\",\n",
       " \"Synset('inimesed.n.01')\",\n",
       " \"Synset('kogu.n.02')\",\n",
       " \"Synset('kogu.n.01')\",\n",
       " \"Synset('komplekt.n.01')\",\n",
       " \"Synset('organisatsioon.n.01')\",\n",
       " \"Synset('ühing.n.01')\",\n",
       " \"Synset('valitsus.n.01')\",\n",
       " \"Synset('asutus.n.01')\",\n",
       " \"Synset('kirik.n.01')\",\n",
       " \"Synset('osakond.n.02')\",\n",
       " \"Synset('maa.n.04')\",\n",
       " \"Synset('kompanii.n.01')\",\n",
       " \"Synset('osakond.n.01')\",\n",
       " \"Synset('vahend.n.01')\",\n",
       " \"Synset('halduskogu.n.01')\",\n",
       " \"Synset('klubi.n.01')\",\n",
       " \"Synset('kool.n.01')\",\n",
       " \"Synset('komisjon.n.01')\",\n",
       " \"Synset('valitsusasutus.n.01')\",\n",
       " \"Synset('instituut.n.01')\",\n",
       " \"Synset('süsteem.n.01')\",\n",
       " \"Synset('liikumine.n.02')\",\n",
       " \"Synset('ala.n.04')\",\n",
       " \"Synset('külg.n.01')\",\n",
       " \"Synset('piir.n.01')\",\n",
       " \"Synset('linn.n.01')\",\n",
       " \"Synset('maa.n.03')\",\n",
       " \"Synset('piirkond.n.03')\",\n",
       " \"Synset('joon.n.02')\",\n",
       " \"Synset('punkt.n.02')\",\n",
       " \"Synset('osa.n.03')\",\n",
       " \"Synset('ala.n.02')\",\n",
       " \"Synset('maakond.n.01')\",\n",
       " \"Synset('pind.n.01')\",\n",
       " \"Synset('muutmine.n.01')\",\n",
       " \"Synset('maa-ala.n.01')\",\n",
       " \"Synset('suund.n.02')\",\n",
       " \"Synset('jääk.n.01')\",\n",
       " \"Synset('kate.n.01')\",\n",
       " \"Synset('kere.n.01')\",\n",
       " \"Synset('osa.n.02')\",\n",
       " \"Synset('kõrgendik.n.01')\",\n",
       " \"Synset('lohk.n.01')\",\n",
       " \"Synset('muutumine.n.01')\",\n",
       " \"Synset('sete.n.01')\",\n",
       " \"Synset('auk.n.01')\",\n",
       " \"Synset('taevakeha.n.01')\",\n",
       " \"Synset('vesi.n.01')\",\n",
       " \"Synset('maa.n.02')\",\n",
       " \"Synset('kujuteldav olend.n.01')\",\n",
       " \"Synset('jumalus.n.01')\",\n",
       " \"Synset('looja.n.01')\",\n",
       " \"Synset('üleminek.n.01')\",\n",
       " \"Synset('kaitsja.n.02')\",\n",
       " \"Synset('meelelahutuskunstnik.n.01')\",\n",
       " \"Synset('ekspert.n.01')\",\n",
       " \"Synset('naine.n.02')\",\n",
       " \"Synset('elanik.n.01')\",\n",
       " \"Synset('pärismaalane.n.01')\",\n",
       " \"Synset('intellektuaal.n.01')\",\n",
       " \"Synset('liider.n.01')\",\n",
       " \"Synset('mees.n.02')\",\n",
       " \"Synset('omataoline.n.01')\",\n",
       " \"Synset('usklik.n.01')\",\n",
       " \"Synset('õnnetu inimene.n.01')\",\n",
       " \"Synset('töötaja.n.01')\",\n",
       " \"Synset('eurooplane.n.01')\",\n",
       " \"Synset('tuttav.n.01')\",\n",
       " \"Synset('advokaat.n.01')\",\n",
       " \"Synset('kunstiinimene.n.01')\",\n",
       " \"Synset('assistent.n.01')\",\n",
       " \"Synset('atleet.n.01')\",\n",
       " \"Synset('laps.n.02')\",\n",
       " \"Synset('laps.n.01')\",\n",
       " \"Synset('kunstnik.n.01')\",\n",
       " \"Synset('pooldaja.n.01')\",\n",
       " \"Synset('arst.n.01')\",\n",
       " \"Synset('teenistuja.n.01')\",\n",
       " \"Synset('järelkäija.n.01')\",\n",
       " \"Synset('sõber.n.01')\",\n",
       " \"Synset('sugulane.n.01')\",\n",
       " \"Synset('poiss.n.01')\",\n",
       " \"Synset('tapmine.n.01')\",\n",
       " \"Synset('muusik.n.01')\",\n",
       " \"Synset('kantseleitöötaja.n.01')\",\n",
       " \"Synset('mõjujõud.n.01')\",\n",
       " \"Synset('esindaja.n.01')\",\n",
       " \"Synset('valitseja.n.01')\",\n",
       " \"Synset('sõdur.n.01')\",\n",
       " \"Synset('naine.n.01')\",\n",
       " \"Synset('kirjanik.n.01')\",\n",
       " \"Synset('looduslik fenomen.n.01')\",\n",
       " \"Synset('tagajärg.n.01')\",\n",
       " \"Synset('puhastamine.n.01')\",\n",
       " \"Synset('fortuuna.n.01')\",\n",
       " \"Synset('jõud.n.01')\",\n",
       " \"Synset('seen.n.01')\",\n",
       " \"Synset('puu.n.01')\",\n",
       " \"Synset('põõsas.n.01')\",\n",
       " \"Synset('vili.n.01')\",\n",
       " \"Synset('lehestik.n.01')\",\n",
       " \"Synset('omand.n.01')\",\n",
       " \"Synset('aktiva.n.01')\",\n",
       " \"Synset('rahahulk.n.01')\",\n",
       " \"Synset('raha.n.01')\",\n",
       " \"Synset('valuuta.n.01')\",\n",
       " \"Synset('münt.n.01')\",\n",
       " \"Synset('rahalised kohustused.n.01')\",\n",
       " \"Synset('dokument.n.01')\",\n",
       " \"Synset('register.n.01')\",\n",
       " \"Synset('protsess.n.01')\",\n",
       " \"Synset('areng.n.01')\",\n",
       " \"Synset('töötlemine.n.01')\",\n",
       " \"Synset('liikumine.n.01')\",\n",
       " \"Synset('ühik.n.01')\",\n",
       " \"Synset('arv.n.02')\",\n",
       " \"Synset('ruum.n.01')\",\n",
       " \"Synset('ühendus.n.01')\",\n",
       " \"Synset('osa.n.01')\",\n",
       " \"Synset('sugulus.n.01')\",\n",
       " \"Synset('suhe.n.03')\",\n",
       " \"Synset('suund.n.01')\",\n",
       " \"Synset('keha.n.01')\",\n",
       " \"Synset('kujund.n.01')\",\n",
       " \"Synset('reis.n.01')\",\n",
       " \"Synset('joon.n.01')\",\n",
       " \"Synset('olukord.n.02')\",\n",
       " \"Synset('seisund.n.02')\",\n",
       " \"Synset('situatsioon.n.01')\",\n",
       " \"Synset('suhe.n.02')\",\n",
       " \"Synset('suhe.n.01')\",\n",
       " \"Synset('staatus.n.02')\",\n",
       " \"Synset('ühiskondlik seisund.n.01')\",\n",
       " \"Synset('liigutus.n.01')\",\n",
       " \"Synset('üksmeel.n.01')\",\n",
       " \"Synset('korralagedus.n.01')\",\n",
       " \"Synset('haigus.n.02')\",\n",
       " \"Synset('tõbi.n.01')\",\n",
       " \"Synset('kasvaja.n.01')\",\n",
       " \"Synset('õli.n.01')\",\n",
       " \"Synset('taimehaigus.n.01')\",\n",
       " \"Synset('trauma.n.01')\",\n",
       " \"Synset('vaevus.n.01')\",\n",
       " \"Synset('põletik.n.01')\",\n",
       " \"Synset('vähendamine.n.01')\",\n",
       " \"Synset('vaimuhaigus.n.01')\",\n",
       " \"Synset('liit.n.01')\",\n",
       " \"Synset('ametiväärikus.n.01')\",\n",
       " \"Synset('puudus.n.02')\",\n",
       " \"Synset('puue.n.01')\",\n",
       " \"Synset('materjal.n.01')\",\n",
       " \"Synset('segu.n.01')\",\n",
       " \"Synset('sulam.n.01')\",\n",
       " \"Synset('hape.n.01')\",\n",
       " \"Synset('aatom.n.01')\",\n",
       " \"Synset('element.n.02')\",\n",
       " \"Synset('metalliline element.n.01')\",\n",
       " \"Synset('proteiin.n.01')\",\n",
       " \"Synset('reaktiiv.n.01')\",\n",
       " \"Synset('keemiline ühend.n.01')\",\n",
       " \"Synset('algaine.n.01')\",\n",
       " \"Synset('maapind.n.01')\",\n",
       " \"Synset('rasv.n.01')\",\n",
       " \"Synset('kasv.n.01')\",\n",
       " \"Synset('kiud.n.01')\",\n",
       " \"Synset('kütus.n.01')\",\n",
       " \"Synset('voolav aine.n.01')\",\n",
       " \"Synset('mineraal.n.01')\",\n",
       " \"Synset('paber.n.01')\",\n",
       " \"Synset('pulber.n.01')\",\n",
       " \"Synset('sool.n.01')\",\n",
       " \"Synset('mürk.n.01')\",\n",
       " \"Synset('tahke aine.n.01')\",\n",
       " \"Synset('puit.n.01')\",\n",
       " \"Synset('kellaaeg.n.01')\",\n",
       " \"Synset('päev.n.01')\",\n",
       " \"Synset('kuu.n.01')\",\n",
       " \"Synset('moment.n.01')\",\n",
       " \"Synset('tegevus.n.01')\",\n",
       " \"Synset('tava.n.01')\",\n",
       " \"Synset('mäng.n.01')\",\n",
       " \"Synset('loom.n.01')\",\n",
       " \"Synset('etendus.n.01')\",\n",
       " \"Synset('tants.n.01')\",\n",
       " \"Synset('muusika.n.01')\",\n",
       " \"Synset('manööver.n.02')\",\n",
       " \"Synset('mängujoonis.n.01')\",\n",
       " \"Synset('löök.n.01')\",\n",
       " \"Synset('taim.n.01')\",\n",
       " \"Synset('töö.n.02')\",\n",
       " \"Synset('tegevusala.n.01')\",\n",
       " \"Synset('töökoht.n.03')\",\n",
       " \"Synset('objekt.n.01')\",\n",
       " \"Synset('hool.n.01')\",\n",
       " \"Synset('ravi.n.01')\",\n",
       " \"Synset('töö.n.01')\",\n",
       " \"Synset('aine.n.01')\",\n",
       " \"Synset('tundma.v.01')\",\n",
       " \"Synset('tundmine.n.02')\",\n",
       " \"Synset('vedelik.n.01')\",\n",
       " \"Synset('pigment.n.01')\",\n",
       " \"Synset('rääkima.v.02')\",\n",
       " \"Synset('panema.v.01')\",\n",
       " \"Synset('panemine.n.02')\",\n",
       " \"Synset('olema.v.04')\",\n",
       " \"Synset('seadma.v.01')\",\n",
       " \"Synset('seadmine.n.03')\",\n",
       " \"Synset('esinema.v.02')\",\n",
       " \"Synset('esinemine.n.03')\",\n",
       " \"Synset('tegelema.v.01')\",\n",
       " \"Synset('tegelemine.n.02')\",\n",
       " \"Synset('käsitlema.v.01')\",\n",
       " \"Synset('käsitlemine.n.01')\",\n",
       " \"Synset('esitama.v.05')\",\n",
       " \"Synset('esitamine.n.02')\",\n",
       " \"Synset('uurima.v.01')\",\n",
       " \"Synset('uurimine.n.04')\",\n",
       " \"Synset('uurima.v.02')\",\n",
       " \"Synset('uurimine.n.05')\",\n",
       " \"Synset('seadma.v.02')\",\n",
       " \"Synset('seadmine.n.04')\",\n",
       " \"Synset('arranžeerima.v.01')\",\n",
       " \"Synset('arranžeerimine.n.01')\",\n",
       " \"Synset('ümber seadma.v.01')\",\n",
       " \"Synset('dramatiseerima.v.01')\",\n",
       " \"Synset('dramatiseerimine.n.01')\",\n",
       " \"Synset('ennistama.v.01')\",\n",
       " \"Synset('vestlema.v.01')\",\n",
       " \"Synset('vestlemine.n.01')\",\n",
       " \"Synset('elama.v.01')\",\n",
       " \"Synset('elamine.n.02')\",\n",
       " \"Synset('jooksma.v.02')\",\n",
       " \"Synset('jooksmine.n.02')\",\n",
       " \"Synset('minema.v.07')\",\n",
       " \"Synset('minemine.n.04')\",\n",
       " \"Synset('arenema.v.01')\",\n",
       " \"Synset('arenemine.n.03')\",\n",
       " \"Synset('minema.v.11')\",\n",
       " \"Synset('minemine.n.05')\",\n",
       " \"Synset('andma.v.01')\",\n",
       " \"Synset('andmine.n.04')\",\n",
       " \"Synset('andma.v.02')\",\n",
       " \"Synset('andmine.n.05')\",\n",
       " \"Synset('andma.v.05')\",\n",
       " \"Synset('andmine.n.06')\",\n",
       " \"Synset('hakkama.v.02')\",\n",
       " \"Synset('hakkamine.n.02')\",\n",
       " \"Synset('hakkama.v.03')\",\n",
       " \"Synset('hakkamine.n.03')\",\n",
       " \"Synset('tekkima.v.01')\",\n",
       " \"Synset('hakkama.v.05')\",\n",
       " \"Synset('muutma.v.02')\",\n",
       " \"Synset('muutmine.n.02')\",\n",
       " \"Synset('nägema.v.01')\",\n",
       " \"Synset('nägemine.n.04')\",\n",
       " \"Synset('leidma.v.02')\",\n",
       " \"Synset('leidmine.n.02')\",\n",
       " \"Synset('nägema.v.03')\",\n",
       " \"Synset('nägemine.n.05')\",\n",
       " \"Synset('algama.v.04')\",\n",
       " \"Synset('algamine.n.02')\",\n",
       " \"Synset('avama.v.01')\",\n",
       " \"Synset('avamine.n.02')\",\n",
       " \"Synset('kasutama.v.01')\",\n",
       " \"Synset('kasutamine.n.02')\",\n",
       " \"Synset('leidma.v.01')\",\n",
       " \"Synset('leidmine.n.03')\",\n",
       " \"Synset('otsima.v.01')\",\n",
       " \"Synset('otsimine.n.02')\",\n",
       " \"Synset('leidma.v.04')\",\n",
       " \"Synset('leidmine.n.04')\",\n",
       " \"Synset('leidma.v.05')\",\n",
       " \"Synset('leidmine.n.05')\",\n",
       " \"Synset('suutma.v.01')\",\n",
       " \"Synset('suutmine.n.01')\",\n",
       " \"Synset('kandma.v.01')\",\n",
       " \"Synset('kandmine.n.01')\",\n",
       " \"Synset('ajama.v.06')\",\n",
       " \"Synset('ajamine.n.01')\",\n",
       " \"Synset('ajama.v.07')\",\n",
       " \"Synset('ajamine.n.02')\",\n",
       " \"Synset('lõikama.v.01')\",\n",
       " \"Synset('lõikamine.n.02')\",\n",
       " \"Synset('hääldama.v.01')\",\n",
       " \"Synset('hääldamine.n.02')\",\n",
       " \"Synset('kuuluma.v.01')\",\n",
       " \"Synset('kuulumine.n.01')\",\n",
       " \"Synset('kuuluma.v.02')\",\n",
       " \"Synset('tekkima.v.03')\",\n",
       " \"Synset('tekkimine.n.03')\",\n",
       " \"Synset('koosnema.v.01')\",\n",
       " \"Synset('koosnemine.n.01')\",\n",
       " \"Synset('valmistama.v.02')\",\n",
       " \"Synset('valmistamine.n.03')\",\n",
       " \"Synset('valmistama.v.03')\",\n",
       " \"Synset('valmistamine.n.04')\",\n",
       " \"Synset('moodustama.v.02')\",\n",
       " \"Synset('moodustamine.n.02')\",\n",
       " \"Synset('moodustama.v.04')\",\n",
       " \"Synset('moodustamine.n.03')\",\n",
       " \"Synset('moodustama.v.05')\",\n",
       " \"Synset('moodustamine.n.04')\",\n",
       " \"Synset('osutama.v.02')\",\n",
       " \"Synset('osutamine.n.01')\",\n",
       " \"Synset('osutama.v.03')\",\n",
       " \"Synset('osutamine.n.02')\",\n",
       " \"Synset('esitama.v.04')\",\n",
       " \"Synset('esitamine.n.03')\",\n",
       " \"Synset('esitama.v.07')\",\n",
       " \"Synset('esitamine.n.04')\",\n",
       " \"Synset('esitama.v.06')\",\n",
       " \"Synset('esitamine.n.05')\",\n",
       " \"Synset('kasvatama.v.02')\",\n",
       " \"Synset('kasvatamine.n.03')\",\n",
       " \"Synset('kasvatama.v.05')\",\n",
       " \"Synset('kasvatamine.n.04')\",\n",
       " \"Synset('kasvatama.v.06')\",\n",
       " \"Synset('kasvatamine.n.05')\",\n",
       " \"Synset('elama.v.02')\",\n",
       " \"Synset('elamine.n.03')\",\n",
       " \"Synset('elama.v.03')\",\n",
       " \"Synset('elamine.n.04')\",\n",
       " \"Synset('elama.v.04')\",\n",
       " \"Synset('elamine.n.05')\",\n",
       " \"Synset('lähtuma.v.01')\",\n",
       " \"Synset('lähtumine.n.01')\",\n",
       " \"Synset('lähtuma.v.03')\",\n",
       " \"Synset('lähtumine.n.02')\",\n",
       " \"Synset('lähtuma.v.04')\",\n",
       " \"Synset('lähtumine.n.03')\",\n",
       " \"Synset('ümbritsema.v.01')\",\n",
       " \"Synset('ümbritsemine.n.01')\",\n",
       " \"Synset('ümbritsema.v.02')\",\n",
       " \"Synset('ümbritsemine.n.02')\",\n",
       " \"Synset('ümbritsema.v.03')\",\n",
       " \"Synset('ümbritsemine.n.03')\",\n",
       " \"Synset('tõmbama.v.02')\",\n",
       " \"Synset('tõmbamine.n.02')\",\n",
       " \"Synset('tõmbama.v.05')\",\n",
       " \"Synset('tõmbamine.n.03')\",\n",
       " \"Synset('kandma.v.02')\",\n",
       " \"Synset('kandmine.n.02')\",\n",
       " \"Synset('sallima.v.01')\",\n",
       " \"Synset('sallimine.n.01')\",\n",
       " \"Synset('kandma.v.05')\",\n",
       " \"Synset('kandmine.n.03')\",\n",
       " \"Synset('kandma.v.06')\",\n",
       " \"Synset('kandmine.n.04')\",\n",
       " \"Synset('kandma.v.07')\",\n",
       " \"Synset('kandmine.n.05')\",\n",
       " \"Synset('rõhutama.v.01')\",\n",
       " \"Synset('rõhutamine.n.02')\",\n",
       " \"Synset('rõhutama.v.02')\",\n",
       " \"Synset('rõhutamine.n.03')\",\n",
       " \"Synset('piirama.v.05')\",\n",
       " \"Synset('piiramine.n.03')\",\n",
       " \"Synset('piirama.v.06')\",\n",
       " \"Synset('piiramine.n.04')\",\n",
       " \"Synset('piirama.v.07')\",\n",
       " \"Synset('piiramine.n.05')\",\n",
       " \"Synset('tooma.v.01')\",\n",
       " \"Synset('toomine.n.01')\",\n",
       " \"Synset('kestma.v.02')\",\n",
       " \"Synset('kestmine.n.01')\",\n",
       " \"Synset('kestmine.n.02')\",\n",
       " \"Synset('tingima.v.01')\",\n",
       " \"Synset('tingimine.n.03')\",\n",
       " \"Synset('kuluma.v.04')\",\n",
       " \"Synset('kulumine.n.03')\",\n",
       " \"Synset('töötlema.v.01')\",\n",
       " \"Synset('töötlemine.n.02')\",\n",
       " \"Synset('töötlema.v.02')\",\n",
       " \"Synset('töötlemine.n.03')\",\n",
       " \"Synset('töötlema.v.03')\",\n",
       " \"Synset('töötlemine.n.04')\",\n",
       " \"Synset('kahjustama.v.01')\",\n",
       " \"Synset('kahjustamine.n.02')\",\n",
       " \"Synset('einestama.v.01')\",\n",
       " \"Synset('einestamine.n.01')\",\n",
       " \"Synset('märkima.v.02')\",\n",
       " \"Synset('märkimine.n.02')\",\n",
       " \"Synset('võimaldama.v.02')\",\n",
       " \"Synset('võimaldamine.n.02')\",\n",
       " \"Synset('võimaldama.v.03')\",\n",
       " \"Synset('võimaldamine.n.03')\",\n",
       " \"Synset('arenema.v.02')\",\n",
       " \"Synset('arenemine.n.04')\",\n",
       " \"Synset('kujunema.v.02')\",\n",
       " \"Synset('kujunemine.n.02')\",\n",
       " \"Synset('moodustuma.v.02')\",\n",
       " \"Synset('moodustumine.n.01')\",\n",
       " \"Synset('kaduma.v.06')\",\n",
       " \"Synset('kadumine.n.03')\",\n",
       " \"Synset('kaduma.v.10')\",\n",
       " \"Synset('kadumine.n.04')\",\n",
       " \"Synset('vedama.v.02')\",\n",
       " \"Synset('vedamine.n.04')\",\n",
       " \"Synset('ilmuma.v.02')\",\n",
       " \"Synset('ilmumine.n.02')\",\n",
       " \"Synset('ilmuma.v.03')\",\n",
       " \"Synset('ilmumine.n.03')\",\n",
       " \"Synset('ilmumine.n.04')\",\n",
       " \"Synset('lisama.v.02')\",\n",
       " \"Synset('lisamine.n.03')\",\n",
       " \"Synset('lisama.v.03')\",\n",
       " \"Synset('lisamine.n.04')\",\n",
       " \"Synset('koguma.v.01')\",\n",
       " \"Synset('kogumine.n.01')\",\n",
       " \"Synset('puuduma.v.01')\",\n",
       " \"Synset('puudumine.n.02')\",\n",
       " \"Synset('puuduma.v.02')\",\n",
       " \"Synset('puudumine.n.03')\",\n",
       " \"Synset('jooksma.v.04')\",\n",
       " \"Synset('jooksmine.n.03')\",\n",
       " \"Synset('rõhuma.v.01')\",\n",
       " \"Synset('rõhumine.n.01')\",\n",
       " \"Synset('rõhuma.v.03')\",\n",
       " \"Synset('rõhumine.n.02')\",\n",
       " \"Synset('takistama.v.01')\",\n",
       " \"Synset('takistamine.n.01')\",\n",
       " \"Synset('avama.v.02')\",\n",
       " \"Synset('avamine.n.03')\",\n",
       " \"Synset('sisaldama.v.01')\",\n",
       " \"Synset('sisaldamine.n.01')\",\n",
       " \"Synset('minema.v.01')\",\n",
       " \"Synset('minemine.n.06')\",\n",
       " \"Synset('asendit muutma.v.01')\",\n",
       " \"Synset('liigutamine.n.04')\",\n",
       " \"Synset('minema.v.04')\",\n",
       " \"Synset('minemine.n.07')\",\n",
       " \"Synset('jalutama.v.01')\",\n",
       " \"Synset('jalutamine.n.02')\",\n",
       " \"Synset('põrutama.v.01')\",\n",
       " \"Synset('põrutamine.n.01')\",\n",
       " \"Synset('purjetama.v.01')\",\n",
       " \"Synset('purjetamine.n.01')\",\n",
       " \"Synset('minema.v.03')\",\n",
       " \"Synset('minemine.n.08')\",\n",
       " \"Synset('suunduma.v.01')\",\n",
       " \"Synset('suundumine.n.01')\",\n",
       " \"Synset('eemalduma.v.01')\",\n",
       " \"Synset('eemaldumine.n.01')\",\n",
       " \"Synset('minema.v.05')\",\n",
       " \"Synset('minemine.n.09')\",\n",
       " \"Synset('lõppema.v.01')\",\n",
       " \"Synset('lõppemine.n.02')\",\n",
       " \"Synset('minema.v.06')\",\n",
       " \"Synset('minemine.n.10')\",\n",
       " \"Synset('vallanduma.v.01')\",\n",
       " \"Synset('vallandumine.n.01')\",\n",
       " \"Synset('minema.v.09')\",\n",
       " \"Synset('minemine.n.11')\",\n",
       " \"Synset('õnnestuma.v.01')\",\n",
       " \"Synset('õnnestumine.n.02')\",\n",
       " \"Synset('minema.v.10')\",\n",
       " \"Synset('minemine.n.12')\",\n",
       " \"Synset('sünnis olema.v.01')\",\n",
       " \"Synset('minema.v.12')\",\n",
       " \"Synset('minemine.n.13')\",\n",
       " \"Synset('minema.v.15')\",\n",
       " \"Synset('minemine.n.14')\",\n",
       " \"Synset('minema.v.16')\",\n",
       " \"Synset('minemine.n.15')\",\n",
       " \"Synset('olema.v.03')\",\n",
       " \"Synset('olemine.n.09')\",\n",
       " \"Synset('jääma.v.02')\",\n",
       " \"Synset('jäämine.n.04')\",\n",
       " \"Synset('jääma.v.03')\",\n",
       " \"Synset('jäämine.n.05')\",\n",
       " \"Synset('jääma.v.05')\",\n",
       " \"Synset('jäämine.n.06')\",\n",
       " \"Synset('annetama.v.01')\",\n",
       " \"Synset('annetamine.n.02')\",\n",
       " \"Synset('maksma.v.01')\",\n",
       " \"Synset('maksmine.n.03')\",\n",
       " \"Synset('laenama.v.01')\",\n",
       " \"Synset('laenamine.n.01')\",\n",
       " \"Synset('loobuma.v.01')\",\n",
       " \"Synset('loobumine.n.03')\",\n",
       " \"Synset('andma.v.03')\",\n",
       " \"Synset('andmine.n.08')\",\n",
       " \"Synset('saak.n.01')\",\n",
       " \"Synset('andma.v.06')\",\n",
       " \"Synset('andmine.n.09')\",\n",
       " \"Synset('andma.v.07')\",\n",
       " \"Synset('andmine.n.10')\",\n",
       " \"Synset('andma.v.08')\",\n",
       " \"Synset('andmine.n.11')\",\n",
       " \"Synset('andma.v.09')\",\n",
       " \"Synset('andmine.n.12')\",\n",
       " \"Synset('korraldama.v.03')\",\n",
       " \"Synset('korraldamine.n.06')\",\n",
       " \"Synset('andma.v.10')\",\n",
       " \"Synset('andmine.n.13')\",\n",
       " \"Synset('andma.v.11')\",\n",
       " \"Synset('andmine.n.14')\",\n",
       " \"Synset('andma.v.12')\",\n",
       " \"Synset('andmine.n.15')\",\n",
       " \"Synset('panema.v.10')\",\n",
       " \"Synset('panemine.n.05')\",\n",
       " ...]"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wn.all_synsets()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "which returns all the synsets there are or:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"Synset('veel.b.01')\",\n",
       " \"Synset('veel.b.02')\",\n",
       " \"Synset('veel.b.03')\",\n",
       " \"Synset('veel.b.05')\",\n",
       " \"Synset('veel.b.06')\",\n",
       " \"Synset('alles.b.01')\",\n",
       " \"Synset('alles.b.02')\",\n",
       " \"Synset('alles.b.03')\",\n",
       " \"Synset('alles.b.04')\",\n",
       " \"Synset('alles.b.05')\",\n",
       " \"Synset('juba.b.01')\",\n",
       " \"Synset('juba.b.02')\",\n",
       " \"Synset('juba.b.03')\",\n",
       " \"Synset('jälle.b.01')\",\n",
       " \"Synset('jälle.b.02')\",\n",
       " \"Synset('jälle.b.03')\",\n",
       " \"Synset('eile.b.01')\",\n",
       " \"Synset('eile.b.02')\",\n",
       " \"Synset('varem.b.01')\",\n",
       " \"Synset('varem.b.02')\",\n",
       " \"Synset('kohe.b.01')\",\n",
       " \"Synset('kohe.b.02')\",\n",
       " \"Synset('pärast.b.01')\",\n",
       " \"Synset('pärast.b.02')\",\n",
       " \"Synset('pärast.b.03')\",\n",
       " \"Synset('edaspidi.b.02')\",\n",
       " \"Synset('tagurpidi.b.01')\",\n",
       " \"Synset('tagurpidi.b.02')\",\n",
       " \"Synset('tagurpidi.b.03')\",\n",
       " \"Synset('järsku.b.01')\",\n",
       " \"Synset('järsku.b.02')\",\n",
       " \"Synset('kohe.b.03')\",\n",
       " \"Synset('kohe.b.04')\",\n",
       " \"Synset('pärale.b.03')\",\n",
       " \"Synset('kohale.b.01')\",\n",
       " \"Synset('kohale.b.02')\",\n",
       " \"Synset('enne.b.01')\",\n",
       " \"Synset('enne.b.02')\",\n",
       " \"Synset('enne.b.03')\",\n",
       " \"Synset('kõigepealt.b.01')\",\n",
       " \"Synset('enne.b.04')\",\n",
       " \"Synset('esmalt.b.02')\",\n",
       " \"Synset('eelnevalt.b.01')\",\n",
       " \"Synset('eelnevalt.b.02')\",\n",
       " \"Synset('eeskätt.b.01')\",\n",
       " \"Synset('eeskätt.b.02')\",\n",
       " \"Synset('esmajoones.b.01')\",\n",
       " \"Synset('esmajoones.b.02')\",\n",
       " \"Synset('eelkõige.b.01')\",\n",
       " \"Synset('eelkõige.b.02')\",\n",
       " \"Synset('eriti.b.01')\",\n",
       " \"Synset('hiljuti.b.01')\",\n",
       " \"Synset('ammu.b.01')\",\n",
       " \"Synset('ammu.b.02')\",\n",
       " \"Synset('ammu.b.03')\",\n",
       " \"Synset('ammuks.b.02')\",\n",
       " \"Synset('nüüd.b.01')\",\n",
       " \"Synset('nüüd.b.02')\",\n",
       " \"Synset('samuti.b.01')\",\n",
       " \"Synset('pealegi.b.03')\",\n",
       " \"Synset('muudkui.b.02')\",\n",
       " \"Synset('aina.b.02')\",\n",
       " \"Synset('aina.b.03')\",\n",
       " \"Synset('liiati.b.02')\",\n",
       " \"Synset('ainuüksi.b.02')\",\n",
       " \"Synset('ainult.b.03')\",\n",
       " \"Synset('järjest.b.02')\",\n",
       " \"Synset('järgemööda.b.02')\",\n",
       " \"Synset('ainult.b.04')\",\n",
       " \"Synset('alatasa.b.02')\",\n",
       " \"Synset('pidevalt.b.01')\",\n",
       " \"Synset('pidevalt.b.02')\",\n",
       " \"Synset('viimati.b.01')\",\n",
       " \"Synset('viivitamata.b.01')\",\n",
       " \"Synset('otsekohe.b.01')\",\n",
       " \"Synset('algul.b.01')\",\n",
       " \"Synset('algul.b.02')\",\n",
       " \"Synset('esiti.b.02')\",\n",
       " \"Synset('tegelikult.b.01')\",\n",
       " \"Synset('tegelikult.b.02')\",\n",
       " \"Synset('esiteks.b.01')\",\n",
       " \"Synset('esiteks.b.02')\",\n",
       " \"Synset('aga.b.02')\",\n",
       " \"Synset('aga.b.03')\",\n",
       " \"Synset('küll.b.02')\",\n",
       " \"Synset('küll.b.03')\",\n",
       " \"Synset('kindlasti.b.01')\",\n",
       " \"Synset('vähemalt.b.01')\",\n",
       " \"Synset('siiski.b.02')\",\n",
       " \"Synset('küll.b.04')\",\n",
       " \"Synset('küll.b.05')\",\n",
       " \"Synset('küll.b.06')\",\n",
       " \"Synset('ootamatult.b.01')\",\n",
       " \"Synset('kindlasti.b.02')\",\n",
       " \"Synset('tugevasti.b.01')\",\n",
       " \"Synset('kõvasti.b.01')\",\n",
       " \"Synset('valjult.b.01')\",\n",
       " \"Synset('kindlalt.b.02')\",\n",
       " \"Synset('vääramatult.b.01')\",\n",
       " \"Synset('vankumatult.b.01')\",\n",
       " \"Synset('kõigutamatult.b.01')\",\n",
       " \"Synset('vapralt.b.01')\",\n",
       " \"Synset('kindlalt.b.04')\",\n",
       " \"Synset('otse.b.02')\",\n",
       " \"Synset('otse.b.03')\",\n",
       " \"Synset('püstiselt.b.01')\",\n",
       " \"Synset('hiljem.b.01')\",\n",
       " \"Synset('pärast.b.04')\",\n",
       " \"Synset('pealegi.b.04')\",\n",
       " \"Synset('lihtsalt.b.01')\",\n",
       " \"Synset('lausa.b.02')\",\n",
       " \"Synset('otsekoheselt.b.01')\",\n",
       " \"Synset('avameelselt.b.01')\",\n",
       " \"Synset('siiralt.b.01')\",\n",
       " \"Synset('ometi.b.01')\",\n",
       " \"Synset('otse.b.05')\",\n",
       " \"Synset('otsejoones.b.04')\",\n",
       " \"Synset('nüüd.b.03')\",\n",
       " \"Synset('ometi.b.02')\",\n",
       " \"Synset('ometi.b.03')\",\n",
       " \"Synset('siis.b.02')\",\n",
       " \"Synset('ometi.b.04')\",\n",
       " \"Synset('otsekohe.b.02')\",\n",
       " \"Synset('otsekohe.b.03')\",\n",
       " \"Synset('otsekohe.b.04')\",\n",
       " \"Synset('otsekohe.b.05')\",\n",
       " \"Synset('otsekui.b.01')\",\n",
       " \"Synset('püsti.b.02')\",\n",
       " \"Synset('ülespoole.b.01')\",\n",
       " \"Synset('püsti.b.03')\",\n",
       " \"Synset('õigetpidi.b.01')\",\n",
       " \"Synset('püsti.b.04')\",\n",
       " \"Synset('uhkelt.b.01')\",\n",
       " \"Synset('püsti.b.05')\",\n",
       " \"Synset('püsti.b.06')\",\n",
       " \"Synset('püsti.b.07')\",\n",
       " \"Synset('õieli.b.01')\",\n",
       " \"Synset('püsti.b.08')\",\n",
       " \"Synset('väga.b.01')\",\n",
       " \"Synset('püstivarvukil.b.01')\",\n",
       " \"Synset('kikivarvul.b.01')\",\n",
       " \"Synset('kikivarvul.b.02')\",\n",
       " \"Synset('hiilivalt.b.01')\",\n",
       " \"Synset('salaja.b.01')\",\n",
       " \"Synset('vaikselt.b.01')\",\n",
       " \"Synset('püstijalu.b.01')\",\n",
       " \"Synset('püstijalu.b.02')\",\n",
       " \"Synset('täna.b.01')\",\n",
       " \"Synset('täna.b.02')\",\n",
       " \"Synset('praegu.b.02')\",\n",
       " \"Synset('praegu.b.01')\",\n",
       " \"Synset('hetketi.b.01')\",\n",
       " \"Synset('mõnikord.b.01')\",\n",
       " \"Synset('vahepeal.b.03')\",\n",
       " \"Synset('vahepeal.b.04')\",\n",
       " \"Synset('mõneti.b.01')\",\n",
       " \"Synset('kuidagi-viisi.b.01')\",\n",
       " \"Synset('aeg-ajalt.b.01')\",\n",
       " \"Synset('perioodiliselt.b.01')\",\n",
       " \"Synset('hetkeliselt.b.01')\",\n",
       " \"Synset('hetkeliselt.b.02')\",\n",
       " \"Synset('hetkelt.b.01')\",\n",
       " \"Synset('poolenisti.b.01')\",\n",
       " \"Synset('poolenisti.b.02')\",\n",
       " \"Synset('osaliselt.b.01')\",\n",
       " \"Synset('peaaegu.b.01')\",\n",
       " \"Synset('peaaegu.b.02')\",\n",
       " \"Synset('ligikaudu.b.01')\",\n",
       " \"Synset('enam-vähem.b.01')\",\n",
       " \"Synset('peaaegu.b.03')\",\n",
       " \"Synset('äärepealt.b.01')\",\n",
       " \"Synset('vaikselt.b.02')\",\n",
       " \"Synset('aeglaselt.b.01')\",\n",
       " \"Synset('aegamööda.b.01')\",\n",
       " \"Synset('aegamööda.b.02')\",\n",
       " \"Synset('aeglasevõitu.b.01')\",\n",
       " \"Synset('täpselt.b.02')\",\n",
       " \"Synset('perfektselt.b.01')\",\n",
       " \"Synset('täiesti.b.02')\",\n",
       " \"Synset('absoluutselt.b.02')\",\n",
       " \"Synset('üldse.b.02')\",\n",
       " \"Synset('täpselt.b.03')\",\n",
       " \"Synset('täpselt.b.04')\",\n",
       " \"Synset('arusaadavalt.b.01')\",\n",
       " \"Synset('arusaadavalt.b.02')\",\n",
       " \"Synset('loomulikult.b.01')\",\n",
       " \"Synset('nimelt.b.02')\",\n",
       " \"Synset('täpsemalt.b.02')\",\n",
       " \"Synset('nimelt.b.04')\",\n",
       " \"Synset('teadlikult.b.01')\",\n",
       " \"Synset('sihilikult.b.01')\",\n",
       " \"Synset('meelega.b.01')\",\n",
       " \"Synset('sendipealt.b.01')\",\n",
       " \"Synset('loomulikult.b.02')\",\n",
       " \"Synset('loomulikult.b.03')\",\n",
       " \"Synset('üsna.b.01')\",\n",
       " \"Synset('võrdlemisi.b.01')\",\n",
       " \"Synset('täpselt.b.06')\",\n",
       " \"Synset('täpselt.b.07')\",\n",
       " \"Synset('parasjagu.b.02')\",\n",
       " \"Synset('parasjagu.b.04')\",\n",
       " \"Synset('mõõdukalt.b.01')\",\n",
       " \"Synset('liialdamatult.b.01')\",\n",
       " \"Synset('liialdamata.b.02')\",\n",
       " \"Synset('liialdatult.b.01')\",\n",
       " \"Synset('liialdatult.b.02')\",\n",
       " \"Synset('piisavalt.b.01')\",\n",
       " \"Synset('küllaldaselt.b.01')\",\n",
       " \"Synset('homme.b.01')\",\n",
       " \"Synset('hommepäev.b.01')\",\n",
       " \"Synset('hommepäev.b.02')\",\n",
       " \"Synset('varsti.b.01')\",\n",
       " \"Synset('peagi.b.01')\",\n",
       " \"Synset('homme.b.02')\",\n",
       " \"Synset('ülehomme.b.01')\",\n",
       " \"Synset('päev-päevalt.b.01')\",\n",
       " \"Synset('päev päeva järel.b.01')\",\n",
       " \"Synset('alati.b.01')\",\n",
       " \"Synset('alati.b.02')\",\n",
       " \"Synset('ikka.b.02')\",\n",
       " \"Synset('alati.b.04')\",\n",
       " \"Synset('igavesti.b.01')\",\n",
       " \"Synset('alati.b.05')\",\n",
       " \"Synset('jäädavalt.b.01')\",\n",
       " \"Synset('jäägitult.b.01')\",\n",
       " \"Synset('sageli.b.01')\",\n",
       " \"Synset('alatihti.b.01')\",\n",
       " \"Synset('pidevalt.b.03')\",\n",
       " \"Synset('pahatihti.b.01')\",\n",
       " \"Synset('ilma.b.01')\",\n",
       " \"Synset('ilma.b.02')\",\n",
       " \"Synset('iial.b.01')\",\n",
       " \"Synset('eal.b.01')\",\n",
       " \"Synset('ilmaasjata.b.01')\",\n",
       " \"Synset('asjatult.b.01')\",\n",
       " \"Synset('kasutult.b.01')\",\n",
       " \"Synset('niisama.b.04')\",\n",
       " \"Synset('kergesti.b.01')\",\n",
       " \"Synset('naljalt.b.01')\",\n",
       " \"Synset('pealegi.b.02')\",\n",
       " \"Synset('tasuta.b.01')\",\n",
       " \"Synset('samuti.b.02')\",\n",
       " \"Synset('sarnaselt.b.01')\",\n",
       " \"Synset('naljaviluks.b.01')\",\n",
       " \"Synset('naljatamisi.b.01')\",\n",
       " \"Synset('ajaliselt.b.01')\",\n",
       " \"Synset('varakult.b.01')\",\n",
       " \"Synset('aegsasti.b.01')\",\n",
       " \"Synset('kunagi.b.02')\",\n",
       " \"Synset('ikka ja jälle.b.01')\",\n",
       " \"Synset('ammu.b.04')\",\n",
       " \"Synset('kaua.b.01')\",\n",
       " \"Synset('igavesti.b.02')\",\n",
       " \"Synset('igavesti.b.03')\",\n",
       " \"Synset('alalõpmata.b.01')\",\n",
       " \"Synset('igavesti.b.04')\",\n",
       " \"Synset('tohutult.b.01')\",\n",
       " \"Synset('igaviisi.b.01')\",\n",
       " \"Synset('igati.b.02')\",\n",
       " \"Synset('üüratult.b.01')\",\n",
       " \"Synset('lähemal.b.01')\",\n",
       " \"Synset('ligemal.b.01')\",\n",
       " \"Synset('lähemalt.b.01')\",\n",
       " \"Synset('üksikasjalikumalt.b.01')\",\n",
       " \"Synset('ligemalt.b.01')\",\n",
       " \"Synset('täpsemalt.b.03')\",\n",
       " \"Synset('lähemalt.b.02')\",\n",
       " \"Synset('lähemale.b.01')\",\n",
       " \"Synset('lähemale.b.02')\",\n",
       " \"Synset('kaugemal.b.01')\",\n",
       " \"Synset('kaugemal.b.02')\",\n",
       " \"Synset('lähemal.b.02')\",\n",
       " \"Synset('peamiselt.b.01')\",\n",
       " \"Synset('põhiliselt.b.01')\",\n",
       " \"Synset('põhiliselt.b.02')\",\n",
       " \"Synset('peaasjalikult.b.02')\",\n",
       " \"Synset('enamasti.b.01')\",\n",
       " \"Synset('tavaliselt.b.01')\",\n",
       " \"Synset('peamiselt.b.02')\",\n",
       " \"Synset('tavaliselt.b.02')\",\n",
       " \"Synset('normaalselt.b.01')\",\n",
       " \"Synset('standardselt.b.01')\",\n",
       " \"Synset('tavaliselt.b.03')\",\n",
       " \"Synset('korrapäraselt.b.01')\",\n",
       " \"Synset('üldiselt.b.01')\",\n",
       " \"Synset('korrapäraselt.b.02')\",\n",
       " \"Synset('korralikult.b.01')\",\n",
       " \"Synset('korratult.b.01')\",\n",
       " \"Synset('korrektselt.b.01')\",\n",
       " \"Synset('ilusasti.b.01')\",\n",
       " \"Synset('ilusasti.b.02')\",\n",
       " \"Synset('õigesti.b.01')\",\n",
       " \"Synset('korrektselt.b.02')\",\n",
       " \"Synset('puhtalt.b.01')\",\n",
       " \"Synset('puhtalt.b.02')\",\n",
       " \"Synset('kohati.b.01')\",\n",
       " \"Synset('tükati.b.01')\",\n",
       " \"Synset('laiguti.b.01')\",\n",
       " \"Synset('kohati.b.02')\",\n",
       " \"Synset('kohati.b.03')\",\n",
       " \"Synset('osalt.b.02')\",\n",
       " \"Synset('kohkumisi.b.01')\",\n",
       " \"Synset('hirmunult.b.01')\",\n",
       " \"Synset('hirmukahkvel.b.01')\",\n",
       " \"Synset('aastati.b.01')\",\n",
       " \"Synset('kunagi.b.03')\",\n",
       " \"Synset('vähehaaval.b.01')\",\n",
       " \"Synset('aja jooksul.b.01')\",\n",
       " \"Synset('lõpuks.b.01')\",\n",
       " \"Synset('viimaks.b.01')\",\n",
       " \"Synset('lõpuks.b.02')\",\n",
       " \"Synset('päriselt.b.01')\",\n",
       " \"Synset('päriselt.b.02')\",\n",
       " \"Synset('päriselt.b.04')\",\n",
       " \"Synset('päriseks.b.02')\",\n",
       " \"Synset('aineti.b.01')\",\n",
       " \"Synset('ainiti.b.01')\",\n",
       " \"Synset('ainiti.b.02')\",\n",
       " \"Synset('kikikõrvu.b.01')\",\n",
       " \"Synset('kikikõrvu.b.02')\",\n",
       " \"Synset('ainuüksi.b.03')\",\n",
       " \"Synset('aiva.b.01')\",\n",
       " \"Synset('samaaegselt.b.01')\",\n",
       " \"Synset('alal.b.01')\",\n",
       " \"Synset('alaliselt.b.01')\",\n",
       " \"Synset('püsivalt.b.01')\",\n",
       " \"Synset('katkematult.b.01')\",\n",
       " \"Synset('lõpmatuseni.b.01')\",\n",
       " \"Synset('alamal.b.01')\",\n",
       " \"Synset('allpool.b.01')\",\n",
       " \"Synset('allpool.b.02')\",\n",
       " \"Synset('edaspidi.b.03')\",\n",
       " \"Synset('järgnevalt.b.01')\",\n",
       " \"Synset('anuvalt.b.01')\",\n",
       " \"Synset('paluvalt.b.01')\",\n",
       " \"Synset('aplamisi.b.01')\",\n",
       " \"Synset('ahnesti.b.01')\",\n",
       " \"Synset('küpsiküüsi.b.01')\",\n",
       " \"Synset('nobedasti.b.01')\",\n",
       " \"Synset('väledasti.b.01')\",\n",
       " \"Synset('vilkalt.b.01')\",\n",
       " \"Synset('silmapilkselt.b.01')\",\n",
       " \"Synset('momentaanselt.b.01')\",\n",
       " \"Synset('samas.b.01')\",\n",
       " \"Synset('ülikiiresti.b.01')\",\n",
       " \"Synset('armetult.b.01')\",\n",
       " \"Synset('viletsalt.b.01')\",\n",
       " \"Synset('armetult.b.02')\",\n",
       " \"Synset('armetult.b.03')\",\n",
       " \"Synset('haletsusväärselt.b.01')\",\n",
       " \"Synset('õnnetult.b.01')\",\n",
       " \"Synset('kehvasti.b.01')\",\n",
       " \"Synset('halvasti.b.01')\",\n",
       " \"Synset('arutult.b.01')\",\n",
       " \"Synset('ebaharilikult.b.01')\",\n",
       " \"Synset('ennekuulmatult.b.01')\",\n",
       " \"Synset('ennenägematult.b.01')\",\n",
       " \"Synset('piiskhaaval.b.01')\",\n",
       " \"Synset('vähehaaval.b.02')\",\n",
       " \"Synset('terahaaval.b.01')\",\n",
       " \"Synset('kildhaaval.b.01')\",\n",
       " \"Synset('vähehaaval.b.03')\",\n",
       " \"Synset('sammhaaval.b.01')\",\n",
       " \"Synset('tollhaaval.b.01')\",\n",
       " \"Synset('tasapisi.b.01')\",\n",
       " \"Synset('lühidalt.b.01')\",\n",
       " \"Synset('kokkuvõtlikult.b.01')\",\n",
       " \"Synset('lakooniliselt.b.01')\",\n",
       " \"Synset('napisõnaliselt.b.01')\",\n",
       " \"Synset('tänavu.b.01')\",\n",
       " \"Synset('eks.b.01')\",\n",
       " \"Synset('eks.b.02')\",\n",
       " \"Synset('eksprompt.b.01')\",\n",
       " \"Synset('ekstra.b.01')\",\n",
       " \"Synset('eraldi.b.02')\",\n",
       " \"Synset('eriliselt.b.02')\",\n",
       " \"Synset('eraldi.b.01')\",\n",
       " \"Synset('ärevil.b.01')\",\n",
       " \"Synset('erutatult.b.01')\",\n",
       " \"Synset('murelikult.b.01')\",\n",
       " \"Synset('esialgselt.b.01')\",\n",
       " \"Synset('esialgu.b.02')\",\n",
       " \"Synset('esimese hooga.b.01')\",\n",
       " \"Synset('kõigepealt.b.02')\",\n",
       " \"Synset('kogemata.b.01')\",\n",
       " \"Synset('arupidavalt.b.01')\",\n",
       " \"Synset('kaaluvalt.b.01')\",\n",
       " \"Synset('järelemõtlevalt.b.01')\",\n",
       " \"Synset('kaalutletult.b.01')\",\n",
       " \"Synset('mõistlikult.b.01')\",\n",
       " \"Synset('arutult.b.02')\",\n",
       " \"Synset('inimese moodi.b.01')\",\n",
       " \"Synset('rumalalt.b.01')\",\n",
       " \"Synset('totralt.b.01')\",\n",
       " \"Synset('ogaralt.b.01')\",\n",
       " \"Synset('erksalt.b.01')\",\n",
       " \"Synset('vilkalt.b.02')\",\n",
       " \"Synset('reipalt.b.01')\",\n",
       " \"Synset('virgelt.b.01')\",\n",
       " \"Synset('haigevõitu.b.01')\",\n",
       " \"Synset('hajakil.b.01')\",\n",
       " \"Synset('hajali.b.01')\",\n",
       " \"Synset('hajali.b.02')\",\n",
       " \"Synset('hajameelselt.b.01')\",\n",
       " \"Synset('hõredalt.b.01')\",\n",
       " \"Synset('laialipillatult.b.01')\",\n",
       " \"Synset('tihedalt.b.01')\",\n",
       " \"Synset('sporaadiliselt.b.01')\",\n",
       " \"Synset('harva.b.01')\",\n",
       " \"Synset('haruharva.b.01')\",\n",
       " \"Synset('harvavõitu.b.01')\",\n",
       " \"Synset('hõredavõitu.b.01')\",\n",
       " \"Synset('harvem.b.01')\",\n",
       " \"Synset('tihedalt.b.02')\",\n",
       " \"Synset('kokkusurutult.b.02')\",\n",
       " \"Synset('hasartselt.b.01')\",\n",
       " \"Synset('innukalt.b.01')\",\n",
       " \"Synset('entusiastlikult.b.01')\",\n",
       " \"Synset('vaimustunult.b.01')\",\n",
       " \"Synset('agaralt.b.01')\",\n",
       " \"Synset('heakskiitvalt.b.01')\",\n",
       " \"Synset('tuliselt.b.01')\",\n",
       " \"Synset('tuhinal.b.01')\",\n",
       " \"Synset('ahinal.b.01')\",\n",
       " \"Synset('temperamentselt.b.01')\",\n",
       " \"Synset('kiretult.b.01')\",\n",
       " \"Synset('tundeliselt.b.01')\",\n",
       " \"Synset('jaatavalt.b.01')\",\n",
       " \"Synset('jaatavalt.b.02')\",\n",
       " \"Synset('eitavalt.b.01')\",\n",
       " \"Synset('eitavalt.b.02')\",\n",
       " \"Synset('hukkamõistvalt.b.01')\",\n",
       " \"Synset('laitvalt.b.01')\",\n",
       " \"Synset('laiuti.b.01')\",\n",
       " \"Synset('laitmatult.b.01')\",\n",
       " \"Synset('laksti.b.01')\",\n",
       " \"Synset('lamaskil.b.01')\",\n",
       " \"Synset('lamaskile.b.01')\",\n",
       " \"Synset('pikali.b.01')\",\n",
       " \"Synset('pikali.b.02')\",\n",
       " \"Synset('maha.b.01')\",\n",
       " \"Synset('pikali.b.03')\",\n",
       " \"Synset('maha.b.02')\",\n",
       " \"Synset('allapoole.b.01')\",\n",
       " \"Synset('madalamale.b.01')\",\n",
       " \"Synset('alla.b.01')\",\n",
       " \"Synset('maha.b.03')\",\n",
       " \"Synset('allapoole.b.02')\",\n",
       " \"Synset('ülespoole.b.02')\",\n",
       " \"Synset('alaspidi.b.01')\",\n",
       " \"Synset('alaspäi.b.01')\",\n",
       " \"Synset('madalale.b.02')\",\n",
       " \"Synset('madalale.b.03')\",\n",
       " \"Synset('maha.b.04')\",\n",
       " \"Synset('alasti.b.01')\",\n",
       " \"Synset('alasti.b.02')\",\n",
       " \"Synset('alasti.b.03')\",\n",
       " \"Synset('allatuult.b.01')\",\n",
       " \"Synset('vastutuult.b.01')\",\n",
       " \"Synset('ülesmäge.b.01')\",\n",
       " \"Synset('allamäge.b.01')\",\n",
       " \"Synset('allamäge.b.02')\",\n",
       " \"Synset('ülesmäge.b.02')\",\n",
       " \"Synset('allavoolu.b.01')\",\n",
       " \"Synset('allajõge.b.01')\",\n",
       " \"Synset('vastuvoolu.b.01')\",\n",
       " \"Synset('allpool.b.03')\",\n",
       " \"Synset('küüsitsi.b.01')\",\n",
       " \"Synset('laatsakil.b.01')\",\n",
       " \"Synset('laatsakile.b.01')\",\n",
       " \"Synset('lösakil.b.01')\",\n",
       " \"Synset('lösakile.b.01')\",\n",
       " \"Synset('röötsakil.b.01')\",\n",
       " \"Synset('lääbakil.b.01')\",\n",
       " \"Synset('viltu.b.01')\",\n",
       " \"Synset('upakil.b.01')\",\n",
       " \"Synset('viltu.b.02')\",\n",
       " \"Synset('kaldu.b.01')\",\n",
       " \"Synset('kaldu.b.02')\",\n",
       " \"Synset('kreenis.b.01')\",\n",
       " \"Synset('kreeni.b.01')\",\n",
       " \"Synset('längakil.b.01')\",\n",
       " \"Synset('längakile.b.01')\",\n",
       " \"Synset('längamisi.b.01')\",\n",
       " \"Synset('kiivas.b.01')\",\n",
       " \"Synset('kiiva.b.01')\",\n",
       " \"Synset('kiiva.b.02')\",\n",
       " \"Synset('kiiva.b.03')\",\n",
       " \"Synset('kaardu.b.01')\",\n",
       " \"Synset('kõõrdi.b.02')\",\n",
       " \"Synset('kõõrdi.b.03')\",\n",
       " \"Synset('kõõrdi.b.04')\",\n",
       " \"Synset('kõõrdis.b.01')\",\n",
       " \"Synset('käekõrvalt.b.01')\",\n",
       " \"Synset('käekõrvale.b.01')\",\n",
       " \"Synset('käsikäes.b.01')\",\n",
       " \"Synset('käsikäes.b.02')\",\n",
       " \"Synset('sõbralikult.b.01')\",\n",
       " \"Synset('käsitsi.b.01')\",\n",
       " \"Synset('käsitsi.b.02')\",\n",
       " \"Synset('käsipuusakil.b.01')\",\n",
       " \"Synset('käsipõsakil.b.01')\",\n",
       " \"Synset('käsipuusakile.b.01')\",\n",
       " \"Synset('käsipõsakile.b.01')\",\n",
       " \"Synset('kätte.b.01')\",\n",
       " \"Synset('kätte.b.02')\",\n",
       " \"Synset('kätte.b.03')\",\n",
       " \"Synset('kätte.b.04')\",\n",
       " \"Synset('kätte.b.05')\",\n",
       " \"Synset('kätte.b.06')\",\n",
       " \"Synset('kätte.b.07')\",\n",
       " \"Synset('käuhti.b.01')\",\n",
       " \"Synset('käuksti.b.01')\",\n",
       " \"Synset('täiendavalt.b.01')\",\n",
       " \"Synset('pealekauba.b.02')\",\n",
       " \"Synset('pealekuti.b.01')\",\n",
       " \"Synset('ülestikku.b.01')\",\n",
       " \"Synset('kohakuti.b.01')\",\n",
       " \"Synset('vastamisi.b.01')\",\n",
       " \"Synset('silmitsi.b.01')\",\n",
       " \"Synset('seljakuti.b.01')\",\n",
       " \"Synset('selili.b.01')\",\n",
       " \"Synset('selili.b.02')\",\n",
       " \"Synset('kohaselt.b.01')\",\n",
       " \"Synset('kohaselt.b.02')\",\n",
       " \"Synset('kohaselt.b.03')\",\n",
       " \"Synset('sobivalt.b.02')\",\n",
       " \"Synset('kõlblikult.b.01')\",\n",
       " \"Synset('sündsalt.b.01')\",\n",
       " \"Synset('kohatult.b.01')\",\n",
       " \"Synset('võimekalt.b.01')\",\n",
       " \"Synset('kombe.b.01')\",\n",
       " \"Synset('jutti.b.02')\",\n",
       " \"Synset('järsult.b.01')\",\n",
       " \"Synset('järsku.b.04')\",\n",
       " \"Synset('kibestunult.b.01')\",\n",
       " \"Synset('mürgiselt.b.01')\",\n",
       " \"Synset('leebelt.b.01')\",\n",
       " \"Synset('lehthaaval.b.01')\",\n",
       " \"Synset('lehvikjalt.b.01')\",\n",
       " \"Synset('leigelt.b.01')\",\n",
       " \"Synset('jahedalt.b.01')\",\n",
       " \"Synset('ametlikult.b.01')\",\n",
       " \"Synset('jahedavõitu.b.01')\",\n",
       " \"Synset('ametlikult.b.02')\",\n",
       " \"Synset('mitteametlikult.b.01')\",\n",
       " \"Synset('mitutpidi.b.01')\",\n",
       " \"Synset('molukil.b.01')\",\n",
       " \"Synset('monarhistlikult.b.01')\",\n",
       " \"Synset('monotoonselt.b.01')\",\n",
       " \"Synset('mornilt.b.01')\",\n",
       " \"Synset('tusaselt.b.01')\",\n",
       " \"Synset('süngelt.b.01')\",\n",
       " \"Synset('masendavalt.b.01')\",\n",
       " \"Synset('masendavalt.b.02')\",\n",
       " \"Synset('kurvameelselt.b.01')\",\n",
       " \"Synset('rõõmsameelselt.b.01')\",\n",
       " \"Synset('nukrameelselt.b.01')\",\n",
       " \"Synset('meeleldi.b.01')\",\n",
       " \"Synset('kurblikult.b.01')\",\n",
       " \"Synset('mahlakalt.b.01')\",\n",
       " \"Synset('huvitavalt.b.01')\",\n",
       " \"Synset('igavalt.b.01')\",\n",
       " \"Synset('üksluiselt.b.01')\",\n",
       " \"Synset('murdeti.b.01')\",\n",
       " \"Synset('muretult.b.01')\",\n",
       " \"Synset('rahulikult.b.01')\",\n",
       " \"Synset('rahutult.b.01')\",\n",
       " \"Synset('rahulikult.b.02')\",\n",
       " \"Synset('rahulikult.b.03')\",\n",
       " \"Synset('rahulikult.b.04')\",\n",
       " \"Synset('rahulikult.b.05')\",\n",
       " \"Synset('vaoshoitult.b.01')\",\n",
       " \"Synset('rahustavalt.b.01')\",\n",
       " \"Synset('kärsitult.b.01')\",\n",
       " \"Synset('rahvuseti.b.01')\",\n",
       " \"Synset('rajuvil.b.01')\",\n",
       " \"Synset('rakkes.b.01')\",\n",
       " \"Synset('rakkus.b.01')\",\n",
       " \"Synset('raksti.b.01')\",\n",
       " \"Synset('raksu.b.01')\",\n",
       " \"Synset('raksupealt.b.01')\",\n",
       " \"Synset('raskelt.b.02')\",\n",
       " \"Synset('raskelt.b.03')\",\n",
       " \"Synset('nässu.b.01')\",\n",
       " \"Synset('katki.b.01')\",\n",
       " \"Synset('katki.b.02')\",\n",
       " \"Synset('katki.b.03')\",\n",
       " \"Synset('katki.b.04')\",\n",
       " \"Synset('katki.b.05')\",\n",
       " \"Synset('halvasti.b.02')\",\n",
       " \"Synset('korras.b.01')\",\n",
       " \"Synset('hästi.b.02')\",\n",
       " \"Synset('üdini.b.01')\",\n",
       " \"Synset('sügavalt.b.01')\",\n",
       " \"Synset('üle kere.b.01')\",\n",
       " \"Synset('näruselt.b.01')\",\n",
       " \"Synset('nigerlikult.b.01')\",\n",
       " \"Synset('näruselt.b.02')\",\n",
       " \"Synset('kõrgel.b.01')\",\n",
       " \"Synset('madalal.b.01')\",\n",
       " \"Synset('kõrgel.b.02')\",\n",
       " \"Synset('madalal.b.02')\",\n",
       " \"Synset('kõrgel.b.03')\",\n",
       " \"Synset('madalal.b.03')\",\n",
       " \"Synset('madalalt.b.01')\",\n",
       " \"Synset('madalalt.b.02')\",\n",
       " \"Synset('kõrgelt.b.01')\",\n",
       " \"Synset('sügavalt.b.02')\",\n",
       " \"Synset('madalalt.b.03')\",\n",
       " \"Synset('kõrgelt.b.02')\",\n",
       " \"Synset('madalalt.b.04')\",\n",
       " \"Synset('kõrgelt.b.03')\",\n",
       " \"Synset('heledalt.b.01')\",\n",
       " \"Synset('peenikeselt.b.01')\",\n",
       " \"Synset('kõrgelt.b.04')\",\n",
       " \"Synset('rohkesti.b.01')\",\n",
       " \"Synset('silmapaistvalt.b.01')\",\n",
       " \"Synset('rikkalikult.b.01')\",\n",
       " \"Synset('arvukalt.b.01')\",\n",
       " \"Synset('palju.b.01')\",\n",
       " \"Synset('vähe.b.01')\",\n",
       " \"Synset('vähevõitu.b.01')\",\n",
       " \"Synset('kõrgelt.b.05')\",\n",
       " \"Synset('arvuliselt.b.01')\",\n",
       " \"Synset('vaevu.b.01')\",\n",
       " \"Synset('põgusalt.b.01')\",\n",
       " \"Synset('kergelt.b.01')\",\n",
       " \"Synset('vaevu.b.02')\",\n",
       " \"Synset('põgusalt.b.02')\",\n",
       " \"Synset('korraks.b.01')\",\n",
       " \"Synset('põgusalt.b.03')\",\n",
       " \"Synset('korraks.b.02')\",\n",
       " \"Synset('korraga.b.03')\",\n",
       " \"Synset('kergakil.b.01')\",\n",
       " \"Synset('kergelt.b.03')\",\n",
       " \"Synset('veidi.b.01')\",\n",
       " \"Synset('raasuke.b.01')\",\n",
       " \"Synset('tsipake.b.01')\",\n",
       " \"Synset('palju.b.02')\",\n",
       " \"Synset('kergelt.b.04')\",\n",
       " \"Synset('sujuvalt.b.02')\",\n",
       " \"Synset('ladusalt.b.01')\",\n",
       " \"Synset('kergelt.b.05')\",\n",
       " \"Synset('õhukeselt.b.01')\",\n",
       " \"Synset('nattipidi.b.01')\",\n",
       " \"Synset('karvupidi.b.01')\",\n",
       " \"Synset('natukesehaaval.b.01')\",\n",
       " \"Synset('tasapisi.b.03')\",\n",
       " \"Synset('sosinal.b.01')\",\n",
       " \"Synset('valjuhäälselt.b.01')\",\n",
       " \"Synset('kuuldavalt.b.01')\",\n",
       " \"Synset('rangelt.b.01')\",\n",
       " \"Synset('rangelt.b.02')\",\n",
       " \"Synset('kurjalt.b.01')\",\n",
       " \"Synset('nõudlikult.b.01')\",\n",
       " \"Synset('vihaselt.b.01')\",\n",
       " \"Synset('kurjalt.b.02')\",\n",
       " \"Synset('kurjalt.b.03')\",\n",
       " \"Synset('nõudlikult.b.02')\",\n",
       " \"Synset('pirtsakalt.b.01')\",\n",
       " \"Synset('valivalt.b.01')\",\n",
       " \"Synset('kapriisselt.b.01')\",\n",
       " \"Synset('kiivalt.b.01')\",\n",
       " \"Synset('kiivalt.b.02')\",\n",
       " \"Synset('armukadedalt.b.01')\",\n",
       " \"Synset('hoolega.b.01')\",\n",
       " \"Synset('hooletult.b.01')\",\n",
       " \"Synset('lohakavõitu.b.01')\",\n",
       " \"Synset('ettevaatamatult.b.01')\",\n",
       " \"Synset('hooletult.b.02')\",\n",
       " \"Synset('ettevaatlikult.b.01')\",\n",
       " \"Synset('ülepeakaela.b.01')\",\n",
       " \"Synset('ligadi-logadi.b.01')\",\n",
       " \"Synset('etteotsa.b.01')\",\n",
       " \"Synset('ettepoole.b.01')\",\n",
       " \"Synset('tahapoole.b.01')\",\n",
       " \"Synset('edasisuunas.b.01')\",\n",
       " \"Synset('tagasisuunas.b.01')\",\n",
       " \"Synset('ette-taha.b.01')\",\n",
       " \"Synset('edasi-tagasi.b.01')\",\n",
       " \"Synset('edasi-tagasi.b.02')\",\n",
       " \"Synset('ettepoole.b.02')\",\n",
       " \"Synset('edasi-tagasi.b.03')\",\n",
       " \"Synset('edasi.b.02')\",\n",
       " \"Synset('edasi.b.03')\",\n",
       " \"Synset('edasi.b.04')\",\n",
       " \"Synset('jätkuvalt.b.01')\",\n",
       " \"Synset('endistviisi.b.01')\",\n",
       " \"Synset('edasi.b.05')\",\n",
       " \"Synset('edasi.b.06')\",\n",
       " \"Synset('edasi.b.07')\",\n",
       " \"Synset('järsult.b.02')\",\n",
       " \"Synset('täielikult.b.03')\",\n",
       " \"Synset('järsult.b.04')\",\n",
       " \"Synset('laugelt.b.01')\",\n",
       " \"Synset('mahedasti.b.01')\",\n",
       " \"Synset('laugelt.b.02')\",\n",
       " \"Synset('sumedalt.b.01')\",\n",
       " \"Synset('kaheti.b.01')\",\n",
       " \"Synset('kaheti.b.02')\",\n",
       " \"Synset('muuseas.b.01')\",\n",
       " \"Synset('kahjuks.b.01')\",\n",
       " \"Synset('õnneks.b.01')\",\n",
       " \"Synset('hea.b.01')\",\n",
       " \"Synset('õnnetuseks.b.01')\",\n",
       " \"Synset('paraku.b.01')\",\n",
       " \"Synset('paraku.b.02')\",\n",
       " \"Synset('lohakil.b.01')\",\n",
       " \"Synset('laokil.b.01')\",\n",
       " \"Synset('hukas.b.01')\",\n",
       " \"Synset('räämas.b.01')\",\n",
       " \"Synset('lohakil.b.02')\",\n",
       " \"Synset('segamini.b.01')\",\n",
       " \"Synset('segamini.b.02')\",\n",
       " \"Synset('segamini.b.03')\",\n",
       " \"Synset('üha.b.02')\",\n",
       " \"Synset('kord-korralt.b.01')\",\n",
       " \"Synset('vist.b.01')\",\n",
       " \"Synset('ilmselt.b.01')\",\n",
       " \"Synset('nähtavasti.b.01')\",\n",
       " \"Synset('küllap.b.01')\",\n",
       " \"Synset('oletatavasti.b.01')\",\n",
       " \"Synset('ehk.b.01')\",\n",
       " \"Synset('küllap.b.02')\",\n",
       " \"Synset('usutavasti.b.01')\",\n",
       " \"Synset('silmnähtavalt.b.01')\",\n",
       " \"Synset('küllakil.b.01')\",\n",
       " \"Synset('küllakile.b.01')\",\n",
       " \"Synset('küllalt.b.01')\",\n",
       " \"Synset('küllalt.b.02')\",\n",
       " \"Synset('küllalt.b.03')\",\n",
       " \"Synset('külmalt.b.01')\",\n",
       " \"Synset('ükskõikselt.b.01')\",\n",
       " \"Synset('külmalt.b.02')\",\n",
       " \"Synset('asjalikult.b.01')\",\n",
       " \"Synset('ebamõistlikult.b.01')\",\n",
       " \"Synset('külmalt.b.03')\",\n",
       " \"Synset('külmalt.b.04')\",\n",
       " \"Synset('soojalt.b.01')\",\n",
       " \"Synset('südamlikult.b.01')\",\n",
       " \"Synset('osavõtlikult.b.01')\",\n",
       " \"Synset('kaastundlikult.b.01')\",\n",
       " \"Synset('heldelt.b.01')\",\n",
       " \"Synset('hoolimatult.b.01')\",\n",
       " \"Synset('jõhkralt.b.01')\",\n",
       " \"Synset('heldinult.b.01')\",\n",
       " \"Synset('härdalt.b.01')\",\n",
       " \"Synset('härgamisi.b.01')\",\n",
       " \"Synset('raskepäraselt.b.01')\",\n",
       " \"Synset('haledasti.b.01')\",\n",
       " \"Synset('haledasti.b.02')\",\n",
       " \"Synset('haledavõitu.b.01')\",\n",
       " \"Synset('rängalt.b.01')\",\n",
       " \"Synset('põhjalikult.b.01')\",\n",
       " \"Synset('põhjalikult.b.02')\",\n",
       " \"Synset('rängalt.b.02')\",\n",
       " \"Synset('kõvasti.b.03')\",\n",
       " \"Synset('kõvasti.b.04')\",\n",
       " \"Synset('vastupidavalt.b.01')\",\n",
       " \"Synset('püsivalt.b.02')\",\n",
       " \"Synset('energiliselt.b.01')\",\n",
       " \"Synset('kõvasti.b.05')\",\n",
       " \"Synset('järeleandmatult.b.01')\",\n",
       " \"Synset('visalt.b.01')\",\n",
       " \"Synset('visalt.b.02')\",\n",
       " \"Synset('visalt.b.03')\",\n",
       " \"Synset('aeglaselt.b.02')\",\n",
       " \"Synset('kõvasti.b.06')\",\n",
       " \"Synset('kõvasti.b.07')\",\n",
       " \"Synset('ohtralt.b.01')\",\n",
       " \"Synset('tõsiselt.b.01')\",\n",
       " \"Synset('eluohtlikult.b.01')\",\n",
       " \"Synset('rängalt.b.04')\",\n",
       " \"Synset('rusuvalt.b.01')\",\n",
       " \"Synset('rängalt.b.05')\",\n",
       " \"Synset('ränkraskelt.b.01')\",\n",
       " \"Synset('nõrgalt.b.01')\",\n",
       " \"Synset('tugevasti.b.03')\",\n",
       " \"Synset('nõrgalt.b.02')\",\n",
       " \"Synset('nõrgalt.b.03')\",\n",
       " \"Synset('nõudekohaselt.b.01')\",\n",
       " \"Synset('nõrgamõistuslikult.b.01')\",\n",
       " \"Synset('nässu.b.02')\",\n",
       " \"Synset('valesti.b.01')\",\n",
       " \"Synset('mokas.b.01')\",\n",
       " \"Synset('lörris.b.01')\",\n",
       " \"Synset('lörri.b.01')\",\n",
       " \"Synset('sassi.b.01')\",\n",
       " \"Synset('kortsu.b.01')\",\n",
       " \"Synset('kortsu.b.02')\",\n",
       " \"Synset('krussi.b.01')\",\n",
       " \"Synset('rulli.b.01')\",\n",
       " \"Synset('keerdu.b.01')\",\n",
       " \"Synset('lokki.b.01')\",\n",
       " \"Synset('keerdu.b.02')\",\n",
       " \"Synset('krussi.b.02')\",\n",
       " \"Synset('keerdu.b.03')\",\n",
       " \"Synset('siia-sinna.b.01')\",\n",
       " \"Synset('lonkshaaval.b.01')\",\n",
       " \"Synset('lonksti.b.01')\",\n",
       " \"Synset('lonksu.b.01')\",\n",
       " \"Synset('loiult.b.01')\",\n",
       " \"Synset('lõdvalt.b.01')\",\n",
       " \"Synset('lõdvalt.b.02')\",\n",
       " \"Synset('ette.b.02')\",\n",
       " \"Synset('külge.b.01')\",\n",
       " \"Synset('ette.b.03')\",\n",
       " \"Synset('ette.b.04')\",\n",
       " \"Synset('ette.b.06')\",\n",
       " \"Synset('tagantjärele.b.01')\",\n",
       " \"Synset('tagatipuks.b.01')\",\n",
       " \"Synset('ette.b.07')\",\n",
       " \"Synset('ette.b.09')\",\n",
       " \"Synset('ette.b.10')\",\n",
       " \"Synset('ette.b.11')\",\n",
       " \"Synset('ette.b.13')\",\n",
       " \"Synset('külge.b.02')\",\n",
       " \"Synset('külge.b.03')\",\n",
       " \"Synset('kinni.b.01')\",\n",
       " \"Synset('lahti.b.01')\",\n",
       " \"Synset('kinni.b.02')\",\n",
       " \"Synset('külge.b.04')\",\n",
       " \"Synset('juurde.b.02')\",\n",
       " \"Synset('külge.b.05')\",\n",
       " \"Synset('külge.b.06')\",\n",
       " \"Synset('ligi.b.02')\",\n",
       " \"Synset('külge.b.07')\",\n",
       " \"Synset('pihta.b.01')\",\n",
       " \"Synset('kinniselt.b.01')\",\n",
       " \"Synset('vastu.b.01')\",\n",
       " \"Synset('avatult.b.01')\",\n",
       " \"Synset('kinniselt.b.02')\",\n",
       " \"Synset('avatult.b.02')\",\n",
       " \"Synset('kinniselt.b.03')\",\n",
       " \"Synset('kinniselt.b.04')\",\n",
       " \"Synset('kinnisevõitu.b.01')\",\n",
       " \"Synset('kinni.b.03')\",\n",
       " \"Synset('kinni.b.04')\",\n",
       " \"Synset('umbe.b.01')\",\n",
       " \"Synset('kinni.b.05')\",\n",
       " \"Synset('kinni.b.06')\",\n",
       " \"Synset('kinni.b.07')\",\n",
       " \"Synset('kinni.b.08')\",\n",
       " \"Synset('kinni.b.09')\",\n",
       " \"Synset('kinni.b.10')\",\n",
       " \"Synset('nässi.b.01')\",\n",
       " \"Synset('kängu.b.01')\",\n",
       " \"Synset('käpuli.b.01')\",\n",
       " \"Synset('käpuli.b.02')\",\n",
       " \"Synset('ninali.b.01')\",\n",
       " \"Synset('näoli.b.01')\",\n",
       " \"Synset('suuli.b.01')\",\n",
       " \"Synset('käppapidi.b.01')\",\n",
       " \"Synset('käppapidi.b.02')\",\n",
       " \"Synset('ninapidi.b.01')\",\n",
       " \"Synset('ninapidi.b.02')\",\n",
       " \"Synset('koos.b.01')\",\n",
       " \"Synset('koos.b.02')\",\n",
       " \"Synset('koos.b.03')\",\n",
       " \"Synset('koos.b.04')\",\n",
       " \"Synset('koos.b.05')\",\n",
       " \"Synset('kobaras.b.01')\",\n",
       " \"Synset('koos.b.06')\",\n",
       " \"Synset('kooris.b.01')\",\n",
       " \"Synset('läbisegi.b.01')\",\n",
       " \"Synset('läbisegi.b.02')\",\n",
       " \"Synset('ühtlasi.b.01')\",\n",
       " \"Synset('üksiti.b.01')\",\n",
       " \"Synset('samaaegselt.b.02')\",\n",
       " \"Synset('kõrvuti.b.01')\",\n",
       " \"Synset('rööbiti.b.01')\",\n",
       " \"Synset('samas.b.03')\",\n",
       " \"Synset('sealsamas.b.01')\",\n",
       " \"Synset('siinsamas.b.01')\",\n",
       " \"Synset('sealsamas.b.02')\",\n",
       " \"Synset('sealkandis.b.01')\",\n",
       " \"Synset('seal.b.03')\",\n",
       " \"Synset('seal.b.04')\",\n",
       " \"Synset('siis.b.03')\",\n",
       " \"Synset('sealhulgas.b.01')\",\n",
       " \"Synset('kusjuures.b.01')\",\n",
       " \"Synset('niikaugel.b.01')\",\n",
       " \"Synset('ausalt.b.01')\",\n",
       " \"Synset('kuskil.b.01')\",\n",
       " \"Synset('kuskil.b.02')\",\n",
       " \"Synset('kuhugi.b.01')\",\n",
       " \"Synset('kuskil.b.03')\",\n",
       " \"Synset('umbes.b.01')\",\n",
       " \"Synset('kus.b.01')\",\n",
       " \"Synset('kusmaal.b.01')\",\n",
       " \"Synset('kuspool.b.01')\",\n",
       " \"Synset('kõikjal.b.01')\",\n",
       " \"Synset('kus.b.02')\",\n",
       " \"Synset('kus.b.03')\",\n",
       " \"Synset('kus.b.04')\",\n",
       " \"Synset('kus.b.05')\",\n",
       " \"Synset('niikaua.b.01')\",\n",
       " \"Synset('laiali.b.01')\",\n",
       " \"Synset('laiali.b.02')\",\n",
       " \"Synset('lahti.b.02')\",\n",
       " \"Synset('lahti.b.03')\",\n",
       " \"Synset('avakil.b.01')\",\n",
       " \"Synset('laiali.b.03')\",\n",
       " \"Synset('laiali.b.04')\",\n",
       " \"Synset('avalikult.b.01')\",\n",
       " \"Synset('varjamatult.b.01')\",\n",
       " \"Synset('avalikult.b.02')\",\n",
       " \"Synset('kõrvuti.b.02')\",\n",
       " \"Synset('rinnu.b.01')\",\n",
       " \"Synset('küljekuti.b.01')\",\n",
       " \"Synset('külgepidi.b.01')\",\n",
       " \"Synset('külitsi.b.03')\",\n",
       " \"Synset('samamoodi.b.02')\",\n",
       " \"Synset('ühesuguselt.b.01')\",\n",
       " \"Synset('võrdselt.b.01')\",\n",
       " \"Synset('võrdselt.b.02')\",\n",
       " \"Synset('viigiliselt.b.01')\",\n",
       " \"Synset('praokil.b.01')\",\n",
       " \"Synset('kissis.b.01')\",\n",
       " \"Synset('irvakil.b.01')\",\n",
       " \"Synset('irvisui.b.01')\",\n",
       " \"Synset('irvitamisi.b.01')\",\n",
       " \"Synset('laialdaselt.b.01')\",\n",
       " \"Synset('ulatuslikult.b.01')\",\n",
       " \"Synset('rikkalt.b.01')\",\n",
       " \"Synset('laialt.b.03')\",\n",
       " \"Synset('priskelt.b.01')\",\n",
       " \"Synset('lahedalt.b.01')\",\n",
       " \"Synset('külluslikult.b.01')\",\n",
       " \"Synset('külluslikult.b.02')\",\n",
       " \"Synset('pillavalt.b.01')\",\n",
       " \"Synset('uhkesti.b.01')\",\n",
       " \"Synset('ekstravagantselt.b.01')\",\n",
       " \"Synset('kuninglikult.b.01')\",\n",
       " \"Synset('imestunult.b.01')\",\n",
       " \"Synset('imestusväärselt.b.01')\",\n",
       " \"Synset('imetoredasti.b.01')\",\n",
       " \"Synset('toredasti.b.01')\",\n",
       " \"Synset('toredasti.b.02')\",\n",
       " \"Synset('luksuslikult.b.01')\",\n",
       " \"Synset('šikilt.b.01')\",\n",
       " \"Synset('vahvasti.b.01')\",\n",
       " \"Synset('fantastiliselt.b.01')\",\n",
       " \"Synset('suurepäraselt.b.01')\",\n",
       " \"Synset('klassikaliselt.b.01')\",\n",
       " \"Synset('kaugele.b.01')\",\n",
       " \"Synset('kaugele.b.02')\",\n",
       " \"Synset('kaugele.b.03')\",\n",
       " \"Synset('jantlikult.b.01')\",\n",
       " \"Synset('naeruväärselt.b.01')\",\n",
       " \"Synset('kentsakalt.b.01')\",\n",
       " \"Synset('maitsekalt.b.01')\",\n",
       " \"Synset('nooblilt.b.01')\",\n",
       " \"Synset('peenelt.b.01')\",\n",
       " \"Synset('suursuguselt.b.01')\",\n",
       " \"Synset('majesteetselt.b.01')\",\n",
       " \"Synset('väärikalt.b.01')\",\n",
       " \"Synset('väljapeetult.b.01')\",\n",
       " \"Synset('peenelt.b.02')\",\n",
       " \"Synset('peenelt.b.03')\",\n",
       " \"Synset('hästi.b.03')\",\n",
       " \"Synset('detailselt.b.01')\",\n",
       " \"Synset('pulk-pulgalt.b.01')\",\n",
       " \"Synset('oskuslikult.b.01')\",\n",
       " \"Synset('lõnghaaval.b.01')\",\n",
       " \"Synset('igakülgselt.b.01')\",\n",
       " \"Synset('sügavuti.b.01')\",\n",
       " \"Synset('meisterlikult.b.01')\",\n",
       " \"Synset('oskuslikult.b.02')\",\n",
       " \"Synset('kavalalt.b.01')\",\n",
       " \"Synset('peenelt.b.04')\",\n",
       " \"Synset('velpalt.b.01')\",\n",
       " \"Synset('leidlikult.b.01')\",\n",
       " \"Synset('nupukalt.b.01')\",\n",
       " \"Synset('peenutsevalt.b.01')\",\n",
       " \"Synset('sügavuti.b.02')\",\n",
       " \"Synset('südikalt.b.01')\",\n",
       " \"Synset('apaatselt.b.01')\",\n",
       " \"Synset('tragilt.b.01')\",\n",
       " \"Synset('ettevõtlikult.b.01')\",\n",
       " \"Synset('toimekalt.b.01')\",\n",
       " \"Synset('krapsakalt.b.01')\",\n",
       " \"Synset('krapsti.b.01')\",\n",
       " \"Synset('sügaval.b.01')\",\n",
       " \"Synset('sügavalt.b.04')\",\n",
       " \"Synset('ohtlikult.b.01')\",\n",
       " \"Synset('tõsiselt.b.02')\",\n",
       " \"Synset('tõsiselt.b.03')\",\n",
       " \"Synset('otsas.b.01')\",\n",
       " \"Synset('otsas.b.02')\",\n",
       " \"Synset('peal.b.01')\",\n",
       " \"Synset('otsast.b.01')\",\n",
       " \"Synset('pealt.b.01')\",\n",
       " \"Synset('otsast.b.02')\",\n",
       " \"Synset('otsakuti.b.01')\",\n",
       " \"Synset('otsakuti.b.02')\",\n",
       " \"Synset('otsakuti.b.03')\",\n",
       " \"Synset('otsatult.b.01')\",\n",
       " \"Synset('pealt.b.02')\",\n",
       " ...]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wn.all_synsets(pos=wn.ADV)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "which returns all the synset of which part of speech is \"adverb\". We can\n",
    "also query synsets by providing a lemma and a part of speech using:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"Synset('koer.n.01')\", \"Synset('kaak.n.01')\"]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wn.synsets(\"koer\",pos=wn.VERB)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By neglecting \"pos\", it matches once again all the synsets with \"koer\"\n",
    "as lemma:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"Synset('koer.n.01')\", \"Synset('kaak.n.01')\"]"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wn.synsets(\"koer\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The API allows to query synset's details. For example, we can retrieve\n",
    "name and pos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'king.n.01'"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "synset = wn.synset(\"king.n.01\")\n",
    "synset.name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also query definition and examples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'jalalaba kattev kontsaga jalats, mis ei ulatu pahkluust kõrgemale'"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "synset.definition()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Jalad hakkasid katkistes kingades külmetama.']"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "synset.examples()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Relations\n",
    "\n",
    "We can also query related synsets. There are relations, for which there\n",
    "are specific methods:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"Synset('jalats.n.01')\"]"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "synset.hypernyms()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"Synset('peoking.n.01')\",\n",
       " \"Synset('rihmking.n.01')\",\n",
       " \"Synset('lapseking.n.01')\"]"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "synset.hyponyms()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "synset.meronyms()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "synset.holonyms()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "More specific relations can be queried with a universal method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"Synset('jäätisemüüja.n.01')\",\n",
       " \"Synset('jäätisekauplus.n.01')\",\n",
       " \"Synset('jäätisekampaania.n.01')\",\n",
       " \"Synset('jäätisekohvik.n.01')\"]"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "synset = wn.synset('jäätis.n.01')\n",
    "synset.get_related_synsets('fuzzynym')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Similarities\n",
    "\n",
    "We can measure distance or similarity between two synsets in several\n",
    "ways. For calculating similarity, we provide path, Leacock-Chodorow and\n",
    "Wu-Palmer similarities:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "synset = wn.synset('jalats.n.01')\n",
    "target_synset = wn.synset('kinnas.n.01')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3333333333333333"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "synset.path_similarity(target_synset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.159484249353372"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "synset.lch_similarity(target_synset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8571428571428571"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "synset.wup_similarity(target_synset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In addition, we can also find the closest common ancestor via hypernyms:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"Synset('kehakate.n.01')\"]"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "synset.lowest_common_hypernyms(target_synset)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
